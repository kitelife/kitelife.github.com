<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>BitPacking</title>
        <description>精进，求诸己身</description>
        <link>https://blog.xiayf.cn/</link>
        <atom:link href="https://blog.xiayf.cn/rss.xml" rel="self" type="application/rss+xml"/>
        <pubDate>2025-07-29T02:21:17.92976+08:00</pubDate>
        <lastBuildDate>2025-07-29T02:21:17.92976+08:00</lastBuildDate>
        <generator>LingDong</generator>
        
        <item>
            <title>译文：数据系统中一致性究竟是什么意思？</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文： &lt;a href=&apos;https://risingwave.com/blog/what-consistency-really-means-in-data-systems/&apos;&gt;What Consistency Really Means in Data Systems?&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;致谢：本译文基于 &lt;a href=&apos;https://chromewebstore.google.com/detail/immersive-translate-trans/bpoadfkcbjbfhfodiogcnhhhpibjhbnh&apos;&gt;沉浸式翻译 chrome 插件&lt;/a&gt; 的翻译结果，人工调整润色而成。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从事流处理系统开发工作的过去几年里，别人经常对我提出这样一个问题 - “你的系统可以实现强一致性（consistency）吗？”。我常常想自信地推介我们的产品，但现实是，这个问题回答起来其实挺复杂的。要想把这个问题讲清楚，挑战不在于问题本身，而在于“一致性”对不同的人来说意味着不同的东西，取决于他们的技术背景。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;事实上，问这个问题的很多人，技术背景都不同，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据库&lt;/li&gt;
&lt;li&gt;分布式系统&lt;/li&gt;
&lt;li&gt;流式系统（streaming system）&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些技术背景的人对一致性都有各自不同的理解。没有理解他们问这个问题的上下文背景，就贸然回答，容易导致误解。本文中，我将解释清楚在这些不同数据系统中一致性究竟是什么意思。&lt;/p&gt;
&lt;h2&gt;数据库中的一致性&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在传统数据库中，ACID 性质（原子性/Atomicity、一致性/Consistency、隔离型/Isolation、持久性/Durability） 的核心之一就是一致性。这一性质保证了每个事务都将数据库从一个有效状态转换到弄一个有效状态。例如：在一次银行交易中，一个账户扣款另一个账户收款，一致性确保总余额保持不变。千万不要将一致性和原子性混淆了，原子性是指交易/事务要么全有要么全无（all-or-nothing）的性质。例如：原子性确保一个事务中的所有操作要么全部成功完成，要么全部不执行，数据库中不会留下部分事务的效果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;总之，数据库中的一致性强调的是事务过程中保持数据正确性和有效性（validity）的规则。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/snze3I1iDwybl5h.png&apos; title=&apos;consistency-bank-transaction.png&apos; alt=&apos;consistency-bank-transaction.png&apos; width=&apos;600&apos;/&gt;
&lt;h2&gt;分布式系统中的一致性&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于分布式系统的讨论经常涉及一个基础概念 - 著名 &lt;a href=&apos;https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86&apos;&gt;CAP 定理&lt;/a&gt; 中的一致性。该定理最初由加州大学伯克利分校的研究人员提出，已成为分布式系统相关大学课程和专业对话中的基本话题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在 CAP 定理中，“一致性”特指跨不同节点分布的多个副本之间数据的统一性（uniformity）。在分布式系统中确保这种一致性特别有挑战。该定理强调了三个关键属性的重要权衡：一致性、可用性（availability）和分区容错性（partition tolerance）。根据 CAP 定理，一个分布式系统同时只能实现这三个属性中的两个。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在这个上下文语境下，一致性确保在任何给定时间点不同节点上的数据副本体现的信息相同。这对于维护数据完整性至关重要，尤其在涉及网络故障或延迟的场景中。该定理揭示了在多个节点间保持数据同步的固有困难，突出了在设计和维护可靠的分布式系统时平衡这三种相互竞争需求所面临的持续挑战。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/q3kitoETbShzwI9.png&apos; title=&apos;consistency-data-sync-multi-node.png&apos; alt=&apos;consistency-data-sync-multi-node.png&apos; width=&apos;600&apos;/&gt;
&lt;h2&gt;流式系统中的一致性&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在讨论流式系统时，关于一致性的讨论通常与数据库或分布式系统的一致性不同，这反映了流式系统中独特的需求和挑战。&lt;a href=&apos;https://www.confluent.io/blog/rethinking-distributed-stream-processing-in-kafka/&apos;&gt;一致性和完整性：重新思考 Apache Kafka 中的分布式流处理&lt;/a&gt;一文中，作者认为“精确一次”语义概念是流式系统中一致性的关键特征。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在流式系统中，保持一致性，并非和数据复制相关，而是强调确保每条事件数据仅被处理一次，不多不少，即使在发生系统故障时也是如此。例如，考虑实时处理一次金融交易的情况。如果系统在处理过程中崩溃，那么在系统恢复后，必须确保该交易不会被重复处理。这种精确处理一次的要求对于保持流式数据的完整性和一致性至关重要 - 确保每笔交易都仅被精确处理一次，无论系统是否发生中断。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/L4aKt7XFdk6DSxm.png&apos; title=&apos;consistency-mathias-verraes.png&apos; alt=&apos;consistency-mathias-verraes.png&apos; width=&apos;600&apos;/&gt;
&lt;h2&gt;人们真正想要的是什么？&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下表格突出对比了不同系统对一致性要求的差异：&lt;/p&gt;
&lt;table class=&quot;table table-bordered&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th style=&quot;text-align: left&quot;&gt;系统类型&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;一致性需求&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;示例&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;数据库&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;事务完整性&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;银行交易应始终保持账户平衡&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;分布式系统&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;节点间数据一致性&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;社交媒体上的个人资料更新必须处处一致&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;流式系统&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;次序和处理语义保障&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;每笔金融交易仅被实时处理一次&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在实际应用中，用户和企业真正追求的是可靠性和数据完整性，这超越了标准教科书对一致性的定义。他们期望系统不仅稳健可靠，而且能够有效管控现实世界的复杂性。于用户而言，衡量系统是否成功的终极标准是其能够始终正确地提供结果，不会出错。必须认识到：要达到这种程序的一致性，系统不能仅仅“感觉上”是正确的，必须具备理论上的严谨性和功能上的可靠性（being theoretically sound and functionally reliable）。&lt;/p&gt;
&lt;h2&gt;分布式流数据库中的一致性&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;好的，我们来深入探讨一个更有趣的话题：分布式流数据库中的数据一致性。如果你不了解流数据库是什么，&lt;a href=&apos;https://ksqldb.io/&apos;&gt;KsqlDB&lt;/a&gt; 和 &lt;a href=&apos;https://github.com/pipelinedb/pipelinedb&apos;&gt;PipelineDB&lt;/a&gt; 就是此类系统。本质上，流数据库是为流处理量身定制的。感兴趣的读者可以参考我&lt;a href=&apos;https://risingwave9.wpcomstaging.com/blog/streaming-databases-everything-you-wanted-to-know/&apos;&gt;之前写的文章&lt;/a&gt;了解更多细节。在 RisingWave，我们开发了一个分布式流数据库，旨在降低流处理的成本和复杂性。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;分布式流数据库是数据库、分布式系统和流系统的结合。那么，它的一致性是什么样的呢？理想情况下，流数据库可以在所有场景下实现一致性，不过这当然也取决于具体系统的实现。在这里我也无法概述所有分布式流数据库的一致性模型，不过可以仅聚焦于 RisingWave： RisingWave 中的一致性看起来是什么样的？我们从三个维度来探讨这个问题。&lt;/p&gt;
&lt;h3&gt;数据库上下文中的“一致性”&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RisingWave 提供这种一致性。RisingWave 有效地确保其内部状态能够无缝地从一种有效状态转换到另一种有效状态。然而，需要注意，RisingWave 支持只读事务，不过并不支持跨不同表的读写事务。因此，如果有人需要一个 OLTP 数据库来管理复杂的事务型工作负载，可能选择 &lt;a href=&apos;https://www.mysql.com/&apos;&gt;MySQL&lt;/a&gt;、&lt;a href=&apos;https://www.postgresql.org/&apos;&gt;Postgres&lt;/a&gt;、&lt;a href=&apos;https://www.cockroachlabs.com/&apos;&gt;CockroachDB&lt;/a&gt; 或 &lt;a href=&apos;https://www.pingcap.com/&apos;&gt;TiDB&lt;/a&gt; 这些方案更为合适。RisingWave 的这一设计决策主要是考虑到两个因素：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;专注于流数据&lt;/strong&gt;：RisingWave 专为优化流数据处理而设计。引入完整的事务能力会显著增大系统的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;与传统 OLTP 数据库集成&lt;/strong&gt;：通常情况下，传统 OLTP 数据库负责处理上游的事务序列化。RisingWave，作为一个下游系统，专注于实时分析。深度集成事务处理会导致显著的性能下降，尤其是在现实操作的苛刻条件下。&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/NUuJqaDg3dnmIy7.png&apos; title=&apos;consistency-in-database-context.png&apos; alt=&apos;consistency-in-database-context.png&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此外，RisingWave 被设计用于理解和处理来自上游 OLTP 数据库的事务语义，这对金融等行业（sectors）的客户来说是一个关键特性。&lt;/p&gt;
&lt;h3&gt;分布式系统上下文中的“一致性”&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RisingWave 提供这种一致性。RisingWave 可以实现跨多个区域的高可用性。RisingWave 没有通过 Paxos 或 Raft 等复杂的共识协议来确保副本间的一致性，而是借助 S3 进行数据存储。S3 不仅存储数据库表，还存储流处理的内部状态，有效地在多个副本间复制数据以保持一致性。&lt;/p&gt;
&lt;h3&gt;流式系统上下文中的“一致性”&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RisingWave 提供这种一致性。RisingWave 能够确保精确一次语义，也能轻巧地管理乱序数据处理。这种能力保证了每个数据事件被精确处理一次，无论数据流是否存在中断或干扰，从而在流数据中保持高度一致性。&lt;/p&gt;
&lt;h3&gt;总结&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;所谓数据系统的一致性，在数据库、分布式系统和流式系统之间涵义差别很大：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据库关注事务完整性。&lt;/li&gt;
&lt;li&gt;分布式系统强调复制节点之间如何访存数据（how data is accessed across replicated nodes）。&lt;/li&gt;
&lt;li&gt;流式系统优先考虑消息处理语义保证，比如精确一次语义。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RisingWave 作为一个健壮、可适应的分布式流数据库，有效地满足这些多样化的需求。我们的设计实现方式不仅遵循理论的一致性标准，在实际应用中也表现出色。对于数据一致性需求变化多样的领域（in the evolving landscape of data consistency），RisingWave 是一个可靠的解决方案。&lt;/p&gt;</description>
            <pubDate>2025-06-22</pubDate>
            <link>https://blog.xiayf.cn/posts/consistency-in-data-systems.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/consistency-in-data-systems.html</guid>
        </item>
        
        <item>
            <title>absl::Hash 的一个误用</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;近期在写 &lt;a href=&apos;https://github.com/kitelife/lingdong&apos;&gt;LingDong&lt;/a&gt; 的 &lt;a href=&apos;https://github.com/kitelife/lingdong/blob/7077f1def3790d1ab3f1c9a7f5809c71c98c2ddc/src/plugin/plantuml.hpp#L191&apos;&gt;PlantUML&lt;/a&gt; 插件时，一开始使用了 &lt;code&gt;absl::Hash&lt;/code&gt; 来计算 PlantUML 输出的 svg 图内容的哈希值，作为输出文件名。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;auto hash_value = absl::Hash&amp;amp;lt;std::string&amp;amp;gt;{}(absl::StrJoin(codeblock-&amp;amp;gt;lines, &amp;amp;quot;\n&amp;amp;quot;));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发现：即使文章中 plantuml 原始绘图代码没有变更，每次构建，都会产出新的 svg 文件（文件名是文件内容的哈希值，从文件名看都是新文件）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一开始猜测 PlantUML 生成的 svg 图内容中暗含了什么生成时间点之类的字符串。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;经单测分析：对于相同的原始字符串，一次单测运行中两次生成的哈希值是相同的，不同次单测运行中生成的哈希值不同。那么基本可以确定问题原因是 &lt;code&gt;absl::Hash&lt;/code&gt; 哈希依赖于某个不确定的种子。分析源码会发现：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;absl::Hash&amp;amp;lt;std::string&amp;amp;gt;{}(...)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;会间接调用 &lt;code&gt;MixingHashState::hash&lt;/code&gt;，其实现为：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;template &amp;amp;lt;typename T, absl::enable_if_t&amp;amp;lt;!IntegralFastPath&amp;amp;lt;T&amp;amp;gt;::value, int&amp;amp;gt; = 0&amp;amp;gt;
static size_t hash(const T&amp;amp;amp; value) {
  return static_cast&amp;amp;lt;size_t&amp;amp;gt;(combine(MixingHashState{}, value).state_);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中 &lt;code&gt;MixingHashState{}&lt;/code&gt; 调用私有的无参构造函数进行实例化：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;MixingHashState() : state_(Seed()) {}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;state_&lt;/code&gt; 成员变量 和 &lt;code&gt;Seed()&lt;/code&gt; 成员函数的定义如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;  // Seed()
  //
  // A non-deterministic seed.
  //
  // The current purpose of this seed is to generate non-deterministic results
  // and prevent having users depend on the particular hash values.
  // It is not meant as a security feature right now, but it leaves the door
  // open to upgrade it to a true per-process random seed. A true random seed
  // costs more and we don&amp;amp;apos;t need to pay for that right now.
  //
  // On platforms with ASLR, we take advantage of it to make a per-process
  // random value.
  // See https://en.wikipedia.org/wiki/Address_space_layout_randomization
  //
  // On other platforms this is still going to be non-deterministic but most
  // probably per-build and not per-process.
  ABSL_ATTRIBUTE_ALWAYS_INLINE static uint64_t Seed() {
#if (!defined(__clang__) || __clang_major__ &amp;amp;gt; 11) &amp;amp;amp;&amp;amp;amp; \
    (!defined(__apple_build_version__) ||            \
     __apple_build_version__ &amp;amp;gt;= 19558921)  // Xcode 12
    return static_cast&amp;amp;lt;uint64_t&amp;amp;gt;(reinterpret_cast&amp;amp;lt;uintptr_t&amp;amp;gt;(&amp;amp;amp;kSeed));
#else
    // Workaround the absence of
    // https://github.com/llvm/llvm-project/commit/bc15bf66dcca76cc06fe71fca35b74dc4d521021.
    return static_cast&amp;amp;lt;uint64_t&amp;amp;gt;(reinterpret_cast&amp;amp;lt;uintptr_t&amp;amp;gt;(kSeed));
#endif
  }
  static const void* const kSeed;

  uint64_t state_;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;而 &lt;code&gt;kSeed&lt;/code&gt; 静态成员变量的初始化逻辑为 - 存储自身的地址：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;ABSL_CONST_INIT const void* const MixingHashState::kSeed = &amp;amp;amp;kSeed;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;C++ 程序中，&lt;strong&gt;静态变量的地址在编译期可知（链接时确定），静态变量在程序启动时初始化（早于 main 执行）&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于安全考虑，现代操作系统都会使用“&lt;a href=&apos;https://en.wikipedia.org/wiki/Address_space_layout_randomization&apos;&gt;地址空间配置随机加载（ASLR）&lt;/a&gt;” 这一机制，导致：&lt;strong&gt;同一程序中的同一静态变量，不同次运行或者在不同进程中，内存地址不同&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;absl::Hash&lt;/code&gt; 基于这一机制来生成哈希的不确定种子值。&lt;a href=&apos;https://abseil.io/docs/cpp/guides/hash#abslhash&apos;&gt;Abseil 官方指南&lt;/a&gt;中其实也有一处不太显眼的说明：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;NOTE: the hash codes computed by absl::Hash are not guaranteed to be stable across different runs of your program, or across different dynamically loaded libraries in your program.&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这也就意味着：基于 &lt;code&gt;absl::Hash&lt;/code&gt; 生成的哈希值以及 Abseil 中依赖哈希逻辑的容器不能持久化以后续使用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Abseil 库中似乎也未提供方法以绕过这一机制。只好改成使用 C++ 标准库中的 &lt;code&gt;std::hash&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;auto hash_value = std::hash&amp;amp;lt;std::string&amp;amp;gt;{}(absl::StrJoin(codeblock-&amp;amp;gt;lines, &amp;amp;quot;\n&amp;amp;quot;));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;std::hash&lt;/code&gt; 生成的哈希值是确定性的，其实现基于 &lt;a href=&apos;https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2&apos;&gt;MurmurHash2&lt;/a&gt; 和 &lt;a href=&apos;https://github.com/google/cityhash&apos;&gt;CityHash&lt;/a&gt; 哈希算法。&lt;/p&gt;</description>
            <pubDate>2025-06-15</pubDate>
            <link>https://blog.xiayf.cn/posts/absl-hash-misuse.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/absl-hash-misuse.html</guid>
        </item>
        
        <item>
            <title>译文：小心 fast-math</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://simonbyrne.github.io/notes/fastmath&apos;&gt;Beware of fast-math&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;一、fast-math 是什么？&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;fast-math 是一个编译器标志（flag），或者许多编程语言和编译器中存在的一个配置项，包括如下这些：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html&apos;&gt;GCC&lt;/a&gt; 和 &lt;a href=&apos;https://clang.llvm.org/docs/UsersManual.html#cmdoption-ffast-math&apos;&gt;Clang&lt;/a&gt; 中的 &lt;code&gt;-ffast-math&lt;/code&gt;（&lt;code&gt;-Ofast&lt;/code&gt; 也会包含这个编译标志）&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/compiler-options/compiler-option-details/floating-point-options/fp-model-fp.html&apos;&gt;ICC&lt;/a&gt; 中的 &lt;code&gt;-fp-model=fast&lt;/code&gt;（默认行为）&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://docs.microsoft.com/en-us/cpp/build/reference/fp-specify-floating-point-behavior?view=msvc-170&apos;&gt;MSVC&lt;/a&gt; 中的 &lt;code&gt;/fp:fast&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Julia 中的 &lt;code&gt;--math-mode=false&lt;/code&gt; &lt;a href=&apos;https://docs.julialang.org/en/v1/manual/command-line-options/#command-line-options&apos;&gt;命令行配置项&lt;/a&gt; 或 &lt;code&gt;@fastmath&lt;/code&gt; &lt;a href=&apos;https://docs.julialang.org/en/v1/base/math/#Base.FastMath.@fastmath&apos;&gt;宏&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那它实际会干啥呢？名副其实，让数学计算更快。听起来很棒，我们当然应该这样做！&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;我的意思是：fast-math 的核心是牺牲某些情况下的正确性，换取速度。如果 fast-math 任何情况下都能给出正确的结果，那它就不是 fast-math 了，而是数学计算的标准方式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;-- &lt;a href=&apos;https://discourse.julialang.org/t/whats-going-on-with-exp-and-math-mode-fast/64619/7?u=simonbyrne&apos;&gt;Mosè Giordano&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/IEEE_754&apos;&gt;IEEE 754标准&lt;/a&gt; 规定了浮点运算的规则，所有流行的编程语言基本都遵从该标准。编译器默认仅被允许执行遵从这些规则的优化手段。fast-math 允许编译器打破其中一些规则，这些突破常规的做法初看似乎无害，不过某些情况下可能会产生一些重大的下游效应&lt;sup id=&quot;fnref:译注1&quot;&gt;&lt;a href=&quot;#fn:译注1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[译注1]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html&apos;&gt;GCC&lt;/a&gt; 中，&lt;code&gt;-ffast-math&lt;/code&gt;（或 &lt;code&gt;-Ofast&lt;/code&gt;） 会启用以下编译选项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;-fno-math-errno&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-funsafe-math-optimizations&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ffinite-math-only&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-fno-rounding-math&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-fno-signaling-nans&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-fcx-limited-range&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;以及 &lt;code&gt;-fexcess-precision=fast&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：&lt;code&gt;-funsafe-math-optimizations&lt;/code&gt; 本身又包含一组编译选项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;-fno-signed-zeros&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-fno-trapping-math&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-fassociative-math&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;以及 &lt;code&gt;-freciprocal-math&lt;/code&gt; 等等&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中一些编译选项大多数情况下都不太可能会造成什么问题：&lt;code&gt;-fno-math-errno&lt;/code&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;、&lt;code&gt;-fno-signaling-nans&lt;/code&gt;、&lt;code&gt;-fno-trapping-math&lt;/code&gt; 会禁用很少使用（且支持不佳）的特性。其他一些，比如 &lt;code&gt;-freciprocal-math&lt;/code&gt; 可能会略微降低精度，但在大多数情况下不太可能会造成什么问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://kristerw.github.io/2021/10/19/fast-math/&apos;&gt;Krister Walfridsson&lt;/a&gt; 对其中部分编译选项做了非常棒（也更客观一点）的解释，不过我想重点关注一下其中的三个。&lt;/p&gt;
&lt;h2&gt;二、&lt;code&gt;-ffinite-math-only&lt;/code&gt;&lt;/h2&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;基于参数和结果不会是 NaN 或正负 Inf 的假设，对浮点运算做优化。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其意图是允许编译器执行一些&lt;a href=&apos;https://stackoverflow.com/a/10145714/392585&apos;&gt;额外的优化&lt;/a&gt;，不过如果存在 NaN 或 Inf 值，则优化后的运行结果会不正确，例如：&lt;code&gt;x == x&lt;/code&gt; 条件判断会被假设始终为真（实际上如果 &lt;code&gt;x&lt;/code&gt; 是一个 NaN 值，则这个条件判断结果应该为假）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这听起来真不错！我的代码不会产生任何 NaN 或 Inf 值，所以这个优化应该不会造成任何问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是，如果你的代码之所以不会产生任何 NaN 中间结果，是因为代码内部调用了 &lt;code&gt;isnan&lt;/code&gt; 来确保正确地处理了 NaN 值，那又会怎么样呢？&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://gcc.godbolt.org/e#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1AB9U8lJL6yAngGVG6AMKpaAVxYMQAJlIOAMngMmABy7gBGmMQg0gAOqAqEtgzObh7epHEJNgIBQaEsEVHSlpjWSUIETMQEKe6ePiVlAhVVBLkh4ZHRFpXVtWkNvW2BHQVdkgCUFqiuxMjsHACkXgDMgchuWADUiyuOLEwECAB0CLvYixoAgoEEW/yo1LSoh/cTOwDsAEKXV1v/W2ImAIswYWzwCmYDGoE12P2uiw%2BABEOFNaJwAKy8TwcLSkVCcRxbBQzOaYHarHikAiaVFTADW0Q%2Bxw%2BAE4AByrdkY1kadkfLwffScSS8FgSDQaUg4vEEji8BQgKU03Go0hwWAwRAoVAsGJ0SLkShoPUGqLIYBcLg%2BGi0AiRRUQMK00hhQJVACenCpJrYggA8gxaF7VaQsAcjOJQ/ggWUAG6YRWhzCqUque3e3i3TDo0O0PBhYie5xYF0EYh4cXcNVUAzABQANTwmAA7v6YoxMzJBCIxOwpN35Eo1C7dFx9IYTGZ9AXFZApqgYtkGEmALRUKhMBQEVcHI5bVf%2BlYKnOlZf2BhOFx1CQ%2BfwjfKFEArDLxRICfqea2vrJJdqProX0aZcWj6a80m/YDyiGf9OiiIChk/W8elaWCxngqYSVmeY9HLTAFh4NFMWxF05VUdkADZVwoyQtmAZBkC2K1ji8LYIEcUgtlwQgSApFZxy2ZxTXoYg%2BK4CZeBVLQJimBBMCYLAoggBkQAxKVc1FUhxTU6VSM4BUlWpWkpg1bUTX1ESjQgcyzRQDZJy4FZJT4Oh7WIR1nVDN1mGIEMfV1P0CEDYMXXDScozxGMzzwBMkzxFM0wzatyEEHMXXzQtiwwBY8XLStMymWsmHrJtW3bTtkv4HtRHEAcqqHFR1FDXQfAMIwQFMYxzAyudlPxJckjXDctx3PcEAPI8Tysc8IAcJDx3vPI4L0TJ32ScCvx/Na0KfccoOaRCNr0faGFA4YlvQ47DtSTbt1Qh9lvE6ZsP7akgQItVcyxXTQzIyjqNo%2ByjCYlZjg0MG2I4rj8CIUTln4zihIsyI%2BK8CSjNVGTSDkhSuj6jSxVUqUZV4OUDOVYyVIxLwWI0LgPgoqQNFZa0PhfXNjx%2B2V9Ix6SiI4LwSN%2BnmpLpUgE3cpJoiAA%3D&quot;&gt;&lt;/iframe&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;基于 &lt;a href=&apos;https://twitter.com/johnregehr/status/1440024236257542147&apos;&gt;John Regehr 写的一个示例&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;解释一下这段代码：这个函数将返回寄存器 &lt;code&gt;eax&lt;/code&gt; 与自己做 xor 异或操作，从而将返回寄存器设置为 0，这意味着函数将始终返回 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;没错，你的编译器这时移除了所有那些检查操作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个做法看起来可能是显然的（“你告诉编译器不会存在 NaN 值，那为什么它还要做检测？”），也可能是荒谬的（“如果都不做检测，那又怎么能安全地把 NaN 值优化掉呢？”），对错与否，取决于你问谁，即使是编译器开发者也&lt;a href=&apos;https://twitter.com/johnregehr/status/1440021297103134720&apos;&gt;无法达成一致意见&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这也许是 fast-math 相关 &lt;a href=&apos;https://stackoverflow.com/q/7263404/392585&apos;&gt;StackOverflow 问题&lt;/a&gt;和 &lt;a href=&apos;https://github.com/numba/numba/issues/2919&apos;&gt;GitHub&lt;/a&gt; &lt;a href=&apos;https://github.com/google/jax/issues/276&apos;&gt;bug&lt;/a&gt; &lt;a href=&apos;https://github.com/pytorch/glow/issues/2073&apos;&gt;报告&lt;/a&gt;中最常见的原因。因此，如果你的代码经过 fast-math 编译优化后给出了错误结果，那么第一反应应该是关掉这个编译选项（&lt;code&gt;-fno-finite-math-only&lt;/code&gt;）。&lt;/p&gt;
&lt;h2&gt;三、&lt;code&gt;-fassociative-math&lt;/code&gt;&lt;/h2&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;允许在浮点运算序列中重新结合操作数。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个编译选项允许编译器改变浮点运算序列中的求值顺序。例如，如果有一个表达式 &lt;code&gt;(a+b)+c&lt;/code&gt;，编译器可以将其调整为求值 &lt;code&gt;a+(b+c)&lt;/code&gt;。这两个表达式对于实数在数学上是等价的，但在浮点运算中它们的求值结果并不相等：它们产生的误差可能不同，在某些情况下差异可能非常显著：&lt;/p&gt;
&lt;pre class=&quot;language-julia&quot;&gt;&lt;code&gt;julia&amp;amp;gt; a = 1e9+1; b = -1e9; c = 0.1;

julia&amp;amp;gt; (a+b)+c
1.1

julia&amp;amp;gt; a+(b+c)
1.100000023841858&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;3.1 向量化&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么我们为什么要启用这个编译选项呢？一个主要原因是它能启用向量/SIMD 指令相关的优化。&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://gcc.godbolt.org/e#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1AB9U8lJL6yAngGVG6AMKpaAVxYMQAJlIOAMngMmABy7gBGmMQSXKQADqgKhLYMzm4e3nEJSQIBQaEsEVFcMZaY1slCBEzEBKnunj6l5QKV1QS5IeGR0RZVNXXpjX3tgZ0F3cUAlBaorsTI7BwApF4AzIHIblgA1EurjixMBAgAdAh72EsaAIJX11S0qEfbCu5eAKwAbNSPzwBU22qxEmuwA7AAhO7baHbB5PAgvPaQm4w7aBBF4JFQmEKXarAAi2w0Jw0VCxKJh/GI2wgeDxhI0SLReMc2w%2BnyZmK8kO52xBSwh2NRuL2hJFvKBS3e4OZUsJTKFAvxQuImAIcwYiNWyNuoPxHGmtE4714ng4WlIqE4rIUs3mmF2ax4pAImgN0wA1iBJKCTqCAJwADjWgfe/o0gdBXlB%2Bk4kl4LAkGg0pDNFqtHF4ChAKdd5oNpDgsBgiBQqBYsTokXIlDQFarUWQwGKPhotAIkWzEDCbtIYUC1QAnpxnXW2IIAPIMWjD/OkLCHIziOf4VXlABumGzc8wqjKrg7I946MwRrntDwYWIQ%2BcWF7BGIeET3ALDyYwAUADU8JgAO4T2JGCPGRBBEMR2CkED5CUNRe10GIDCMEBTGMcwLzCbNIGmVBYhsARtwAWgnVYs1PMo8M8CAHAGTwYn8UZ8kKPR4kSCiaOYrIKI6RiJgsMjmgYVp%2Bhceo9CaCihJGPIuiKXo2nYkphm4mSJGmW05gWPQH0wRYeENY1TV7DNVEDT4CM%2BSRtmAZBkG2YoTi8GlHFIbZcEIEhHVWGJtmcet6GpFYvMmXg8y0SZpgQTAmCwKIIE9EB3hTM941IRNEtTIzOCzHMXTdaYi1LOtK38msICKhsUGbLhWzoDtiC7Hs537ZhiFnUdy3HAgpxnXsF0MYBlwtVdyLwTdtwtXd90PF9yEEU9e3Q69WtvRYLQfJ8j2mN8P2/P8AKAmb%2BFA0RxEgo7oJUdQ510HxEJMMx9EvTC4stXDkkI4jtgIqgqCYBQCAIw5jlIqwKPsBgnBE9I6Ih5TxlkljshSKHaMyVjkjhpiSn4iThgUvjQYqJSGJUxT5JRsTiek%2BHVJmDSIJdVVdILM8TQyudjNM8zLOs2z7MciBnNc/AiACp0XN84rIk8rxgty/NwtISLou6F7koTBKUzTXgM2y3M8vi94vAcjQuFBT4pA0f1qtBVZYw4Ej2fTLL5bC/SOC8QyOZd0L3VITd6uSb0gA&quot;&gt;&lt;/iframe&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可能有些人不太熟悉 SIMD 操作（或汇编语言），所以这里我简要解释一下（其他人可以跳过这一部分）。由于原始时钟速度没能再显著提高，处理器能够提升性能的一种方式是使用可以一次处理一个“向量”（简单来说，就是内存中连续存放的一组值）的操作（或者说指令）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种情况下，不再是执行一系列浮点数加法（&lt;code&gt;addss&lt;/code&gt;），而是利用一个 SIMD 指令（&lt;code&gt;addps&lt;/code&gt;），以浮点向量为参（当前示例中浮点向量包含4个浮点数，如果启用 AVX512 指令，则会多达16个浮点数），一次操作就能完成该向量与另一个向量逐元素地相加。对整个数组完成向量化相加后，以一个归约步骤将向量求和为单个值。这意味着不是如下这样求值：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;s = arr[0] + arr[1];
s = s + arr[2];
s = s + arr[3];
...
s = s + arr[255];&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实际是如下这样做：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;s0 = arr[0] + arr[4]; s1 = arr[1] + arr[5]; s2 = arr[2] + arr[6];  s3 = arr[3] + arr[7];
s0 = s0 + arr[8];     s1 = s1 + arr[9];     s2 = s2 + arr[10];     s3 = s3 + arr[11]);
...
s0 = s0 + arr[252];   s1 = s1 + arr[253];   s2 = s2 + arr[254];    s3 = s3 + arr[255]);
sa = s0 + s1;
sb = s2 + s3;
s = sa + sb;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中每行代码都只对应一条浮点指令。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;问题是编译器通常不被允许做这个优化：它要求以不同于代码中指定的结合分组方式来求和，所以可能会得出不一样的结果&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt;。尽管在当前示例中它很可能是无害的（甚至可能提高精度&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[3]&lt;/a&gt;&lt;/sup&gt;），但并不总是如此。&lt;/p&gt;
&lt;h3&gt;3.2 补偿算术&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然而，有些算法严格依赖于浮点运算的执行顺序。&lt;em&gt;补偿算术&lt;/em&gt;就会利用这一点来计算中间计算中产生的误差，并在后续计算中对此进行校正。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;利用补偿算术的最知名算法应该是 &lt;a href=&apos;https://en.wikipedia.org/wiki/Kahan_summation_algorithm&apos;&gt;Kahan 求和&lt;/a&gt;，它能校正求和循环中加法步骤产生的舍入误差。我们可以启用 &lt;code&gt;-ffast-math&lt;/code&gt; 来编译 Kahan 求和算法的一种实现，并将结果与上面简单的循环求和进行对比：&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;600px&quot; src=&quot;https://gcc.godbolt.org/e#z:OYLghAFBqd5TKALEBjA9gEwKYFFMCWALugE4A0BIEAZgQDbYB2AhgLbYgDkAjF%2BTXRMiAZVQtGIHgBYBQogFUAztgAKAD24AGfgCsp5eiyagA%2BudTkVjVEQJDqzTAGF09AK5smUgMzknADIETNgAcp4ARtikIABM5AAO6ErE9kyuHl6%2BicmpQkEh4WxRMfHW2LZpIkQspEQZnt48fuWVQtW1RAVhkdFxVjV1DVnNA53dRSVxAJRW6O6kqJxcNPToLEQA1EqetGsbmwBUm7Wk05sApADsAEIXWgCCm8%2Bbq%2BtbShc%2Bd48vm8FbAhfH5PF5KS4%2BAAimy0ADotDRgfdQc9BKRNhACBDoVpgf8Ic5NrEAKwANjxQNidypm3O1xBf2e4K%2B0OZNNOF2JN3xnOheORL2ukIFz1I2CICyY2yRjyFyK4s3o3GJ/G8XB05HQ3EJSnmi2wl1iPj45CI2gVswA1iBiVpDNxpPw2Da7WqNVquPwlCA7Wb1QryHBYCgMGwEgxopRqKHw4wYqhgDwePE6PQiNFvRAIubyBFgrUAJ7cE2hjjCADyTHoRf95BwbGMwEktcIYsqADdsN7a9h1BV3Oni/wAdglbX6AQIqRC64cDmiKQCM7eAHVixgEoAGoEbAAd3LCWYQ7kwjEEk4MhPihUGhz%2Bh4hkbIHMpksE4i3sgs3QCTsQm7AC05Y%2BJsAE0DQLBKEQAENkQSBeqOFR/t4EBOMMTT%2BEwmATL0MQPkkKTIehBgEXkTA4cUfQPq0yEdEMbiNAYNFVIMXTBD0lF4WM9GZBhUHjOxkxUbMuoLEsBgLtgyx8IqyqqjmHrqAAHKSAGktImzAKgqCbEmsKxBizjkJs%2BDEGQhrGsZrhhhG6IXEaPDTPwfo6NMsxINgLA4DEEBWi69pcI65BuvwHpej6prmm5AWxE6IA%2BNIsKkjwWjSFcJLSDwtpXFofghZq3DOVFgaIEGyBoFgeCECQFBULQEasBwx6CKe4iSJeLXXmomi1vo8RGCYz4WHMYnLG8Bw7GwpiWiwSDGHs7xHCcpBnJctwiqi%2BwfMZlibEQxkFjKKL/MI/xHX8zJQpsOksjC8KIt8G2vOZmLYjCFIEkSZIUvZ1LcnS62/IyBZvRyXJAsS0IAdd52Mlst1styh2PUDfw3VdEBbNDSjnNDyMMoyl3QkQsNrcKqNihKpBSp8KMPHKjwBmOKrBQp2rbHqSwWbFkX%2BtFHleX0vnkNatoBUFzo%2BFcsLEqztZhVYEUuQGZUQCG6A2XGUYQDGtloImyYCAw6akJm2a1nmrCkDWJYa2WRCVtWOb1o2zYaq2SEEJ23Yar2/aDiulDCKOObvtO1uzssGoLkuQ6zGuG7bnuB5HoHnVnu1sidco3V3v0A1mMN76fsLP7IYBwGgeBkHQbB8FWIhbQoWhDEjJh2GCbhJG5ERrcYaRyEUVM1GN7RrHESPNhjwJhRd9R4990xrFD8JI36v0knSUzcly%2B63DKap6madpuk8PphnGaZNXc1ZGuxtE3NObzrnuZ53nUH5YtjkF%2BUK96vpRVklwHmktYjwjJDwAAnJlEkWVIHqV3qFQqz8ValRQIQcC2t05tQvFneQOdbzjiQN6B89BiEYJoEQAsh4IqkGIf0OhSgKFUJoVoIBLNf7cEhAQcCmwk67gfgfNSGktI6T0gZds4IhFH1EaffSRU%2BZAIlvFHwsIfDqI0ZozRiCCqekVgAxRIspBaDhCYsx5jzGkO4D4eS8tkHK2ip2U2aQQDSCAA&quot;&gt;&lt;/iframe&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;它和上面原始的求和代码给出了完全相同的汇编。为什么？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果你将 &lt;code&gt;t&lt;/code&gt; 的表达式代入 &lt;code&gt;c&lt;/code&gt;，会得到：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;c = ((s + y) - s) - y);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;再应用重新结合（reassociation）操作数，编译器将确定 &lt;code&gt;c&lt;/code&gt; 实际上始终为零，所以可以完全移除。沿着这一逻辑进一步推理，&lt;code&gt;y = arr[i]&lt;/code&gt; 以及循环内部的内容实际为：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;s = s + arr[i];&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，它“优化”成与上面简单的求和循环一样了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这可能看起来是一个微小的权衡，但补偿算术通常用于实现核心数学函数，例如：三角函数和指数函数。允许编译器在这些函数内部重新结合操作数，可能会给出&lt;a href=&apos;https://github.com/JuliaLang/julia/issues/30073#issuecomment-439707503&apos;&gt;灾难性的错误结果&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;四、将次正规数&lt;sup id=&quot;fnref:译注2&quot;&gt;&lt;a href=&quot;#fn:译注2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[译注2]&lt;/a&gt;&lt;/sup&gt;清零&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一点是最微妙的，但无疑是最大的隐患，因为它会影响未使用 fast-math 编译的代码，并且仅在 &lt;code&gt;-funsafe-math-optimizations&lt;/code&gt; 的文档中隐晦地提了一句：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;在链接时使用，它可能包含一些会改变默认 FPU 控制字或触发一些其他类似优化的库或启动文件。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这是啥意思？这指的是浮点数相关的那些有点烦人的特殊情况之一 - 次正规数（有时也称为非规格化数）。&lt;a href=&apos;https://en.wikipedia.org/wiki/Subnormal_number&apos;&gt;维基百科提供了一个比较不错的概述&lt;/a&gt;，但在这里你需要知道的主要是（a）它们非常接近零，以及（b）它们在许多处理器上会造成显著的性能下降&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[4]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;解决这一问题的简单方法是“清零”（FTZ，Flush To Zero），即，如果返回的结果是一个非规格化值，则取代之返回零。在很多情况下这是可以接受的，这个做法在音频和图形应用中很常见。但很多场景下它并不适用：FTZ 会破坏一些重要的浮点数误差分析结果，比如 &lt;a href=&apos;https://en.wikipedia.org/wiki/Sterbenz_lemma&apos;&gt;Sterbenz 引理&lt;/a&gt;，也因此可能出现非预期的结果（比如：迭代算法无法收敛）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这里我们想要说的问题在于 FTZ 在大多数硬件上的实际实现方式：它不是针对单条指令设置，而是&lt;a href=&apos;https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/floating-point-operations/understanding-floating-point-operations/setting-the-ftz-and-daz-flags.html&apos;&gt;由浮点环境控制&lt;/a&gt;的，更具体地来说，它是由浮点控制寄存器控制的，在多数系统中，该寄存器是在线程级别设置的，启用 FTZ 将影响同一线程中的所有其他操作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;GCC 通过 &lt;code&gt;-funsafe-math-optimizations&lt;/code&gt; 启用 FTZ，即使在构建共享库时也是如此。这意味着仅仅加载一个共享库就可能改变完全不相关的代码的执行结果，这可真是&lt;a href=&apos;https://github.com/JuliaCI/BaseBenchmarks.jl/issues/253#issuecomment-573589022&apos;&gt;一种有趣的调试体验&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;五、程序员能做啥？&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我曾在推特上开玩笑地说“别让你的朋友使用 fast-math”，不过严肃地说，我承认它确实有合理的使用场景，也能带来实在的性能提升；随着 SIMD 通道变宽，指令变得更复杂（SIMD lanes get wider and instructions get fancier），这些优化的价值只会增加。至少，它可以为进一步的性能优化提供参考。那么，何时以及如何安全地使用它呢？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果你并不关心结果的精确性：我来自科学计算领域，这个领域的程序主要输出一堆数字，从业人员也需要关注数值结果的精确性，但是许多其他领域虽然涉及一些浮点计算，但计算结果的精确性实质影响很小，比如：音频、图形、游戏和机器学习这些领域。我对这些领域的要求不太熟悉，不过&lt;a href=&apos;https://gcc.gnu.org/legacy-ml/gcc/2001-07/msg02150.html&apos;&gt;20年前 Linus Torvalds 提过一个有趣的抱怨&lt;/a&gt;,认为过于严格的浮点数语义在科学领域之外几乎无关紧要。尽管如此，&lt;a href=&apos;https://twitter.com/supahvee1234/status/1382907921848221698&apos;&gt;一些轶事&lt;/a&gt;表明 fast-math 可能会造成问题，所以了解清楚它干了什么以及为什么要这么干，很可能仍然是有用的。如果你在这些领域工作，我很想听听你的经验，特别是如果你发现这些优化中有些会产生积极或消极的影响。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;我认为，一般而言，对&lt;code&gt;-ffast-math&lt;/code&gt;可能会或不会做的变换进行防御性编程，基本上是无法解决实质性问题的。如果没能理解编译器的行为，就为编译器提供 &lt;code&gt;-ffast-math&lt;/code&gt; 选项，相当于赠予你的敌人核武器。但这并不意味着你不能使用它！只是你必须充分测试，以确信在你的系统上编译器不会发生爆炸。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;-- &lt;a href=&apos;https://discourse.julialang.org/t/when-if-a-b-x-1-a-b-divides-by-zero/7154/5?u=simonbyrne&apos;&gt;Matt Bauman&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果你确实关心结果的精确性，那你需要小心谨慎地对待 fast-math。一种常见做法是到处启用 fast-math，观察错误结果，然后尝试像处理 bug 一样隔离并修复根因。不幸的是，这个工作并不简单：你无法插入分支来检查 NaN 和 Inf 值（编译器会直接移除它们），你无法依赖调试器，因为 &lt;a href=&apos;https://gitlab.com/libeigen/eigen/-/issues/1674#note_709679831&apos;&gt;bug 可能会在调试版本中消失&lt;/a&gt;，并且它甚至会&lt;a href=&apos;https://bugzilla.redhat.com/show_bug.cgi?id=1127544&apos;&gt;破坏打印功能&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;所以你必须谨慎地对待 fast-math。一个典型的过程可能是：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1、开发可靠的验证测试用例（validation tests）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2、开发有用的基准测试（benchmarks）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;3、启用 fast-math，并比较基准测试结果&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;4、有选择地启用/禁用 fast-math 优化项&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[5]&lt;/a&gt;&lt;/sup&gt;，以识别：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;哪些优化会影响性能，&lt;/li&gt;
&lt;li&gt;哪些会导致问题，&lt;/li&gt;
&lt;li&gt;以及这些变化在代码中的哪些位置发生。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;5、验证最终的数值结果&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一过程的目标应该是在尽可能少的地方使用最少数量的 fast-math 选项，同时通过充分的测试来确保启用优化的代码位置结果仍然是正确的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;或者，你可以考虑其他方法来获得相同的性能提升：在某些情况下，可以通过重写代码来得到相同的结果。例如：许多科学计算代码库中经常可以看到 &lt;code&gt;x * (1/y)&lt;/code&gt; 这样的表达式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 SIMD 操作，&lt;a href=&apos;https://www.openmp.org/spec-html/5.0/openmpsu42.html&apos;&gt;OpenMP&lt;/a&gt; 或 &lt;a href=&apos;https://ispc.github.io/&apos;&gt;ISPC&lt;/a&gt; 这些工具库提供一些结构来编写代码方便实现自动化 SIMD 优化。Julia 提供了 &lt;code&gt;@simd&lt;/code&gt; 宏，但使用它也有一些重要的注意事项。极端情况下，你也可以使用 &lt;a href=&apos;https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/&apos;&gt;SIMD 内联函数&lt;/a&gt;，但需要更多的付出和专业知识，并且难以移植到新的平台。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后，如果你正在编写一个开源库，请不要&lt;a href=&apos;https://github.com/tesseract-ocr/tesseract/blob/5884036ecdb2807419cbd21b7ca44b630f547d80/Makefile.am#L140&apos;&gt;在 Makefile 中硬编码 fast-math&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;六、编程语言和编译器开发者能做啥？&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我认为 fast-math 的广泛使用应该被视为一个基础的设计失败：由于未能为程序员提供他们需要的特性来充分利用现代硬件，程序员只好退而求其次去启用一个已知明显不安全的编译选项。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;首先，GCC 应该解决 FTZ 库问题：&lt;a href=&apos;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522&apos;&gt;这个 bug 已经提出9年了，但仍然处于 NEW 标记状态&lt;/a&gt;。至少，这个行为应该有更清晰的文档说明，并提供一个特定的选项来禁用它。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除此之外，还有2个主要的方法：教育用户，以及提供更精细的优化控制。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;教育用户最简单的方法就是给这个编译选项起一个更好的名字。与其叫“fast-math”，不如叫“unsafe-math”。文档也应该改进，让用户快速清晰地了解这些选择带来的后果。例如：代码检查工具和编译器警告信息可以提醒用户代码中的 &lt;code&gt;isnan&lt;/code&gt; 现在已无用处，或者仅仅高亮显示哪些代码区域受到了优化的影响。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其次，编程语言和编译器需要提供更好的工具来支持完成同样的工作。理想的方式，这些行为不应该通过编译器标志来启用或禁用，这是一个非常粗粒度的工具，而是应该在代码中局部地指定，例如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;GCC 和 Clang 都允许&lt;a href=&apos;https://stackoverflow.com/a/40702790/392585&apos;&gt;以每个函数为单位启用/禁用优化&lt;/a&gt;：这些函数粒度的优化方式，应该标准化，然后所有编译器都来支持这个标准。&lt;/li&gt;
&lt;li&gt;应该提供更精细的控制选项，比如：一个指令（pragma）或宏，以便用户可以断言“在任何情况下都不应该移除这个&lt;code&gt;isnan&lt;/code&gt;检查 / 这个算术表达式应该重新结合”。&lt;/li&gt;
&lt;li&gt;与当前设计不同，提供一种机制来标记某些加法或减法操作，告知编译器无论存在什么样的编译器选项都可以重新结合优化（或者合并优化为单个乘加融合算子（contract into a fused-multiply-add operation））&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[6]&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些优化机制的具体语义应该如何，仍然是尚待讨论解决的问题： 如果将一个普通的 &lt;code&gt;+&lt;/code&gt; 和一个 fast-math 的 &lt;code&gt;+&lt;/code&gt; 组合使用，它们能否重新结合？ 作用域规则应该是什么样的，以及与跨过程（inter-procedural）优化这类优化应该如何交互？这些问题很困难但非常重要，解决好了，程序员就能够安全地使用这些优化特性。&lt;/p&gt;
&lt;h2&gt;七、补充更新&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从我写下这篇笔记以来，有一些更新：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Brendan Dolan-Gavitt 写了一篇精彩的文章来介绍 &lt;a href=&apos;https://moyix.blogspot.com/2022/09/someones-been-messing-with-my-subnormals.html&apos;&gt;Python 第三方包中启用了 FTZ 的库&lt;/a&gt;：文中还提供了一些不错的建议，方便确定你使用的库编译时是否启用了 fast-math。
&lt;ul&gt;&lt;li&gt;他还对&lt;a href=&apos;https://github.com/moyix/2_ffast_2_furious&apos;&gt;相关的缓冲区溢出漏洞&lt;/a&gt;做了概念验证（PoC）。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Clang 在使用 fast-math 构建共享库时也会启用 FTZ，但前提是系统全局安装了 GCC。我已&lt;a href=&apos;https://github.com/llvm/llvm-project/issues/57589&apos;&gt;提交了这个 issue&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;MSVC 不会移除 &lt;code&gt;isnan&lt;/code&gt; 检查，不过在使用 fast-math 编译时&lt;a href=&apos;https://twitter.com/dotstdy/status/1567748577962741760&apos;&gt;生成了看起来更糟糕的代码&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;FTZ 库的问题&lt;a href=&apos;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522#c45&apos;&gt;将在 GCC 13 中修复&lt;/a&gt;！&lt;/li&gt;&lt;/ul&gt;
&lt;hr&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;&lt;ol&gt;&lt;li id=&quot;fn:1&quot;&gt;&lt;p&gt;显然，GCC 中的 &lt;code&gt;-fno-math-errno&lt;/code&gt; &lt;a href=&apos;https://twitter.com/kwalfridsson/status/1450556903994675205&apos;&gt;会影响 malloc&lt;/a&gt;，所以可能并不那么无害。&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:2&quot;&gt;&lt;p&gt;实际上，可以构造一个数组，以不同方式对数组求和，&lt;a href=&apos;https://discourse.julialang.org/t/array-ordering-and-naive-summation/1929?u=simonbyrne&apos;&gt;几乎可以得到任何浮点数值结果&lt;/a&gt;。&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:3&quot;&gt;&lt;p&gt;数值分析中的一个重要结论是：求和的&lt;a href=&apos;https://www.google.com/books/edition/Accuracy_and_Stability_of_Numerical_Algo/5tv3HdF-0N8C?hl=en&amp;gbpv=1&amp;pg=PA82&amp;printsec=frontcover&apos;&gt;误差界限与中间求和结果绝对值之和成正比&lt;/a&gt;。SIMD 求和将累加操作分散到多个值上，因此通常会得到较小的中间求和结果。&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:4&quot;&gt;&lt;p&gt;&lt;a href=&apos;https://stackoverflow.com/a/54938328&apos;&gt;这里有个问答帖子对次正规数为什么会导致性能损耗做了很好的讲解&lt;/a&gt;。&lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:5&quot;&gt;&lt;p&gt;如上所述，&lt;code&gt;-fno-finite-math-only&lt;/code&gt; 应该是首先尝试的选项。&lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:6&quot;&gt;&lt;p&gt;Rust 通过&lt;a href=&apos;https://stackoverflow.com/a/40707111/392585&apos;&gt;实验性内置函数&lt;/a&gt;提供类似的功能，不过我不完全清楚支持哪些优化。&lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:译注1&quot;&gt;&lt;p&gt;【译注1】指某个事件或行动的结果对于后续环节或相关方产生的影响。&lt;a href=&quot;#fnref:译注1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:译注2&quot;&gt;&lt;p&gt;【译注2】英文单词 subnormals，如果不理解其语义可以参考&lt;a href=&apos;https://segmentfault.com/q/1010000042733312&apos;&gt;什么是次正规数&lt;/a&gt;。&lt;a href=&quot;#fnref:译注2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</description>
            <pubDate>2025-06-06</pubDate>
            <link>https://blog.xiayf.cn/posts/beware-of-fast-math.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/beware-of-fast-math.html</guid>
        </item>
        
        <item>
            <title>译文：RaBitQ 二值量化入门</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文:  &lt;a href=&apos;https://www.elastic.co/search-labs/blog/rabitq-explainer-101&apos;&gt;RaBitQ binary quantization 101&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;一、引言&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;正如我们之前在 &lt;a href=&apos;https://blog.xiayf.cn/posts/scalar-quantization-101.html&apos;&gt;标量量化入门&lt;/a&gt; 中讨论的那样，大多数嵌入模型输出$float32$类型向量值，这个精度对于表征向量空间来说通常过于冗余。标量量化技术大大减少了表征这些向量所需的存储空间。之前我们也讨论过 &lt;a href=&apos;https://www.elastic.co/search-labs/blog/bit-vectors-in-elasticsearch&apos;&gt;Elasticsearch 中的比特向量&lt;/a&gt;，以及二值量化导致的损失通常是不可接受的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;借助 &lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt;中提出的二值量化技术，可以解决将数据简单量化为比特向量（bit vector）过程中所遇到的问题，通过更细致地划分空间以及保留变换的残差，实现与标量量化相近的精度质量。相比其他类似技术，比如&lt;a href=&apos;http://hal.archives-ouvertes.fr/docs/00/51/44/62/PDF/paper_hal.pdf&apos;&gt;乘积量化(PQ)&lt;/a&gt;，这些新技术能够实现性能更优的距离计算，通常得到的计算结果也更准，也能实现标量量化通常不可能实现的32倍压缩（32x level of compression）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文中，我们将解释二值量化的一些核心要素，相关的数学细节请参阅 &lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;二、构建比特向量&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于距离计算，可以更高效地预计算某些部分，所以我们对索引构建和查询构造两个环节区分处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以三个非常简单的二维向量 $v_1$、$v_2$和$v_3$ 的索引构建（indexing）为例，看看如何对他们进行转换和存储，实现查询时的高效距离计算。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_1=[0.56,0.82]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_2=[1.23,0.71]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_3=[-3.28,2.13]$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们的目标是将这些向量转换为更小的表征形式，支持：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;以合理的形式快速地估算向量距离&lt;/li&gt;
&lt;li&gt;也确保空间中的向量分布能够将召回实际的最近邻所需要处理的数据向量总数降下来&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以通过以下方式实现：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将每个向量变换移动到超球体内部，对于我们的例子来说，超球体是一个二维圆，单位圆&lt;/li&gt;
&lt;li&gt;将每个向量分别吸附（snapping）到圆内某个区域的单个代表性点上&lt;/li&gt;
&lt;li&gt;保留校正因子以便更准确地近似计算每个向量与查询向量之间的距离&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面分步骤解析这个过程。&lt;/p&gt;
&lt;h2&gt;三、找一个代表性质心&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了划分每一维，需要选择一个枢轴点（pivot point）。为了简化，将选择一个点来转换我们所有的数据向量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于示例向量$v_1$、$v_2$和$v_3$，选择它们的质心作为枢轴点。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_{1}=[0.56,0.82]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_{2}=[1.23,0.71]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_{3}=[-3.28,2.13]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$c=[(0.56+1.23+-3.28)/3,(0.82+0.71+2.13)/3]$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$c=[-0.49, 1.22]$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将所有这些点一起绘制出来：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/t9BEZycxnGLmuKd.webp&apos; title=&apos;rabitq-101-pic-1&apos; alt=&apos;rabitq-101-pic-1&apos; width=&apos;600&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图 1：基于示例向量及其派生质心绘制的二维平面图。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将残差向量做归一化后，分别命名为 $v_{c1}$、$v_{c2}$和$v_{c3}$。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$
\begin{array}{l}
v_{c1}=(v_{1}-c) /\| v_{1}-c\|\\
v_{c2}=(v_{2}-c) /\| v_{2}-c\|\\
v_{c3}=(v_{3}-c) /\| v_{3}-c\|
\end{array}
$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对其中一个向量做数学运算：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$v_{c1}=(v_{1}-c)/\| v_{1}-c\|$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
v_{1}-c&amp;=[0.56,0.82]-[-0.49,1.22]\\
&amp;=[1.05,-0.39]
\end{aligned}$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$
\| v_{1}-c\| =1.13
$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
v_{c1}&amp;=(v_{1}-c)/\| v_{1}-c\|\\
&amp;=([1.05,-0.39])/\| [1.05,-0.39]\|\\
&amp;=([1.05,-0.39])/1.13\\
&amp;=[0.94,-0.35]
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对另外两个向量做同样的数学运算，结果分别为：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$
\begin{aligned}v_{c2}&amp;=\left[ 0.96,-0.28 \right]\\ v_{c3}&amp;=\left[ -0.95,0.31 \right]\end{aligned}
$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面这个动态图，可以方便我们形象地理解这个转换和归一化过程。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/Ls2nz3BpexGFfyD.gif&apos; title=&apos;rabitq-101-pic-2&apos; alt=&apos;rabitq-101-pic-2&apos; width=&apos;600&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图 2：示例向量及其派生质心在单位圆内的变换动画。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;四、仅使用 1 比特&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将数据向量集中和归一化之后，可以应用标准的&lt;a href=&apos;https://www.elastic.co/search-labs/blog/bit-vectors-in-elasticsearch&apos;&gt;二值量化&lt;/a&gt;编码 - 对于经过转换的向量的每个分量，如果其为负数，则编码为0，正数则编码为1。在我们的二维示例中，即将单位圆分成四个象限，$v_{c1}$、$v_{c2}$和$v_{c3}$对应的二值向量分别变为$r_1=[1,0],r_2=[1,0],r_3=[0,1]$。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后将每个数据向量分别吸附（snapping）到对应区域的一个代表性点上，确切来说，这些代表性点为单位圆上与每个轴距离相等的点：$\pm \frac{1}{\sqrt{d}}$ &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将经过的量化的三个向量分别表示为$\overline{v}_1$、$\overline{v}_2$和$\overline{v}_3$。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么，以 $v_{c1}$  为例，将其吸附到对应区域中的代表性点 $r_1$，则得到：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
\overline{v}_1&amp;=\frac{1}{\sqrt{d}} \left( 2r_{1}-1 \right)\\
&amp;=\frac{1}{\sqrt{2}} [1,-1]\\
&amp;=\left[ \frac{1}{\sqrt{2}} ,-\frac{1}{\sqrt{2}} \right]
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下是 $v_2$和$v_3$ 这2个原始数据向量（译注：也就是 $v_{c2}$ 和 $v_{c3}$）的量化形式：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
\overline{v}_2&amp;=\left[ \frac{1}{\sqrt{2}} ,-\frac{1}{\sqrt{2}} \right]\\
\overline{v}_3&amp;=\left[ -\frac{1}{\sqrt{2}} ,\frac{1}{\sqrt{2}} \right]
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如 &lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt; 所述，选取的这些代表性点具备一些不错的数学性质，与&lt;a href=&apos;http://hal.archives-ouvertes.fr/docs/00/51/44/62/PDF/paper_hal.pdf&apos;&gt;乘积量化（PQ）&lt;/a&gt; 的码本类似（not unlike）。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/FwhH1C3vxcgKBzJ.gif&apos; title=&apos;rabitq-101-pic-3&apos; alt=&apos;rabitq-101-pic-3&apos; width=&apos;600&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图 3：二值量化后的向量吸附到对应区域中代表性点的过程。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;至此，对于向量的每个分量都有一个1比特的近似值，尽管直接用于计算比较距离有些不太准确（somewhat fuzzy）。显然，在当前这个量化状态下，$\overline{v}_1$和$\overline{v}_2$是相同的，这样不太理想，问题类似于之前讨论将浮点数向量编码为 &lt;a href=&apos;https://www.elastic.co/search-labs/blog/bit-vectors-in-elasticsearch&apos;&gt;ElasticSearch 中的比特向量&lt;/a&gt; 是说的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种方法的优雅之处在于，查询时可以使用类似于点积的东西计算近似距离来快速比较每个数据向量和每个查询向量。后文中讨论处理查询时会详细介绍。&lt;/p&gt;
&lt;h2&gt;五、问题与方案&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如上所述，将浮点数向量转换为比特向量时会丢失大量信息。我们需要一些额外的信息来帮助补偿这种损失以及校正距离估算。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了恢复保真度（fidelity），我们将每个向量到质心的距离以及向量（例如$v_{c1}$）与其量化形式（例如$\overline{v}_1$）的投影（点积）存储为两个$float32$值。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;到质心的欧式距离比较简单直观，之前在量化每个向量时已经计算过：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
\left\| v_{1}-c \right\|&amp;=1.13\\
\left\| v_{2}-c \right\|&amp;=1.79\\
\left\| v_{3}-c \right\|&amp;=2.92
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;预先计算每个数据向量到质心的距离可以恢复向量的中心化变换。类似地，我们将计算查询向量到质心的距离。直观上，质心充当了一个中介，而不是直接计算查询向量和数据向量之间的距离。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;向量与其量化向量的点积是：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
v_{c1}\cdot \bar{v}_{1}&amp;=v_{c1}\cdot \frac{1}{\sqrt{2}} \left( 2r_{1}-1 \right)\\
&amp;=[0.94,-0.35]\cdot \left[ \frac{1}{\sqrt{2}} ,-\frac{1}{\sqrt{2}} \right]\\
&amp;=0.90\end{aligned}
$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外两个向量的结果为：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
v_{c2}\cdot \overline{v}_2&amp;=0.95\\
v_{c3}\cdot \overline{v}_3&amp;=0.89
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;量化向量与原始向量的点积，作为第二个校正因子，捕捉了量化向量与其原始位置的距离。&lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt; 的 3.2 节说明量化数据与查询向量之间以朴素方式（in a naive fashion）计算的点积存在偏差。这个因子正好补偿了它。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们做这种量化转换是为了减少数据向量的总大小并降低向量比较的开销。虽然在我们二维示例中，这些校正因子看似很大，但随着向量维度的增加，它们会变得微不足道。例如，一个 1024 维的向量，如果以$float32$形式存储，需要占用 4096 字节。如果以这种比特压缩和校正因子形式存储，只占用 136 字节。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;若想更好地理解我们为什么使用这些因子，请参阅 &lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt;，它详细介绍了涉及的数学知识。&lt;/p&gt;
&lt;h2&gt;六、查询向量&lt;/h2&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$q=[0.68, -1.72]$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了能够将我们的量化数据向量与查询向量进行比较，首先必须将查询向量相对于单位圆进行偏移，转换为量化形式。我们将查询向量称为$q$，转换后的向量称为$q_c$，标量量化后的向量称为$\overline{q}$。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
q-c&amp;=[(0.68- -0.49),(-1.72-1.22)]\\
&amp;=[1.17,-2.95]
\end{aligned}$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
q_{c}&amp;=(q-c)/\| q-c\|\\
&amp;=[1.17,-2.95]/3.17\\
&amp;=[0.37,-0.92]
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来，我们将查询向量标量量化到4个比特，我们将这个向量称为$\overline{q}$。请注意，我们不是直接量化到比特表示，而是使用一个$int4$标量量化，$\overline{q}$作为 $int4$ 字节数组，用于估计距离。我们可以利用这种非对称量化在不增加额外存储的情况下保留更多信息。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$lower = -0.92$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$upper = 0.37$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
width&amp;=\left( upper-lower \right) /\left( 2^{4}-1 \right)\\
&amp;=(0.37--0.92)/15\\
&amp;=0.08
\end{aligned}$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
\bar{q}&amp;=\lfloor (q_{c}-lower )/width \rfloor\\
&amp;=\lfloor ([0.37,-0.92]-[-0.92,-0.92])/0.08\rfloor\\
&amp;=[15,0]
\end{aligned}$$&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/z9jOGPw7oiAqv2f.gif&apos; title=&apos;rabitq-101-pic-4&apos; alt=&apos;rabitq-101-pic-4&apos; width=&apos;600&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图 4：对查询向量应用质心转换的过程。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如您所见，因为我们只有两个维度，我们的量化查询向量由处于$int4$取值范围内两个值组成。对于更长的向量，你会看到各种 $int4$ 值，其中有一个是取值范围的最大值，还有一个是最小值。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在可以执行距离计算，对每个索引数据向量与这个查询向量做比较 - 将量化数据向量每一维分别与量化查询向量的对应维相乘，再将所有维的乘积相加。基本上，就是一个普通的点积，但使用的是比特值和字节值（bits and bytes）。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
\overline{q} \cdot r_{1}&amp;=\left[ 15,0 \right] \cdot \left[ 1,0 \right]\\
&amp;=15
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接着应用校正因子来解开（unroll）量化，从而得到一个更准确的距离估计。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;要实现这一点，我们要从量化查询向量中拿到取值范围的上下界（对查询向量做标量量化时衍生出来的）。此外，还需要查询向量到质心的距离。由于前面计算过查询向量与质心之间的距离，此处引用过来即可：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\|q-c\| = 3.17$$&lt;/p&gt;
&lt;h2&gt;七、估算距离&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;好的！我们已经对索引数据向量和查询向量做了量化并收集了校正因子。现在可以计算$v_1$和$q$之间的估计距离了。我们将欧几里得距离计算公式转换为一个具有更多计算友好项的方程：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}dist(v_{1},q)&amp;=\| v_{1}-q\|\\
&amp;=\sqrt{\| (v_{1}-c)-(q-c)\|^{2}}\\
&amp;=\sqrt{\| v_{1}-c\|^{2} +\| q-c\|^{2} -2\times \| v_{1}-c\| \times \| q-c\| \times (q_{c}\cdot v_{c1})}
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种形式中，多数因子，我们之前推导过，比如 $\|v_1−c\|$，明显可以在查询之前提前计算好，或者也不是直接对查询向量和任一给定数据向量（比如 $v_1$） 做比较计算。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然而我们仍然需要计算$q_c⋅v_{c1}$.。可以利用校正因子和二值量化距离度量$\overline{q}⋅r_1$来合理且快速地估算这个值。下面我们来详细解释一下。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$q_{c}\cdot v_{c1}\approx (q_{c}\cdot \overline{v}_{1} )/(v_{c1}\cdot \overline{v}_{1} )$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;先估算$q_c⋅\overline{v}_1$，这个估算公式本质上是使用之前定义的代表点来解开（unroll）转换：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$q_{c}\cdot \overline{v}_{1} \approx (lower+width\cdot \overline{q} )\cdot (\frac{1}{\sqrt{d}} (2r_{1}-1))$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;具体来说，$(\frac{1}{\sqrt{d}} (2r_{1}-1)$将二值化的数值映射回代表点，$lower+width\cdot \overline{q}$ 则撤销了用于计算标量量化查询向量部分的移位和缩放（shift and scale）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以将这个估算公式重写为更利于计算的形式，如下所示。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过，我们先定义几个辅助变量：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将 $r_1$中 1 的总位数定义为$\overline{v}_{b1}$，当前例子中等于 $1$&lt;/li&gt;
&lt;li&gt;将 $\overline{q}$&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt;中所有量化值的总和（total number）定义为$\overline{q}_b$，当前例子中等于 $15$&lt;/li&gt;&lt;/ul&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
q_{c}\cdot \overline{v}_{1}&amp;\approx \frac{2\times \textit{width}}{\sqrt{d}} \times (\overline{q} \cdot r_{1})+\frac{2\times \textit{lower}}{\sqrt{d}} \times \overline{v}_{b1} -\frac{\textit{width}}{\sqrt{d}} \times \overline{q}_{b} -\sqrt{d} \times \textit{lower}\\
&amp;\approx \frac{2\times 0.08}{\sqrt{2}} \times 15+\frac{2\times -0.92}{\sqrt{2}} \times 1-\frac{0.08}{\sqrt{2}} \times 15-\sqrt{2} \times -0.92\\
&amp;\approx 0.92
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;利用这个值和$v_{c1}⋅\overline{v}_1$（在对数据向量建索引时预先计算好），代入公式，计算$q_c\cdot v_{c1}$的近似值：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
q_{c}\cdot v_{c1}&amp;\approx (q_{c}\cdot \overline{v}_{1} )/(v_{c1}\cdot \overline{v}_{1} )\\
&amp;\approx 0.92/0.90\\
&amp;\approx 1.01
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后，将这个近似值代入前面那个更大的距离公式中（注意：我们使用的是$q_c⋅v_{c1}$的估计值）：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
dist(v_{1},q)&amp;=\sqrt{\| v_{1}-c\|^{2} +\| q-c\|^{2} -2\times \| v_{1}-c\| \times \| q-c\| \times (q_{c}\cdot v_{c1})}\\ est\_ dist(v_{1},q)&amp;=\sqrt{1.13^{2}+3.17^{2}-2\times 1.13\times 3.17\times 1.01}
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;应用所有校正因子后，我们得到了两个向量之间距离的一个合理的估计值。例如，当前例子中，原始数据向量$v_1$、$v_2$、$v_3$ 与$q$  之间的估计距离与真实距离的比较如下：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
est\_ dist(v_{1},q)&amp;=2.02\\
est\_ dist(v_{2},q)&amp;=1.15\\
est\_ dist(v_{3},q)&amp;=6.15
\end{aligned}$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\begin{aligned}
eucl\_ dist(v_{1},q)&amp;=2.55\\
eucl\_ dist(v_{2},q)&amp;=2.50\\
eucl\_ dist(v_{3},q)&amp;=5.52
\end{aligned}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于线性代数应用时如何推导或简化的详细信息，请参阅 &lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;八、重新排序&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从上一节的结果可以看出，这些估计距离确实是估计值。二值量化产出的向量，对其计算出来的向量距离，即使应用额外的校正因子，也仅仅是原始向量之间距离的近似值。实验证明，通过引入一个多阶段过程，可以实现高召回率。这证实了&lt;a href=&apos;https://arxiv.org/pdf/2405.12497&apos;&gt;RaBitQ 论文&lt;/a&gt;中的发现（findings）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，为了获得高质量的结果，二值量化召回的结果必须使用更精确的距离计算进行重新排序。实际应用中，这个候选子集可以很小，通常使用 100 个或更少的候选者即可实现大型数据集（&gt;1m）&gt;95%的召回率。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 RaBitQ，中间结果在搜索操作过程中会持续重新排序。在我们的实验中，为了实现更可扩展的二值量化，我们将重排序步骤解耦出来。虽然 RaBitQ 能够在搜索过程中通过重新排序来维护更好的前$N$候选列表，代价是需要不断加载完整的$float32$向量，这对于生产环境中一些较大的数据集来说是不可行的。&lt;/p&gt;
&lt;h2&gt;九、总结&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;哇！你顺利地读完了！这篇博客确实很长。对于这个新算法我们非常兴奋，它可以缓解乘积量化（例如码本构建成本、距离估计慢等）的许多痛点，并提供出色的召回率和检索速度。&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;&lt;ol&gt;&lt;li id=&quot;fn:1&quot;&gt;&lt;p&gt;译注：没看懂这个公式 😅&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:2&quot;&gt;&lt;p&gt;译注：原文有误，将 $\overline{q}$ 写成了 $\overline{q}_b$&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</description>
            <pubDate>2025-05-20</pubDate>
            <link>https://blog.xiayf.cn/posts/rabitq-explainer-101.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/rabitq-explainer-101.html</guid>
        </item>
        
        <item>
            <title>译文：标量量化入门</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://www.elastic.co/search-labs/blog/scalar-quantization-101&apos;&gt;Scalar quantization 101&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多数嵌入（embedding）模型会输出 $float32$ 数值精度的向量。这个精度虽然提供了信息高保真，但在真正重要的信息之外也带来一些资源浪费。对于给定的数据集，嵌入不可能在单个维度需要20亿种取值，特别是对于高维度向量而言（比如：386维及以上）。量化以一种有损的方式对向量进行编码，轻微降低信息保真而明显地降低存储空间占用。&lt;/p&gt;
&lt;h2&gt;理解标量量化的分桶&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;标量量化使用更小的数据类型对向量每一维的取值进行分桶。本文的余下部分将假设将 $float32$ 量化到 $int8$ 。为了准确地对值进行分桶，不能简单地将值四舍五入到最近的整数。许多模型输出向量的维度取值空间为 $[-1.0, 1.0]$，如果简单粗暴地四舍五入处理，那么 0.123 和 0.321 这两个不同的向量维度取值都会向下取整到 0。最终，一个向量仅会使用 $int8$ 可用 255 个桶中的2个桶，这样就丢失太多信息了。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/05/J6uMBLimnWhcVyj.jpg&apos; title=&apos;float32-to-int8-buckets.jpeg&apos; alt=&apos;float32-to-int8-buckets.jpeg&apos; width=&apos;500&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图1：量化目标图解 - 将 -1.0 到 1.0 之间的连续值分桶到离散的 $int8$ 数值。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种数值转换背后的数学原理并不太复杂。我们可以先计算浮点数取值区间的最小和最大值，然后使用 &lt;a href=&apos;https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization&apos;&gt;最小-最大归一化&lt;/a&gt;) 对值进行线性变换（linearly shift）。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$int8\approx \frac{127}{max-min} \  \times \left( float32-min \right)$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$float32\approx \frac{max-min}{127} \times int8+min$$&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图2：$int8$ 和 $float32$ 之间的变换公式。注意：这两个变换是有损的，并不是精确变换。下面的例子中，仅使用 $int8$ 取值空间的正数部分。Lucene 的实现也是这样的。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;标量量化的统计视角&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/Quantile&apos;&gt;分位点（quantile）&lt;/a&gt; 是指数值分布的一个切片，这个切片包含一定数量比例的值。例如：一种浮点数取值分布下 99% 的值落在 $[-0.75, 0.86]$ 这个分位点区间内，小于 $-0.75$ 和大于 $0.86$ 的值都被视为离群值/异常值（outliers），因此将 $-0.75$ 和 $0.86$ 分别视为实际的最小值和最大值。如果量化时将离群值包含在内，就意味着那些最常见的值可用的桶偏少了，可用桶少了也就意味着精度更差，信息损失更多。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/19/PhYvL58SluIskbe.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图3:图解 99%  &lt;a href=&apos;https://en.wikipedia.org/wiki/Confidence_interval&apos;&gt;置信区间(confidence interval)&lt;/a&gt;及对应的分位点数值，即 99% 的值落在 $[-0.75, 0.86]$ 这个范围内。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不错，我们现在知道如何对浮点值进行量化了，那么又应该如何计算两个量化后向量的距离呢？就像常规的&lt;a href=&apos;https://en.wikipedia.org/wiki/Dot_product&apos;&gt;点积&lt;/a&gt;计算一样简单吗？&lt;/p&gt;
&lt;h2&gt;标量量化的代数视角&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;目前为止仍然缺失关键的一块拼图 - 如何计算两个量化后向量之间的距离。本文并没有有意避开数学公式，下面也会出现更多数学内容。拿出你的铅笔，回忆一下&lt;a href=&apos;https://en.wikipedia.org/wiki/Polynomial&apos;&gt;多项式&lt;/a&gt; 和基础代数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/Dot_product&apos;&gt;点积&lt;/a&gt;和&lt;a href=&apos;https://en.wikipedia.org/wiki/Cosine_similarity&apos;&gt;余弦相似度&lt;/a&gt;的计算逻辑是将两个向量对应维度上的浮点值相乘，然后将所有维度上的结果相加。我们已经知道如何在 $float32$ 和 $int8$ 值之间做变换，那么应用变换后的乘法公式是什么样的呢？&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$float32_{i}\times float32_{i}^{\prime}\approx \left( \frac{max-min}{127} \times int8_{i}+min \right) \times \left( \frac{max-min}{127} \times int8_{i}^{\prime}+min \right)$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将这个乘法公式展开后（为了简化，以 $\alpha$ 替代 $\frac{max-min}{127}$），如下所示：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\alpha^{2} \times int8_{i}\times int8_{i}^{\prime}+\alpha \times int8_{i}\times min+\alpha \times int8_{i}^{\prime}\times min+min^{2}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来就更有意思了 - 这个算式中仅有一个部分要求同时提供两个变量值。然而，点积并不只是两个浮点数相乘，而是两个向量的每一维对应的浮点值相乘。假设向量的维度为 $dim$，那么以下部分算式都可以提前计算好存下来。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$dim\times \alpha^{2}$ 即 $dim\times \left( \frac{max-min}{127} \right)^{2}$ ，可以提前计算好存为单个浮点数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}$ 和 $\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}^{\prime}$ 都可以分别提前计算好存为单个浮点数，或者在检索时计算一次。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$dim\times min^{2}$ 也可以提前计算好存为单个浮点数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dim\times \alpha^{2} \times dotProduct\left( int8,int8^{\prime} \right) +\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}+\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}^{\prime}+dim\times min^{2}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;点积的整个算式中仅 $dotProduct\left( int8,int8^{\prime} \right)$ 部分需要在检索时计算，加上其他提前计算好的部分就能得到结果。&lt;/p&gt;
&lt;h2&gt;量化的精度保证&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么，这样量化计算的准确性如何？量化后损失信息没有？是的，损失了一些信息，不过量化正是基于我们事实上并不需要所有信息的假设。对于训练得到的嵌入模型，向量各个维度的值分布通常不存在&lt;a href=&apos;https://en.wikipedia.org/wiki/Fat-tailed_distribution&apos;&gt;厚尾性(fat-tails)&lt;/a&gt;。这意味着值分布存在一定的局部性和一致性。此外，量化对每一维度引入的误差是相互独立的，这意味着对于向量的典型运算（比如点积），误差一定程序上会抵消。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;哟，一写就写了一堆内容。现在你应该很好地理解了量化的技术优势，其背后的数学原理，以及如何将线性变换考虑在内计算向量之间的距离。&lt;/p&gt;</description>
            <pubDate>2025-01-13</pubDate>
            <link>https://blog.xiayf.cn/posts/scalar-quantization-101.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/scalar-quantization-101.html</guid>
        </item>
        
        <item>
            <title>译文：k-NN 乘积量化器教程-第2部分</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/&apos;&gt;本教程的第1部分&lt;/a&gt; 讲解了乘积量化器的最基础形式。本文将讲解 &lt;a href=&apos;https://github.com/facebookresearch/faiss/wiki/Getting-started-tutorial&apos;&gt;FAISS 库的 IndexIVFPQ 索引&lt;/a&gt;，该索引类型使用一个乘积量化器以及 &lt;a href=&apos;https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf&apos;&gt;2011 年发表的这篇论文&lt;/a&gt;介绍的一些额外的技术。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面先简要介绍一下该索引引入的两个特性，之后会再详细解释。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;倒排文件索引（IVF）&lt;/em&gt;  - IVF 就是一种数据集预过滤的技术，避免对所有向量进行穷举搜索。它的原理相当直观 - 使用 k-means 聚类算法提前将数据集聚类成一定数量的数据集分区，然后在检索时，先将查询向量与每个分区的质心做比较，找到最近的若干个聚类，然后只在这些聚类分区内做向量搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;残差编码&lt;/em&gt; - 这是对乘积量化器基础形式的一种增强方式 - 加入 IVF 步骤的一些信息。对于每个数据库向量，不再使用 PQ 编码原始的数据库向量，而是对向量相对于所属分区的质心的偏移量（offset）进行编码。后续章节会解释其原理和收益。&lt;/p&gt;
&lt;h2&gt;倒排文件索引（Inverted File Index）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;计算机科学领域，特别是信息检索领域，一个“倒排索引”是指将词汇表中的每个单词映射到数据库中所有文档中该单词出现的所有位置，它非常类似于课本中后面的索引表 - 将单词或概念映射到页号，所以大家将这种数据结构称为“倒排索引”让我有些困扰（因为于我而言它就是一种普通的索引！）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不管怎样，在当前上下文中，这个技术实际就是使用 k-means 聚类对数据集做分割，这样就可以仅对部分分区做搜索而忽略其余的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;构建索引时，使用 k-means 聚类算法将数据集聚类成一定数量的分区。数据集中每个向量仅会被归属到一个聚类/分区中。每个分区包含归属于它的一组向量（也就是 FAISS 作者说的“倒排文件列表”）。也由此得到所有分区的质心组成的一个矩阵，用于计算应该对哪些分区进行搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;按照这种方式对数据集进行分割，并不完美，因为如果一个查询向量实际位于最近聚类的边缘位置，那么查询向量的最近邻居可能实际位于多个附近的聚类中。这个问题的解决方案是简单地多搜索几个分区。搜索多个附近的分区显然会占用更多的检索时间，但是准确性也会更好。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;搜索的时候，将查询向量与所有分区的质心做比较，找到最近的若干个分区质心，实际的数量可以配置。一旦找到了最近的若干个分区质心，就可以仅对这些分区的数据库向量使用乘积量化器做 k-NN 搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意该索引类型中使用的如下术语：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“probe（搜寻）” 这个动词，在当前上下文中，是指选定待搜索的目标分区。因此在代码中你会看到索引参数“nprobe” - 意思就是“待搜寻的分区数量”。&lt;/li&gt;
&lt;li&gt;FAISS 的作者们喜欢使用“Voronoi 单元（cells）”这个词语，而不是我在本文中使用的“数据集分区（dataset partitions）”。一个 Voronoi 单元就是属于一个聚类的空间区域，也就是，这个空间区域涵盖了对应聚类的所有点，这些点的向量与这个聚类的质心的距离，比其他聚类的质心都要近。&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;残差编码（Encoding Residuals）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个特性也是相对比较直观的，不过如果你没有理解的话可能会觉得有点奇怪。其想法是将 IVF 阶段的一些信息加入到乘积量化器中，借此提升准确性（因此这个概念是建立在数据集分区技术之上的）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;先定义一下什么是“残差”向量。暂时抛开乘积量化器不谈（因为它会增大理解的困难，后面我们再把它加回来）。假设我们要做标准的暴力 k-NN 搜索，不过是用数据集分区技术来削减待搜索向量的数量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设我们是用 k-means 将数据集聚类成 100 个聚类（或者叫“数据集分区”）。给定数据集中的一个向量，其残差即是它相对于所属分区的质心的偏移（offset）。也就是，将数据集中的这个向量与其所属聚类的质心的向量相减。质心即是聚类的均值，那么对一组点均减去它们的均值会发生什么？现在这些点就围绕着 0 点了。如下是一个简单的二维示例：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/VJ7siPxgmBhNvFA.png&apos; title=&apos;residuals_one_partition.png&apos; alt=&apos;residuals_one_partition.png&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;开始有趣起来了。假设将一个数据集分区中的所有向量都替换为各自的残差向量，怎么从这个数据集分区中找到查询向量的最近邻？先计算查询向量的残差（相对于分区质心的偏移），然后对这个数据集分区的所有残差向量做最近邻搜索，得到的结果与使用原始向量做搜索是一样的！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于上面的图示，凭直觉可能就能理解，不过还是再看看下面的等式加深理解。&apos;x&apos; 和 &apos;y&apos; 这两个向量的长度为 &apos;n&apos;，它们的 L2 距离计算公式为：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dist_{L2}\left( x,y \right) =\sqrt{\sum_{i}^{n} \left( x_{i}-y_{i} \right)^{2}}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果对 &apos;x&apos; 和 &apos;y&apos; 都减去质心向量 &apos;c&apos;，看起来是什么样的？&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dist_{L2}\left( x-c,y-c \right) =\sqrt{\sum_{i}^{n} \left( (x_{i}-c_{i})-(y_{i}-c_{i}) \right)^{2}} =\sqrt{\sum_{i}^{n} \left( x_{i}-y_{i} \right)^{2}}$$&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;质心部分被抵消掉了！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意使用残差计算出来的距离不只是相对而言（比如距离的序）是相等的，并且确实是正确地计算出了向量之间的 L2 距离。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可能你之前就使用过这种等价关系，均值归一化（对向量减去均值）是一种常见的预处理技术。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过目前为止说的都是单个分区内的计算。将不同分区内的向量做比较又会是什么情况呢？仍然管用，只要针对每个分区分别计算查询向量的残差即可。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面这个图解中包含两个数据集分区。计算残差之后，两个分区的所有点都围绕在 0 点周围了。不过现在是有两个查询向量的残差 - 一个是与蓝色点集（分区 1）比较得到的，另一个是与绿色点集（分区 2）比较得到的。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/iLmu5s84ZvGQUo9.png&apos; title=&apos;residuals_two_partitions.png&apos; alt=&apos;residuals_two_partitions.png&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前面解释过查询向量和数据库向量之间的距离，使用原始向量计算和使用残差向量计算，结果是一样的，还记得吧？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很有意思，不过目前为止还是无用功 - 尚未改变结果的准确性也没有减少计算成本。现在将 PQ 重新放进来一起考虑，就会发现好处在哪了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在训练乘积量化器之前，先计算数据集所有分区所有向量的残差向量。残差向量集合保持原有分区（不会合并在一起），不过现在所有残差向量都围绕着 0 点，相对紧凑地聚集在一起。我们抛弃掉原始的数据集向量，只存储残差向量集。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在所有这些残差向量之上训练习得一个乘积量化器，不再使用原始向量。那有什么不同之处吗？回想一下：乘积量化器的训练过程是先将向量分割成子向量，在每部分子向量之上进行 k-means 聚类，学习到一组原型/质心（或者叫“码本”）用于表征所有向量。使用对应的残差向量来替换原始向量，能够降低数据集中向量的多样性（the variety in the dataset）（论文中，将此描述为：相对于原始向量，残差向量“包含更小的能量（have less energy）”）。之前，聚类存在于空间的各个区域，现在聚类都围绕着 0 点，并且相互之间还存在部分重合。降低了数据集中向量的多样性，就可能使用更少的原型/质心（或者说“代码”）来有效地表征向量！或者，换个角度来说，PQ 中数量有限的代码现在更加准确了，因为这些代码所要描述的向量，相比之前，相互之间区别更小了（less distinct）。我们得到了更多的回报（more bang for our buck）！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过，也是有代价的。回想一下：乘积量化器的魔力在于仅需要将查询向量分块与码本代码之间的部分距离计算出来存为一个相对比较小的表 - 剩下的操作就是查表和加法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在，使用残差向量，对于每个数据集分区而言，查询向量都是不同的 - 对于每个数据集分区，查询向量对应的残差向量都需要基于分区的质心重新计算。因此，对于待搜寻的每个分区，都必须单独计算一个距离表！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过，这个取舍显然是值得的，实际应用中，IndexIVFPQ 索引的表现都很不错。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;就是这样。虽然数据库向量都被各自的残差向量替代了，不过对于乘积量化器来说，没什么不同。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：数据集分区并不会考虑（factor in to）码本训练，我们仍然跨越分区使用所有数据集向量为每部分子向量习得一个码本。你也可以为每个数据集分区单独训练一个 PQ，不过 FAISS 库的作者不赞成这样做，因为分区的数量通常比较大，那么存储这些码本的内存开销会是一个问题。所以，跨分区在所有数据库向量之上训练习得一个 PQ 更好一些。&lt;/p&gt;</description>
            <pubDate>2025-01-10</pubDate>
            <link>https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-2.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-2.html</guid>
        </item>
        
        <item>
            <title>译文：k-NN 乘积量化器教程-第1部分</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;乘积量化器是一种“向量量化器”（后面我会解释这是啥意思），可以用于加速近似最近邻检索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2017年3月发布的 &lt;a href=&apos;https://code.facebook.com/posts/1373769912645926/faiss-a-library-for-efficient-similarity-search/&apos;&gt;Facebook AI 相似性检索（FAISS）库&lt;/a&gt;，风靡一时，乘积量化器是其核心组件，吸引了很多人关注。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本教程的第一部分将解释乘积量化器的最基础形式，ANN 检索中通常是这样实现。第二部分将解释 FAISS 中的 “IndexIVFPQ” 索引，这种索引在基础形式的乘积量化器上添加了不少特性。&lt;/p&gt;
&lt;h2&gt;近似距离穷举搜索&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不同于 ANN 使用的基于树的索引，单独使用乘积量化器的 k-NN 检索仍然是一种“穷举搜索”，这意味着乘积量化器仍然需要将查询向量（query vector）和数据库中所有向量做比较。乘积量化器的核心是近似地且显著地简化向量的距离计算。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;注意：FAISS 中的 IndexIVFPQ 索引在使用乘积量化器之前会预先过滤数据集 - 第二部分会解释。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;以示例解释&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;乘积量化器方法的作者们是信号处理和压缩技术背景的，所以如果你是机器学习方向的，可能对他们的用词和术语比较陌生。不过，如果你熟悉 k-means 聚类（且摒弃所有压缩命名法的词汇），使用一个示例你就能轻松理解乘积量化器的基础知识。之后，我们再回头来看压缩技术相关术语。&lt;/p&gt;
&lt;h2&gt;数据集压缩&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设你有一个 50,000 张的图片集，使用一个卷积神经网络（CNN）完成一些特征的抽取。这样你现在就得到一个 50,000个特征向量的数据集，每个特征向量有 1024 维。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/GYq3ZzBRHSQMCyL.png&apos; title=&apos;image_vectors.png&apos; alt=&apos;image_vectors.png&apos; width=&apos;300&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们要做的第一件事情就是压缩数据集。向量的数量保持不变，但是可以减少每个向量需要的存储空间。注意：我们要做的事情不同于“降维（dimensionality reduction）”！这是因为压缩后的向量中的值其实是符号而不是数值，所以不能直接比较压缩后的向量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;压缩数据集有两大好处：（1）内存访问耗时通常是处理速度的限制因素，（2）对大数据集而言内存容量是个问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;压缩的原理如下所述：对于我们的示例数据集，将所有向量一起切成8个子向量，每个子向量的长度为 128（8个子向量 $\times$ 每个子向量128维 = 原始向量的 1024 维）。这样就将数据集分成8个矩阵，每个矩阵大小为 $[50K \times 128]$。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/19/WJq2XenwRcoSAtM.png&apos; title=&apos;vector_slice.png&apos; alt=&apos;vector_slice.png&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然后对这8个矩阵的每一个单独进行 k-means 聚类，k = 256。这样，对于向量的8个子段的每1个都存在256个质心 - 一共8组质心，每组包含256个质心。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/23/wQHcVTzs6ftJFeg.png&apos; title=&apos;kmeans_clustering.png&apos; alt=&apos;kmeans_clustering.png&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些质心类似于“原型”。它们代表数据集子向量中最常见的模式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以使用这些质心来压缩向量数据集 - 使用最接近/最相似的置信来替代向量中对应的每个子部分，从而得到一个不同于原始向量的一个新向量，不过它们之间应该还是相近的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样我们就能更加高效地存储这些向量 - 不用存储原始的浮点数值，只要存储聚类中心 ID 即可 - 对每个子向量，找到最近的质心，存储该质心的 ID。每个向量也就被替换为8个质心 ID 的一个序列。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：对于8个子部分矩阵的每一个学习到的质心集合是不同的。使用最近质心 id 替换子向量时，只能与对应子部分的 256 个质心做比较。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;每个子部分只有 256 个质心，所以仅需 8 比特就能存储一个质心 ID。每个向量，原本包含 1024 个 32 浮点数（4,096 字节），现在仅是 8 个 8 比特整数的序列（每个向量只要8字节的存储空间！）。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/19/eTMGdN4Vfbrhyl5.png&apos; title=&apos;compression.png&apos; alt=&apos;compression.png&apos; width=&apos;100%&apos;/&gt;
&lt;h2&gt;最近邻搜索&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很棒！向量经过压缩了。不过无法对经过压缩的向量直接计算 L2 距离 - 质心 ID 之间的距离是任意且没有实际意义的！（这就是压缩与降维的不同之处）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来说说怎么进行最近邻搜索，虽仍是穷举搜索（与所有向量计算距离并排序），不过可以更高效地计算距离 - 只需进行表查找以及某种加法即可。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设我们有一个查询向量，期望找到它的最近邻居。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一种不太聪明的方式是先解压缩数据集向量，然后计算 L2 距离。也就是，通过串接不同维度的质心重建出向量。下面我们也会这样干，不过比实际地解压缩所有向量在计算上要高效得多。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;首先，对查询向量的每个子向量，与该子段的 256 个质心中每一个计算 L2 距离的平方。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这意味着要构建一个子向量距离表，这个表有 256 行（一个质心对应一行） 8 列（一个子段对应一列）。构建这个表成本有多大？相当于计算查询向量与 256 个数据集向量的 L2 距离所需要的数学运算次数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一旦有了这个表，就可以开始计算查询向量与 50k 个数据库向量中每一个的近似距离了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;每个数据库向量现在只是 8 个质心  ID 的序列。因此要计算一个数据库向量与查询向量之间的相似距离，只需使用这些质心 ID 从表中查找出对应的部分距离，并将它们加和在一起。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;只需要将这些部分值加起来就完成了？是的！记住我们在处理的是 L2 距离的平方，所以无需平方根操作。计算 L2 的平方，就是将每个子部分的差平方（squared differences）相加，这些加法操作的次序也无关紧要。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种查表方式，与对解压缩向量计算距离的方式，得到的结果是一样的，但是计算成本要小得多。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后一步，与常规的最近邻搜索一样 - 对距离进行排序后找到最小的距离，对应的这些数据库向量就是最近的邻居。打完收工！&lt;/p&gt;
&lt;h2&gt;压缩技术相关术语&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们理解了 PQ 的逻辑原理，现在回过头来学习相关术语就简单了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;广义上而言，量化器就是能够减少变量取值空间（the number of possible values that a variable has）的一种东西。构建一个查找表来减少一张图片的颜色数量（the number of colors），应该是一个不错的例子 - 找到图片中最常见的 256 个颜色数值，放到一张表中，将 24 比特 RGB 色值映射到一个 8 比特整数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们获取所有数据库向量的开始 128 个值（8个子段中第1个），对这些 128 个值（数量 $50k \times 128$）进行聚类训练，得到 256 个质心，这 256 个质心就构成了我们所说的“码本（codebook）”。每个质心（一个包含128个浮点数的向量）被称为一个“代码（code）”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些质心是用来表征数据库向量的，因此这些代码也可称之为“再生产值（reproduction values）” 或“重建值（reconstruction values）”。将质心 ID 对应的代码串接成序列就能创建一个数据库向量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;8 个子段是分别进行 k-means 聚类的，所以实际创建了 8 个独立的码本。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于这 8 个码本，组合代码能够创建 $256^8$ 种可能的向量！因此，实际上我们创建一个非常巨大的码本，包含 $256^8$ 个代码。直接习得并存储如此大的单个码本是不可能的事情，由此可见乘积量化器的魔力。&lt;/p&gt;
&lt;h2&gt;预过滤&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/&apos;&gt;本教程的第2部分&lt;/a&gt;中，我们将学习 FAISS 库中的 IndexIVFPQ 索引，这种索引在使用乘积量化器之前将数据集先分割为多个分区，这样对于每个查询仅需要搜索部分分区。FAISS 发布于 2017 年，IndexIVFPQ 索引使用的乘积量化器方法技术首次见于 &lt;a href=&apos;https://www.irisa.fr/texmex/people/jegou/papers/jegou_searching_with_quantization.pdf&apos;&gt;2011 年的这篇论文&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2025-01-09</pubDate>
            <link>https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-1.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-1.html</guid>
        </item>
        
        <item>
            <title>译文：Arrow 列存格式-序列化与进程间通信</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://arrow.apache.org/docs/format/Columnar.html#serialization-and-interprocess-communication-ipc&apos;&gt;Arrow Columnar Format-Serialization and Interprocess Communication (IPC)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;序列化与进程间通信(IPC)&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本列存格式定义中，序列化数据的基本单元是“成批记录（record batch）”。语义上，一个成批记录是若干数组的一个有序集合，一个数组对应一个字段列（field），这些数组的长度相同，但数据类型可能不同。一个成批记录中字段列的名称和类型信息共同形成该批的 &lt;em&gt;schema&lt;/em&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本小节，我们将定义一种协议，约定如何将若干记录批序列化成一个二进制载荷的流，以及如何无需内存拷贝就能从这些载荷重建出记录批。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本列存进程间通信协议使用如下这些类型的二进制消息格式来构建一个单向流的定义：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Schema&lt;/li&gt;
&lt;li&gt;RecordBatch&lt;/li&gt;
&lt;li&gt;DictionaryBatch&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种我们称之为进程间通信密封消息的格式，包含一个经序列化的 Flatbuffer 类型元数据，后接一个可选的消息体。在描述如何序列化如上三种进程间通信消息类型之前，我们先定义清楚这种消息格式。&lt;/p&gt;
&lt;h3&gt;密封消息格式&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于简单的流式序列化和基于文件的序列化，我们为进程间通信定义一种“密封的”消息格式。这种消息，仅需检查消息的元数据，就能“被反序列化”成内存中的 Arrow 数组对象，无需对实际数据进行拷贝或移动。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种密封二进制消息格式如下所述：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个 32 比特长度的再开始标识。其值为 &lt;code&gt;0xFFFFFFFF&lt;/code&gt;，表示重新开始一个有效消息。这一部分是在版本 0.15.0 引入的，部分原因是为了解决 Flatbuffers 要求8字节对齐的问题。&lt;/li&gt;
&lt;li&gt;消息元数据部分的大小，32 比特长度，小端编码。&lt;/li&gt;
&lt;li&gt;消息元数据，类型为 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Message.fbs&quot;&apos;&gt;Message.fbs&lt;/a&gt;文件中定义的 &lt;code&gt;Message&lt;/code&gt; 类型。&lt;/li&gt;
&lt;li&gt;消息体，其长度必须是8字节的倍数。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;语义上，消息格式形如：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;再开始标识: 0xFFFFFFFF&amp;amp;gt;
&amp;amp;lt;元数据大小: int32&amp;amp;gt;
&amp;amp;lt;flatbuffer 序列化的元数据: bytes&amp;amp;gt;
&amp;amp;lt;填充&amp;amp;gt;
&amp;amp;lt;消息体&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;经序列化的完整消息，长度必须是8字节的倍数，这样消息可以跨多个流实现内存重定位（译注：怎么理解？）。否则，元数据和消息体之间填充量是不确定的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“元数据大小” 等于 &lt;code&gt;Message&lt;/code&gt; 类型的大小加上填充的大小。“flatbuffer 序列化的元数据”即是一个 Flatbuffer &lt;code&gt;Message&lt;/code&gt; 类型的值序列化后的结果，其内部包含如下部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;版本号&lt;/li&gt;
&lt;li&gt;特定的消息类型值（&lt;code&gt;Schema&lt;/code&gt;、&lt;code&gt;RecordBatch&lt;/code&gt;、&lt;code&gt;DictionaryBatch&lt;/code&gt; 三者之一）&lt;/li&gt;
&lt;li&gt;消息体的大小&lt;/li&gt;
&lt;li&gt;应用设置的“自定义元数据”字段。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在读取一个输入流时，通常先解析 &lt;code&gt;Message&lt;/code&gt; 元数据，经验证后获取到消息体的大小，然后读取消息体。&lt;/p&gt;
&lt;h3&gt;Schema 消息&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Schema.fbs&quot;&apos;&gt;Schema.fbs&lt;/a&gt; 这个 Flatbuffers 文件包含所有内置类型的定义，以及用于表达一个给定成批记录 schema 的 &lt;code&gt;Schema&lt;/code&gt; 元数据类型。schema 是若干字段列（&lt;code&gt;Field&lt;/code&gt;）定义的有序序列，每个字段列定义包含列名称和列数据类型。&lt;code&gt;Schema&lt;/code&gt; 类型的值经序列化后不会包含任何数据缓冲区，仅包含类型元数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Field&lt;/code&gt; 这个 Flatbuffers 类型包含单个数组的的元数据，包括如下信息：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;字段列的名称&lt;/li&gt;
&lt;li&gt;字段列的数据类型&lt;/li&gt;
&lt;li&gt;该字段列语义上是否可以为 null。这个和数组的物理内存布局无关，一些系统会明确区分可为 null 的字段列和不可为 null 的字段列，我们希望保留这个元数据以便完整无缺地表达 schema&lt;/li&gt;
&lt;li&gt;对于嵌套类型，还包含一组子类型 &lt;code&gt;Field&lt;/code&gt; 元数据&lt;/li&gt;
&lt;li&gt;一个名为 &lt;code&gt;dictionary&lt;/code&gt; 的属性，标识当前字段列是否字典编码过的。如果是的话，会有一个字典“id” 赋值于此，如此便可为这个字段列匹配后续的字典编码的 IPC 消息。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，我们还提供 schema 级别和字段列级别的 &lt;code&gt;custom_metadata&lt;/code&gt; 属性字段，方便应用系统插入自己的应用元数据，以此自定义行为。&lt;/p&gt;
&lt;h3&gt;RecordBatch 消息&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个 RecordBatch 消息包含若干实际的数据缓冲区，其物理内存布局由 schema 决定。这种消息的元数据提供了每个缓冲区的位置和大小信息，如此，使用指针计算就能重建出那些数组数据结构，也无需内存拷贝。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;成批记录的序列化后形式如下所示：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“消息头部”部分，定义见 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Message.fbs&quot;&apos;&gt;Message.fbs&lt;/a&gt; 中的 &lt;code&gt;RecordBatch&lt;/code&gt; 类型。&lt;/li&gt;
&lt;li&gt;“消息体”部分，若干内存缓冲区的一个平铺序列，依次逐个写入，中间加上适当的填充以确保8字节对齐。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据头部包含如下信息：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;成批记录中，每个平铺字段列的长度和 null 值的数量。&lt;/li&gt;
&lt;li&gt;成批记录消息体中每个“缓冲区”的内存偏移位置和长度。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些字段列信息和缓冲区是对成批记录中的字段列按照原有顺序进行深度优先遍历平铺得到的。例如，我们来看看如下 schema：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;col1: Struct&amp;amp;lt;a: Int32, b: List&amp;amp;lt;item: Int64&amp;amp;gt;, c: Float64&amp;amp;gt;
col2: Utf8&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其平铺版本如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;FieldNode 0: Struct name=&amp;amp;apos;col1&amp;amp;apos;
FieldNode 1: Int32 name=&amp;amp;apos;a&amp;amp;apos;
FieldNode 2: List name=&amp;amp;apos;b&amp;amp;apos;
FieldNode 3: Int64 name=&amp;amp;apos;item&amp;amp;apos;
FieldNode 4: Float64 name=&amp;amp;apos;c&amp;amp;apos;
FieldNode 5: Utf8 name=&amp;amp;apos;col2&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对应生成的缓冲区平铺序列，则如下所示（参考上面的表定义）：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;buffer 0: field 0 validity
buffer 1: field 1 validity
buffer 2: field 1 values
buffer 3: field 2 validity
buffer 4: field 2 offsets
buffer 5: field 3 validity
buffer 6: field 3 values
buffer 7: field 4 validity
buffer 8: field 4 values
buffer 9: field 5 validity
buffer 10: field 5 offsets
buffer 11: field 5 data&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Buffer&lt;/code&gt; 的 Flatbuffers 值描述了每块内存的位置和大小，按照前文定义的密封消息格式进行解析。&lt;/p&gt;
&lt;h3&gt;可变数量缓冲区（Variadic buffers）&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Arrow 列存格式 1.4 版本新增。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;诸如 Utf8View 这些类型，使用不定数量的缓冲区来表现。按照预先顺序拍平的逻辑 schema 中的这类字段列在 RecordBatch 的&lt;code&gt;variadicBufferCounts&lt;/code&gt; 属性中都对应一个值来表示当前 RecordBatch 中属于那个字段列的缓冲区的数量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;例如，来看看如下 schema：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;col1: Struct&amp;amp;lt;a: Int32, b: BinaryView, c: Float64&amp;amp;gt;
col2: Utf8View&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中有两个字段列是有可变数量缓冲区的，因此 RecordBatch 的 &lt;code&gt;variadicBufferCounts&lt;/code&gt; 属性中对应有2个值。若该 schema 的一个 RecordBatch 中 &lt;code&gt;variadicBufferCounts = [3, 2]&lt;/code&gt;，那么平铺的缓冲区序列如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;buffer 0:  col1    validity
buffer 1:  col1.a  validity
buffer 2:  col1.a  values
buffer 3:  col1.b  validity
buffer 4:  col1.b  views
buffer 5:  col1.b  data
buffer 6:  col1.b  data
buffer 7:  col1.b  data
buffer 8:  col1.c  validity
buffer 9:  col1.c  values
buffer 10: col2    validity
buffer 11: col2    views
buffer 12: col2    data
buffer 13: col2    data&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;压缩&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于成批记录的消息体缓冲区内容有3种压缩方式可选：不压缩、使用 &lt;code&gt;lz4&lt;/code&gt; 压缩、使用 &lt;code&gt;zstd&lt;/code&gt; 压缩。消息体中平铺的缓冲区序列，每个缓冲区需要使用相同的压缩编码方式单独压缩。压缩处理后的缓冲区序列中某些缓冲区可能没有被压缩（例如，某些缓冲区经压缩后其大小不会明显变小）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RecordBatch “消息头”中的 &lt;code&gt;compression&lt;/code&gt; 属性用于标记使用的压缩类型，该属性可选，默认值为不压缩。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对缓冲区进行压缩或不进行压缩，区别之处在：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果 &lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#ipc-recordbatch-message&quot;&apos;&gt;RecordBatch 消息&lt;/a&gt;中缓冲区经过压缩
&lt;ul&gt;&lt;li&gt;“消息头”中除了包含成批记录消息体中每个压缩过的缓冲区的大小和内存偏移量之外，还会包含使用的压缩类型。&lt;/li&gt;
&lt;li&gt;“消息体”包含经过压缩的缓冲区平铺序列，序列中每个缓冲区的起始8个字节存储缓冲区未经压缩时的长度，这个长度是小端字节序编码的64比特有符号整数。如果这个长度为 &lt;code&gt;-1&lt;/code&gt;，则表示当前 buffer 实际未经压缩。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;如果 &lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#ipc-recordbatch-message&quot;&apos;&gt;RecordBatch 消息&lt;/a&gt;中缓冲区未经压缩
&lt;ul&gt;&lt;li&gt;“消息头”中仅包含成批记录消息体中每个未经压缩缓冲区的大小和内存偏移量。&lt;/li&gt;
&lt;li&gt;“消息体”则简单地包含未经压缩缓冲区的平铺序列。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;&lt;a href=&apos;&quot;https://en.wikipedia.org/wiki/Endianness&quot;&apos;&gt;字节序&lt;/a&gt;&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Arrow 列存格式默认使用小端序字节编码。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Schema 序列化后的元数据中包含一个 &lt;code&gt;endianness&lt;/code&gt; 属性，表示成批记录使用哪种字节序编码。通常就是生成该 RecordBatch 的系统使用的字节序。该属性的主要用处是确保在使用相同字节序的系统之间传输成批记录数据。如果系统在读取 Schema 时发现字节序和自己不匹配，则应该报错。&lt;/p&gt;
&lt;h3&gt;IPC 流式编码格式&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们为成批记录序列提供了一种流式编码协议或者说“格式”，其表现为一个密封消息序列，每个密封消息都遵循前文所属的格式。流中，先放入 schema，后面放入的所有成批记录 schema 都是同一个。如果 schema 中任一字段列使用字典编码，那么流中会包含一个或多个 &lt;code&gt;DictionaryBatch&lt;/code&gt; 消息。&lt;code&gt;DictionaryBatch&lt;/code&gt; 消息和 &lt;code&gt;RecordBatch&lt;/code&gt; 消息可能会交织出现，但是 &lt;code&gt;RecordBatch&lt;/code&gt; 中使用的所有字典 id 都应该在其前面的 &lt;code&gt;DictionaryBatch&lt;/code&gt; 消息中定义好。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY k - 1&amp;amp;gt;
&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY x DELTA&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY y DELTA&amp;amp;gt;
...
&amp;amp;lt;RECORD BATCH n - 1&amp;amp;gt;
&amp;amp;lt;EOS [optional]: 0xFFFFFFFF 0x00000000&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;注解：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;字典和数据成批记录交织出现的规则有一个特殊情况 - 如果字典成批记录中的向量完全为空，那么数据列所使用的字典可能会出现首个数据成批记录的后面。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实现一个流读取器，在读取每条消息后，需要先读取接下来的8个字节来确定流是否继续以及下一条消息的元数据大小。一旦读到了消息的 flatbuffer 编码元数据，就可以继续读取消息体部分了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;流写入器，可以写入 4字节的再开始标识（&lt;code&gt;0xFFFFFFFF&lt;/code&gt;）拼接上4字节的元数据长度 0（&lt;code&gt;0x00000000&lt;/code&gt;） 来标识流结束（EOS），或者简单关闭流接口。对于流格式，我们推荐使用 “.arrows” 文件扩展名，虽然许多情况下流并不会存为文件。&lt;/p&gt;
&lt;h3&gt;IPC 文件格式&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们定义一种支持随机访问的“文件格式”，作为流式编码格式的一种扩展。文件的起始和末尾均是一个魔术字符串 &lt;code&gt;ARROW1&lt;/code&gt;(加上填充)。起始魔术字符串之后紧跟是流式编码格式的内容，之后在末尾魔术字符串之前，先写入一个尾部（footer） - 包含 schema（流式编码格式的一部分） 的一个拷贝，加上文件中每个数据块的内存偏移量和大小信息。这样就能够随机访问文件中的任一成批记录。可以查看 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/File.fbs&quot;&apos;&gt;File.fbs&lt;/a&gt; 文件了解文件尾部的定义细节。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;语义上，文件格式如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;magic number &amp;amp;quot;ARROW1&amp;amp;quot;&amp;amp;gt;
&amp;amp;lt;empty padding bytes [to 8 byte boundary]&amp;amp;gt;
&amp;amp;lt;STREAMING FORMAT with EOS&amp;amp;gt;
&amp;amp;lt;FOOTER&amp;amp;gt;
&amp;amp;lt;FOOTER SIZE: int32&amp;amp;gt;
&amp;amp;lt;magic number &amp;amp;quot;ARROW1&amp;amp;quot;&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个文件格式并不要求 &lt;code&gt;RecordBatch&lt;/code&gt; 中使用的字典 id 要定义在前面的 &lt;code&gt;DictionaryBatch&lt;/code&gt; 中，主要这些 id 定义在文件的某处即可。此外，每个字典 ID 如果存在多个非增量字典也是无效的（比如：不支持字典覆盖替换）。增量字典按照他们在文件尾部中出现的顺序应用生效。以这种格式创建的文件推荐使用 “.arrow” 文件扩展名。请注意这种格式创建的文件有时也被称为“Feature V2”，使用 “.feature” 文件扩展名，这个名称和扩展名源自“Feature （V1）” - Arrow 项目早期为 Python（Pandas） 和 R 语言的语言无关快速数据框（data frame）存储做的一个概念验证。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另附 - File.fbs 中 Footer 定义：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;include &amp;amp;quot;Schema.fbs&amp;amp;quot;;

namespace org.apache.arrow.flatbuf;

/// ----------------------------------------------------------------------
/// Arrow 文件元数据
///

table Footer {
  version: org.apache.arrow.flatbuf.MetadataVersion;
  schema: org.apache.arrow.flatbuf.Schema;
  dictionaries: [ Block ];
  recordBatches: [ Block ];
  /// 用户自定义元数据
  custom_metadata: [ KeyValue ];
}

struct Block {
  /// Index to the start of the RecordBlock (note this is past the Message header)
  offset: long;
  /// Length of the metadata
  metaDataLength: int;
  /// Length of the data (this is aligned so there can be a gap between this and
  /// the metadata).
  bodyLength: long;
}

root_type Footer;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;字典编码消息&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;字典是以成批记录序列的形式写入流或者文件格式的，其成批记录中仅包含单个字段列。因此，一个字典成批记录序列的完整语义 schema 包括所有字典带的 schema。所以必须先从字典成批记录的 schema 中读取字典类型信息，才能正确地对字典数据进行解析翻译：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;table DictionaryBatch {
  id: long;
  data: RecordBatch;
  isDelta: boolean = false;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;字典消息元数据中的字典 &lt;code&gt;id&lt;/code&gt; 可以在数据成批记录的 schema 中被多次引用，因此同一个字典可以被多个数据字段列使用。可以阅读&lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#dictionary-encoded-layout&quot;&apos;&gt;字典编码内存布局&lt;/a&gt;一节了解字典编码数据的语义。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;字典 &lt;code&gt;isDelta&lt;/code&gt; 标志位允许对前面存在的字典进行扩展，以便支持后续成批记录的解析。如果一个字典成批记录的 &lt;code&gt;isDelta&lt;/code&gt; 设置为真（true），则表示它的向量数据应该和前面同 id 的字典成批记录拼接在一起。假设对一列数据进行流式编码，该列数据为一个字符串列表 &lt;code&gt;[&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;A&amp;quot;]&lt;/code&gt;，其增量（delta）字典成批记录的形式可能如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;B&amp;amp;quot;
(2) &amp;amp;quot;C&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
0
1
2
1

&amp;amp;lt;DICTIONARY 0 DELTA&amp;amp;gt;
(3) &amp;amp;quot;D&amp;amp;quot;
(4) &amp;amp;quot;E&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 1&amp;amp;gt;
3
2
4
0
EOS&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;或者，如果 &lt;code&gt;isDelta&lt;/code&gt; 被设置为假（false），那么同 ID 的字典，后面的会覆盖替换前面的。同样使用如上的例子，对应编码形式可能如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;B&amp;amp;quot;
(2) &amp;amp;quot;C&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
0
1
2
1

&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;C&amp;amp;quot;
(2) &amp;amp;quot;D&amp;amp;quot;
(3) &amp;amp;quot;E&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 1&amp;amp;gt;
2
1
3
0
EOS&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2024-12-07</pubDate>
            <link>https://blog.xiayf.cn/posts/arrow-ipc.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/arrow-ipc.html</guid>
        </item>
        
        <item>
            <title>读码：LevelDB - 杂项</title>
            <description>&lt;h2&gt;10、其他&lt;/h2&gt;
&lt;h3&gt;10.1 Env&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 将 文件系统/时间/线程 等和底层系统相关的操作都抽象封装到 Env 类继承体系中，提升可移植性，默认提供对 Posix 兼容系统（Unix/Linux）的支持。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;Env* Env::Default() {  
  static PosixDefaultEnv env_container;  
  return env_container.env();  
}

// An implementation of Env that forwards all calls to another Env.  
// May be useful to clients who wish to override just part of the  
// functionality of another Env.  
class EnvWrapper : public Env {}
// A wrapper that allows injection of errors.  
class ErrorEnv : public EnvWrapper {}
class InMemoryEnv : public EnvWrapper {}
// Special Env used to delay background operations.  
class SpecialEnv : public EnvWrapper {
// Test Env to override default Env behavior for testing.  
class TestEnv : public EnvWrapper {

class PosixEnv : public Env {}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;10.2 文件锁&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 基于文件锁来防止多个进程打开同一个数据库。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;文件锁使用的文件名称为 &lt;code&gt;LOCK&lt;/code&gt;，对这个文件加锁成功之后，才能执行后续的逻辑。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;assert(db_lock_ == nullptr);
Status s = env_-&amp;amp;gt;LockFile(LockFileName(dbname_), &amp;amp;amp;db_lock_);  
if (!s.ok()) {  
  return s;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Lock the specified file.  Used to prevent concurrent access to  
// the same db by multiple processes.  On failure, stores nullptr in  
// *lock and returns non-OK.  
//  
// On success, stores a pointer to the object that represents the  
// acquired lock in *lock and returns OK.  The caller should call  
// UnlockFile(*lock) to release the lock.  If the process exits,  
// the lock will be automatically released.  
//  
// If somebody else already holds the lock, finishes immediately  
// with a failure.  I.e., this call does not wait for existing locks  
// to go away.  
//  
// May create the named file if it does not already exist.  
virtual Status LockFile(const std::string&amp;amp;amp; fname, FileLock** lock) = 0;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;原理参见：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;https://man7.org/linux/man-pages/man2/fcntl.2.html 的 “Advisory record locking” 部分&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.cnblogs.com/nufangrensheng/p/3554168.html&apos;&gt;高级 I/O 之记录锁&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;int LockOrUnlock(int fd, bool lock) {  
  errno = 0;  
  struct ::flock file_lock_info;  
  std::memset(&amp;amp;amp;file_lock_info, 0, sizeof(file_lock_info));  
  file_lock_info.l_type = (lock ? F_WRLCK : F_UNLCK);  
  file_lock_info.l_whence = SEEK_SET;  
  file_lock_info.l_start = 0;  
  file_lock_info.l_len = 0;  // Lock/unlock entire file.  
  return ::fcntl(fd, F_SETLK, &amp;amp;amp;file_lock_info);  
}&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;cat client 基于 flock 函数来实现文件锁（Open file description locks (non-POSIX)）。与 leveldb 采用的文件锁方式，区别见 fcntl 文档说明：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Open file description locks are advisory byte-range locks whose operation is in most respects identical to the traditional record locks described above.  This lock type is Linux-specific, and available since Linux 3.15.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;The principal difference between the two lock types is that whereas traditional record locks are associated with a process, open file description locks are associated with the open file description on which they are acquired, much like locks acquired with &lt;a href=&apos;https://man7.org/linux/man-pages/man2/flock.2.html&apos;&gt;flock(2)&lt;/a&gt;.  Consequently (and unlike traditional advisory record locks), open file description locks are inherited across &lt;a href=&apos;https://man7.org/linux/man-pages/man2/fork.2.html&apos;&gt;fork(2)&lt;/a&gt; (and &lt;a href=&apos;https://man7.org/linux/man-pages/man2/clone.2.html&apos;&gt;clone(2)&lt;/a&gt; with &lt;strong&gt;CLONE_FILES&lt;/strong&gt;), and are only automatically released on the last close of the open file description, instead of being released on any close of the file.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;...&lt;/p&gt;&lt;/blockquote&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// cat-client中文件锁的实现方式

try {
  lock_file_name_ = FLAGS_cat_multi_process ? std::to_string(getpid()) + FLAGS_cat_id_lock_file
                                            : FLAGS_cat_id_lock_file;

  file_lock_ = new FileLock(lock_file_name_);
  if (!file_lock_-&amp;amp;gt;TryLock()) {
    throw runtime_error(lock_file_name_ + &amp;amp;quot; is locked by another process&amp;amp;quot;);
  }
}
//
bool FileLock::TryLock() {
  //mode_t m = umask(0);
  fd_ = open(file_name_.c_str(), O_RDWR | O_CREAT, 0666);
  if (fd_ &amp;amp;gt;= 0 &amp;amp;amp;&amp;amp;amp; flock(fd_, LOCK_EX | LOCK_NB) &amp;amp;lt; 0) {
    close(fd_);
    fd_ = -1;
    return false;
  }
  return true;
}

bool FileLock::Unlock() {
  if (fd_ &amp;amp;lt; 0) {
    return true;
  }
  remove(file_name_.c_str());
  close(fd_);
  fd_ = -1;
  return true;
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;10.3 整数编码&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;定长编码比较简单，使用小端方式，将 32 比特整数拆成 4个 char 存储，将 64 比特整数拆成 8个char 存储。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/jNUdmrhJYcvGany.png&apos; title=&apos;leveldb-fixed-coding&apos; alt=&apos;leveldb-fixed-coding&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不定长编码稍微有点麻烦，每8个比特需要使用1个比特位来标识当前这个字节是否是最后一个字节，也就是 char 序列中，每个char 只有尾部7个比特用来存储部分值，头部1比特是状态位。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这意味着：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;无符号32比特整数，一旦大于 $2^{28}-1$，就需要5个字节来存储&lt;/li&gt;
&lt;li&gt;无符号64比特整数，一旦大于 $2^{56}-1$，就需要9个字节来存储&lt;/li&gt;
&lt;li&gt;从存储空间来看，就不划算了&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/cJgo1ABkU6nfhC5.png&apos; title=&apos;leveldb-varint-coding&apos; alt=&apos;leveldb-varint-coding&apos; width=&apos;800&apos;/&gt;
&lt;h3&gt;10.4 文件 ID&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除了 LOCK / CURRENT / LOG 文件，对于“ldb 数据文件”、“WAL log 文件”、“MANIFEST-版本变更日志文件”都使用整数 id 来命名(固定6个字符宽度)，比如 id 为 123，文件名形式如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ldb 数据文件：&lt;code&gt;000123.ldb&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;WAL log 文件：&lt;code&gt;000123.log&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MANIFEST-版本变更日志文件：&lt;code&gt;MANIFEST-000123&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;id 全局自增，统一分配：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Allocate and return a new file number  
uint64_t NewFileNumber() { return next_file_number_++; }&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样的好处在于，除非真的需要读取文件时，其他时候的逻辑对于同一种文件类型的不同文件都使用整数 id 来区分，排序/比较等处理逻辑效率更高。&lt;/p&gt;
&lt;h3&gt;10.5 Slice&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Slice&lt;/code&gt; is a simple structure that contains a length and a pointer to an external byte array. Returning a &lt;code&gt;Slice&lt;/code&gt; is a cheaper alternative to returning a &lt;code&gt;std::string&lt;/code&gt; since we do not need to copy potentially large keys and values. In addition, &lt;code&gt;leveldb&lt;/code&gt; methods do not return null-terminated C-style strings since &lt;code&gt;leveldb&lt;/code&gt; keys and values are allowed to contain &apos;\0&apos; bytes.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3&gt;10.6 编程技巧&lt;/h3&gt;
&lt;h4&gt;10.6.1 GUARDED_BY - 线程安全注解&lt;/h4&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;#ifndef GUARDED_BY  
#define GUARDED_BY(x) THREAD_ANNOTATION_ATTRIBUTE__(guarded_by(x))  
#endif&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;https://clang.llvm.org/docs/ThreadSafetyAnalysis.html&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;10.6.2 引用计数&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;类似 C++11 之后的共享指针，leveldb 对一些类使用引用计数来管理生命周期和资源释放。当一个对象的引用计数归0时，会删除自己（&lt;code&gt;delete this&lt;/code&gt;），触发析构函数，完成资源清理操作。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Increase reference count.  
void Ref() { ++refs_; }  
  
// Drop reference count.  Delete if no more references exist.  
void Unref() {  
  --refs_;  
  assert(refs_ &amp;amp;gt;= 0);  
  if (refs_ &amp;amp;lt;= 0) {  
    delete this;  
  }  
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;参考&amp;推荐&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://github.com/google/leveldb/blob/main/doc/index.md&apos;&gt;leveldb 说明文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://github.com/google/leveldb/blob/main/doc/impl.md&apos;&gt;leveldb 逻辑实现说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://github.com/google/leveldb/blob/main/doc/table_format.md&apos;&gt;leveldb ldb 数据文件编码格式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://github.com/google/leveldb/blob/main/doc/log_format.md&apos;&gt;leveldb WAL log 编码格式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://opendatastructures.org/newhtml/ods/latex-saved-html/skiplists.html&apos;&gt;Open Data Structures - Skiplists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/Bloom_filter&apos;&gt;Wikipedia - Bloom filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://man7.org/linux/man-pages/man2/fcntl.2.html&apos;&gt;fcntl(2) — Linux manual page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《The Linux Programming Interface》&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2024-11-23</pubDate>
            <link>https://blog.xiayf.cn/posts/leveldb-note-5.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/leveldb-note-5.html</guid>
        </item>
        
        <item>
            <title>读码：LevelDB - 增删改查</title>
            <description>&lt;h2&gt;9、增删改查&lt;/h2&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/9Gh1agVoq2x6pBU.png&apos; title=&apos;lsm&apos; alt=&apos;lsm&apos; width=&apos;800&apos;/&gt;
&lt;h3&gt;9.1 增删改&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 leveldb（lsm-tree 存储结构）来说，增改操作统一为 put 操作（改也是插入一条新记录），put 操作和删除操作又统一为 write 操作（删除是值为空的写入操作）。write 操作过程为&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先将操作记录（包括原始键值）写到 WAL log 文件&lt;/li&gt;
&lt;li&gt;2、将操作记录到内存中可变 Memtable 的跳表结构中&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;写入过程非常简单，所以 leveldb 的写入吞吐可以非常高。不过有3个性能调优点可以注意一下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、写入操作可以指定是同步的（sync）或者异步的，这里说的&lt;u&gt;同步异步是针对 WAL log 文件写入而言的&lt;/u&gt;，需要在吞吐性能和数据一致性之间做好平衡：
&lt;ul&gt;&lt;li&gt;如果写入操作指定为同步，那么将操作记录到 WAL log 文件后，还要&lt;u&gt;确保文件内容持久化到磁盘&lt;/u&gt;，这个持久化操作对 leveldb 的写入吞吐影响会比较大。&lt;/li&gt;
&lt;li&gt;如果写入操作指定为&lt;u&gt;非同步，那么对 WAL log 的文件写入，实际只是写到内核的文件缓冲区&lt;/u&gt;。如果写入操作记录到可变 Memtable 并返回写入成功状态给调用方后，内核缓冲区内容刷出到磁盘之前，系统 crash 或者机器掉电都会导致写入数据丢失，存在先写后读的一致性问题。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;2、leveldb 的实现中，可变 Memtable 对象和不可变 Memtable 对象均只有一个，并且 Memtable 对象的内存占用存在上限阈值，一旦可变 Memtable 写满且不可变 Memtable 还存在（还没来得及 minor compaction 成 $level_0$ 数据文件），那么写入就会被阻塞，那么：
&lt;ul&gt;&lt;li&gt;可以适当调大 Memtable 内存占用的上限阈值，但也不能调得很大，因为这会导致 compaction 压力会比较大，间接影响读/检索的性能：
&lt;ul&gt;&lt;li&gt;如果 $level_0$ 文件很多，来不及 major compaction，而这些文件的 key 区间又存在重合，就可能需要检索多个 $level_0$ 文件。&lt;/li&gt;
&lt;li&gt;major compaction 涉及较多的文件磁盘 I/O，从而可能影响检索时的文件读取。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;3、“不可变 Memtable 对象均只有一个” 如果调整 leveldb 实现支持存在多个 不可变 Memtable 对象，可能存在优化空间；compaction 目前是单线程处理的，如果调整成某种多线程实现，可能也存在优化空间，不过实现起来应该要复杂得多，并且磁盘 I/O 也容易成为检索性能退化的因素。&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/n1X4jVK9iztOBSJ.png&apos; title=&apos;IO-buffering&apos; alt=&apos;IO-buffering&apos; width=&apos;800&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图片摘自《The Linux Programming Interface》一书 244 页。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 WAL log 非同步写入，leveldb 会将内容先写到一块用户态内存缓冲区中，如果缓冲区满，则先调用 &lt;code&gt;write&lt;/code&gt; 系统调用将用户态缓冲区内容写到内核缓冲区（Kernel buffer cache），将内容的剩余部分继续写到用户态内存缓冲区后，就返回；&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果是同步写入，则会再将用户态缓冲区内容 &lt;code&gt;write&lt;/code&gt; 到内核缓冲区后，再调用 &lt;code&gt;fsync&lt;/code&gt; 系统调用，将内核缓冲区内容刷到磁盘。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3&gt;9.2 查/范围扫描&lt;/h3&gt;
&lt;h4&gt;9.2.1 快照/snapshot&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 中每个 Put/Delete 操作都被分配了一个序列号（SequenceNum），这个序列号是一种“Lamport 时钟” 或者说 “逻辑时间戳”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 支持对数据库做一个快照，这个快照操作非常轻量 - 就是最新分配分配序列号（LastSequence）。这个快照的含义：序列号小于等于LastSequence的操作都属于这个快照的，大于 LastSequence 的操作则不属于这个快照，是在这个快照发生之后发生的。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;const Snapshot* DBImpl::GetSnapshot() {  
  MutexLock l(&amp;amp;amp;mutex_);  
  return snapshots_.New(versions_-&amp;amp;gt;LastSequence());  
}

// Abstract handle to particular state of a DB.  
// A Snapshot is an immutable object and can therefore be safely  
// accessed from multiple threads without any external synchronization.  
class LEVELDB_EXPORT Snapshot {  
 protected:  
  virtual ~Snapshot();  
};

// Snapshots are kept in a doubly-linked list in the DB.  
// Each SnapshotImpl corresponds to a particular sequence number.  
class SnapshotImpl : public Snapshot {  
 public:  
  SnapshotImpl(SequenceNumber sequence_number)  
      : sequence_number_(sequence_number) {}  
  
  SequenceNumber sequence_number() const { return sequence_number_; }  
  
 private:   
  // SnapshotImpl is kept in a doubly-linked circular list. The SnapshotList  
  // implementation operates on the next/previous fields directly.  SnapshotImpl* prev_;  
  SnapshotImpl* next_;  
  
  const SequenceNumber sequence_number_;
};&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;DBImpl&lt;/code&gt; 对象的 &lt;code&gt;snapshots_&lt;/code&gt; 字段上维护着快照的链表，是避免 compaction 过程清除掉了快照依赖的键值数据。比如，假设一次快照的序列号为 123456，对于 UK 存在序列号 123455 和 序列号 123457 两次操作，对于这次快照而言，序列号 123457 的操作是不可见的，这个快照存在期间的 compaction 过程都需要同时保留 UK 的这两次操作。这个快照释放之后，compaction 就可以把序列号 123455 的操作清除掉。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，快照本身虽然很轻量，不过如果长时间不释放，会导致磁盘空间占用膨胀，对检索性能也会有一定的影响。&lt;/p&gt;
&lt;h4&gt;9.2.2 点查&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;指定 key 进行点查的逻辑顺序为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、从可变 Memtable 的跳表中查找，如果找到就返回给调用方（如果找到的是非删除记录，则返回序列号最大的那个记录的值，且返回状态为默认值“找到”，如果找到的是删除记录，则保留返回值为空，返回状态为“未找到”）&lt;/li&gt;
&lt;li&gt;2、1 中没找到，则继续从不可变 Memtable 的跳表中查找，如果找到就返回给调用方&lt;/li&gt;
&lt;li&gt;2、2 中没找到，则从 $level_0$ 开始依次逐层在数据文件中查找，
&lt;ul&gt;&lt;li&gt;因为 $level_0$ 数据文件的 key 区间可以存在重合，所以在 $level_0$ 层检索可能会涉及多个数据文件&lt;/li&gt;
&lt;li&gt;$level_1$~$level_n$ 数据文件的 key 区间不会重合，所以根据最新版本维护的对应层数据文件元信息列表找到目标数据文件即可，如果没找到，则到下一层继续检索&lt;/li&gt;
&lt;li&gt;找到目标数据文件后，先对索引块二分查找找到目标数据块，如果目标数据表是经过压缩的，则需要先经过解压，然后根据数据块中的重置位点列表信息，依次进行 delta 解码遍历&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;点查操作，可以指定一个之前获取的快照信息，如果没有指定，则默认使用最新分配的序列号作为快照，实际查找过程会&lt;u&gt;将快照中的序列号和存储记录中的序列号进行比较，序列号大于快照序列号的记录都会被忽略&lt;/u&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;查找键（LookupKey）的编码方式：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/RqzHL35VbtpE9DT.png&apos; title=&apos;lookup-key-encode&apos; alt=&apos;lookup-key-encode&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;与 Memtable 中跳表节点中的 Key 的编码的区别仅在于不包含 value 的长度和 value 值。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// A helper class useful for DBImpl::Get()  
class LookupKey {
public:
  // Initialize *this for looking up user_key at a snapshot with  
  // the specified sequence number.  
  LookupKey(const Slice&amp;amp;amp; user_key, SequenceNumber sequence);

  // Return a key suitable for lookup in a MemTable.  
  Slice memtable_key() const { return Slice(start_, end_ - start_); }

  // Return an internal key (suitable for passing to an internal iterator)  
  Slice internal_key() const { return Slice(kstart_, end_ - kstart_); }

  // Return the user key  
  Slice user_key() const { return Slice(kstart_, end_ - kstart_ - 8); }

private:
  // We construct a char array of the form:  
  //    klength  varint32               &amp;amp;lt;-- start_  
  //    userkey  char[klength]          &amp;amp;lt;-- kstart_  
  //    tag      uint64  
  //                                    &amp;amp;lt;-- end_  
  // The array is a suitable MemTable key.  
  // The suffix starting with &amp;amp;quot;userkey&amp;amp;quot; can be used as an InternalKey.  
  const char* start_;  
  const char* kstart_;  
  const char* end_;  
  char space_[200];  // Avoid allocation for short keys
}

LookupKey::LookupKey(const Slice&amp;amp;amp; user_key, SequenceNumber s) {  
  size_t usize = user_key.size();  
  size_t needed = usize + 13;  // A conservative estimate  
  char* dst;  
  if (needed &amp;amp;lt;= sizeof(space_)) {  
    dst = space_;  
  } else {  
    dst = new char[needed];  
  }  
  start_ = dst;  
  dst = EncodeVarint32(dst, usize + 8);  
  kstart_ = dst;  
  std::memcpy(dst, user_key.data(), usize);  
  dst += usize;  
  EncodeFixed64(dst, PackSequenceAndType(s, kValueTypeForSeek));  
  dst += 8;  
  end_ = dst;  
}

static uint64_t PackSequenceAndType(uint64_t seq, ValueType t) {  
  assert(seq &amp;amp;lt;= kMaxSequenceNumber);  
  assert(t &amp;amp;lt;= kValueTypeForSeek);  
  return (seq &amp;amp;lt;&amp;amp;lt; 8) | t;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;9.2.3 全库/范围有序扫描（遍历）&lt;/h4&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class DB {
public:
 // Return a heap-allocated iterator over the contents of the database.  
 // The result of NewIterator() is initially invalid (caller must  
 // call one of the Seek methods on the iterator before using it).  
 //  
 // Caller should delete the iterator when it is no longer needed.  
 // The returned iterator should be deleted before this db is deleted.  
 virtual Iterator* NewIterator(const ReadOptions&amp;amp;amp; options) = 0; // 接口
}

// 实现
Iterator* DBImpl::NewIterator(const ReadOptions&amp;amp;amp; options) {  
  SequenceNumber latest_snapshot;  
  uint32_t seed;  
  Iterator* iter = NewInternalIterator(options, &amp;amp;amp;latest_snapshot, &amp;amp;amp;seed);  
  return NewDBIterator(this, user_comparator(), iter,  
                       (options.snapshot != nullptr  
                            ? static_cast&amp;amp;lt;const SnapshotImpl*&amp;amp;gt;(options.snapshot)  
                                  -&amp;amp;gt;sequence_number()  
                            : latest_snapshot),  
                       seed);  
}

// 迭代器接口定义
class Iterator {
public:
  // An iterator is either positioned at a key/value pair, or  
  // not valid.  This method returns true iff the iterator is valid.  
  virtual bool Valid() const = 0;

  // Position at the first key in the source.  The iterator is Valid()  
  // after this call iff the source is not empty.  
  virtual void SeekToFirst() = 0;

  // Position at the last key in the source.  The iterator is  
  // Valid() after this call iff the source is not empty.  
  virtual void SeekToLast() = 0;

  // Position at the first key in the source that is at or past target.  
  // The iterator is Valid() after this call iff the source contains  
  // an entry that comes at or past target.  
  virtual void Seek(const Slice&amp;amp;amp; target) = 0;

  // Moves to the next entry in the source.  After this call, Valid() is  
  // true iff the iterator was not positioned at the last entry in the source.  
  // REQUIRES: Valid()  
  virtual void Next() = 0;  
  
  // Moves to the previous entry in the source.  After this call, Valid() is  
  // true iff the iterator was not positioned at the first entry in source.  
  // REQUIRES: Valid()  
  virtual void Prev() = 0;  
  
  // Return the key for the current entry.  The underlying storage for  
  // the returned slice is valid only until the next modification of  
  // the iterator.  
  // REQUIRES: Valid()  
  virtual Slice key() const = 0;  
  
  // Return the value for the current entry.  The underlying storage for  
  // the returned slice is valid only until the next modification of  
  // the iterator.  
  // REQUIRES: Valid() 
  virtual Slice value() const = 0;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有序遍历接口的使用方式为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、调用 NewIterator 接口获得迭代器对象指针 - &lt;code&gt;Iterator* iter&lt;/code&gt;，&lt;code&gt;options&lt;/code&gt; 参数中可以指定快照，如果未指定，则默认以最新分配的序列号为快照。&lt;/li&gt;
&lt;li&gt;2、调用 迭代器对象指针 的 Seek 相关接口，初始化遍历起始位置状态：
&lt;ul&gt;&lt;li&gt;SeekToFirst：不指定起始 key，从头部顺序遍历（不断调用 Next）&lt;/li&gt;
&lt;li&gt;SeekToLast：不指定起始 key，从尾部逆序遍历（不断调用 Prev）&lt;/li&gt;
&lt;li&gt;Seek：指定起始 key，从起始 key 开始顺序遍历（不断调用 Next）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;3、调用方根据迭代器的 &lt;code&gt;Valid()&lt;/code&gt; 方法返回判断是否遍历结束，或者根据最新遍历到的 key 值做判断是否要结束遍历。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有序（顺序）遍历的实现逻辑类似于 compaction 过程的 N 路归并算法，只不过 compaction 涉及的 level 层 和 level+1 层输入数据文件的 N 路归并排序，而有序遍历则涵盖“可变 memtable”/“不可变 memtable”/“$level_0$~$level_n$ 所有层数据文件”数据库完整状态：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先针对各部分数据创建各自的迭代器：
&lt;ul&gt;&lt;li&gt;“可变 memtable” 一个迭代器&lt;/li&gt;
&lt;li&gt;“不可变 memtable” 一个迭代器&lt;/li&gt;
&lt;li&gt;$level_0$ 层，因为不同文件的 key 区间可能会重合，所以一个文件一个迭代器&lt;/li&gt;
&lt;li&gt;$level_1$~$level_n$ 层，因为不同文件的 key 区间不会重合，所以一层一个迭代器，同一层的数据文件按照 key 区间从小到大排序后依次遍历即可&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2、SeekToFirst / Seek 的逻辑，即是让各个迭代器先各自进行 SeekToFirst / Seek，然后对这些迭代器的读到的首个元素进行比较，获得最小的那个记录&lt;/li&gt;
&lt;li&gt;3、Next 的逻辑，让上次取得最小元素的那个迭代器先 Next 一次，然后对这些迭代器的读到的首个元素进行比较，获得最小的那个记录&lt;/li&gt;
&lt;li&gt;4、对于 2/3 中取到的最小记录，因为存在快照约束以及同一个 key 可能存在多次写入（Put 或 Delete），所以需要：
&lt;ul&gt;&lt;li&gt;跳过序列号大于快照序列号的记录&lt;/li&gt;
&lt;li&gt;同一个 key：如果最后一次写入是 Delete 操作，则跳过该 key 的所有记录；如果最后一次写入是 Put 操作，则跳过最后一次之前的所有记录；从而确保同一个 key 只会遍历返回最新有效的记录。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/5yrW6aOe7q1Iz2F.png&apos; title=&apos;leveldb-db-iterator&apos; alt=&apos;leveldb-db-iterator&apos; width=&apos;830&apos;/&gt;
&lt;h3&gt;9.4 表缓存 &amp; 块缓存&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多线程并发对 leveldb 数据库检索（点查/有序遍历）时，有一些数据文件会被频繁访问（多线程之间以及时序上），将这些文件的句柄以及数据索引等元信息缓存起来进行复用，可以提高检索性能，降低资源消耗。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，按照 ldb 文件“块”格式，数据块内容写入文件之前可以先进行压缩，可能存在一些热点数据块，如果每次检索都根据索引&lt;u&gt;从文件中读取数据块并解压&lt;/u&gt;再做进一步查找，对性能和资源开销影响会比较大，所以也可以在数据块级别做缓存。&lt;/p&gt;
&lt;h4&gt;9.4.1 TableCache - 表缓存&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 中存在两类表/Table，逻辑含义是一致，不过指代的东西不一样：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;MemTable 中的跳表&lt;/li&gt;
&lt;li&gt;一个 ldb 数据文件打开后关联的内存对象，方便检索&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;TableCache 是对“一个 ldb 数据文件打开后关联的内存对象”进行缓存 - 缓存的键为 ldb 数据文件的 id，值为 ldb 数据文件的 Table 对象。实际的缓存实现采用分片/分段 LRU 缓存，提升并发插入/淘汰能力。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 实例在版本信息中维护了所有 level ldb 数据文件的元信息 - key 区间最大值最小值、数据文件的 id 等。检索时，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先根据 key 匹配到目标数据文件的元信息&lt;/li&gt;
&lt;li&gt;2、根据元信息中的数据文件 id，去 TableCache 中查找对应的 Table 对象，如果不存在，则先打开数据文件，读取解析 footer / index / meta / meta index 这些索引信息，准备好 Table 对象，缓存到 TableCache 中&lt;/li&gt;
&lt;li&gt;3、基于 Table 对象继续进行数据文件内的检索流程&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;../plantuml-images/14785157947115067530.svg&apos; title=&apos;14785157947115067530&apos; alt=&apos;14785157947115067530&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 默认参数支持缓存 990 个 Table，ShardedLRUCache 默认分片数为 16，按照公式计算，每个分片支持 缓存 62 个 Table。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;struct Options {
  // 省略
  // Number of open files that can be used by the DB.  You may need to  
  // increase this if your database has a large working set (budget  
  // one open file per 2MB of working set).  
  int max_open_files = 1000;
  // 省略
}

const int kNumNonTableCacheFiles = 10;

static int TableCacheSize(const Options&amp;amp;amp; sanitized_options) {  
  // Reserve ten files or so for other uses and give the rest to TableCache.  
  return sanitized_options.max_open_files - kNumNonTableCacheFiles;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;explicit ShardedLRUCache(size_t capacity) : last_id_(0) {  
  const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards;  
  for (int s = 0; s &amp;amp;lt; kNumShards; s++) {  
    shard_[s].SetCapacity(per_shard);  
  }  
}&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;9.4.2 BlockCache - 块缓存&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;BlockCache 的缓存实现方案，可以由调用方实现，并在打开 leveldb 数据库时在 Options 参数中指定。如果没有设置，则默认使用和 TableCache 一样的缓存实现 - ShardedLRUCache，可缓存的 key 数量为 &lt;code&gt;8 &amp;lt;&amp;lt; 20&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并且需要在检索时的 ReadOptions 参数中指定启用块缓存（默认是启用），才会将块缓存中找不到的数据块读取后插入缓存中。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Should the data read for this iteration be cached in memory?  
// Callers may wish to set this field to false for bulk scans.  
bool fill_cache = true;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;块缓存使用的键为 “缓存 id” 拼接上 数据块在文件中的偏移位置：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;char cache_key_buffer[16];  
EncodeFixed64(cache_key_buffer, table-&amp;amp;gt;rep_-&amp;amp;gt;cache_id);  
EncodeFixed64(cache_key_buffer + 8, handle.offset());  
Slice key(cache_key_buffer, sizeof(cache_key_buffer));  
cache_handle = block_cache-&amp;amp;gt;Lookup(key);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“缓存 id” 和 Table 对象关联，不同 Table 对象的“缓存 id” 不同，所以“缓存 id” 用于在同一个缓存中区分不同数据文件的数据块。ShardedLRUCache 缓存实现以递增整数的方式分配“缓存 id”：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;uint64_t NewId() override {  
  MutexLock l(&amp;amp;amp;id_mutex_);  
  return ++(last_id_);  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;compaction 过程会对输入数据文件进行遍历，并且使用的也是同一个 TableCache 实例和各个 Table 实例，如果这个过程也启用块缓存，则会导致大量非热点的数据块缓存起来，对正常检索造成干扰。所以 &lt;u&gt;compaction 过程会将 fill_cache 设置为 false，关闭 compaction 输入遍历的块缓存&lt;/u&gt;。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Control over blocks (user data is stored in a set of blocks, and  
// a block is the unit of reading from disk).  
  
// If non-null, use the specified cache for blocks.  
// If null, leveldb will automatically create and use an 8MB internal cache.  
Cache* block_cache = nullptr;  
  
// Approximate size of user data packed per block.  Note that the  
// block size specified here corresponds to uncompressed data.  The  
// actual size of the unit read from disk may be smaller if  
// compression is enabled.  This parameter can be changed dynamically.  
size_t block_size = 4 * 1024;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;9.4.3 ShardedLRUCache&lt;/h4&gt;
&lt;img src=&apos;../plantuml-images/3428327419156852348.svg&apos; title=&apos;3428327419156852348&apos; alt=&apos;3428327419156852348&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;HandleTable 是一个“链接法（chaining）” 实现的哈希表，默认初始化 4 个 buckets，每个 bucket 初始值为空指针，指针类型为 &lt;code&gt;LRUHandle*&lt;/code&gt;，即哈希表节点类型。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;HandleTable 中：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;length_&lt;/code&gt;：表示哈希表的当前容量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;elems_&lt;/code&gt;：表示当前哈希表中存储的元素/节点个数，如果 &lt;code&gt;elems_&lt;/code&gt; 超过 &lt;code&gt;length_&lt;/code&gt;，则按当前容量的2倍扩容。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;list_&lt;/code&gt;：即 bucket 数组。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;LRUHandle 中：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;next_hash&lt;/code&gt; 字段：指向当前节点所在 bucket 链表的下一个节点&lt;/li&gt;
&lt;li&gt;&lt;code&gt;next&lt;/code&gt; &amp; &lt;code&gt;pre&lt;/code&gt; 字段：指向节点在 LRU 链表中的前置节点和后置节点&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hash&lt;/code&gt; 字段：存储 key 的哈希值，用于加速在 bucket 链表中遍历查找过程&lt;/li&gt;
&lt;li&gt;&lt;code&gt;refs&lt;/code&gt;：节点自己的引用计数，初始化时会设置为 1，表示被缓存引用；调用方从缓存中获取到这个节点时，计数会加1；调用方不再使用时会调用 &lt;code&gt;ShardedLRUCache::Release&lt;/code&gt; -&gt; &lt;code&gt;LRUCache::Release&lt;/code&gt; -&gt; &lt;code&gt;LRUCache::Unref&lt;/code&gt; 将计数减1，如果引用计数重新变为1，则表示当前这个节点没有任何调用方在使用，仅缓存持有引用。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;ShardedLRUCache 是一个多分片的 LRU 缓存实现，默认16个分片，通过分段锁来减少并发冲突，提升性能。LRU 缓存的检索(Lookup)或插入(Insert)，都先计算 key 的哈希值，将哈希值的头部4个比特的值作为分片 id，然后在目标分片 LRU 缓存中检索或插入。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;LRUCache 是实际的 LRU 缓存实现，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;HandleTable table_&lt;/code&gt;： 实际存放缓存项的哈希表。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LRUHandle in_use_&lt;/code&gt;：如果一个缓存项被某个调用方引用（refs &gt; 1），则会被放入 &lt;code&gt;in_use_&lt;/code&gt; 链表中。这些缓存项不会被 LRU 回收，对于调用方来说是内存安全的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LRUHandle lru_&lt;/code&gt;：如果一个缓存项（LRUHandle）不再被任何调用方引用（refs=1），则将从 &lt;code&gt;in_use_&lt;/code&gt; 链表中移除，被放入 &lt;code&gt;lru_&lt;/code&gt; 双向链表中：
&lt;ul&gt;&lt;li&gt;这些缓存项还被缓存引用，存在 &lt;code&gt;table_&lt;/code&gt; 中&lt;/li&gt;
&lt;li&gt;最新放入的放在队尾 - 这意味着对头的缓存项是最久未被使用的，当缓存项数量超额时，则从 &lt;code&gt;lru_&lt;/code&gt; 链表的头部开始逐个缓存项回收&lt;/li&gt;
&lt;li&gt;如果其中的缓存项后来被调用方再次检索引用，则会从 &lt;code&gt;lru_&lt;/code&gt; 中移除，重新放到 &lt;code&gt;in_use_&lt;/code&gt; 队尾&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Dummy head of LRU list.  
// lru.prev is newest entry, lru.next is oldest entry.  
// Entries have refs==1 and in_cache==true.  
LRUHandle lru_ GUARDED_BY(mutex_);  
  
// Dummy head of in-use list.  
// Entries are in use by clients, and have refs &amp;amp;gt;= 2 and in_cache==true.  
LRUHandle in_use_ GUARDED_BY(mutex_);  
  
HandleTable table_ GUARDED_BY(mutex_);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;LRU 缓存的常规使用方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先从缓存中检索（Lookup），如果未检索到，则：&lt;/li&gt;
&lt;li&gt;2、准备好缓存的键值，插入缓存（Insert），得到缓存项&lt;/li&gt;
&lt;li&gt;3、使用完缓存项后，释放引用（Release）&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lookup 过程 - 如果 HandleTable 哈希表中检索到：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果缓存项的引用计数为 1，表示当前缓存项仅被 LRU 缓存引用，挂接在 &lt;code&gt;lru_&lt;/code&gt; 链表上，所以将当前缓存项从 &lt;code&gt;lru_&lt;/code&gt; 链表上摘除，挂接到 &lt;code&gt;in_use_&lt;/code&gt; 链表队尾，并将引用计数加1&lt;/li&gt;
&lt;li&gt;否则将引用计数加1 即可&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Insert 过程 -&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、构建缓存项 - 申请内存，设置各个字段的值，引用计数设置为 1（Insert 会把缓存项返回给调用方使用）。&lt;/li&gt;
&lt;li&gt;2、将缓存项引用计数加1，并挂接到 &lt;code&gt;in_use_&lt;/code&gt; 的队尾。&lt;/li&gt;
&lt;li&gt;3、将缓存项插入 HandleTable 哈希表。如果哈希表中已存在相同的 key，则还需要释放缓存自己对原有缓存项的引用。&lt;/li&gt;
&lt;li&gt;4、如果缓存项数量超额，则从 &lt;code&gt;lru_&lt;/code&gt; 链表的头部开始逐个回收缓存项（因为这些缓存项仅被缓存自己引用，所以可以安全地进行内存回收），直到缓存项数量未超额。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Release 的过程 -&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、将缓存项的引用计数减1。&lt;/li&gt;
&lt;li&gt;2、将缓存项从 &lt;code&gt;in_use_&lt;/code&gt; 链表中摘除，挂接到 &lt;code&gt;lru_&lt;/code&gt; 链表队尾。&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;9.5、过滤策略-布隆过滤器&lt;/h3&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/If15V9oNdJHp8kW.png&apos; title=&apos;Bloom_filter_speed&apos; alt=&apos;Bloom_filter_speed&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;过滤器匹配返回 false，就一定不在存储中；如果返回 true，有小概率不对（false positive）&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;img src=&apos;../plantuml-images/9237803061677223425.svg&apos; title=&apos;9237803061677223425&apos; alt=&apos;9237803061677223425&apos;/&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class FilterPolicy {
public:  
 virtual ~FilterPolicy();  
  
 // Return the name of this policy.  Note that if the filter encoding  
 // changes in an incompatible way, the name returned by this method
 // must be changed.  Otherwise, old incompatible filters may be
 // passed to methods of this type.
 virtual const char* Name() const = 0;  
  
 // keys[0,n-1] contains a list of keys (potentially with duplicates)  
 // that are ordered according to the user supplied comparator.
 // Append a filter that summarizes keys[0,n-1] to *dst.
 //
 // Warning: do not change the initial contents of *dst.  Instead,
 // append the newly constructed filter to *dst.
 virtual void CreateFilter(const Slice* keys, int n,  
                           std::string* dst) const = 0;  
  
 // &amp;amp;quot;filter&amp;amp;quot; contains the data appended by a preceding call to  
 // CreateFilter() on this class.  This method must return true if
 // the key was in the list of keys passed to CreateFilter().
 // This method may return true or false if the key was not on the
 // list, but it should aim to return false with a high probability.
 virtual bool KeyMayMatch(const Slice&amp;amp;amp; key, const Slice&amp;amp;amp; filter) const = 0;
}

// Return a new filter policy that uses a bloom filter with approximately  
// the specified number of bits per key.  A good value for bits_per_key  
// is 10, which yields a filter with ~ 1% false positive rate.  
//  
// Callers must delete the result after any database that is using the  
// result has been closed.  
//  
// Note: if you are using a custom comparator that ignores some parts  
// of the keys being compared, you must not use NewBloomFilterPolicy()  
// and must provide your own FilterPolicy that also ignores the  
// corresponding parts of the keys.  For example, if the comparator  
// ignores trailing spaces, it would be incorrect to use a  
// FilterPolicy (like NewBloomFilterPolicy) that does not ignore  
// trailing spaces in keys.
const FilterPolicy* NewBloomFilterPolicy(int bits_per_key);&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;static uint32_t BloomHash(const Slice&amp;amp;amp; key) {  
  return Hash(key.data(), key.size(), 0xbc9f1d34);  
}  
  
class BloomFilterPolicy : public FilterPolicy {  
 public:  
  explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key) {  
    // We intentionally round down to reduce probing cost a little bit 
    /* llama3：
    在Bloom过滤器中，哈希函数次数 k 是一个重要参数，它决定了过滤器的大小和精度。一般来说，k越大，过滤器越大，但也越准确；反之，k越小，过滤器越小，但也越不准确。
    在这个实现中，乘以 0.69 的目的是为了计算出一个合适的 k 值，使得过滤器的大小和精度达到一个平衡。具体来说，乘以 0.69 是为了将 bits_per_key 值乘以一个较小的倍数，从而得到一个较小的 k 值。
    好处是：
	1、减少过滤器大小：通过乘以 0.69，可以得到一个较小的 k 值，这意味着过滤器的大小也会相应减小。这对于存储和传输过滤器来说是一个重要的考虑因素。
	2、提高匹配效率：虽然较小的 k 值可能导致过滤器不准确，但在实际应用中，这个影响往往是可以接受的。因为匹配效率会大幅提高，特别是在过滤器大小相对较小时。
	3、平衡精度和大小：乘以 0.69 的方法可以帮助找到一个合适的 k 值，使得过滤器的大小和精度达到一个平衡。这对于实际应用来说非常重要，因为它可以确保过滤器既能准确又能高效。
    */
    k_ = static_cast&amp;amp;lt;size_t&amp;amp;gt;(bits_per_key * 0.69);  // 0.69 =~ ln(2)  
    if (k_ &amp;amp;lt; 1) k_ = 1;  
    if (k_ &amp;amp;gt; 30) k_ = 30;  
  }  
  
  const char* Name() const override { return &amp;amp;quot;leveldb.BuiltinBloomFilter2&amp;amp;quot;; }  
  
  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {  
    // Compute bloom filter size (in both bits and bytes)  
    size_t bits = n * bits_per_key_;  
  
    // For small n, we can see a very high false positive rate.  Fix it  
    // by enforcing a minimum bloom filter length.
    if (bits &amp;amp;lt; 64) bits = 64;  
  
    size_t bytes = (bits + 7) / 8;  
    bits = bytes * 8;  
  
    const size_t init_size = dst-&amp;amp;gt;size();  
    dst-&amp;amp;gt;resize(init_size + bytes, 0);  
    dst-&amp;amp;gt;push_back(static_cast&amp;amp;lt;char&amp;amp;gt;(k_));  // Remember # of probes in filter  
    char* array = &amp;amp;amp;(*dst)[init_size];  
    for (int i = 0; i &amp;amp;lt; n; i++) {  
      // Use double-hashing to generate a sequence of hash values.  
      // See analysis in [Kirsch,Mitzenmacher 2006].
      uint32_t h = BloomHash(keys[i]);  
      const uint32_t delta = (h &amp;amp;gt;&amp;amp;gt; 17) | (h &amp;amp;lt;&amp;amp;lt; 15);  // Rotate right 17 bits  
      for (size_t j = 0; j &amp;amp;lt; k_; j++) {  // 算 k_ 次哈希以及设置 k_ 个比特位
        const uint32_t bitpos = h % bits;  
        // 第几个字节？bitpos / 8
        // 目标字节中的第几个比特？ bitpos % 8
        array[bitpos / 8] |= (1 &amp;amp;lt;&amp;amp;lt; (bitpos % 8));  
        h += delta;  // 每次哈希值有变化
      }  
    }  
  }  
  
  bool KeyMayMatch(const Slice&amp;amp;amp; key, const Slice&amp;amp;amp; bloom_filter) const override {  
    const size_t len = bloom_filter.size();  
    if (len &amp;amp;lt; 2) return false;  
  
    const char* array = bloom_filter.data();  
    const size_t bits = (len - 1) * 8;  
  
    // Use the encoded k so that we can read filters generated by  
    // bloom filters created using different parameters.
    const size_t k = array[len - 1];  
    if (k &amp;amp;gt; 30) {  
      // Reserved for potentially new encodings for short bloom filters.  
      // Consider it a match.
      return true;  
    }  
  
    uint32_t h = BloomHash(key);  
    const uint32_t delta = (h &amp;amp;gt;&amp;amp;gt; 17) | (h &amp;amp;lt;&amp;amp;lt; 15);  // Rotate right 17 bits  
    for (size_t j = 0; j &amp;amp;lt; k; j++) {  
      const uint32_t bitpos = h % bits;  
      if ((array[bitpos / 8] &amp;amp;amp; (1 &amp;amp;lt;&amp;amp;lt; (bitpos % 8))) == 0) return false;  // 任一比特位不匹配，就算不匹配。
      h += delta;  
    }  
    return true;  
  }  
  
 private:  
  size_t bits_per_key_;  
  size_t k_;  
};&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;const int32_t KEY_VALIDATOR_BYTE_SIZE = 128 * 1024 * 1024;  // 128M
const uint64_t KEY_VALIDATOR_VALUE_MASK = 0x3fffffff;  // 30bit
const uint64_t KEY_VALIDATOR_BIT_MASK = 0x07;  
const uint8_t KEY_VALIDATOR_ONE = 1;

const uint8_t KEY_VALIDATOR_LOCK_COUNT = 32;
const uint8_t KEY_VALIDATOR_LOCK_MASK = KEY_VALIDATOR_LOCK_COUNT - 1;

class KeyValidator {
public:
    static KeyValidator&amp;amp;amp; Instance() {
        static KeyValidator instance;
        return instance;
    }

    ~KeyValidator() {
        if (bitmap_data_) {
            delete [] bitmap_data_;
            bitmap_data_ = nullptr;
        }
    }

    bool IsInitialized() {
        return (bitmap_data_ != nullptr);
    }

    bool Init() {
        if (!bitmap_data_) {
            bitmap_data_ = new uint8_t[KEY_VALIDATOR_BYTE_SIZE];
        }
        std::memset(bitmap_data_, 0, KEY_VALIDATOR_BYTE_SIZE);
        // need to catch bad_alloc ?
        LOG(WARNING) &amp;amp;lt;&amp;amp;lt; &amp;amp;quot;KeyValidator initialized succ.&amp;amp;quot;;
        return true;
    }

    bool Update(uint64_t key_id) {
        if (!bitmap_data_) {
            LOG(ERROR) &amp;amp;lt;&amp;amp;lt; &amp;amp;quot;bitmap_data not initialized!&amp;amp;quot;;
            return false;
        }
        uint64_t byte_index = 0;
        uint8_t bit_mask = 0;
        GetByteIndex(key_id, byte_index, bit_mask);
        // lock to ensure multi-thread write
        auto&amp;amp;amp; lock = spin_locks[byte_index &amp;amp;amp; KEY_VALIDATOR_LOCK_MASK];
        lock.Lock();
        bitmap_data_[byte_index] |= bit_mask;
        lock.UnLock();
        return true;
    }

    bool IsValid(uint64_t key_id) {
        if (!bitmap_data_) {
            LOG(ERROR) &amp;amp;lt;&amp;amp;lt; &amp;amp;quot;bitmap_data not initialized!&amp;amp;quot;;
            return false;
        }
        uint64_t byte_index = 0;
        uint8_t bit_mask = 0;
        GetByteIndex(key_id, byte_index, bit_mask);
        return (bitmap_data_[byte_index] &amp;amp;amp; bit_mask);
    }


    bool GetValidKeys(const std::vector&amp;amp;lt;int64_t&amp;amp;gt;&amp;amp;amp; key_list,
                std::vector&amp;amp;lt;int64_t&amp;amp;gt;&amp;amp;amp; result) {
        result.clear();
        result.reserve(key_list.size());
        for (auto&amp;amp;amp; key_id : key_list) {
            if (IsValid(key_id)) {
                result.push_back(key_id);
            }
        }
        return true;
    }

private:
    uint8_t* bitmap_data_ = nullptr;
    std::vector&amp;amp;lt;psarlib::synchronization::SpinLock&amp;amp;gt; spin_locks;

    KeyValidator()
    : spin_locks(KEY_VALIDATOR_LOCK_COUNT) {}

    void GetByteIndex(uint64_t key_id, uint64_t&amp;amp;amp; byte_index, uint8_t&amp;amp;amp; bit_mask) {
        auto value = key_id &amp;amp;amp; KEY_VALIDATOR_VALUE_MASK;
        byte_index = value &amp;amp;gt;&amp;amp;gt; 3;                          // divide by 8
        auto bit_index = value &amp;amp;amp; KEY_VALIDATOR_BIT_MASK;  // mod by 8
        bit_mask = (KEY_VALIDATOR_ONE &amp;amp;lt;&amp;amp;lt; bit_index);
    }
};&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;&lt;ol&gt;&lt;li id=&quot;fn:1&quot;&gt;&lt;p&gt;&lt;a href=&apos;https://hur.st/bloomfilter/&apos;&gt;Bloom Filter Calculator&lt;/a&gt;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</description>
            <pubDate>2024-11-20</pubDate>
            <link>https://blog.xiayf.cn/posts/leveldb-note-4.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/leveldb-note-4.html</guid>
        </item>
        
        <item>
            <title>读码：LevelDB - Compaction 流程</title>
            <description>&lt;h2&gt;6、$level_0$ &amp; $level_1$~$level_n$&lt;/h2&gt;
&lt;h3&gt;6.1 $level_0$&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$level_0$ ldb 数据文件，是将内存中不可变 memtable 的数据落到磁盘生成的。&lt;strong&gt;这些数据文件的 key 范围会有重合&lt;/strong&gt;。leveldb 会记录每个 ldb 文件对应的 key 最小值和最大值等元信息。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class Version {
private:
  // List of files per level  
  std::vector&amp;amp;lt;FileMetaData*&amp;amp;gt; files_[config::kNumLevels];
}

struct FileMetaData {  
  FileMetaData() : refs(0), allowed_seeks(1 &amp;amp;lt;&amp;amp;lt; 30), file_size(0) {}  
  
  int refs;  
  int allowed_seeks;  // Seeks allowed until compaction  
  uint64_t number;  
  uint64_t file_size;    // File size in bytes  
  InternalKey smallest;  // Smallest internal key served by table  
  InternalKey largest;   // Largest internal key served by table  
};&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$level_0$ ldb 文件的数据内容源自：遍历“不可变 memtable” 中跳表的 $L_0$ 层节点，插入“data 块”。跳表的 $L_0$ 层节点链表本就是有序的，第一个节点的 key 即为 最小 key，最后一个节点的 key 即为 最大 key。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Get key 检索时，对于 $level_0$ 层，先对所有 ldb 文件的最小 key 最大 key 进行比较，匹配到所有目标 ldb 文件，并按文件 id 序号从大到小排序（&lt;u&gt;文件 id 序号越大，说明文件越新&lt;/u&gt;），从最新的目标 ldb 文件开始检索，找到了就返回。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了保障检索效率，leveldb 会通过 major compaction 过程尽量控制住 level0 的文件数：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果$level_0$ 文件数超过 kL0_CompactionTrigger（=4），就可以触发 compaction。&lt;/li&gt;
&lt;li&gt;如果 $level_0$ 文件数超过 kL0_SlowdownWritesTrigger（=8），就会对写入进行限速和攒批。&lt;/li&gt;
&lt;li&gt;如果 $level_0$ 文件数超过 kL0_StopWritesTrigger（=12），写入就会停顿，等待 compaction。&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;6.2 $level_1$~$level_n$&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$level_1$~$level_n$ 的数据文件是从 $level_0$ 开始逐层 compaction 而来，这些文件：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;同一层内的文件之间 key 的区间不会出现重合，这样可以减少磁盘读取，提升检索效率；不同层的文件之间 key 区间可以重合。 &lt;u&gt;compaction 的逻辑需要保障这个性质&lt;/u&gt;。&lt;/li&gt;
&lt;li&gt;$level_k$ 文件的内容一定比 $level_{k-1}$ 文件的内容旧，所以如果在 $level_{k-1}$ 层检索有了结果，就不必到 $level_k$ 层检索。&lt;/li&gt;
&lt;li&gt;在 compaction 过程中对于同一个 key 会尽可能丢掉旧的键值数据，以此，减少磁盘占用，提升检索效率。&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;7、Compaction&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;compaction 过程，作为任务，由一个独立的后台线程来执行。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;compaction 主要分两 2 种：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、“minor compaction” - 内存中的 “不可变 memtable” 转存到 $level_0$ 文件。这个 compaction 优先级更高，所以一旦检测到存在“不可变 memtable”就优先处理。&lt;/li&gt;
&lt;li&gt;2、“major compaction” - $level_0$ ~ $level_n$ 逐层之间的 compaction。其中 $level_0$ 与 $level_1$ ~ $level_n$ 不同，$level_0$ 数据文件之间 key 区间存在重合，处理逻辑上存在特殊之处。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“minor compaction” 流程比较简单直接，后续不细说。&lt;/p&gt;
&lt;h3&gt;7.1 major compaction 触发条件&lt;/h3&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// We prefer compactions triggered by too much data in a level over  
// the compactions triggered by seeks.  
const bool size_compaction = (current_-&amp;amp;gt;compaction_score_ &amp;amp;gt;= 1);  
const bool seek_compaction = (current_-&amp;amp;gt;file_to_compact_ != nullptr);&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;void VersionSet::Finalize(Version* v) {  
  // Precomputed best level for next compaction  
  int best_level = -1;  
  double best_score = -1;  
  
  for (int level = 0; level &amp;amp;lt; config::kNumLevels - 1; level++) {  
    double score;  
    if (level == 0) {  
      // We treat level-0 specially by bounding the number of files  
      // instead of number of bytes for two reasons:
      // 
      // (1) With larger write-buffer sizes, it is nice not to do too
      // many level-0 compactions.
      //
      // (2) The files in level-0 are merged on every read and
      // therefore we wish to avoid too many files when the individual
      // file size is small (perhaps because of a small write-buffer
      // setting, or very high compression ratios, or lots of
      // overwrites/deletions).
      score = v-&amp;amp;gt;files_[level].size() /  
              static_cast&amp;amp;lt;double&amp;amp;gt;(config::kL0_CompactionTrigger);  
    } else {  
      // Compute the ratio of current size to size limit.  
      const uint64_t level_bytes = TotalFileSize(v-&amp;amp;gt;files_[level]);  
      score =  
          static_cast&amp;amp;lt;double&amp;amp;gt;(level_bytes) / MaxBytesForLevel(options_, level);  
    }  
  
    if (score &amp;amp;gt; best_score) {  
      best_level = level;  
      best_score = score;  
    }  
  }  
  
  v-&amp;amp;gt;compaction_level_ = best_level;  
  v-&amp;amp;gt;compaction_score_ = best_score;  
}

static double MaxBytesForLevel(const Options* options, int level) {  
  // Note: the result for level zero is not really used since we set  
  // the level-0 compaction threshold based on number of files.  
  // Result for both level-0 and level-1
  double result = 10. * 1048576.0;  
  while (level &amp;amp;gt; 1) {  
    result *= 10;  
    level--;  
  }  
  return result;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 打开/初始化期间或者每次 compaction 结束时都会计算下次 compaction 最应该处理的哪个 level 的数据文件以及紧迫程度（&lt;code&gt;compaction_score_&lt;/code&gt;），不过对于 $level_0$ 和 其他 level 的计算逻辑有区别：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、$level_0$ compaction 紧迫程度，取决于文件数和 compaction 阈值（kL0_CompactionTrigger = 4）的倍数&lt;/li&gt;
&lt;li&gt;2、其他 level 则取决于文件占用的存储空间和阈值的倍数，level 越大，阈值越大 - $level_1$ 阈值为 &lt;code&gt;10. * 1048576.0&lt;/code&gt; 字节（10MB），相邻层之间的阈值为 10 倍关系。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;bool Version::UpdateStats(const GetStats&amp;amp;amp; stats) {  
  FileMetaData* f = stats.seek_file;  
  if (f != nullptr) {  
    f-&amp;amp;gt;allowed_seeks--;  // allowed_seeks 初始值 1 &amp;amp;lt;&amp;amp;lt; 30
    if (f-&amp;amp;gt;allowed_seeks &amp;amp;lt;= 0 &amp;amp;amp;&amp;amp;amp; file_to_compact_ == nullptr) {  
      file_to_compact_ = f;  
      file_to_compact_level_ = stats.seek_file_level;  
      return true;  
    }  
  }  
  return false;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;每次 Get 检索的最后都会对本次检索涉及的&lt;u&gt;第一个数据文件&lt;/u&gt;进行计数，如果文件的检索次数达到上限，就伺机进行 compaction。不过这个条件触发 compaction 的优先级比较低。&lt;/p&gt;
&lt;h3&gt;7.2 major compaction 过程&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不考虑一些细节优化之处，compaction 的核心流程为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、根据触发条件，确定本次 compaction 对哪个 level 的数据库文件处理，然后进一步确定从 level  和 level+1 层中选择哪些数据库文件 compaction：
&lt;ul&gt;&lt;li&gt;（1）、最简单的情况是， 如果该 level 是第一次做 compaction，则选择该 level 的第一个数据文件（也就是最先生成的那个），不过：
&lt;ul&gt;&lt;li&gt;1)、如果之前该 level 做过 major compaction，暂存了状态（处理到哪个最大 key），那么根据暂存状态最大 key 选择下一个数据文件即可，如果没有下一个数据文件了，则从头选择该 level 的第一个数据文件（也就是最先生成的那个）。&lt;/li&gt;
&lt;li&gt;2)、&lt;code&gt;seek_compaction&lt;/code&gt; 触发的 compaction 是针对特定数据库文件的。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;(2)、如果 level = 0，因为 $level_0$ 的数据库文件之间 key 的范围可以重合，所以根据 (1) 选定数据文件的 key 最大值和最小值，还需要进一步确定是否应该把 $level_0$ 的其他数据库文件包含进来。&lt;/li&gt;
&lt;li&gt;(3)、compaction 输出的数据库属于 level+1 层，因为 $level_1$ ~ $level_n$ 同一层的数据库文件之间 key 区间不能有重合，所以还需要根据 (1) 和 (2) 选定的数据库文件的 key 最大值和最小值，确定 level+1 层有哪些数据库文件需要加入到本次 compaction&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// A Compaction encapsulates information about a compaction.
class Compaction {
private:
  int level_;  // compaction 目标 level
  uint64_t max_output_file_size_;  // compaction 产生的新文件大小阈值，如果达到阈值，就结束 compaction
  Version* input_version_;  // 当前对哪个 Version 做 compaction？
  VersionEdit edit_; // 每次 compaction 会产生一个新的 Version

  // Each compaction reads inputs from &amp;amp;quot;level_&amp;amp;quot; and &amp;amp;quot;level_+1&amp;amp;quot;
  // compaction 只会在目标层和相邻下一层之间进行
  std::vector&amp;amp;lt;FileMetaData*&amp;amp;gt; inputs_[2];  // The two sets of inputs

  // State used to check for number of overlapping grandparent files  
  // (parent == level_ + 1, grandparent == level_ + 2)  
  std::vector&amp;amp;lt;FileMetaData*&amp;amp;gt; grandparents_;  // 用于判断是否可以将 level 层的文件直接移动到 level+1 层，见 bool Compaction::IsTrivialMove() const
  size_t grandparent_index_;  // Index in grandparent_starts_  
  bool seen_key_;             // Some output key has been seen  
  int64_t overlapped_bytes_;  // Bytes of overlap between current output  
                            // and grandparent files

  // State for implementing IsBaseLevelForKey  
  
  // level_ptrs_ holds indices into input_version_-&amp;amp;gt;levels_: our state  
  // is that we are positioned at one of the file ranges for each  
  // higher level than the ones involved in this compaction (i.e. for  
  // all L &amp;amp;gt;= level_ + 2).  
  size_t level_ptrs_[config::kNumLevels];
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;Compaction* VersionSet::PickCompaction() {  
  Compaction* c;  
  int level;  
  
  // We prefer compactions triggered by too much data in a level over  
  // the compactions triggered by seeks.
  const bool size_compaction = (current_-&amp;amp;gt;compaction_score_ &amp;amp;gt;= 1);
  const bool seek_compaction = (current_-&amp;amp;gt;file_to_compact_ != nullptr);  
  if (size_compaction) {  
    level = current_-&amp;amp;gt;compaction_level_;  
    assert(level &amp;amp;gt;= 0);  
    assert(level + 1 &amp;amp;lt; config::kNumLevels);  
    c = new Compaction(options_, level);  
  
    // Pick the first file that comes after compact_pointer_[level]  
    for (size_t i = 0; i &amp;amp;lt; current_-&amp;amp;gt;files_[level].size(); i++) {  
      FileMetaData* f = current_-&amp;amp;gt;files_[level][i];  
      if (compact_pointer_[level].empty() ||  
          icmp_.Compare(f-&amp;amp;gt;largest.Encode(), compact_pointer_[level]) &amp;amp;gt; 0) {  
        c-&amp;amp;gt;inputs_[0].push_back(f);  // 选择该 level 上次 compaction 的文件的下一个文件
        break;  
      }  
    }  
    if (c-&amp;amp;gt;inputs_[0].empty()) {  
      // Wrap-around to the beginning of the key space  
      c-&amp;amp;gt;inputs_[0].push_back(current_-&amp;amp;gt;files_[level][0]);  // 如果该 level 整个 key 空间都 compaction 过，则从头开始选择第一个文件
    }  
  } else if (seek_compaction) {  
    level = current_-&amp;amp;gt;file_to_compact_level_;  
    c = new Compaction(options_, level);  
    c-&amp;amp;gt;inputs_[0].push_back(current_-&amp;amp;gt;file_to_compact_);  
  } else {  
    return nullptr;  
  }  
  
  c-&amp;amp;gt;input_version_ = current_;  
  c-&amp;amp;gt;input_version_-&amp;amp;gt;Ref();  
  
  // Files in level 0 may overlap each other, so pick up all overlapping ones  
  if (level == 0) {  
    InternalKey smallest, largest;  
    GetRange(c-&amp;amp;gt;inputs_[0], &amp;amp;amp;smallest, &amp;amp;amp;largest);  
    // Note that the next call will discard the file we placed in  
    // c-&amp;amp;gt;inputs_[0] earlier and replace it with an overlapping set
    // which will include the picked file.
    current_-&amp;amp;gt;GetOverlappingInputs(0, &amp;amp;amp;smallest, &amp;amp;amp;largest, &amp;amp;amp;c-&amp;amp;gt;inputs_[0]);  
    assert(!c-&amp;amp;gt;inputs_[0].empty());  
  }  
  
  SetupOtherInputs(c);  
  
  return c;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;2、如果选定的输入文件，仅有一个文件，且是 level 层文件，则直接将这个文件标记在为本次 compaction 后为 level+1 层文件，从而避免了不必要的文件读写。&lt;/li&gt;
&lt;li&gt;3、否则，对选定好的 level 和 level+1 层数据库文件，打开文件，创建好数据遍历读取的迭代器：
&lt;ul&gt;&lt;li&gt;(1)、单个文件的遍历读取实际是个两层遍历（&lt;code&gt;TwoLevelIterator&lt;/code&gt;） - 第1层遍历针对“index 块”，第2层遍历针对“data 块”，根据“index 块”得到“data 块”的 offset 和 size，遍历“data 块”，获取实际的键值对数据，一个“data 块” 遍历完了，则从“index 块”获取下一个“data 块”的 offset 和 size 继续遍历。&lt;/li&gt;
&lt;li&gt;（2）、因为 compaction 输出的数据库文件内容也需要保持按 key 有序的性质，所以 compaction 过程实际是对多个输入文件的有序遍历。不过 $level_0$ 数据库文件的 key 区间可以重合，所以处理方式也有所区别
&lt;ul&gt;&lt;li&gt;1)、$level_0$ 层的多个数据库文件有序遍历，类似于 N 路归并排序算法 - 每次取 N 个迭代器的头部元素进行比较，取最小的那个元素返回。&lt;/li&gt;
&lt;li&gt;2)、$level_1$ ~ $level_n$ 层的数据库文件 key 区间不会有重合，所以比较简单，按照 key 区间先做一下排序，然后逐个文件遍历读取就可以。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;Iterator* VersionSet::MakeInputIterator(Compaction* c) {  
  ReadOptions options;  
  options.verify_checksums = options_-&amp;amp;gt;paranoid_checks;  
  options.fill_cache = false;  
  
  // Level-0 files have to be merged together.  For other levels,  
  // we will make a concatenating iterator per level.  // TODO(opt): use concatenating iterator for level-0 if there is no overlap  
  const int space = (c-&amp;amp;gt;level() == 0 ? c-&amp;amp;gt;inputs_[0].size() + 1 : 2);  
  Iterator** list = new Iterator*[space];  
  int num = 0;  
  for (int which = 0; which &amp;amp;lt; 2; which++) {  
    if (!c-&amp;amp;gt;inputs_[which].empty()) {  
      if (c-&amp;amp;gt;level() + which == 0) {  
        const std::vector&amp;amp;lt;FileMetaData*&amp;amp;gt;&amp;amp;amp; files = c-&amp;amp;gt;inputs_[which];  
        for (size_t i = 0; i &amp;amp;lt; files.size(); i++) {  
          list[num++] = table_cache_-&amp;amp;gt;NewIterator(options, files[i]-&amp;amp;gt;number,  
                                                  files[i]-&amp;amp;gt;file_size);  
        }  
      } else {  
        // Create concatenating iterator for the files from this level  
        list[num++] = NewTwoLevelIterator(  
            new Version::LevelFileNumIterator(icmp_, &amp;amp;amp;c-&amp;amp;gt;inputs_[which]),  
            &amp;amp;amp;GetFileIterator, table_cache_, options);  
      }  
    }  
  }  
  assert(num &amp;amp;lt;= space);  
  Iterator* result = NewMergingIterator(&amp;amp;amp;icmp_, list, num);  
  delete[] list;  
  return result;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;4、leveldb 基于的 lsm-tree（Log Structured Merge Tree） 结构，并不会对数据进行原地修改和删除 - 同 key 的多次写入（包括删除），都会在结构中增加一条键值记录，检索时以最后一次写入的内容为结果。那么如果系统 workloads 会对相同的 key 存在大量写入，就比较浪费存储空间。所以 compaction 过程中会对同一个 key 多次写入做消除合并，仅保留最后一次写入的（如果最后一次是删除操作，并且 level+2（包括）之后所有层的 key 区间都不会包含这个 key，则最后一次的删除操作也可以消除掉）。&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;compaction 的输入遍历是有序的，那么同一个 key 的多次写入记录在遍历时是连续的，并且&lt;code&gt;InternalKeyComparator&lt;/code&gt;比较器的比较逻辑决定了后写入的会被先遍历到。以如下写入序列来解释消除合并逻辑（以 UK 表示用户写入的原始 key，以$IK_k$ 表示带写入序列号的内部 key）：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt; - 假设写入序列为：“PUT $IK_1$” -&gt; “PUT $IK_2$”，那么 compaction 遍历序列为“PUT $IK_2$” -&gt; “PUT $IK_1$”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;  - (1) 处理 “PUT $IK_2$” 时，发现前面没处理过 UK 的记录，则保留 “PUT $IK_2$”记录写入输出中，同时设置状态位 - 处理过 UK 的记录&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;  - (2) 处理 “PUT $IK_1$” 时，发现前面处理过 UK 的记录（并且这条记录不再被任何快照依赖），则直接将 “PUT $IK_1$” 记录丢弃。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt; - 假设写入序列为：“PUT $IK_1$” -&gt; “DEL $IK_2$”，那么 compaction 遍历序列为 “DEL $IK_2$” -&gt; “PUT $IK_1$”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;  - (1) 处理“DEL $IK_2$” 时，发现前面没处理过 UK 的记录，&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;&gt;   - 1) 如果 level+2（包括）之后所有层也都不包含 UK 的记录（并且这条记录不再被任何快照依赖），则直接丢弃（&lt;u&gt;从检索性能上来说，可能不丢弃更好一点？&lt;/u&gt;）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;&gt;   - 2) 如果 level+2（包括）之后层中包含 UK 的记录，则保留 “DEL $IK_2$”记录写到输出中，同时设置状态位  - 处理过 UK 的记录&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;&gt;  - (2) 处理“PUT $IK_1$” 时，发现前面处理过 UK 的记录，则直接将 “PUT $IK_1$” 记录丢弃。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt; - 如果发现当前处理的 IK 的 UK 与前一次处理的 IK 的 UK 不相同，则重置状态位。&lt;/p&gt;&lt;/blockquote&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Handle key/value, add to state, etc.  
bool drop = false;  
if (!ParseInternalKey(key, &amp;amp;amp;ikey)) {  
  // Do not hide error keys  
  current_user_key.clear();  
  has_current_user_key = false;  
  last_sequence_for_key = kMaxSequenceNumber;  
} else {  
  if (!has_current_user_key ||  
      user_comparator()-&amp;amp;gt;Compare(ikey.user_key, Slice(current_user_key)) !=  
          0) {  
    // First occurrence of this user key  
    current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());  
    has_current_user_key = true;  
    last_sequence_for_key = kMaxSequenceNumber;  
  }  
  
  if (last_sequence_for_key &amp;amp;lt;= compact-&amp;amp;gt;smallest_snapshot) {  
    // Hidden by an newer entry for same user key  
    drop = true;  // (A)  
  } else if (ikey.type == kTypeDeletion &amp;amp;amp;&amp;amp;amp;  
             ikey.sequence &amp;amp;lt;= compact-&amp;amp;gt;smallest_snapshot &amp;amp;amp;&amp;amp;amp;  
             compact-&amp;amp;gt;compaction-&amp;amp;gt;IsBaseLevelForKey(ikey.user_key)) {  
    // For this user key:  
    // (1) there is no data in higher levels
    // (2) data in lower levels will have larger sequence numbers
    // (3) data in layers that are being compacted here and have
    //     smaller sequence numbers will be dropped in the next
    //     few iterations of this loop (by rule (A) above).
    // Therefore this deletion marker is obsolete and can be dropped.
    drop = true;  
  }  
  
  last_sequence_for_key = ikey.sequence;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;int InternalKeyComparator::Compare(const Slice&amp;amp;amp; akey, const Slice&amp;amp;amp; bkey) const {  
  // Order by:  
  //    increasing user key (according to user-supplied comparator)
  //    decreasing sequence number
  //    decreasing type (though sequence# should be enough to disambiguate)
  int r = user_comparator_-&amp;amp;gt;Compare(ExtractUserKey(akey), ExtractUserKey(bkey));  // 先比较用户 key 部分
  if (r == 0) {  // 如果用户key 相同，则比较序列号，序列号大的排在前面
    const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8);  
    const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8);  
    if (anum &amp;amp;gt; bnum) {  
      r = -1;  
    } else if (anum &amp;amp;lt; bnum) {  
      r = +1;  
    }  
  }  
  return r;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;5、如果 compaction 输出的数据文件大小达到阈值（2MB），则结束该文件的写入，并创建一个新的 ldb 数据文件，继续 compaction 写入。在 compaction 完成时，这些若干个输出的 ldb 数据文件会被标记为新版本的 level+1 层数据文件。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Leveldb will write up to this amount of bytes to a file before  
// switching to a new one.  
// Most clients should leave this parameter alone.  However if your  
// filesystem is more efficient with larger files, you could  
// consider increasing the value.  The downside will be longer  
// compactions and hence longer latency/performance hiccups.  
// Another reason to increase this parameter might be when you are  
// initially populating a large database.  
size_t max_file_size = 2 * 1024 * 1024;&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;6、一次 compaction 完成后，输入文件的有效内容都已经写到输出文件，如果不考虑其他因素，这些输入文件可以被删除，保留输出文件即可。不过可能存在检索操作依赖这些输入文件，所以不会即刻删除这些输入文件，而是以版本信息在逻辑上维护每一层最新包含哪些文件（以及如果本次 compaction 未能完整地完成，则还需要把处理到 level 的哪个 key 为止记录到版本信息中）。所以&lt;u&gt;每次 compaction 都会产生一个新的逻辑上的数据版本，将这个版本切换为 leveldb 运行时依赖的当前版本（&lt;code&gt;VersionSet::current_&lt;/code&gt;），后续的检索操作就都在这个新版本所包含数据库文件中进行&lt;/u&gt;。另外：
&lt;ul&gt;&lt;li&gt;1、重新计算下次 compaction 最应该处理的哪个 level 的数据文件以及紧迫程度（&lt;code&gt;compaction_score_&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;2、将新版本信息写入版本描述 MANIFEST 文件中（如果尚不存在，则新建一个），并且如果版本描述 MANIFEST 文件是新创建的，则将该  MANIFEST 文件名存为 CURRENT 文件。这样，如果当前 leveldb 进程挂了或者机器节点宕机，还可以基于 CURRENT 文件指向的  MANIFEST 文件中的版本信息，恢复出最新最新版本状态。&lt;/li&gt;
&lt;li&gt;3、对当前不再依赖（依赖关系怎么维护的？）的 ldb 文件/MANIFEST 文件/“WAL log” 文件进行删除清理。
&lt;ul&gt;&lt;li&gt;不被任何版本依赖的 ldb 文件，都可以删除&lt;/li&gt;
&lt;li&gt;不被当前 CURRENT 文件指向的 MANIFEST 文件，可以删除&lt;/li&gt;
&lt;li&gt;“WAL log” 文件保留最新的两个即可（memtable 和不可变 memtable 对应的“WAL log”文件）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;Status DBImpl::InstallCompactionResults(CompactionState* compact) {  
  mutex_.AssertHeld();  
  Log(options_.info_log, &amp;amp;quot;Compacted %d@%d + %d@%d files =&amp;amp;gt; %lld bytes&amp;amp;quot;,  
      compact-&amp;amp;gt;compaction-&amp;amp;gt;num_input_files(0), compact-&amp;amp;gt;compaction-&amp;amp;gt;level(),  
      compact-&amp;amp;gt;compaction-&amp;amp;gt;num_input_files(1), compact-&amp;amp;gt;compaction-&amp;amp;gt;level() + 1,  
      static_cast&amp;amp;lt;long long&amp;amp;gt;(compact-&amp;amp;gt;total_bytes));  
  
  // Add compaction outputs  
  compact-&amp;amp;gt;compaction-&amp;amp;gt;AddInputDeletions(compact-&amp;amp;gt;compaction-&amp;amp;gt;edit());  
  const int level = compact-&amp;amp;gt;compaction-&amp;amp;gt;level();  
  for (size_t i = 0; i &amp;amp;lt; compact-&amp;amp;gt;outputs.size(); i++) {  
    const CompactionState::Output&amp;amp;amp; out = compact-&amp;amp;gt;outputs[i];  
    compact-&amp;amp;gt;compaction-&amp;amp;gt;edit()-&amp;amp;gt;AddFile(level + 1, out.number, out.file_size,  
                                         out.smallest, out.largest);  
  }  
  return versions_-&amp;amp;gt;LogAndApply(compact-&amp;amp;gt;compaction-&amp;amp;gt;edit(), &amp;amp;amp;mutex_);  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;void DBImpl::RemoveObsoleteFiles() {  
  mutex_.AssertHeld();  
  
  if (!bg_error_.ok()) {  
    // After a background error, we don&amp;amp;apos;t know whether a new version may  
    // or may not have been committed, so we cannot safely garbage collect.
    return;  
  }  
  
  // Make a set of all of the live files  
  std::set&amp;amp;lt;uint64_t&amp;amp;gt; live = pending_outputs_;  
  versions_-&amp;amp;gt;AddLiveFiles(&amp;amp;amp;live);  
  
  std::vector&amp;amp;lt;std::string&amp;amp;gt; filenames;  
  env_-&amp;amp;gt;GetChildren(dbname_, &amp;amp;amp;filenames);  // Ignoring errors on purpose  
  uint64_t number;  
  FileType type;  
  std::vector&amp;amp;lt;std::string&amp;amp;gt; files_to_delete;  
  for (std::string&amp;amp;amp; filename : filenames) {  
    if (ParseFileName(filename, &amp;amp;amp;number, &amp;amp;amp;type)) {  
      bool keep = true;  
      switch (type) {  
        case kLogFile:  
          keep = ((number &amp;amp;gt;= versions_-&amp;amp;gt;LogNumber()) ||  
                  (number == versions_-&amp;amp;gt;PrevLogNumber()));  
          break;  
        case kDescriptorFile:  
          // Keep my manifest file, and any newer incarnations&amp;amp;apos;  
          // (in case there is a race that allows other incarnations)
		  keep = (number &amp;amp;gt;= versions_-&amp;amp;gt;ManifestFileNumber());  
          break;  
        case kTableFile:  
          keep = (live.find(number) != live.end());  
          break;  
        case kTempFile:  
          // Any temp files that are currently being written to must  
          // be recorded in pending_outputs_, which is inserted into &amp;amp;quot;live&amp;amp;quot;
          keep = (live.find(number) != live.end());  
          break;  
        case kCurrentFile:  
        case kDBLockFile:  
        case kInfoLogFile:  
          keep = true;  
          break;  
      }  
  
      if (!keep) {  
        files_to_delete.push_back(std::move(filename));  
        if (type == kTableFile) {  
          table_cache_-&amp;amp;gt;Evict(number);  
        }  
        Log(options_.info_log, &amp;amp;quot;Delete type=%d #%lld\n&amp;amp;quot;, static_cast&amp;amp;lt;int&amp;amp;gt;(type),  
            static_cast&amp;amp;lt;unsigned long long&amp;amp;gt;(number));  
      }  
    }  
  }  
  
  // While deleting all files unblock other threads. All files being deleted  
  // have unique names which will not collide with newly created files and
  // are therefore safe to delete while allowing other threads to proceed.
  mutex_.Unlock();  
  for (const std::string&amp;amp;amp; filename : files_to_delete) {  
    env_-&amp;amp;gt;RemoveFile(dbname_ + &amp;amp;quot;/&amp;amp;quot; + filename);  
  }  
  mutex_.Lock();  
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;8、版本&lt;/h2&gt;
&lt;h3&gt;8.1 MANIFEST - descriptor log 文件&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如前所述，数据版本变更信息（VersionEdit）会持久化存储到 MANIFEST 文件中。MANIFEST 文件内容的编码结构同 WAL log。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据版本变更信息包含8个部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、用户自定义 key 比较器的名称（如果用户配置的话）&lt;/li&gt;
&lt;li&gt;2、最新 WAL log 文件的 id&lt;/li&gt;
&lt;li&gt;3、前一个 WAL log 文件的 id&lt;/li&gt;
&lt;li&gt;4、下一个可用的文件 id&lt;/li&gt;
&lt;li&gt;5、下一个可用的序列号&lt;/li&gt;
&lt;li&gt;6、每个 level 最近一次的 compaction 暂存信息（compaction 遍历的最后一个 key）&lt;/li&gt;
&lt;li&gt;7、每个 level 可以删除的数据文件的元数据（compaction 的输入文件）&lt;/li&gt;
&lt;li&gt;8、每个 level 新增的数据文件的元数据（compaction 的输出文件）&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Tag numbers for serialized VersionEdit.  These numbers are written to  
// disk and should not be changed.  
enum Tag {  
  kComparator = 1,  
  kLogNumber = 2,  
  kNextFileNumber = 3,  
  kLastSequence = 4,  
  kCompactPointer = 5,  
  kDeletedFile = 6,  
  kNewFile = 7,  
  // 8 was used for large value refs  
  kPrevLogNumber = 9  
};

void VersionEdit::EncodeTo(std::string* dst) const {  
  if (has_comparator_) {  
    PutVarint32(dst, kComparator);  
    PutLengthPrefixedSlice(dst, comparator_);  
  }  
  if (has_log_number_) {  
    PutVarint32(dst, kLogNumber);  
    PutVarint64(dst, log_number_);  
  }  
  if (has_prev_log_number_) {  
    PutVarint32(dst, kPrevLogNumber);  
    PutVarint64(dst, prev_log_number_);  
  }  
  if (has_next_file_number_) {  
    PutVarint32(dst, kNextFileNumber);  
    PutVarint64(dst, next_file_number_);  
  }  
  if (has_last_sequence_) {  
    PutVarint32(dst, kLastSequence);  
    PutVarint64(dst, last_sequence_);  
  }  
  
  for (size_t i = 0; i &amp;amp;lt; compact_pointers_.size(); i++) {  
    PutVarint32(dst, kCompactPointer);  
    PutVarint32(dst, compact_pointers_[i].first);  // level  
    PutLengthPrefixedSlice(dst, compact_pointers_[i].second.Encode());  
  }  
  
  for (const auto&amp;amp;amp; deleted_file_kvp : deleted_files_) {  
    PutVarint32(dst, kDeletedFile);  
    PutVarint32(dst, deleted_file_kvp.first);   // level  
    PutVarint64(dst, deleted_file_kvp.second);  // file number  
  }  
  
  for (size_t i = 0; i &amp;amp;lt; new_files_.size(); i++) {  
    const FileMetaData&amp;amp;amp; f = new_files_[i].second;  
    PutVarint32(dst, kNewFile);  
    PutVarint32(dst, new_files_[i].first);  // level  
    PutVarint64(dst, f.number);  
    PutVarint64(dst, f.file_size);  
    PutLengthPrefixedSlice(dst, f.smallest.Encode());  
    PutLengthPrefixedSlice(dst, f.largest.Encode());  
  }  
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;8.2 CURRENT 文件&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;CURRENT 文件中存储的是最新有效的 MANIFEST 文件名。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据库打开，恢复状态的流程为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、从 CURRENT 中获取最新有效的 MANIFEST 文件名&lt;/li&gt;
&lt;li&gt;2、从最新有效的 MANIFEST 文件中读取到&lt;u&gt;最后一个 VersionEdit 版本信息&lt;/u&gt;&lt;/li&gt;
&lt;li&gt;3、根据 VersionEdit 版本信息，计算出最新可用的 Version 信息（仅包含每个 level 包含哪些数据文件），并计算该版本下一次 compaction 应该处理哪个 level 的数据文件（&lt;code&gt;compaction_level_&lt;/code&gt;）和紧迫程度（&lt;code&gt;compaction_score_&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;4、将最新可用的 Version 加入到 &lt;code&gt;versions_&lt;/code&gt;（&lt;code&gt;VersionSet&lt;/code&gt;） 的版本链中，并恢复  &lt;code&gt;versions_&lt;/code&gt; 的一些状态信息，以及确定是否复用 CURRENT指向的那个 MANIFEST 文件（如果 MANIFEST 文件大小超过阈值（&lt;code&gt;size_t max_file_size = 2 * 1024 * 1024&lt;/code&gt;） 则不复用，而是创建一个新的）&lt;/li&gt;
&lt;li&gt;5、根据从“最后一个 VersionEdit 原始版本信息” 恢复到 &lt;code&gt;versions_&lt;/code&gt; 的“前一个 WAL log 文件 id”- &lt;code&gt;min_log&lt;/code&gt; 和“最新一个 WAL log 文件 id” - &lt;code&gt;prev_log&lt;/code&gt;，&lt;u&gt;将文件 id 大于等于 &lt;code&gt;min_log&lt;/code&gt; 或者等于 &lt;code&gt;pre_log&lt;/code&gt; 的所有 WAL log 文件找出来，按照文件 id 从小大到排序， 然后顺序遍历解析，恢复出 memtable 内存状态&lt;/u&gt;，并在最后确保所有内存状态持久化落到 $level_0$ 文件中。
&lt;ul&gt;&lt;li&gt;“将文件 id 大于等于 &lt;code&gt;min_log&lt;/code&gt; 或者等于 &lt;code&gt;pre_log&lt;/code&gt; 的所有 WAL log 文件找出来，按照文件 id 从小大到排序， 然后顺序遍历解析，恢复出 memtable 内存状态”：这个逻辑也意味着并&lt;strong&gt;不需要&lt;/strong&gt;在创建一个新的 WAL log 文件时就产生一个新的版本，&lt;strong&gt;也不需要&lt;/strong&gt;把最新版本信息持久化写到  MANIFEST 文件 中。因此也不会和 compaction 版本变更存在操作冲突。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;8.3 VersionEdit &amp; VersionSet &amp; Version&lt;/h3&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class VersionEdit {
public:
  // Add the specified file at the specified number.  
  // REQUIRES: This version has not been saved (see VersionSet::SaveTo)  
  // REQUIRES: &amp;amp;quot;smallest&amp;amp;quot; and &amp;amp;quot;largest&amp;amp;quot; are smallest and largest keys in file  
  void AddFile(int level, uint64_t file, uint64_t file_size,  
               const InternalKey&amp;amp;amp; smallest, const InternalKey&amp;amp;amp; largest) {  
    FileMetaData f;  
    f.number = file;  
    f.file_size = file_size;  
    f.smallest = smallest;  
    f.largest = largest;  
    new_files_.push_back(std::make_pair(level, f));  
  }  
  
  // Delete the specified &amp;amp;quot;file&amp;amp;quot; from the specified &amp;amp;quot;level&amp;amp;quot;.  
  void RemoveFile(int level, uint64_t file) {  
    deleted_files_.insert(std::make_pair(level, file));  
  }

private:
  typedef std::set&amp;amp;lt;std::pair&amp;amp;lt;int, uint64_t&amp;amp;gt;&amp;amp;gt; DeletedFileSet;  
  
  std::string comparator_;  
  uint64_t log_number_;  
  uint64_t prev_log_number_;  
  uint64_t next_file_number_;  
  SequenceNumber last_sequence_;  
  bool has_comparator_;  
  bool has_log_number_;  
  bool has_prev_log_number_;  
  bool has_next_file_number_;  
  bool has_last_sequence_;  
  
  std::vector&amp;amp;lt;std::pair&amp;amp;lt;int, InternalKey&amp;amp;gt;&amp;amp;gt; compact_pointers_;  
  DeletedFileSet deleted_files_;  
  std::vector&amp;amp;lt;std::pair&amp;amp;lt;int, FileMetaData&amp;amp;gt;&amp;amp;gt; new_files_;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;VersionEdit 是 Version 版本信息处于编辑/变更的状态，是 Version 版本信息操作的一种日志结构，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;compaction 过程涉及对最新版本的两个 level 可删除文件和新增文件的记录，以及 compaction 暂存状态的记录。&lt;/li&gt;
&lt;li&gt;持久化记录到 MANIFEST 文件中，用于恢复数据库的状态。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class VersionSet {
public:
  VersionSet(const std::string&amp;amp;amp; dbname, const Options* options,  
           TableCache* table_cache, const InternalKeyComparator*);

  // Apply *edit to the current version to form a new descriptor that  
  // is both saved to persistent state and installed as the new  
  // current version.  Will release *mu while actually writing to the file.  
  // REQUIRES: *mu is held on entry.  
  // REQUIRES: no other thread concurrently calls LogAndApply()  
  Status LogAndApply(VersionEdit* edit, port::Mutex* mu)  
      EXCLUSIVE_LOCKS_REQUIRED(mu);

  // Recover the last saved descriptor from persistent storage.  
  Status Recover(bool* save_manifest);

  // Return the current version.  
  Version* current() const { return current_; }  
  
  // Return the current manifest file number  
  uint64_t ManifestFileNumber() const { return manifest_file_number_; }  
  
  // Allocate and return a new file number  
  uint64_t NewFileNumber() { return next_file_number_++; }

  // Pick level and inputs for a new compaction.  
  // Returns nullptr if there is no compaction to be done.  
  // Otherwise returns a pointer to a heap-allocated object that  
  // describes the compaction.  Caller should delete the result.  
  Compaction* PickCompaction();

  // Create an iterator that reads over the compaction inputs for &amp;amp;quot;*c&amp;amp;quot;.  
  // The caller should delete the iterator when no longer needed.  
  Iterator* MakeInputIterator(Compaction* c);

private:
  Env* const env_;  
  const std::string dbname_;  
  const Options* const options_;  
  TableCache* const table_cache_;  
  const InternalKeyComparator icmp_;  
  uint64_t next_file_number_;  
  uint64_t manifest_file_number_;  
  uint64_t last_sequence_;  
  uint64_t log_number_;  
  uint64_t prev_log_number_;  // 0 or backing store for memtable being compacted  
  
  // Opened lazily  
  WritableFile* descriptor_file_;  
  log::Writer* descriptor_log_;  
  Version dummy_versions_;  // Head of circular doubly-linked list of versions.  
  Version* current_;        // == dummy_versions_.prev_  
  
  // Per-level key at which the next compaction at that level should start.  
  // Either an empty string, or a valid InternalKey.  
  std::string compact_pointer_[config::kNumLevels];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;VersionSet 对象维护着版本双向链表以及其他必要信息，用于支持 compaction 操作、对 $level_0$~$level_n$ 的检索操作 等。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class Version {
public:
  // Lookup the value for key.  If found, store it in *val and  
  // return OK.  Else return a non-OK status.  Fills *stats.  
  // REQUIRES: lock is not held  
  Status Get(const ReadOptions&amp;amp;amp;, const LookupKey&amp;amp;amp; key, std::string* val,  
             GetStats* stats);

private:
  Iterator* NewConcatenatingIterator(const ReadOptions&amp;amp;amp;, int level) const;

  VersionSet* vset_;  // VersionSet to which this Version belongs  
  Version* next_;     // Next version in linked list  
  Version* prev_;     // Previous version in linked list  
  int refs_;          // Number of live refs to this version  
  
  // List of files per level  
  std::vector&amp;amp;lt;FileMetaData*&amp;amp;gt; files_[config::kNumLevels];  
  
  // Next file to compact based on seek stats.  
  FileMetaData* file_to_compact_;  
  int file_to_compact_level_;  
  
  // Level that should be compacted next and its compaction score.  
  // Score &amp;amp;lt; 1 means compaction is not strictly needed.  These fields  
  // are initialized by Finalize().  
  double compaction_score_;  
  int compaction_level_;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;compaction 的输入文件在 compaction 之后本来是可以删除的，但是&lt;u&gt;这些文件可能被检索/遍历等操作所依赖引用&lt;/u&gt;，所以基于 Version 版本来解决文件粒度的并发操作冲突。只有当一个版本不被任何操作所引用时，才会被释放，只有这个版本依赖的数据文件也才可以被删除。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;和 leveldb 中很多类实现的对象生命周期维护方式一样， Version 也采用引用计数的方式来维护生命周期，如果版本对象的引用计数归零，则自动析构自己，析构的逻辑包括从版本双链表中移除自己（这里可能存在并发冲突吗？），以及移除对各 level 文件元信息的引用。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;void Version::Ref() { ++refs_; }  
  
void Version::Unref() {  
  assert(this != &amp;amp;amp;vset_-&amp;amp;gt;dummy_versions_);  
  assert(refs_ &amp;amp;gt;= 1);  
  --refs_;  
  if (refs_ == 0) {
    delete this;  
  }  
}

Version::~Version() {  
  assert(refs_ == 0);  
  
  // Remove from linked list  
  prev_-&amp;amp;gt;next_ = next_;  
  next_-&amp;amp;gt;prev_ = prev_;  
  
  // Drop references to files  
  for (int level = 0; level &amp;amp;lt; config::kNumLevels; level++) {  
    for (size_t i = 0; i &amp;amp;lt; files_[level].size(); i++) {  
      FileMetaData* f = files_[level][i];  
      assert(f-&amp;amp;gt;refs &amp;amp;gt; 0);  
      f-&amp;amp;gt;refs--;  
      if (f-&amp;amp;gt;refs &amp;amp;lt;= 0) {  
        delete f;  
      }  
    }  
  }  
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2024-11-15</pubDate>
            <link>https://blog.xiayf.cn/posts/leveldb-note-3.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/leveldb-note-3.html</guid>
        </item>
        
        <item>
            <title>读码：LevelDB - ldb 数据文件格式</title>
            <description>&lt;h2&gt;5、leveldb 数据文件格式 - ldb&lt;/h2&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;beginning_of_file&amp;amp;gt;
[data block 1]
[data block 2]
...
[data block N]
[meta block 1]
...
[meta block K]
[metaindex block]
[index block]
[Footer]        (fixed size; starts at file_size - sizeof(Footer))
&amp;amp;lt;end_of_file&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 文件（文件后缀 &lt;code&gt;.ldb&lt;/code&gt;）内容由 N 个 “data 块” 部分、 K 个 “meta 块” 部分、1个 “metaindex 块” 部分、1个 “index 块”部分、1个 “Footer” 部分依次构成。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/4jKOHEMRi6SYD9n.png&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;830&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;ldb 数据文件的加载解析流程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、取文件末尾的 28 个字节，解析出(1) metaindex block 的 offset &amp; size (2) index block 的 offset &amp; size&lt;/li&gt;
&lt;li&gt;2、根据 metaindex block 的 offset &amp; size 解析出 “过滤策略名称” 和 meta block 的 offset &amp; size
&lt;ul&gt;&lt;li&gt;根据“过滤策略名称” 实例化过滤策略&lt;/li&gt;
&lt;li&gt;对于 meta block 的解析，先解析出“第3部分” 和 “第4部分”的值，得到“第1部分”的长度，继而得到“第2️部分”的偏移位置和长度（也即 &lt;code&gt;filter_offsets_&lt;/code&gt; 的内容）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;3、根据 index block 的 offset &amp; size 解析出所有 data block 的“key 区间”、offset 和 size&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“点查”，对于 ldb 数据文件的检索流程为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、使用 key，从最新版本中从小到大逐个 level 匹配其文件元数据&lt;/li&gt;
&lt;li&gt;2、对目标 ldb 文件，使用 key 从 index block 中通过二分查找匹配到目标 data block 的 offset &amp; size&lt;/li&gt;
&lt;li&gt;3、根据目标 data block 的 offset 对 meta block 的 &lt;code&gt;filter_offsets_&lt;/code&gt; 计算而后取到目标过滤数据块，交给过滤策略实例进行初步的匹配筛选&lt;/li&gt;
&lt;li&gt;4、如果 3 中没有匹配到，则根据目标 data block 的 offset 计算取到 data block 的“重置位点序列”，继而对 data block 的“键值对序列”进行解析遍历匹配&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.1 “Footer”部分&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;长度为固定值 &lt;code&gt;kEncodedLength&lt;/code&gt;（$2 * BlockHandle::kMaxEncodedLength + 8 = 28$）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;先后存入：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、“metaindex 块”在文件中的偏移位置 offset 和 块大小 size。&lt;/li&gt;
&lt;li&gt;2、“index” 块在文件中的偏移位置 offset 和 块大小 size。&lt;/li&gt;
&lt;li&gt;3、将“Footer”长度填充 到 $2 * BlockHandle::kMaxEncodedLength = 20$ 长度。&lt;/li&gt;
&lt;li&gt;4、以小端序写入一个64比特的魔法数。&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/9fXToy6AGZe4C82.png&apos; title=&apos;ldb-footer&apos; alt=&apos;ldb-footer&apos; width=&apos;600&apos;/&gt;
&lt;h3&gt;5.2 “块”的格式&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将键值写入块的内存缓冲区时，每连续 16 （默认值，可配置）个键会进行 delta 编码压缩：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先计算当前键与前一次写入键的共同前缀长度&lt;/li&gt;
&lt;li&gt;2、依次写入“键共同前缀长度”、“当前键去掉共同前缀后的长度”、“值的长度”、“当前键去掉共同前缀后的内容”、“值内容”&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果连续“delta 编码压缩”的键数/写入次数达到阈值 16，则将当前内存缓冲区的大小记录到“重置位点列表”（&lt;code&gt;restarts_&lt;/code&gt;）中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将块的内存缓存区内容落到文件的流程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、把&lt;u&gt;“重置位点列表”中的元素&lt;/u&gt;依次逐个添加到缓冲区尾部。&lt;/li&gt;
&lt;li&gt;2、将&lt;u&gt;“重置位点”数量&lt;/u&gt;以固定32比特长度添加到缓冲区尾部。&lt;/li&gt;
&lt;li&gt;3、将缓冲区内容整体做一次通用压缩（可配置 不压缩、snappy 压缩、zstd 压缩）。&lt;/li&gt;
&lt;li&gt;4、将压缩后的字节序列写入文件后，再将 压缩类型(CompressionType，1字节) 和 “压缩后的字节序列 与 压缩类型” 的 crc32 校验码（4字节）写到文件的尾部。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;enum CompressionType {  
  // NOTE: do not change the values of existing entries, as these are  
  // part of the persistent format on disk.
  kNoCompression = 0x0,  
  kSnappyCompression = 0x1,  
  kZstdCompression = 0x2,  
};&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/UzgZTxtOsaqYn9w.png&apos; title=&apos;ldb-block-encode&apos; alt=&apos;ldb-block-encode&apos; width=&apos;800&apos;/&gt;
&lt;h3&gt;5.3 “data 块”&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 文件中“data 块”数据是按照 key 有序存储的。同一个文件中，块与块之间有序，块之间 key 范围不会有重合，块内内容也是按 key 有序存储。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为有序， 使用默认的 BytewiseComparator，delta 编码压缩效果通常会明显。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于“data 块”，如果块的内存缓冲区内容大小（通用压缩前的原始内容大小+重置位点数组大小+重置位点数组长度）超过 4KB（可配置，配置项 &lt;code&gt;block_size&lt;/code&gt;），就会将块的内存缓冲区作为一个“data 块”落到文件中。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Approximate size of user data packed per block.  Note that the  
// block size specified here corresponds to uncompressed data.  The  
// actual size of the unit read from disk may be smaller if  
// compression is enabled.  This parameter can be changed dynamically.  
size_t block_size = 4 * 1024;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;5.4 “index 块”&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“index 块” 存储 “data 块” 的索引信息。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当一个“data 块”从内存缓存区落到文件后，将该“data 块”最后/最大的 key（经存储优化处理后） 作为 键（&lt;u&gt;大致含义-当前块中所有 key 都小于该键，下一个块中所有 key 都大于等于该键&lt;/u&gt;），该“data 块”在文件中的偏移位置 offset 和 块大小 size 打包后作为值，写入“index 块”内存缓冲区。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当 leveldb 文件的所有“data 块”都写入文件后，会将“index 块”内存缓冲区内容也按照“块”格式写入文件。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Get key 检索时，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先从 “Footer” 部分取出“index 块的” offer 和 size，&lt;/li&gt;
&lt;li&gt;2、然后在“index 块”进行二分查找，找到目标“data 块”，&lt;/li&gt;
&lt;li&gt;3、从目标“data 块”中解析出来重置位点数组，继续进行二分查找。&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.5 “meta 块” &amp; “metaindex 块”&lt;/h3&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// A FilterBlockBuilder is used to construct all of the filters for a  
// particular Table.  It generates a single string which is stored as  
// a special block in the Table.  
//  
// The sequence of calls to FilterBlockBuilder must match the regexp:  
//      (StartBlock AddKey*)* Finish  
class FilterBlockBuilder {  
 public:  
  explicit FilterBlockBuilder(const FilterPolicy*);  
  
  void StartBlock(uint64_t block_offset);  
  void AddKey(const Slice&amp;amp;amp; key);  
  Slice Finish();  
  
 private:  
  void GenerateFilter();  
  
  const FilterPolicy* policy_;  

  std::string keys_;             // Flattened key contents  
  std::vector&amp;amp;lt;size_t&amp;amp;gt; start_;    // Starting index in keys_ of each key  

  std::string result_;           // Filter data computed so far  
  std::vector&amp;amp;lt;Slice&amp;amp;gt; tmp_keys_;  // policy_-&amp;amp;gt;CreateFilter() argument  
  std::vector&amp;amp;lt;uint32_t&amp;amp;gt; filter_offsets_;  
};

void FilterBlockBuilder::StartBlock(uint64_t block_offset) {  
  uint64_t filter_index = (block_offset / kFilterBase);  
  assert(filter_index &amp;amp;gt;= filter_offsets_.size());  
  while (filter_index &amp;amp;gt; filter_offsets_.size()) {  
    GenerateFilter();  
  }  
}

void FilterBlockBuilder::AddKey(const Slice&amp;amp;amp; key) {  
  Slice k = key;  
  start_.push_back(keys_.size());  
  keys_.append(k.data(), k.size());  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;目前的实现，如果 leveldb 文件中存在“meta 块”，应该也只会有一个，即&lt;strong&gt;过滤数据块&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果 leveldb 数据库开启了检索时过滤策略（FilterPolicy），则对于写入“data 块”的每个 key，都会被记录到 filter 内存缓冲区（&lt;code&gt;FilterBlockBuilder&lt;/code&gt;）中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当一个“data 块”刷到文件后，就对 FilterBlockBuilder 中存入的 key 序列算一下“过滤数据”，拼接到 &lt;code&gt;result_&lt;/code&gt; 后面，以及将最新计算的“过滤数据”在 &lt;code&gt;result_&lt;/code&gt; 中的偏移位置存到 &lt;code&gt;filter_offets_&lt;/code&gt; 向量中。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;准备处理第一个“data 块”时，
- FilterBlockBuilder 的 filter_offsets_ 为空数组 []， result_ 为空字符串 &amp;amp;quot;&amp;amp;quot;
- 当第一个“data 块”刷到数据文件后，准备处理第二个“data 块”，因&amp;amp;lt;u&amp;amp;gt;逻辑上&amp;amp;lt;/u&amp;amp;gt;约束每 2KB 数据算一次过滤数据
	- case-1：如果第一个“data 块”大小 &amp;amp;lt; 4KB（大概率是这样），那么 filter_index = 1，对这个“data 块”的所有 key 算一次过滤数据，result_ 长度为 a， filter_offset_ 将变成 [0],
	- case-2：如果第一个“data 块”大小 &amp;amp;gt;（=）4KB且&amp;amp;lt; 8KB，那么 filter_index = 2，对这个“data 块”的所有 key 算一次过滤数据，result_ 长度为 a&amp;amp;apos;，filter_offset_ 将变成 [0, a&amp;amp;apos;]
	- case-3：如果第一个“data 块”大小 &amp;amp;gt;（=）8KB且&amp;amp;lt; 16KB，那么 filter_index = 3，对这个“data 块”的所有 key 算一次过滤数据，result_ 长度为 a&amp;amp;apos;&amp;amp;apos;，filter_offset_ 将变成 [0, a&amp;amp;apos;&amp;amp;apos;, a&amp;amp;apos;&amp;amp;apos;]
- 如果第二个“data 块”为&amp;amp;lt;u&amp;amp;gt;最后一个&amp;amp;lt;/u&amp;amp;gt;，不管大小多少，刷到数据文件后，对第二个“data 块”的所有 key 算一次过滤数据，result_ 长度为 b
	- 对于 case-1，filter_offset_ 先填充为 [0, a]，最后会填充为 [0, a, b]
	- 对于 case-2，filter_offset_ 先填充为 [0, a&amp;amp;apos;, a&amp;amp;apos;]，最后会填充为 [0, a&amp;amp;apos;, a&amp;amp;apos;, b]
	- 对于 case-3，filter_offset_ 先填充为 [0, a&amp;amp;apos;&amp;amp;apos;, a&amp;amp;apos;&amp;amp;apos;, a&amp;amp;apos;&amp;amp;apos;]，最后会填充为 [0, a&amp;amp;apos;&amp;amp;apos;, a&amp;amp;apos;&amp;amp;apos;, a&amp;amp;apos;&amp;amp;apos;, b]
- 那么在过滤匹配时，
	- 对于第一个“data 块”，因其 offset 为 0，所以 filter_offset_ 的 0 &amp;amp;amp; 1 位置的值为区间从 result_ 中去对应的过滤数据
	- 对于第二个“data 块”，
		- case-1 时，其 offset &amp;amp;lt; 4KB，以 filter_offset_ 的 1 &amp;amp;amp; 2 位置的值为区间从 result_ 中去对应的过滤数据
		- case-2 时，其 offset 在 [4KB, 8KB) 区间，以 filter_offset_ 的 2 &amp;amp;amp; 3 位置的值为区间从 result_ 中去对应的过滤数据
		- case-3 时，其 offset 在 [8KB, 16KB) 区间，以 filter_offset_ 的 3 &amp;amp;amp; 4 位置的值为区间从 result_ 中去对应的过滤数据
- 所以 FilterBlockBuilder 的处理逻辑会对 filter_offset_ 做一些额外的填充，确保根据“data 块”在文件中的偏移位置 offset，能够正确地找到对应的 过滤数据块。&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当 leveldb 文件的所有“data 块”都写入文件后，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、将 &lt;code&gt;filter_offets_&lt;/code&gt; 中的偏移位置数据逐个以 32 比特定长编码后拼接到 &lt;code&gt;result_&lt;/code&gt; 后面，&lt;/li&gt;
&lt;li&gt;2、接着将“还未拼接偏移位置数据时的 &lt;code&gt;result_&lt;/code&gt; 长度”以 32 比特定长编码后拼接到 &lt;code&gt;result_&lt;/code&gt; 后面，&lt;/li&gt;
&lt;li&gt;3、然后将 kFilterBaseLg（=11）参数拼接到后面（占用1个字节），&lt;/li&gt;
&lt;li&gt;4、最后将 &lt;code&gt;result_&lt;/code&gt; 作为“meta 块”的原始数据&lt;strong&gt;不经压缩地&lt;/strong&gt;写入文件中。（&lt;u&gt;这里有点特殊，和其他块不太一样，其他块都是键值对编码写入的&lt;/u&gt;）&lt;/li&gt;&lt;/ul&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/MvG4UNntp7ibmPF.png&apos; title=&apos;ldb-filter-block&apos; alt=&apos;ldb-filter-block&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并将 过滤策略 名称拼接上前缀&lt;code&gt;filter.&lt;/code&gt; 作为 键，将meta 块（“过滤数据块”）在文件中的偏移位置 offset 和块大小 size 编码后作为值，写入 metaindex 块中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;打开数据库时，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先从 “Footer” 部分读取“metaindex 块”的偏移位置 offset 和 块大小 size&lt;/li&gt;
&lt;li&gt;2、从“metaindex 块”中解析出使用的“过滤策略”名称，以及过滤数据，初始化过滤策略&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Get key 检索时，对 ldb 文件的“data 块”进行检索时，都先根据过滤策略做一下过滤，从而减少文件的磁盘读取次数。&lt;/p&gt;</description>
            <pubDate>2024-11-13</pubDate>
            <link>https://blog.xiayf.cn/posts/leveldb-note-2.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/leveldb-note-2.html</guid>
        </item>
        
        <item>
            <title>读码：LevelDB - 接口定义与数据写入</title>
            <description>&lt;h2&gt;0、设计概要&amp;接口定义&lt;/h2&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/9Gh1agVoq2x6pBU.png&apos; title=&apos;lsm&apos; alt=&apos;lsm&apos; width=&apos;800&apos;/&gt;
&lt;img src=&apos;../plantuml-images/10988454778988851872.svg&apos; title=&apos;10988454778988851872&apos; alt=&apos;10988454778988851872&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于 DB 类的静态方法 Open 来打开/初始化一个数据库，Open 会实例化一个 DBImpl 对象，调用其私有方法 Recover 来恢复/初始化状态，并将 DBImpl 对象指针赋值给 dbptr 返回给调用方，调用方通过 dbptr 调用 Put/Write/Delete/Get/NewIterator 进行读写操作。&lt;/p&gt;
&lt;h2&gt;1、WriteBatch&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Put 和 Delete 是针对单个 key 进行操作，在底层会将键值操作包装成 WriteBatch 对象，然后调用 Write 接口执行实际的操作流程。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以在调用侧实例化 WriteBatch 对象，将一批增删操作都先填充到 WriteBatch 对象，然后直接调用 Write 接口执行一批操作，这样写吞吐应该会更高一点。这批操作是&lt;u&gt;原子的&lt;/u&gt;（一起写成功或者失败）。&lt;/p&gt;
&lt;img src=&apos;../plantuml-images/11051565628098698760.svg&apos; title=&apos;11051565628098698760&apos; alt=&apos;11051565628098698760&apos;/&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;//
typedef uint64_t SequenceNumber; // 虽然序列号使用了的 uint64_t 类型，但是实际只会使用 56 比特，即最大值为 ((0x1ull &amp;amp;lt;&amp;amp;lt; 56) - 1)
// We leave eight bits empty at the bottom so a type and sequence#  
// can be packed together into 64-bits.  
static const SequenceNumber kMaxSequenceNumber = ((0x1ull &amp;amp;lt;&amp;amp;lt; 56) - 1);
//
typedef SkipList&amp;amp;lt;const char*, KeyComparator&amp;amp;gt; Table;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;rep_ 存储结构&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;// WriteBatch::rep_ :=  
//    sequence: fixed64  
//    count: fixed32  
//    data: record[count]  
// record :=  
//    kTypeValue varstring varstring         |  
//    kTypeDeletion varstring  
// varstring :=  
//    len: varint32  
//    data: uint8[len]&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/nACmfLPxBvcRpyM.png&apos; title=&apos;write-batch&apos; alt=&apos;write-batch&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;$SequenceNum$ 是当前 WriteBatch 所有操作的基准序列号，即 WriteBatch 中第一个操作的序列号为 $SequenceNum + 0$ ，第二个操作的序列号为 $SequenceNum + 1$，依次类推。为每次操作分配一个唯一的序列号，是为了方便实现快照能力。后面再解释。&lt;/p&gt;
&lt;h2&gt;2、写入缓冲与攒批&lt;/h2&gt;
&lt;img src=&apos;../plantuml-images/12524554170754623315.svg&apos; title=&apos;12524554170754623315&apos; alt=&apos;12524554170754623315&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 的 write 写入过程基于 Writer （双端）队列实现缓冲和可能的攒批（合并多个 WriteBatch），提升写入的吞吐性能。攒批的性能空间来自 - 如果写入时发现 level0 文件过多（compaction 未完成，影响读/检索性能），则认为需要对写入进行限速，将写入先在 Write 队列中缓冲，攒 1ms 左右，合并成一个大的 WriteBatch 然后写入 memtable。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/vfKFoAlU7b6hjna.png&apos; title=&apos;write-deque&apos; alt=&apos;write-deque&apos; width=&apos;450&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果本次写入的 Writer 为队列头部，则说明当前写入压力应该不大，可以直接进行写入操作 -&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先确认写入条件是否满足：
&lt;ul&gt;&lt;li&gt;(1) level0 文件数是否超过阈值（8），如果超过，说明写入压力有点大（都来不及 minor compaction 啦），则释放互斥锁，当前线程休眠 1ms（攒批的性能空间在这！）&lt;/li&gt;
&lt;li&gt;（2） 如果当前 memtable 空间已满（默认大小 4MB，可配置），并且前一个 memtable（当前已不可变）还没有被 compaction 落盘或者 level0 文件数操作更大的一个阈值（12），则等待后台 compaction 完成&lt;/li&gt;
&lt;li&gt;（3） 如果当前 memtable 空间已满，但是前一个 memtable 已被 compaction 且 level0 文件数也不多，则将当前 memtable 切换为不可变 memtable，并申请一个新的 memtable，同时清理掉当前的 WAL log 文件，准备个新的 WAL log 文件。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2、遍历 Writer 队列，直到队尾或者遇到一个非异步写入操作或者达到攒批大小阈值，将遍历到的 Writer 中的 WriteBatch 合并成一个 WriteBatch&lt;/li&gt;
&lt;li&gt;3、将合并后的 WriteBatch 的 &lt;code&gt;rep_&lt;/code&gt; 先写入 WAL log 文件&lt;/li&gt;
&lt;li&gt;4、然后将 WriteBatch 中的操作按序解析出来，写入 memtable (Put 或 Delete)。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果本次写入的 Writer 非队列的头部，等待之前写入队列的线程攒批处理，以及最后被唤醒。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果不考虑等待 compaction，整个写入过程最慢的步骤是写 WAL 日志，所以 WriteBatch 设计是为 WAL 日志写入优化的，对于 memtable 写入反而多了一点解析的性能开销。&lt;/p&gt;
&lt;h2&gt;3、WAL log 文件&lt;/h2&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;static const int kBlockSize = 32768;

// Header is checksum (4 bytes), length (2 bytes), type (1 byte).  
static const int kHeaderSize = 4 + 2 + 1;&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/05/gwpxDFuWGIb56r2.png&apos; title=&apos;wal-log-format&apos; alt=&apos;wal-log-format&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 会将 WriteBatch 的 &lt;code&gt;rep_&lt;/code&gt; 当作字节序列写入 log 文件中。不过 log 文件存储的单元结构为块（block），块大小为 32768 字节。一个 WriteBatch 的 &lt;code&gt;rep_&lt;/code&gt; 的大小可能大于/等于/小于一个块大小，也就是写入一个 &lt;code&gt;rep_&lt;/code&gt; 可能填不满一个块或者正好填满一个块或者跨多个块。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果一次写入后，当前 block 剩余的空间不足以填充下一次写入的头部，则直接将剩余空间以 &lt;code&gt;\x00&lt;/code&gt; 填满。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样编码的好处？- 读取解析时，按块大小进行读取，速度更快，顺序解析也方便。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“WAL log” 的核心作用：写入 memtable 的键值对数据，并没有落盘到 ldb 数据库文件中，如果在 minor compaction 成 $level_0$ 文件之前，机器节点故障，导致 memtable 以及不可变 memtable 中的数据丢失，还可以通过“WAL log” 文件内容来恢复。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那也意味着，如果一旦不可变 memtable 数据 compaction 到 $level_0$ 文件后，这些数据状态对应的“WAL log” 内容就没没有实际用处了，可以及时清理掉。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 写入数据时，如果发现 memtable 占用内存已达到阈值，并且不可变 memtable 数据已被 minor compaction 成 $level_0$ 文件，则会将 memtable 切换成不可变 memtable，同时创建一个新的“WAL log”，并申请一个新的 memtable。不过此时新的不可变 memtable 还没被 minor compaction 成 $level_0$ 文件，所以前一个“WAL log”文件也还要保留，不能删除。&lt;/p&gt;
&lt;h2&gt;4、MemTable&lt;/h2&gt;
&lt;img src=&apos;../plantuml-images/12787296856683968814.svg&apos; title=&apos;12787296856683968814&apos; alt=&apos;12787296856683968814&apos;/&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;typedef SkipList&amp;amp;lt;const char*, KeyComparator&amp;amp;gt; Table;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MemTable 是对应一个“WAL log” 文件的内存存储结构。&lt;u&gt;单个 MemTable 内存占用阈值为 4MB(&lt;code&gt;write_buffer_size&lt;/code&gt;)&lt;/u&gt;，当可变 MemTable 的内存占用达到阈值时，就尝试切换成不可变 MemTable，并创建一个新的 WAL log 文件以及对应的可变 MemTable 来承接写入，而不可变 MemTable 的内容等待被 minor compaction 刷成一个 $level_0$ ldb 数据文件。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Amount of data to build up in memory (backed by an unsorted log  
// on disk) before converting to a sorted on-disk file.  
//  
// Larger values increase performance, especially during bulk loads.  
// Up to two write buffers may be held in memory at the same time,  
// so you may wish to adjust this parameter to control memory usage.  
// Also, a larger write buffer will result in a longer recovery time  
// the next time the database is opened.  
size_t write_buffer_size = 4 * 1024 * 1024;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4.1 Arena&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Arena 的特点是整块内存申请，整块内存一次性释放，从而优化内存的申请释放开销。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;leveldb 里 Arena 的生命周期与 MemTable 对象保持一致，MemTable 对象的所有 Add 操作涉及的内存分配都在同一 Arena 对象上进行， MemTable 对象切换成不可变状态并存储为 level0 ldb 文件后，Arena 对象的所有内存块随着 MemTable 对象析构而一次性释放。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;static const int kBlockSize = 4096;&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/yZ8lKoRXL3V4cm7.png&apos; title=&apos;memtable-arena&apos; alt=&apos;memtable-arena&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从 Arena 申请内存空间时，如果最新一个可用块的剩余内存大小（&lt;code&gt;alloc_bytes_remaining_&lt;/code&gt;）小于当前申请的内存大小 bytes，则先申请一个新的内存块，然后从新内存块上分配内存空间 - 如果当前申请的内存大小大于整块大小的 1/4，则单独占用一个内存块。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;所以 Arena 内存块大小必须大于实际一次申请的最大内存，并且为减少内存碎片，应该要根据代码中实际的内存分配情况来确定 Arena 内存块大小。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MemTable 的 Arena 内存块大小只有一种。有些项目中内存分配情况比较复杂的话，其 Arena 设计通常会使用多种内存块大小 ，以此提高灵活性，减少内存碎片浪费。&lt;/p&gt;
&lt;h3&gt;4.2 Table - 跳表&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;跳表可以兼顾有序链表的快速查找、快速插入/删除、遍历，算法复杂度 $O(logN)$，实现简单。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://opendatastructures.org/newhtml/ods/latex-saved-html/skiplists.html&apos;&gt;Open Data Structures - Skiplists&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;查找过程示意图&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&apos;../assets/leveldb/skiplist-searchpath.svg&apos; title=&apos;skiplist-search-path&apos; alt=&apos;skiplist-search-path&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;插入过程示意图&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&apos;../assets/leveldb/skiplist-add.svg&apos; title=&apos;skiplist-add&apos; alt=&apos;skiplist-add&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;跳表定义&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;template &amp;amp;lt;typename Key, class Comparator&amp;amp;gt;  
class SkipList {
public:
  explicit SkipList(Comparator cmp, Arena* arena);
  void Insert(const Key&amp;amp;amp; key);
  bool Contains(const Key&amp;amp;amp; key) const;
private:
  Comparator const compare_;  
  Arena* const arena_;  // Arena used for allocations of nodes  
  Node* const head_;
  // Modified only by Insert().  Read racily by readers, but stale  
  // values are ok.  
  std::atomic&amp;amp;lt;int&amp;amp;gt; max_height_;  // Height of the entire list  
  // Read/written only by Insert().  
  Random rnd_;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;跳表节点定义&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;template &amp;amp;lt;typename Key, class Comparator&amp;amp;gt;  
struct SkipList&amp;amp;lt;Key, Comparator&amp;amp;gt;::Node {
  explicit Node(const Key&amp;amp;amp; k) : key(k) {}
  Key const key;

private:
  // Array of length equal to the node height.  next_[0] is lowest level link.
  std::atomic&amp;amp;lt;Node*&amp;amp;gt; next_[1];
}&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;key&lt;/code&gt; 存储节点实际的值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;next_&lt;/code&gt; 数组中每个指针指向横向的邻居节点&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;memtable 对跳表模板实际使用的实际类型为：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;typedef SkipList&amp;amp;lt;const char*, KeyComparator&amp;amp;gt; Table;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对 Key - &lt;code&gt;char*&lt;/code&gt; 的实际编码方式：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;class MemTableInserter : public WriteBatch::Handler {  
 public:  
  SequenceNumber sequence_;  
  MemTable* mem_;  
  
  void Put(const Slice&amp;amp;amp; key, const Slice&amp;amp;amp; value) override {  
    mem_-&amp;amp;gt;Add(sequence_, kTypeValue, key, value);  // 插入
    sequence_++;  
  }  
  void Delete(const Slice&amp;amp;amp; key) override {  
    mem_-&amp;amp;gt;Add(sequence_, kTypeDeletion, key, Slice());  // 删除
    sequence_++;  
  }  
};

void MemTable::Add(SequenceNumber s, ValueType type, const Slice&amp;amp;amp; key,  
                   const Slice&amp;amp;amp; value) {  
  // Format of an entry is concatenation of:  
  //  key_size     : varint32 of internal_key.size()
  //  key bytes    : char[internal_key.size()]
  //  tag          : uint64((sequence &amp;amp;lt;&amp;amp;lt; 8) | type)
  //  value_size   : varint32 of value.size()
  //  value bytes  : char[value.size()]
  size_t key_size = key.size();  
  size_t val_size = value.size();  
  size_t internal_key_size = key_size + 8;  // 另外8字节存储 Tag
  const size_t encoded_len = VarintLength(internal_key_size) +  
                             internal_key_size + VarintLength(val_size) +  
                             val_size;  
  char* buf = arena_.Allocate(encoded_len);  
  char* p = EncodeVarint32(buf, internal_key_size);  
  std::memcpy(p, key.data(), key_size);  
  p += key_size;  
  EncodeFixed64(p, (s &amp;amp;lt;&amp;amp;lt; 8) | type);  
  p += 8;  
  p = EncodeVarint32(p, val_size);  
  std::memcpy(p, value.data(), val_size);  
  assert(p + val_size == buf + encoded_len);  
  table_.Insert(buf);  
}&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/HMisDYbkf6eUdCV.png&apos; title=&apos;skiplist-node-key&apos; alt=&apos;skiplist-node-key&apos; width=&apos;800&apos;/&gt;
&lt;ul&gt;&lt;li&gt;整数变长编码：“key 长度” 和 “value 长度”正常是32bit（4字节）整数，但 key 和 value 实际可能是比较短的字节序列（比如：长度小于128时，只要1个字节就能存储长度，而不是4字节）。&lt;/li&gt;
&lt;li&gt;序列号仅使用尾部7个字节：序列号大小不会超过7个字节？确认一下哪里有约束&lt;/li&gt;
&lt;li&gt;操作/值类型：
&lt;ul&gt;&lt;li&gt;&lt;code&gt;kTypeValue = 0x1&lt;/code&gt; 表示当前操作为 插入，有对应的值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kTypeDeletion = 0x0&lt;/code&gt; 表示当前操作为 删除，无对应的值（或者说值为空）。&lt;u&gt;正常来说，后面无需再编码“value 长度” 和 “value 值”，不过代码实现中似乎还是占用了1个字节来存储“value 长度” 0，可以优化？&lt;/u&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;KeyComparator&lt;/code&gt; 的定义：&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;struct KeyComparator {  
  const InternalKeyComparator comparator;  
  explicit KeyComparator(const InternalKeyComparator&amp;amp;amp; c) : comparator(c) {}  
  int operator()(const char* a, const char* b) const;  //
};

int MemTable::KeyComparator::operator()(const char* aptr,  
                                        const char* bptr) const {  
  // Internal keys are encoded as length-prefixed strings.  
  Slice a = GetLengthPrefixedSlice(aptr);  // 取出 internal key（包含 tag）
  Slice b = GetLengthPrefixedSlice(bptr);  
  return comparator.Compare(a, b);  
}

class InternalKeyComparator : public Comparator {  
 private:  
  const Comparator* user_comparator_; // 用户可配置自定义的 key 比较器，默认为 BytewiseComparator - 逐个字节比较
  
 public:  
  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) {}  
  const char* Name() const override;  
  int Compare(const Slice&amp;amp;amp; a, const Slice&amp;amp;amp; b) const override;  
  void FindShortestSeparator(std::string* start,  
                             const Slice&amp;amp;amp; limit) const override;  
  void FindShortSuccessor(std::string* key) const override;  
  
  const Comparator* user_comparator() const { return user_comparator_; }  
  
  int Compare(const InternalKey&amp;amp;amp; a, const InternalKey&amp;amp;amp; b) const;  
};

int InternalKeyComparator::Compare(const Slice&amp;amp;amp; akey, const Slice&amp;amp;amp; bkey) const {  
  // Order by:  
  //    increasing user key (according to user-supplied comparator)
  //    decreasing sequence number
  //    decreasing type (though sequence# should be enough to disambiguate)
  int r = user_comparator_-&amp;amp;gt;Compare(ExtractUserKey(akey), ExtractUserKey(bkey));  // ExtractUserKey 会忽略 Tag，比较原始 key
  if (r == 0) {  
    const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8);  // 取出 Tag
    const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8);  // 取出 Tag
    if (anum &amp;amp;gt; bnum) {  // 比较 Tag（序列号 + 操作类型）
      r = -1;  
    } else if (anum &amp;amp;lt; bnum) {  
      r = +1;  
    }  
  }  
  return r;  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实际的比较逻辑为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、先比较原始的 key，小的排在前面&lt;/li&gt;
&lt;li&gt;2、如果原始 key 相等，则比较序列号，&lt;u&gt;序列号大的排在前面（&lt;strong&gt;有点奇怪？这个逻辑很关键！点查/有序遍历/compaction 同 key 记录去重等依赖这个逻辑&lt;/strong&gt;）&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;4.3 引用计数&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MemTable 使用的 引用计数 变量 &lt;code&gt;int refs_&lt;/code&gt;，不是原子变量，所以计数增减都需要加互斥锁。并且因为计数减到小于等于0时， memtable 还需要析构自己，所以必须加锁。&lt;/p&gt;
&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code&gt;// Drop reference count.  Delete if no more references exist.  
void Unref() {  
  --refs_;  
  assert(refs_ &amp;amp;gt;= 0);  
  if (refs_ &amp;amp;lt;= 0) {  
    delete this;  
  }  
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2024-11-10</pubDate>
            <link>https://blog.xiayf.cn/posts/leveldb-note-1.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/leveldb-note-1.html</guid>
        </item>
        
        <item>
            <title>团队开发流程规范</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;本文原是针对实际工作中团队的情况编写的一份流程规范说明，隐去敏感信息之后存放于此。&lt;/em&gt;&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2023/04/05/wQ9bOaXyNiCjh5H.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;开发流程规范 是一种团队文化，也是服务和业务稳定性的基本保障线。&lt;/p&gt;
&lt;h2&gt;一、文档&lt;/h2&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;共识：“谋定而后动”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;团队的开发工作主要来自3个方面：工程优化（平响优化、性能优化、稳定性/可用性优化等）、算法业务需求、产品业务需求。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（强制）每一项开发工作实际编码之前，都需要梳理一份文档，放在 开发文档 目录下&lt;/li&gt;
&lt;li&gt;（建议）文档命名规则如示例 “w1-20220721-xxx需求”、“w1-20220721-xxx优化”，“w1” 是文档的按序编号。&lt;/li&gt;
&lt;li&gt;（建议）每一项工作，上线/推全后，部署相关信息、工程指标变化、业务指标变化、资源成本变化、遗留待优化的非关键问题等相关信息也应补充到文档中。&lt;/li&gt;
&lt;li&gt;（建议）如果走实验流程，也在在文档中加上“实验推进板块”，记录实验推进情况，遇到的问题等，特别是对于多场景实验推进的情况。&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.1 工程优化 文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;背景/现状描述/问题分析&lt;/li&gt;
&lt;li&gt;优化方案/设计方案&lt;/li&gt;
&lt;li&gt;预期收益&lt;/li&gt;
&lt;li&gt;分工排期&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.2 算法业务需求文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确算法负责人，链接上算法侧相关文档（要求算法同学提供） - 文档中包含 背景、预期收益、算法逻辑/模型等要点信息&lt;/li&gt;
&lt;li&gt;明确工程方案，对于复杂的算法业务需求，应该给出设计概要&lt;/li&gt;
&lt;li&gt;预估资源成本&lt;/li&gt;
&lt;li&gt;明确项目优先级 和 排期 / Deadline&lt;/li&gt;
&lt;li&gt;对于高优紧急需求，尽可能预先明确进度风险点&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.3 产品业务需求文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确产品负责人，链接上产品侧相关文档（要求产品同学提供） - 文档中包含 背景、预期收益、产品规则等要点信息&lt;/li&gt;
&lt;li&gt;明确工程方案，对于复杂的产品业务需求，应该给出设计概要&lt;/li&gt;
&lt;li&gt;预估资源成本&lt;/li&gt;
&lt;li&gt;明确项目优先级 和 排期 / Deadline&lt;/li&gt;
&lt;li&gt;对于高优紧急需求，尽可能预先明确进度风险点&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.4 所有文档&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（强制）必须包含：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;测试用例设计和全面完整的测试报告/diff 报告&lt;/li&gt;
&lt;li&gt;包含对应各个代码库变更的 MR 链接、发布版本的 tag 链接&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;二、编码&lt;/h2&gt;
&lt;h3&gt;2.1 统一代码规范&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;共识：新代码统一新风格，老代码风格维持不变。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;2.1.1 C++&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/cppguide.html&apos;&gt;Google C++ Style Guide&lt;/a&gt;、&lt;a href=&apos;https://zh-google-styleguide.readthedocs.io/en/latest/google-cpp-styleguide/contents/&apos;&gt;Google C++ 风格指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码规范/风格检查工具：&lt;a href=&apos;https://github.com/cpplint/cpplint&apos;&gt;cpplint&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Google 官方提供的工具，用于检测 C++ 代码是否符合 Google C++ Style Guide&lt;/li&gt;
&lt;li&gt;VS Code 插件：&lt;a href=&apos;https://marketplace.visualstudio.com/items?itemName=mine.cpplint&apos;&gt;cpplint - Visual Studio Marketplace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vim 插件：&lt;a href=&apos;https://github.com/vim-syntastic/syntastic&apos;&gt;vim-syntastic/syntastic: Syntax checking hacks for vim (github.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clion 插件：&lt;a href=&apos;https://plugins.jetbrains.com/plugin/7871-clion-cpplint&apos;&gt;CLion-cpplint - CLion Plugin | Marketplace (jetbrains.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;代码格式化工具：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html&apos;&gt;clang-format&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;项目根目录下放置 .clang-format 文件，编辑器/IDE 配置成编码时自动格式化或者保存时自动格式化：&lt;/li&gt;
&lt;li&gt;VS Code 插件：&lt;a href=&apos;https://marketplace.visualstudio.com/items?itemName=xaver.clang-format&apos;&gt;Clang-Format - Visual Studio Marketplace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vim 集成：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html#vim-integration&apos;&gt;https://clang.llvm.org/docs/ClangFormat.html#vim-integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clion 集成：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html#clion-integration&apos;&gt;https://clang.llvm.org/docs/ClangFormat.html#clion-integration &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;---
BasedOnStyle: Google
---
Language: Cpp
IndentWidth: 4
ColumnLimit: 120
DerivePointerAlignment: false
PointerAlignment: Left
SortIncludes: CaseSensitive
Standard: Auto
AccessModifierOffset: -4
SpacesBeforeTrailingComments: 2
AllowShortBlocksOnASingleLine: Never
AllowShortIfStatementsOnASingleLine: Never
AllowShortLoopsOnASingleLine: false
AllowShortFunctionsOnASingleLine: Empty
AlignTrailingComments: true
BinPackParameters: false
AllowAllParametersOfDeclarationOnNextLine: false&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;2.1.2 Java&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/javaguide.html&apos;&gt;Google Java Style Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.jetbrains.com/idea/&apos;&gt;IDE - Jetbrains IDEA&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;下载代码风格定义文件：&lt;a href=&apos;https://raw.githubusercontent.com/google/styleguide/gh-pages/intellij-java-google-style.xml&apos;&gt;intellij-java-google-style.xml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;导入 IDEA&lt;/li&gt;
&lt;li&gt;安装 Save Actions 插件&lt;/li&gt;
&lt;li&gt;配置 Save Actions 插件&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;2.1.3 Python&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Python 3 + &lt;a href=&apos;https://docs.python.org/3/library/venv.html&apos;&gt;venv 虚拟环境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/pyguide.html&apos;&gt;Google Python Style Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码规范/风格检查工具：&lt;a href=&apos;https://pylint.pycqa.org/en/latest/&apos;&gt;pylint&lt;/a&gt;、&lt;a href=&apos;https://google.github.io/styleguide/pyguide.html#21-lint&apos;&gt;https://google.github.io/styleguide/pyguide.html#21-lint&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Vim 集成：&lt;a href=&apos;https://github.com/vim-syntastic/syntastic&apos;&gt;vim-syntastic/syntastic: Syntax checking hacks for vim (github.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VS Code 集成：&lt;a href=&apos;https://code.visualstudio.com/docs/python/linting#_pylint&apos;&gt;Linting Python in Visual Studio Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyCharm 插件：&lt;a href=&apos;https://plugins.jetbrains.com/plugin/11084-pylint&apos;&gt;Pylint - IntelliJ IDEA &amp; PyCharm Plugin | Marketplace (jetbrains.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;代码格式化工具：&lt;a href=&apos;https://github.com/google/yapf/&apos;&gt;yapf&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Vim 集成：&lt;a href=&apos;https://github.com/google/yapf/tree/main/plugins#vim&apos;&gt;https://github.com/google/yapf/tree/main/plugins#vim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VS Code 集成：&lt;a href=&apos;https://code.visualstudio.com/docs/python/editing#_formatting&apos;&gt;Editing Python Code in Visual Studio Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyCharm 集成：&lt;a href=&apos;https://github.com/google/yapf/issues/631&apos;&gt;How do I install yapf in pycharm · Issue #631 · google/yapf (github.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.2 代码分支管理&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;共识：一个代码库一个主分支；所有开发分支在测试/实验验证之后都需要合入主分支&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（强制）基本的 git 工作流：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每项开发工作，都从主分支签出一个（公共）开发分支&lt;/li&gt;
&lt;li&gt;如果是多人协作的开发工作，则基于新签出的公共开发分支，每个人各自签出个人的开发分支，进行独立开发&lt;/li&gt;
&lt;li&gt;个人开发自测完成后，合入公共开发分支，进行集成测试联调&lt;/li&gt;
&lt;li&gt;如果走实验流程，则使用（公共）开发分支的 sandbox 镜像部署实验集群&lt;/li&gt;
&lt;li&gt;实验推全反转下线后，（公共）开发分支合入主分支，并基于主分支上的正式 tag 镜像发布基准集群&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（建议）分支命名规范：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（公共）开发分支：
&lt;ul&gt;&lt;li&gt;常规需求开发分支：feature/[目标服务名]-[文档 ID]&lt;/li&gt;
&lt;li&gt;紧急需求开发分支：urgent/[目标服务名]-[文档 ID]&lt;/li&gt;
&lt;li&gt;紧急修复开发分支：hotfix/[目标服务名]-[文档 ID]&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;个人开发分支：在（公共）开发分支后带上个人 ID，示例：feature/[目标服务名]-[文档 ID]-[个人 ID]&lt;/li&gt;
&lt;li&gt;对紧急需求和紧急修复开发分支，可以先创建一个文档，拿到文档 ID，内容可能来不及写得非常完善，但之后应该进行补充完善&lt;/li&gt;
&lt;li&gt;不符合规范的开发分支，不能推送到远程代码库（不能对团队其他人可见），通过 git hook 来强行限制&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（建议）所有（公共）开发分支、（需要代码评审的）个人开发分支，都应该创建对应的 MR，邀请其他人进行代码评审时，提供对应的 MR&lt;/p&gt;
&lt;h3&gt;2.3 Commit 规范&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://www.conventionalcommits.org/zh-hans/v1.0.0/&apos;&gt;约定式提交 (conventionalcommits.org)&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（建议）参考 Apache 顶级项目的实践（如 apache/arrow），commit log 的“描述”部分先带上文档链接。&lt;/p&gt;
&lt;h3&gt;2.4 MR 与代码评审&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;共识：质量把关、经验传承&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从团队和长远来看，Code Review 的重要性再怎么强调都不为过。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（强制）每个开发分支的工作在开实验或者合入主分支之前，都需要邀请至少 3 名资深同学进行 Code Review&lt;/li&gt;
&lt;li&gt;（强制）评审员在确认没有意见或者所有优化意见都已得到合理解决后对 MR 进行点赞 👍&lt;/li&gt;
&lt;li&gt;（强制）开发分支/MR 需要攒 3 个以上的点赞才能开实验流量或者合入主分支&lt;/li&gt;
&lt;li&gt;（强制）对于基于分支开实验流量的分支代码，也必须经 code review 后，基于分支进行打实验 tag，并基于实验 tag 进行线上发布。&lt;/li&gt;
&lt;li&gt;（建议）适当约束分支合入权限，仅资深同学（具体名单？）才能将开发分支/MR 合入主分支&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-markdown&quot;&gt;&lt;code&gt;变更应该组织成1个或多个补丁/MR，视变更大小而定，组织方式遵循以下规范指南：
- MR 应该小一点
- MR 应该都可以独立编译并且是正确的（所有测试用例都通过）。不需要你验证这一点，但是需要在代码中放入一种标记来反映 MR 是否违反了这条规则。例如：在 fix 一个问题之前，先引入一个回归测试用例用例。
- MR 应该自包含（高内聚），并且只做一件事情。
- 每个 MR 都应该包含一份描述性的提交日志（commit log）。
- MR 的描述信息不应该假设代码评审人是一个专家。它应该包含足够的上下文信息，确保即使一个普通的小白也能理解。
- MR 的描述信息应该自包含，也不要引用无法保持关联的讨论信息（“如每日沟通达成的一致结论”）。
- MR 应该包含变更的动机（背景）。不能简单地说一句“让 X 完成 Y”，而应该仔细解释为什么要这么做。 &lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另附：&lt;a href=&apos;https://google.github.io/eng-practices/&apos;&gt;Google Engineering Practices Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2.5 CI 约束&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因当前一个代码库支持产出不同服务的二进制程序和 Docker 镜像，为加速 CI，使用了条件编译，根据不同条件触发不同 CI 流水线。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;根据分支名的目标服务名对应触发不同 CI 流水线（all 则触发所有的 CI 流水线）&lt;/li&gt;
&lt;li&gt;MR 合入 master 分支时，必须触发所有 CI 流水线。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;基于 .gitlab-ci.yml 配置强行约束。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;2.6 版本 Tag 规范&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;正式tag
&lt;ul&gt;&lt;li&gt;只能在 master 分支上打 tag，tag 命名规范为 v主版本号.次版本号.修订号，基于 语义化版本&lt;/li&gt;
&lt;li&gt;tag 内容必须包含必要的描述性信息，声明此次变更的内容，包含相关的 MR、文档链接&lt;/li&gt;
&lt;li&gt;hotfix 版本 tag，应该以 fix 之前的 tag 为前缀，加上“-hotfix” 后缀，示例：v10.0.1-hotfix；如果对同一个 tag 的代码发生了不只一次 hotfix，则继续补充上秒级的时间戳作为后缀&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;实验tag
&lt;ul&gt;&lt;li&gt;在分支上打tag进行线上实验开量，tag命名规范：exp.文档编号.迭代版本号，示例：exp.w88.0&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.7 监控打点和日志&lt;/h3&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;共识：以尽可能小的性能开销最大化系统的可观测性&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;（建议）多使用 ROC 打点，借助多维数据分析，方便问题定位分析&lt;/li&gt;
&lt;li&gt;（强制）注意日志级别（DEBUG、INFO、ERROR、FATAL）的语义
&lt;ul&gt;&lt;li&gt;不要使用非 DEBUG 级别来输出 DEBUG 日志&lt;/li&gt;
&lt;li&gt;注意 FATAL 的实际影响&lt;/li&gt;
&lt;li&gt;不同环境使用不同的日志级别，生产环境不要输出 DEBUG 日志，https://github.com/google/glog#setting-flags&lt;/li&gt;
&lt;li&gt;（建议）使用 glog vlog 来进一步控制不同环境/场景下的日志量，https://github.com/google/glog#verbose-logging&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（强制）不要默默地失败
&lt;ul&gt;&lt;li&gt;ERROR/WARNING 日志&lt;/li&gt;
&lt;li&gt;Event 打点&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）使用 Event 打点充分表现输入量、输入类型、输出量、变化趋势
&lt;ul&gt;&lt;li&gt;请求 QPS、增量消息 TPS、不同类型增量消息的 TPS、。。。&lt;/li&gt;
&lt;li&gt;基准数据的统计计数&lt;/li&gt;
&lt;li&gt;请求来源：客户端类型粒度、客户端 ip 粒度、场景维度、媒体维度、。。。&lt;/li&gt;
&lt;li&gt;trigger 数、各类过滤器数目统计&lt;/li&gt;
&lt;li&gt;检索结果数量、截断后/实际返回给客户端的结果数量&lt;/li&gt;
&lt;li&gt;各类过滤器的过滤量&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）使用 Transaction 表现耗时分布 - 整体耗时多少、时间都花在哪些环节（包括 RPC 框架内的等待时延）：Tt = T1 + T2 + ...&lt;/li&gt;
&lt;li&gt;（建议）使用 Metric 表现跨节点/集群/场景的业务指标变化趋势&lt;/li&gt;
&lt;li&gt;（建议）性能考虑，打点接口调用次数应小于等于请求 QPS、消息 TPS&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.8 最佳实践&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）尽早严格检测请求、数据、配置等输入的合法性&lt;/li&gt;
&lt;li&gt;（建议）尽量不使用配置中心的配置监听&lt;/li&gt;
&lt;li&gt;（建议）多了解使用基础库 - boost、abseil-cpp 等&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;三、测试&lt;/h2&gt;
&lt;h3&gt;3.1 单元测试&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确单元测试与集成测试的区别，&lt;a href=&apos;https://zh.wikipedia.org/wiki/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95&apos;&gt;wikipedia - 单元测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;单元测试的作用：
&lt;ul&gt;&lt;li&gt;验证某个逻辑的当前实验是否符合预期&lt;/li&gt;
&lt;li&gt;更重要的是对以后的代码变更可能造成的非预期影响/破坏进行一定的防御&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;GoogleTest，用好 Mocking&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（强制）CI 强制要求新增/变更代码的测试覆盖率。（基于 .gitlab-ci.yml 配置强行约束？）&lt;/p&gt;
&lt;h3&gt;3.2 集成测试&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）任何代码变更，都必须经过自测/集成测试
&lt;ul&gt;&lt;li&gt;任务可以正常跑起来，变更的逻辑已生效，产出的结果确认符合预期&lt;/li&gt;
&lt;li&gt;服务可以正常运行起来，变更的逻辑已生效，可以正常加载数据/索引，请求响应的结果确认符合预期&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）测试环境/工具
&lt;ul&gt;&lt;li&gt;独立的测试验证集群&lt;/li&gt;
&lt;li&gt;开发机环境下的 Docker 环境 + 代码库中的 Dockerfile
&lt;ul&gt;&lt;li&gt;docker build -t image-name .&lt;/li&gt;
&lt;li&gt;docker run -dp 8003:8003 image-name&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;易用的脚本 - 一键启动+索引数据加载、易用的客户端工具、易用的数据校验工具&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;3.3 批量 Diff 测试&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（强制）如果代码变更影响了索引或者检索逻辑，则应该进行充分的 diff：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果走实验，则部署新实验集群后开实验之前，进行 基准集群 VS. 实验集群 的请求结果 diff&lt;/li&gt;
&lt;li&gt;如果不走实验，则基于独立的测试验证集群，进行 生产集群 VS. 测试集群 的请求结果 diff
&lt;ul&gt;&lt;li&gt;diff 完成后，即刻释放测试集群资源&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;对于 diff 结果，不管最后的 diff 率有多小，只要有 diff，就需要确认 diff 来源/原因是否符合预期&lt;/li&gt;
&lt;li&gt;diff 的不同请求数量必须达到 1000 以上&lt;/li&gt;
&lt;li&gt;统一使用易用且功能完善的 diff 工具&lt;/li&gt;
&lt;li&gt;生产集群发版或者实验集群开流量之前，在周知相关人员时，必须一并提供 diff 结果以及已确认 diff 来源符合预期&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;四、发布&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;（强制）流量高峰期不发版&lt;/li&gt;
&lt;li&gt;（建议）周五晚上及周末不发版&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;4.1 发布之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）评估确认好本次发布前后服务集群负载是否会有变化，如果变更会影响集群负载上涨，则应提前扩容&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内进行通告，通告模板如下：&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;变更通知：
- 变更内容：xxxx
- 涉及集群和场景：xxx
- 操作人：xxx
- 相关文档（含需求背景、工程方案、代码 MR、diff / 测试报告等信息） 或 实验链接：xxx&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4.2 发布期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）先灰度发布一行或者少量行，确认各项工程指标+业务指标无异常后，再全量发布&lt;/li&gt;
&lt;li&gt;（强制）发布期间需要保持关注告警以及关键工程指标和业务指标&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;4.3 发布之后&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（强制）发版完成后，确认各项工程指标/业务指标正常后，在相关大群内周知发版完成，确认各项指标平稳/符合预期&lt;/p&gt;
&lt;h2&gt;五、实验&lt;/h2&gt;
&lt;h3&gt;5.1 实验开量之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）人工刷 demo，全链路验证&lt;/li&gt;
&lt;li&gt;（强制）实验集群资源预估准备，包括评估链路中间环节资源负载变化&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内通告，通告信息：实验名、实验链接&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.2 实验期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）实验刚开量时，关注实时报表 10~30 分钟变化趋势：&lt;/li&gt;
&lt;li&gt;（建议）每天及时查看实验平台上当前实验的天级实验报表，如果有较明显的负向指标，则应及时通告出来，与相关同学一起分析可能的原因&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.3 实验扩量或推全之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）实验集群资源预估准备，包括评估链路中间环节资源负载变化&lt;/li&gt;
&lt;li&gt;（强制）与相关算法同学确认好实验时长与实验效果是否达到扩量要求&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内通告，通告信息：实验名、实验链接、流量从多少变化到多少&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.4 实验扩量或推全操作期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）对实验集群负载情况保持关注&lt;/li&gt;
&lt;li&gt;（建议）对于推全操作，尽可能灰度推全，中间步骤留一定时间确认集群负载和流量变化是否符合预期&lt;/li&gt;
&lt;li&gt;（建议）先开反转，再进行推全，避免不必要的资源腾挪扩缩，也能一定程度上控制风险&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;六、规范落地&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;（建议）规范流程支持工具和平台不断优化，尽可能减少规范流程造成的人力负担&lt;/li&gt;
&lt;li&gt;（建议）不断更新完善规范&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2023-04-05</pubDate>
            <link>https://blog.xiayf.cn/posts/team-dev-process-std.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/team-dev-process-std.html</guid>
        </item>
        
        <item>
            <title>与一个前 leader 的交流笔记</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;如下这份笔记，是 19 年和一个前 leader 交流后记录下来的。说是交流，其实是针对我当时工作中存在的问题，他给我提出的一些改进建议。如今再看看，仍然能引起自己的思考。&lt;/p&gt;
&lt;h2&gt;2019-10-27&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;如何讨论需求/技术方案&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;系统性理解需求
&lt;ul&gt;&lt;li&gt;全面梳理技术方案，论证方案的不合理之处&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;如何证明方案不合理？
&lt;ul&gt;&lt;li&gt;资源成本（机器、人力），重复工作也是对资源的一种浪费&lt;/li&gt;
&lt;li&gt;对效果（收入等）的影响&lt;/li&gt;
&lt;li&gt;要站在“公正”的角度来论证，从大家共有的认知(机器、带宽、内存)出发&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后才是什么系统复杂度（说到这个点，很容易扯淡，谁都会说自己复杂）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;讨论问题的时候，自己不做，但不要从“硬推给别人的角度”去讨论，而是要从“为啥自己不应该做”的角度出发。比如做了，导致系统耦合，复杂，做了导致多余的调用量更多等 。&lt;/p&gt;
&lt;h2&gt;2019-12-17&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;跨团队工作讨论时，围绕应该怎么做（怎么做最合理）来讨论，而不是围绕如果自己来做会有什么困难来讨论&lt;/li&gt;
&lt;li&gt;项目/系统要有 目标/长远架构图（最终做成什么样子，核心 KPI）&lt;/li&gt;
&lt;li&gt;做好向上汇报&lt;/li&gt;
&lt;li&gt;不要拿“做的过程中的困难”来搪塞不做，而是要从客观事实的角度来问应不应该做&lt;/li&gt;
&lt;li&gt;不要聚焦于解决现实世界的一个个问题，而是要靠具体的一个个问题，抽象出一张大图&lt;/li&gt;
&lt;li&gt;把自己的系统做成链路上最极致的那个，而不是等别人做好后来反推自己变革&lt;/li&gt;
&lt;li&gt;要区分重要和不重要的事情，核心的事情要仔细揣摩，没有人是傻子，那些资深的人说出的话更要揣摩，理解&lt;/li&gt;
&lt;li&gt;要有规划和愿景，leader 没有这些，团队走不远&lt;/li&gt;&lt;/ol&gt;</description>
            <pubDate>2022-11-16</pubDate>
            <link>https://blog.xiayf.cn/posts/talk-about-how-to-do.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/talk-about-how-to-do.html</guid>
        </item>
        
        <item>
            <title>读文：关于 MMAP 与 SSD</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;设计一种存储，第一要明确应用场景和存储系统的工作负载，第二要了解底层硬件的特点。&lt;/p&gt;
&lt;h2&gt;1、&lt;a href=&apos;https://db.cs.cmu.edu/mmap-cidr2022/&apos;&gt;Are You Sure You Want to Use MMAP in Your Database Management System? &lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MMAP（Memory-mapped file I/O）是操作系统提供的一种功能特性 - 将二级存储（磁盘、SSD）上一个文件的内容映射到程序/进程的地址空间，然后程序就可以以指针访问内存页的方式来访问文件内容。当程序访问到某个内存页时，操作系统就会自动将对应文件内容加载到该内存页中，当内存用满了，也会自动剔除某些内存页。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MMAP 其实就一个现成的缓冲池（buffer pool），核心特点就是简单易用，不需要重复开发，缺点是在需要时无法精确控制其行为。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 MMAP 的优势是由操作系统封装了如下功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从磁盘读数据&lt;/li&gt;
&lt;li&gt;不同线程读相同数据的并发处理&lt;/li&gt;
&lt;li&gt;缓存和缓冲管理（Caching and buffer management）&lt;/li&gt;
&lt;li&gt;从内存中剔除/驱逐内存页&lt;/li&gt;
&lt;li&gt;同一个机器上不同进程之间可以友好交互 🤔&lt;/li&gt;
&lt;li&gt;跟踪脏页以及将脏页写入磁盘 🤔&lt;/li&gt;
&lt;li&gt;相比 read/write 系统调用，mmap 不需要将内存页从内核空间拷贝到用户空间，而是直接从操作系统的内存页缓存中直接访问内存页，有一定的性能优势&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MMAP 相关 POSIX API：mmap、madvise、mlock、msync。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/U7xMgzj36dZDGaO.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;① A program calls mmap and receives a pointer to the memory-mapped file contents.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;② The OS reserves part of the program’s virtual address space but does not load any part of the file.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;③ The program accesses the file’s contents using the pointer.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;④ The OS attempts to retrieve the page.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;⑤ Since no valid mapping exists for the specified virtual address, the OS triggers a page fault to load the referenced part of the file from secondary storage into a physical memory page.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;⑥ The OS adds an entry to the page table that maps the virtual address to the new physical address.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;⑦ The initiating CPU core also caches this entry in its local translation lookaside buffer (TLB) to accelerate future accesses.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过论文作者认为 mmap 存在一些数据安全性和系统性性能问题，为解决这些问题而引入的工程成本会抵消掉简单性：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;1、事务安全性（Transactional Safety）&lt;/strong&gt;：由于透明的页式调度机制，操作系统可能会任意时刻将一个脏页刷到二级存储中，不管写事务是否已提交。DBMS 无法组织这种内存数据刷出，并且发生时也不会接收到任何信号。所以基于 mmap 的数据库系统只能采用复杂的协议来确保（写/更新）事务安全，手段上大概分3种：操作系统写时复制、用户空间写时复制、影子页管理（shadow paging）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;2、I/O 停顿（I/O Stalls）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;mmap 不支持异步读；自己搞缓冲池的话，可以使用异步 I/O（比如 libaio、io_uring）来避免查询时阻塞线程&lt;/li&gt;
&lt;li&gt;对于 mmap，因为操作系统会自动/透明地剔除一些内存页，这样可能导致 - 如果某些只读查询命中了已被剔除的内存页，就会无法预知地触发阻塞性的页错误/缺页处理&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;解决方案：1、使用 mlock，不过操作系统对一个进程能锁住的内存页数量有限制；2、使用 madvise 的 MADV_SEQUENTIAL 标记，仅能问题的一部分；3、使用额外的线程来进行内存页预取，避免主线程被阻塞，不过会引入较大的复杂性&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;3、错误处理&lt;/strong&gt;：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;DBMS 的核心职责之一是确保数据完整性 - 比如：校验磁盘数据是否有损坏&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用 mmap，DBMS 需要在每次内存页访问时检查校验和（checksum），因为内存页一次访问之后操作系统可能会将该页驱逐到磁盘&lt;/li&gt;
&lt;li&gt;如果 DBMS 是使用非内存安全的编程语言编写的，就有可能在指针操作时损坏内存页内容，所以需要在内存页刷到二级存储之前进行错误检测，mmap 会默默地将损坏的内存页持久化到二级存储&lt;/li&gt;
&lt;li&gt;使用 mmap 也更难优雅地进行 I/O 错误处理，和 mmap 内存交互的任何代码都可能抛出 SIGBUS 信号，DBMS 必须使用信号处理器（signal handlers）来处理 ❓&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;4、性能问题（最重大）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;大家普遍认为 mmap 性能优于传统文件 I/O（read/write），因为它避免两个开销：(1) 显式调用 read/write 系统调用的开销 (2) mmap 会返回指向操作系统页缓存的页指针，因此避免了到用户内存空间的一次内存拷贝，也因此降低了内存占用；由此，大家也认为在 SSD 上 mmap 的性能优势会进一步扩大。&lt;/li&gt;
&lt;li&gt;不过实验测试发现：对于高带宽的二级存储设备（比如 SSD），DBMS 管理的数据量大于内存空间时，操作系统的页驱逐机制（page eviction mechanisms）多线程扩展性比较差（备注：因为 SSD I/O 带宽大、访问速度快，页驱逐机制就可能成了瓶颈）（we have found that the OS’s page eviction mechanisms cannot scale beyond a few threads for larger-thanmemory DBMS workloads on high-bandwidth secondary storage devices. We believe that one of the main reasons these performance issues have gone largely unnoticed is due to historically limited file I/O bandwidth）。瓶颈源于3个因素：
&lt;ul&gt;&lt;li&gt;页表争用（page table contention）/ 锁（备注：当前 linux 内核实现优化了这个问题，&lt;a href=&apos;https://github.com/torvalds/linux/blob/master/Documentation/mm/split_page_table_lock.rst&apos;&gt;linux/split_page_table_lock.rst at master · torvalds/linux (github.com)&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;单线程页驱逐（single-threaded page eviction），&lt;a href=&apos;https://biriukov.dev/docs/page-cache/4-page-cache-eviction-and-page-reclaim/&apos;&gt;Page Cache eviction and page reclaim | Viacheslav Biriukov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;旁路转换缓冲击落（TLB shootdowns）：TLB shootdowns occur during page eviction when a core needs to invalidate mappings in a remote TLB. Whereas flushing the local TLB is inexpensive, issuing interprocessor interrupts to synchronize remote TLBs can take thousands of cycles
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://juejin.cn/post/6844904084957315086&apos;&gt;深入理解 Linux 内核--jemalloc 引起的 TLB shootdown 及优化 - 掘金 (juejin.cn)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.kernel.org/doc/html/v4.18/core-api/cachetlb.html&apos;&gt;Cache and TLB Flushing Under Linux — The Linux Kernel documentation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实验分析：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;As a baseline, we used the fio storage benchmarking tool (v3.25) with direct I/O (O_DIRECT) to bypass the OS page cache. Our analysis focused exclusively on read-only workloads, which represent the best-case scenario for mmap-based DBMSs.&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/FlAJqH8E4K1UWvp.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/qhz3OQHlgaZ2YMn.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/oczkfgLw9EMR1ue.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么，到底要不要使用 mmap 呢？直接使用 ssd？还是自己搞一个 buffer pool？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;论文作者给出这样的结论：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;以下情况不要使用 mmap：
&lt;ul&gt;&lt;li&gt;需要以事务安全的方式进行更新操作&lt;/li&gt;
&lt;li&gt;希望处理缺页错误时不会阻塞在慢 I/O 上，或者希望明确控制哪些数据应该在内存中&lt;/li&gt;
&lt;li&gt;关心错误处理，也希望始终返回正确的数据结果&lt;/li&gt;
&lt;li&gt;要求在快速持久化存储设备（比如 SSD）上获得高吞吐&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;以下情况可能应该使用 mmap：
&lt;ul&gt;&lt;li&gt;内存可以容纳整个数据工作集（或者说整个数据库），并且是只读的工作负载&lt;/li&gt;
&lt;li&gt;希望将一个产品快速推向市场，也不关注数据一致性或者长期的工程技术债&lt;/li&gt;
&lt;li&gt;Otherwise, never 🤣🙃&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;彩蛋：论文的奇数页页眉  😂&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/AIqHKTC213FYaxX.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100&apos;/&gt;
&lt;h2&gt;2、&lt;a href=&apos;https://ayende.com/blog/196161-C/re-are-you-sure-you-want-to-use-mmap-in-your-database-management-system&apos;&gt;re: Are You Sure You Want to Use MMAP in Your Database Management System? &lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文作者认为自己实现一个内存分页管理器/缓冲池比较复杂，使用 mmap 来实现存储系统会很快。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过吐槽了原论文没有给出可供选择的替代方案，基准测试和结论之间也没太多相关性（compares apples to camels），也低估了自己实现一个替代 mmap 的缓冲池的复杂性。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不用 mmap 的话，论文提及的那些问题，也是要解决的（If you aren’t using mmap, on the other hand, you still need to handle all those issues. That is a key point that I believe isn’t addressed in the paper. Solving those issues properly (and efficiently) is a seriously challenging task. Given that you are building a specialized solution, you can probably do better than the generic mmap, but it will absolutely have a cost. That cost is both in terms of runtime overhead as well as increased development time.）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;原论文的实验说明了 mmap 的性能问题，但是换个 buffer pool 的实现能不能获得更好的性能呢？该文作者持悲观态度。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;存储系统实际面对的工作负载不会是完全的随机读（写）或顺序扫描，通常都具有一定的热点数据，这时 buffer pool 的优势就会体现出来？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;关于“问题 1 - 事务安全性” - 不用 mmap，解决这个问题的方案没什么不同（I don’t actually care if the data is written to memory behind my back. What I care about is MVCC (a totally separate concern than buffer management). The fact that I’m copying the modified data to the side means that I Can support concurrent transactions with far greater ease.）&lt;/li&gt;
&lt;li&gt;关于“问题 2 - I/O 停顿” - 该文作者认为确实个问题（not having control over the I/O means that you may incur a page fault at any time），并且是基于 mmap 的系统要面对的最大问题。不过实际情况是 linux 系统中 io_uring 之外的异步 I/O 方案在某些时候异步操作也会是阻塞的。是否使用 mmap，这个问题的解决方案也没有本质区别。&lt;/li&gt;
&lt;li&gt;关于“问题 3 - 错误处理” - 该文作者以自己开发的 Voron 为例说明即使使用 mmap，也可以较好地实现校验和检查（使用一个 bitmap 来记录哪些内存页被访问过，在第一次访问某个内存页的时候检查校验和），并认为程序一次运行过程中对于指定的一个内存页检查一次就可以，其他情况下的检查都是没有意义的。When you use read() to get data from the disk, you have no guarantees that the data wasn’t fetched from a cache along the way. So you may validate the data you read is “correct”, while the on disk representation is broken. For that reason, we only do the check once, instead of each time. 🤔 好像不是这个理？
&lt;ul&gt;&lt;li&gt;至于发现 I/O 错误，如何处理？该文作者认为答案只有一个 - 让它崩溃然后重新恢复并运行（Crash and then run recovery from scratch），因为如果 I/O 系统返回了一个错误，应用逻辑也不会有任何方式知道 I/O 系统的当前状态是什么，应该怎么解决，唯一的方式就是停下来，重新加载一切（应用 WAL 进行恢复），回到一个稳定状态。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;关于“问题 4 - 性能问题” -
&lt;ul&gt;&lt;li&gt;页表争用（page table contention）：linux 内核已优化解决&lt;/li&gt;
&lt;li&gt;单线程页驱逐（single-threaded page eviction）：如果写/更新频率不高，脏页不多的话，也不会成为性能瓶颈&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://stackoverflow.com/questions/3748384/what-is-tlb-shootdown&apos;&gt;旁路转换缓冲击落（TLB shootdowns）&lt;/a&gt;：在一定条件下才会成为性能瓶颈，当你真的遇到时应该也会多花钱买内存来解决 🤣🙃（In order to actually observe the cost of TLS Shootdown in a significant manner, you need to have: (1) really fast I/O (2)working set that significantly exceeds memory (3) no other work that needs to be done for processing a request; In practice, if you have really fast I/O, you spent money on that, you’ll more likely get more RAM as well. And you typically need to do something with the data you read, which means that you won’t notice the TLB shootdown as much）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;3、&lt;a href=&apos;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&apos;&gt;WiscKey: Separating Keys from Values in SSD-Conscious Storage&lt;/a&gt; /   &lt;a href=&apos;https://dgraph.io/blog/post/badger/&apos;&gt;Introducing Badger: A fast key-value store written purely in Go&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;WiscKey 是一个基于 LSM (Log Structured Merge)树的 KV 存储引擎，针对 SSD 的随机读和顺序读性能特点，将 Key 和 Value 分开存储，以尽可能缩小 I/O 放大问题，提升性能。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Value 存放在 Log 文件中，LSM 树仅存储 Key 和 Value 在 Log 文件的位置以及长度/大小。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 Value 比较大的应用场景，性能优势明显。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/y84VKqJZWMSjBu7.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为 LSM 树不存储 Value 本身，通常比较小，可以全部放在内存中，所以不考虑获取 Value 的值，点查和范围查找速度非常快。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;LSM 树比较小，所以 Compaction 次数少，速度快（特别是如果整个 LSM 都放在内存中的话）。Compaction 过程中不需要读写 Value 的值，所以 I/O 放大倍数要小很多。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/2tvp5LROXG4UYrw.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;点查过程，从 LSM 树中获取 Value 的位置和大小后，需要从 Value Log 中获取 Value 值。因为 LSM 树小，所以读放大倍数小，综合起来看，WiscKey 点查的性能优势依旧明显。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;范围查找/遍历过程，先从 LSM 树中获得目标范围内的所有 Value 的位置和大小，放入队列，使用多线程进行并发预取，利用 SSD 随机读的吞吐能力随并发树近线性增长的特点。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/APbQlhq3nWsf47j.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/j357k6XMfYO2udm.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;400&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Value Log 也需要 GC，清理掉无用的 Value 值。LSM 树的 Compaction 主要是为了提升查找/检索的性能/效率，控制读放大，减少内存/磁盘空间占用是次要的。Value Log 的 GC 则主要是为了减少内存/磁盘空间占用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了实现在线的轻量级 GC，Value Log 中也存储了 Key，&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/JMKxWiaCovyhgr8.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;tail 指向 Value Log 有效值范围内时序上最先写入的那个 value 的位置。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;head 指向 Value Log 中下一个新 value 写入的位置。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;tail 和 head 及其对应的位置信息均作为 kv 存入 LSM 树中（head 的指向什么时候会更新？：每次有新值写入的时候都更新？还是在 GC 的过程中才会更新？）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;GC 的流程为：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;① 从 tail 指向的位置开始顺序扫描一块数据，根据其中的 key 检索 LSM 树，确认当前 value 是否有效（没有被删除也没有被覆盖）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;② 如果有效则插入到 head 指向的位置，head 指向移动到下一个位置；如果无效，则直接丢弃&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;③ 一块数据处理完成后，移动 tail 指向到下一个位置，释放/回收原来数据块的存储空间；然后继续循环处理&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;疑问&lt;/strong&gt;：1. GC 过程中每次向 head 插入有效值时，是否先要从 LSM 树中查询最新指向的位置？2. 在根据 key 从 LSM 树查询后将有效值写入 head 位置前，有新数据写入的话，怎么处理？GC 期间是否要停止正常的写操作？还是说对某个临界区加锁？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;LSM 树原理：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/k6cHFOUluo1Ibfp.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/17WubUhqSpCjMr5.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/Tomk3VOEs7jduQl.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://zhuanlan.zhihu.com/p/181498475&apos;&gt;LSM树详解 - 知乎 (zhihu.com)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;4、&lt;a href=&apos;http://www.vldb.org/pvldb/vol14/p364-didona.pdf&apos;&gt;Toward a Better Understanding and Evaluation of Tree Structures on Flash SSDs（VLDB）&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;PTS - Persistent tree data structure&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 LSM 树（RocksDB）和 B+ 树（WiredTiger）来分析 SSD 基准测试（Benchmarking）中可能踩到的 7 个坑（pitfall）：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（1）Running short tests / 测试过于短平快&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;随着使用时间的增加，SSD 的性能会一定的动态变化。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Because both the PTS and SSD performance vary over time, short-lived tests are unable to capture how the systems will behave under a continuous（non-bursty）workload.&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/HSuzIeC8itjndGw.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;WA-A（应用/存储系统的写放大） increases over time while the levels of the LSM-Tree fills up, and its curve flattens once the layout of the LSM tree has stabilized.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;WA-D（SSD 设备的写放大） increases over time because of the effect of garbage collection.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（2）Ignoring the device write amplification (WA-D) / 忽视了 SSD 设备本身的写放大&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;WA-D directly affects the throughput of the device, which strongly correlates with the application-level throughput.&lt;/li&gt;
&lt;li&gt;WA-D is an essential measure of the I/O efficiency of a PTS. 端到端的写放大倍数应该是 WA-A 乘以 WA-D&lt;/li&gt;
&lt;li&gt;WA-D measures the flash-friendliness of a PTS.
&lt;ul&gt;&lt;li&gt;A low WA-D indicates that a PTS generates a write access that does not incur much garbage collection overhead in the SSD.&lt;/li&gt;
&lt;li&gt;以前大家可能认为 LSM 树（顺序写）相比 B+ 树（随机写）对 SSD 更友好，但实测 WA-D 颠覆了这个认知&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（3）Ignoring the internal state of the SSD / 忽视了 SSD 的初始内部状态&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/pFyqSCVZnrHB1g9.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Trim(Discard)的出现主要是为了提高GC的效率以及减少写入放大的发生，最大作用是清空待删除的无效数据&lt;/strong&gt;。在SSD执行读、擦、写步骤的时候，预先把擦除的步骤先做了，这样才能发挥出SSD的性能，通常SSD掉速很大一部分原因就是待删除的无效数据太多，每次写入的时候主控都要先做清空处理，所以性能受到了限制。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;The steady-state performance of a PTS can greatly differ depending on the initial state of the drive, this is surprising.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;This phenomenon is caused by how the LBA (logic block address)  access patterns of RocksDB and WiredTiger intertwine with the SSD garbage collection mechanism as a function of the initial state the drive.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;WiredTiger only writes to a limited portion of the logical block address space.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（4）Ignore the dataset size / 忽视了数据集大小&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/SlVWJfP5rO7xpNQ.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;The amount of data stored by the SSD changes its behavior and affects overall performance.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;The performance degradation brought by the larger dataset is primarily due to the idiosyncrasies（特质/特点） of the SSD: larger datasets lead to more valid pages in each flash block, which increases the amount of data being relocated upon performing garbage collection, i.e., the WA-D&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（5）Ignoring the extra storage capacity a PTS needs to manage data and store additional meta-data / 未考虑空间放大（Space amplification）&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;涉及存储成本&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（6）Ignoring SSD over-provisioning&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;成本与性能之间的权衡折中 - 可以预留一部分 SSD 空间给 SSD 做 GC 使用，这部分空间对文件系统不可见。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/YEFp5g69mnqBe3w.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;（7）Ignoring the effect of the underlying storage technology on performance&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;5、SSD 原理相关资料&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://zhuanlan.zhihu.com/p/102089411&apos;&gt;浅谈分布式存储之SSD基本原理 - 知乎 (zhihu.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://mp.weixin.qq.com/s/_uiCsFXWjepeHSdgiUABhg&apos;&gt;聊聊 SSD 的基本原理 (qq.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://xiongduo.cn/posts/coding-for-ssds-part-1-introduction-and-table-of-contents.html&apos;&gt;为SSD编程（1）：简介和目录 (xiongduo.cn)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://www.ssdfans.com/?p=8077&apos;&gt;SSD背后的秘密：SSD基本工作原理 (ssdfans.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2022-09-14</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-about-mmap-ssd.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-about-mmap-ssd.html</guid>
        </item>
        
        <item>
            <title>Disruptor 等待策略引发的 CPU 负载异常问题</title>
            <description>&lt;h2&gt;背景&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;工作中，我负责的系统是一个数据流处理服务 - 以流水线（pipeline）的形式分多级异步处理：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/14/ONwUsrlhLmIq8BW.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中的 队列 实际使用的是 &lt;a href=&apos;https://github.com/LMAX-Exchange/disruptor&apos;&gt;Disruptor&lt;/a&gt;，多生产者单消费者模式：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat(name).setDaemon(true).build();
Disruptor&amp;amp;lt;Event&amp;amp;lt;T&amp;amp;gt;&amp;amp;gt;  disruptor = new Disruptor&amp;amp;lt;&amp;amp;gt;(Event&amp;amp;lt;T&amp;amp;gt;::new, bufferSize, factory, ProducerType.MULTI, new SleepingWaitStrategy());
disruptor.handleEventsWith((Event&amp;amp;lt;T&amp;amp;gt; event, long sequence, boolean endOfBatch) -&amp;amp;gt; {
    consumer.accept(event.value, endOfBatch);
    event.value = null;
});&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;服务运行在 k8s 集群上，每个容器节点上可能会运行多个 pipeline，也即意味着单个节点上会存在多个 disruptor 实例。&lt;/p&gt;
&lt;h2&gt;现象&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;近期突然收到测试环境很多节点（生产环境也有少量节点）的 CPU 使用率告警 - CPU 使用率持续 5 分钟以上超过 90%，如下其中一个任务节点的 CPU 使用率监控图：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/14/XJVsiMI3b9m5dlB.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/14/2YwPQAqaICr879x.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;cpu.busy = cpu.system + cpu.user + 软/硬中断&lt;/code&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意其中 &lt;code&gt;cpu.system&lt;/code&gt; 比 &lt;code&gt;cpu.user&lt;/code&gt; 高不少，&lt;code&gt;cpu.busy&lt;/code&gt; 又比 &lt;code&gt;cpu.system&lt;/code&gt; 高不少。也即 CPU 时间片资源主要消耗在 内核态 和中断逻辑上（对于这些任务而言 &lt;code&gt;cpu.user&lt;/code&gt; 指标也是异常的）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些节点运行的任务，几乎没有数据需要处理，也就是说几乎是空跑的。从线程数量监控以及 jstack 输出的堆栈跟踪信息，也未发现明显异常。&lt;/p&gt;
&lt;h2&gt;原因排查&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将测试环境的任务在本地环境运行起来，并基于 &lt;a href=&apos;https://www.lightbend.com/blog/profiling-jvm-applications&apos;&gt;How to profile JVM applications&lt;/a&gt; 一文中提到的火焰图工具，产出对应 JVM 应用的火焰图：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/14/zQMWsBeKbuZLamN.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从图中可以大致看出其中 &lt;code&gt;com/lmax/disruptor/SleepingWaitStrategy:::waitFor&lt;/code&gt; / &lt;code&gt;jdk/internal/misc/Unsafe:::park&lt;/code&gt; 比较可疑，在调用栈中耗时最长。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从项目源码和 jstack 输出的堆栈跟踪信息可以看到，测试任务中大致涉及 18个 disruptor 实例，均使用 &lt;code&gt;SleepingWaitStrategy&lt;/code&gt; 等待策略，该策略的 &lt;a href=&apos;https://github.com/LMAX-Exchange/disruptor/blob/master/src/main/java/com/lmax/disruptor/SleepingWaitStrategy.java#L56&apos;&gt;waitFor&lt;/a&gt; 方法实现如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;public long waitFor(final long sequence, Sequence cursor, final Sequence dependentSequence, final SequenceBarrier barrier) throws AlertException {
    long availableSequence;
    // 默认 200
    int counter = retries;

    while ((availableSequence = dependentSequence.get()) &amp;amp;lt; sequence) {
      counter = applyWaitMethod(barrier, counter);
    }

    return availableSequence;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;waitFor 方法中核心调用了 &lt;a href=&apos;https://github.com/LMAX-Exchange/disruptor/blob/master/src/main/java/com/lmax/disruptor/SleepingWaitStrategy.java#L76&apos;&gt;applyWaitMethod&lt;/a&gt; ：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;private int applyWaitMethod(final SequenceBarrier barrier, int counter) throws AlertException {
    barrier.checkAlert();

    if (counter &amp;amp;gt; 100)
    {
        --counter;
    }
    else if (counter &amp;amp;gt; 0)
    {
        --counter;
        Thread.yield();
    }
    else
    {
        // sleepTimeNs 默认 100
        // 间接调用  jdk/internal/misc/Unsafe:::park 方法
        LockSupport.parkNanos(sleepTimeNs);
    }

    return counter;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/LockSupport.html#parkNanos-long-&apos;&gt;LockSupport.parkNanos&lt;/a&gt; 方法的作用简单而言即让当前线程睡眠 sleepTimeNs 纳秒。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Disruptor 作为一个任务队列，自带一个线程池，线程池的线程工厂即构造方法传入的 factory，线程数量等于 &lt;a href=&apos;https://github.com/LMAX-Exchange/disruptor/blob/master/src/main/java/com/lmax/disruptor/dsl/Disruptor.java#L165&apos;&gt;disruptor.handleEventsWith&lt;/a&gt; 调用时传入的回调方法数量，handleEventsWith 的参数数量不定:&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;public final EventHandlerGroup&amp;amp;lt;T&amp;amp;gt; handleEventsWith(final EventHandler&amp;amp;lt;? super T&amp;amp;gt;... handlers)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;18个 Disruptor 实例，每个实例有一个消费者线程，消费者线程不断检查队列中是否有新的 &lt;code&gt;Event&amp;lt;T&amp;gt;&lt;/code&gt; 任务需要处理，如果有，则调用 EventHandler 回调方法进行处理，否则睡眠 sleepTimeNs 纳秒。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;到此，结合监控指标，可以大致猜测：由于 sleepTimeNs 较小，导致多个线程的状态不断在 &lt;code&gt;运行&lt;/code&gt;、&lt;code&gt;睡眠&lt;/code&gt;、&lt;code&gt;等待调度&lt;/code&gt; 之间切换，线程上下文切换非常频繁。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;围绕 LockSupport.parkNanos 编写一个测试程序，来复现这个问题：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.locks.LockSupport;

public class Test {

  public static void main(String[] args) throws InterruptedException {
    ExecutorService tp = Executors.newFixedThreadPool(18);
    for (int idx = 0; idx &amp;amp;lt; 18; idx++) {
      tp.submit(() -&amp;amp;gt; {
        while (true) {
          LockSupport.parkNanos(100);
        }
      });
    }
    CountDownLatch wg = new CountDownLatch(1);
    wg.await();
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在 3.2 GHz 6-Core Intel Core i7 配置 macOS 系统中，这个测试程序可以稳定地将 CPU 使用率控制在 700%+，如下 &lt;code&gt;top -pid [测试程序的进程 id]&lt;/code&gt; 命令的输出：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/14/Z6jixvuWY1yTnL4.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中 CSW 为线程上下文切换的次数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;既然问题原因在于多个线程频繁睡眠导致，那么解决方案也比较简单：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;使用更大的值来替换 sleepTimeNs 默认值：&lt;code&gt;new Disruptor&amp;lt;&amp;gt;(Event&amp;lt;T&amp;gt;::new, bufferSize, factory, ProducerType.MULTI, new SleepingWaitStrategy(200, 1000 * 1000 / 10)); // 0.1 ms&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用其他等待策略（WaitStrategy），比如：&lt;code&gt;com.lmax.disruptor.BlockingWaitStrategy&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过解决方案也有微小的负作用 - 部分新任务/&lt;code&gt;Event&amp;lt;T&amp;gt;&lt;/code&gt;实例的处理时延会增大，但在我们的数据流处理场景下，这点时延增大对业务完全没有影响。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过，这个问题应该是一直存在，为什么近期才收到告警，为什么以前从监控上未发现？&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;为什么近期才收到告警？因为这个监控告警是近期公司监控平台才统一配置的&lt;/li&gt;
&lt;li&gt;为什么以前从监控上未发现？因为公司切换了新的监控平台，老的监控平台没有 cpu.busy 这个指标，而这些没什么数据要处理的任务长时间不需要开发维护，也就未得到及时关注。&lt;/li&gt;&lt;/ol&gt;
&lt;h2&gt;扩展资料&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;上下文切换耗时多少？&lt;a href=&apos;https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html&apos;&gt;How long does it take to make a context switch?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LockSupport.parkNanos(100)&lt;/code&gt; 真的就是睡眠 100 纳秒吗？&lt;a href=&apos;https://hazelcast.com/blog/locksupport-parknanos-under-the-hood-and-the-curious-case-of-parking/&apos;&gt;LockSupport.parkNanos() Under the Hood and the Curious Case of Parking&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</description>
            <pubDate>2020-07-14</pubDate>
            <link>https://blog.xiayf.cn/posts/disruptor-wait-strategy-cpu-busy.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/disruptor-wait-strategy-cpu-busy.html</guid>
        </item>
        
        <item>
            <title>译文：如何剖析 JVM 应用</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://www.lightbend.com/blog/profiling-jvm-applications&apos;&gt;How to profile JVM applications&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Hi 大家好。工具团队（tooling team）近期的一个关注点是改进 sbt 贡献流程（ improvement of the contribution process to sbt）。我们一直在思考的另一个事情是 sbt 的性能。为一举解决这两件事情，我调研了 Jason Zaugg、Johannes Rudolph 这些人如何剖析 JVM 应用，这篇文章即是调研结果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这里论述的技术应该可以应用于Java 和 Scala，也基本与你使用的工具无关。&lt;/p&gt;
&lt;h2&gt;火焰图（使用 async-profiler 生成）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;剖析 JVM 应用的方式有多种，但新晋热门是Netflix 高级性能架构师（Senior Performance Architect）Brendan Gregg 发明的&lt;strong&gt;火焰图&lt;/strong&gt;。开发者先收集堆栈踪迹抽样数据（stack trace samples），然后将其处理成一张交互式的 svg 图。若要快速了解火焰图，可阅读如下链接资料：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://www.youtube.com/watch?v=ugRrFdda_JQ&apos;&gt;Using FlameGraphs To Illuminate The JVM by Nitsan Wakart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.youtube.com/watch?v=D53T1Ejig1Q&apos;&gt;USENIX ATC ’17: Visualizing Performance with Flame Graphs&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我推荐的第一个火焰图工具是  Andrei Pangin 发起的 async-profiler，在 macOS 和 Linux 操作系统环境下均可使用，上手使用也更简单。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;下载安装器 &lt;a href=&apos;https://github.com/jvm-profiling-tools/async-profiler/releases/tag/v1.2&apos;&gt;async-profiler 1.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;假设你的系统中存在一个命令查找路径 &lt;code&gt;$HOME/bin&lt;/code&gt;，在 &lt;code&gt;$HOME/bin&lt;/code&gt; 目录下创建符号链接指向 &lt;code&gt;build/&lt;/code&gt; 和 &lt;code&gt;profiler.sh&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;pre class=&quot;language-bash&quot;&gt;&lt;code&gt;ln -s ~/App/async-profiler/profiler.sh $HOME/bin/profiler.sh
ln -s ~/App/async-profiler/build $HOME/bin/build&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来，关闭所有 Java 应用，以及任何可能影响剖析过程的东西，比如 Slack，然后在终端程序（terminal）中运行你的应用。对于我而言，则是尝试剖析 &lt;code&gt;sbt&lt;/code&gt; 的初始化加载过程：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ sbt exit&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在另一个终端中，运行：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ jps
92746 sbt-launch.jar
92780 Jps&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由此我们知道应用的进程 ID。对于我而言，目标进程 ID 是 &lt;code&gt;92746&lt;/code&gt;。在应用运行的同时，运行如下命令：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ profiler.sh -d 60 &amp;amp;lt;process id&amp;amp;gt;
Started [cpu] profiling
--- Execution profile ---
Total samples:         31602
Non-Java:              3239 (10.25%)
GC active:             46 (0.15%)
Unknown (native):      14667 (46.41%)
Not walkable (native): 3 (0.01%)
Unknown (Java):        433 (1.37%)
Not walkable (Java):   8 (0.03%)
Thread exit:           1 (0.00%)
Deopt:                 9 (0.03%)

Frame buffer usage:    55.658%

Total: 1932000000 (6.11%)  samples: 1932
  [ 0] java.lang.ClassLoader$NativeLibrary.load
  [ 1] java.lang.ClassLoader.loadLibrary0
  [ 2] java.lang.ClassLoader.loadLibrary
  [ 3] java.lang.Runtime.loadLibrary0
  [ 4] java.lang.System.loadLibrary
....&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;命令会输出一大堆有用的堆栈跟踪信息（stacktraces），为将这些信息可视化为一张火焰图，运行如下命令：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;profiler.sh -d 60 -f /tmp/flamegraph.svg &amp;amp;lt;process id&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;命令最后应该会产出文件 &lt;code&gt;/tmp/flamegraph.svg&lt;/code&gt;。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/dZVkB9xq2Gy6NfA.png&apos; title=&apos;flamegraph&apos; alt=&apos;flamegraph&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你自己来体验一下 &lt;a href=&apos;https://downloads.lightbend.com/website/blog/2019/flamegraph.svg?_ga=2.187105832.1642569835.1594378538-197429397.1594378538&apos;&gt;flamegraph.svg&lt;/a&gt; 输出的信息。&lt;/p&gt;
&lt;h2&gt;火焰图（使用 perf-map-agent 生成）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽然 async-profiler 上手使用很简单，但火焰图真正有趣之处在于可以混合展现 JVM 堆栈追踪和原生代码（native code）堆栈跟踪信息，让开发者可以看到 CPU 实际消耗在程序的何处。Lightbend 公司的 Johannes Rudolph 为此写了一个工具 - &lt;a href=&apos;https://github.com/jvm-profiling-tools/perf-map-agent&apos;&gt;perf-map-agent&lt;/a&gt;。该工具在 macOS 环境下会使用 &lt;code&gt;dtrace&lt;/code&gt;，在 Linux 环境下会使用 &lt;code&gt;perf&lt;/code&gt;。如果你想确认瓶颈是否出现在原生代码中，这个工具会特别有用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们先要编译 &lt;a href=&apos;https://github.com/jvm-profiling-tools/perf-map-agent&apos;&gt;perf-map-agent&lt;/a&gt;。对于 macOS 环境，在运行 &lt;code&gt;cmake .&lt;/code&gt; 之前需要先设置 &lt;code&gt;JAVA_HOME&lt;/code&gt; 环境变量：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cd work
$ git clone https://github.com/brendangregg/FlameGraph.git

$ git clone https://github.com/jvm-profiling-tools/perf-map-agent.git
$ cd perf-map-agent
$ export JAVA_HOME=$(/usr/libexec/java_home)
$ cmake .
-- The C compiler identification is AppleClang 9.0.0.9000039
-- The CXX compiler identification is AppleClang 9.0.0.9000039
...
$ make&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在一个新的终端中，带 &lt;code&gt;-XX:+PreserveFramePointer&lt;/code&gt; 标记参数运行 sbt：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ sbt -J-Dsbt.launcher.standby=20s -J-XX:+PreserveFramePointer exit&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在另一个终端中运行：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cd quicktest/
$ export JAVA_HOME=$(/usr/libexec/java_home)
$ export FLAMEGRAPH_DIR=$HOME/work/FlameGraph
$ jps
94592 Jps
94549 sbt-launch.jar
$ $HOME/work/perf-map-agent/bin/dtrace-java-flames 94549
dtrace: system integrity protection is on, some features will not be available

dtrace: description &amp;amp;apos;profile-99 &amp;amp;apos; matched 2 probes
Flame graph SVG written to DTRACE_FLAME_OUTPUT=&amp;amp;apos;/Users/xxx/work/quicktest/flamegraph-94549.svg&amp;amp;apos;.&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;理论上这样会产出更全面的火焰图，不过对于 &lt;code&gt;sbt exit&lt;/code&gt;，产出的火焰图看起来可能有点凌乱。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/s9BbWAnluTPwE3J.png&apos; title=&apos;flamegraph-2&apos; alt=&apos;flamegraph-2&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果 sbt 操作已经经过即时编译器优化（the operations are already JITed），或者操作比较特殊（the operation is more specific），那么火焰图的效果会更好。为了得到效果更好的火焰图，我们可以将相同的操作多重复几次：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ sbt -J-Dsbt.launcher.standby=20s -J-XX:+PreserveFramePointer reload reload reload reload exit&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样就可以产出程序的稳定态火焰图，逐步放大火焰图，就可以找到执行的热点路径。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/93YyjxR5ATS1Dnq.png&apos; title=&apos;flamegraph-3&apos; alt=&apos;flamegraph-3&apos; width=&apos;100%&apos;/&gt;
&lt;h2&gt;Flamescope&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Netflix 公司近期发布了一个新的火焰图可视化工具 - &lt;a href=&apos;https://medium.com/netflix-techblog/netflix-flamescope-a57ca19d47bb&apos;&gt;Flamescope&lt;/a&gt;，可以将火焰图过滤限制在一个特定的时间范围内。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/djm2hkvC98irQu7.png&apos; title=&apos;FlameScope&apos; alt=&apos;FlameScope&apos; width=&apos;200&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Martin Spier 和 Brendan Gregg 为研究扰动以及其他时间相关的问题（perturbations and other time-based issues）而开发了这个工具。常规的火焰图是聚合了所有堆栈追踪抽样数据，如果系统中发生了一个短时小故障，就会被深埋于其他追踪信息中，这个工具就是为了解决这个问题。&lt;/p&gt;
&lt;h2&gt;JMH (sbt-jmh)&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为 JIT 存在预热等特点，增大了基准测试的困难。JMH 会将相同的测试运行多次，消除 JIT 预热等特点造成的影响，从而更准确地测量代码的性能。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 sbt 用户而言，Lightbend 公司 Konrad Malawski 编写的 &lt;a href=&apos;https://github.com/ktoso/sbt-jmh&apos;&gt;sbt-jmh&lt;/a&gt; 进一步简化了 JMH 测试。并且它也集成了 async-profiler。&lt;/p&gt;
&lt;h2&gt;VisualVM&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我也想提一下传统的 JVM 剖析工具。因为 &lt;a href=&apos;https://visualvm.github.io/&apos;&gt;VisualVM&lt;/a&gt; 开源了，所以就来说说它。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1、先打开 VisualVM&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2、在一个终端中启动 sbt&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;3、从 VisualVM 界面的 Local 应用目录下应该可以看到 &lt;code&gt;xsbt.boot.Boot&lt;/code&gt;&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/EB7vsuo1HjaTtQw.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;4、打开它，选择 抽样功能（sampler） 或 剖析功能（profiler），在你想要开始的时间点点击 CPU 按钮&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/07/13/aoiIDfMKw9pjY4Z.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果你对 &lt;a href=&apos;https://www.yourkit.com/&apos;&gt;YourKit&lt;/a&gt; 比较熟悉，也可以使用它，用法比较相似。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;火焰图对堆栈跟踪抽样数据进行可视化，方便识别应用代码中的热点路径。也有助于确认代码变更是否实际影响了应用性能。&lt;/p&gt;</description>
            <pubDate>2020-07-13</pubDate>
            <link>https://blog.xiayf.cn/posts/how-to-profile-jvm-applications.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/how-to-profile-jvm-applications.html</guid>
        </item>
        
        <item>
            <title>读文：Kafka 官方设计文档</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://kafka.apache.org/documentation/#design&apos;&gt;http://kafka.apache.org/documentation/#design&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;数据持久化&lt;/h2&gt;
&lt;h4&gt;不用惧怕文件系统&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;磁盘的读写速度，取决于如何读写。对于线性读写方式，操作系统做了充分的优化：提前读 - 预取若干数据块，滞后写 - 将小的逻辑写操作合并成一个大的物理写操作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://queue.acm.org/detail.cfm?id=1563874&apos;&gt;研究&lt;/a&gt;表明：&lt;a href=&apos;http://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg&apos;&gt;顺序读写磁盘（sequential disk access）的速度有些时候比随机访问内存还要快&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现代操作系统激进地尽可能将空闲内存用作磁盘缓存。所有磁盘读写都经过操作系统提供的统一缓存。这个特性没法轻易关闭，除非直接 I/O （direct I/O），因此，如果程序在用户进程中进行数据缓存，缓存的数据通常也是和操作系统页缓存重复的，缓存两遍，没啥意义，也浪费内存。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;而且，Kafka 是构建在 JVM 之上的，了解 Java 内存使用方式的人应该都知道：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;对象的内存开销非常高，通常是实际数据大小的2倍（甚至更多）&lt;/li&gt;
&lt;li&gt;随着堆上数据量增大，Java 的 GC 表现也会更糟糕&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，使用文件系统并依赖于操作系统内存页缓存，优于在程序中维护一块内存缓存或其它结构。至少操作系统内存页缓存的可用内存翻倍了。另外，如果使用紧凑的字节结构来缓存数据，相比使用对象，可用内存可能还会翻倍。在 32GB 内存的机器上这么搞，缓存可用到 20-30GB，还不会对 GC 造成了什么坏影响。并且，即使服务重启，这块缓存空间也是热的（除非机器重启），用户进程内的内存缓存在服务重启后得重建（10GB的数据缓存可能需要10分钟左右）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样也可以简化代码逻辑，因为缓存和文件系统之间的一致性由操作系统来保证了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样一分析，设计就简单了：我们反其道而行之，所有数据都直接写到文件系统上持久化日志文件中，不需要在程序中使用内存缓存，也不必确保将数据刷到磁盘。这实际意味着数据转移到了内核的内存页缓存。&lt;/p&gt;
&lt;h4&gt;常量时间就能搞定&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;B 树的 O(log N) 时间复杂度，对于磁盘操作来说，并不能等同于常量时间复杂度。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 采用日志文件方式，确保读写操作的时间复杂度是 O(1)。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 不会在消息一被消费就立即删除，而是保留一段时间，这样对于消费者来说也更灵活一些。&lt;/p&gt;
&lt;h2&gt;效率&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 Kafka 这类系统而言，即使像前述那样消除了糟糕的磁盘访问模式，也会遇到两个导致数据效率低的问题：&lt;strong&gt;过多的小 I/O 操作&lt;/strong&gt;，以及&lt;strong&gt;过多的字节拷贝&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;小 I/O 问题在客户端与服务端之间，以及服务端内部的数据持久化操作中都会发生。对此，Kafka 协议建立在 “消息集” （即一批消息）的抽象之上，这样网络请求读写的是一批一批的消息，减少了网络往返的时间开销（注：消息处理的实时性会相对差一点）。服务端也是一次将一批消息写到日志文件中，消费者也按序一次获取一批消息。这一简单的优化可以将吞吐能力提升几个数量级。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于过多的字节拷贝问题，在消息量大的时候，影响比较明显。Kafka 采用了一种标准化的二进制消息格式，producer、broker、consumer 都使用这种格式，这样数据块在传输期间不需要变动。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;broker 维护的消息日志只是一个目录下的一堆文件，文件内容是按序写入的消息集，消息集的数据格式同于 producer、consumer 使用的。共用一种数据格式方便了一个重要的操作优化：持久化日志块的网络传输。对于从内存页缓存（pagecache）到网络套接字（socket）的数据传输操作，现代 UNIX 操作系统提供了一种高度优化的代码执行路径。Linux 中使用 &lt;a href=&apos;http://man7.org/linux/man-pages/man2/sendfile.2.html&apos;&gt;sendfile 系统调用&lt;/a&gt; 可以利用这个优化。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;要理解 sendfile 的收益，需要先理解从文件到套接字传输数据的常规代码执行路径：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;操作系统从磁盘将数据读到内核空间的内存页缓存（pagecache）&lt;/li&gt;
&lt;li&gt;应用程序从内核空间减数据读到用户空间缓冲区&lt;/li&gt;
&lt;li&gt;应用程序将数据从用户空间缓冲区读到内核空间的套接字缓冲区&lt;/li&gt;
&lt;li&gt;操作系统将数据从套接字缓冲区读到 NIC 缓冲区，网卡从 NIC 缓冲区读取数据通过网络发出去&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一代码执行路径，涉及 4 次数据拷贝和 2 次系统调用，很显然是低效的。使用 sendfile，可以避免内核空间和用户空间之间一些不必要的数据拷贝，操作系统可以直接将数据从内存页缓存发送到网络。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;进一步了解 sendfile 以及 Java 平台如何支持零拷贝，可以阅读&lt;a href=&apos;https://developer.ibm.com/articles/j-zerocopy/&apos;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;生产者（The Producer）&lt;/h2&gt;
&lt;h4&gt;负载均衡&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;消息应该发到哪个分区（partition）由客户端根据哈希算法（或者随机）决定，并且消息是直接由 producer 发到目标分区的 leader broker，没有任何中间路由层。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;所有 Kafka 节点都可以响应元数据请求 - 告知客户端（producer 或 consumer）哪些服务节点还存活以及某个 topic 的各个分区 leader 分别是哪个节点（疑惑：如果某个分区 leader 节点挂掉之后，客户端如何获知？何时可以获知？）&lt;/p&gt;
&lt;h2&gt;消息交付语义&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;producer 和 consumer 之间的消息交付语义，分 3 种：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;最多消费一次 - 消息可能会丢失，但不会被重复消费&lt;/li&gt;
&lt;li&gt;最少消费一次 - 消息不会丢，但可能被重复消费&lt;/li&gt;
&lt;li&gt;仅消费一次 - 每个消息都会被消费且仅消费一次&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个问题可以分成两个阶段的问题：&lt;strong&gt;producer 向 broker 发布一个消息时的持久性保证&lt;/strong&gt; 以及 &lt;strong&gt;consumer 消费一个消息时的语义保证&lt;/strong&gt; （the durability guarantees for publishing a message and the guarantees when consuming a message）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;producer 向 Kafka 集群发消息时，会提供一个请求参数 &lt;code&gt;acks&lt;/code&gt;：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;acks=0：表示 producer 不需要等分区 leader broker 返回任何响应，将消息存入套接字缓冲区（socket buffer）就当做消息已经发送成功。所以可靠性是没有保证的。&lt;/li&gt;
&lt;li&gt;acks=1：表示 分区 leader broker 将消息写入自己的本地日志文件，就向 producer 响应成功，不必等待分区副本 broker 同步好消息。&lt;/li&gt;
&lt;li&gt;acks=-1 或 acks=all：表示 分区 leader broker 需要等待所有同步副本 broker 同步好消息并响应成功，才向 producer 响应成功&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第 2 种情况，如果分区 leader broker 挂掉/不存活，则副本未来得及同步的消息会丢失。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第 3 种情况，只要有同步副本正常同步消息，那么即使 leader 挂了也不会丢数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果 leader 被系统判定为不存活，则会从（同步）副本中选举一个新的 leader，那么 Kafka 如何判定一个节点是否存活？存活判定依赖 2 个条件：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;节点必须维持与 Zookeeper 的 session 连接（通过 Zookeeper 的心跳机制）&lt;/li&gt;
&lt;li&gt;如果是一个从节点（follower），则必须不断从 leader 节点同步消息数据，且同步进度没有落后太多&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果 producer 在发送消息的过程中发生网络问题，它没法判定分区 leader 是否收到消息。0.11.0.0 版本之前，producer 只能重发消息，别无他法，因此只能提供“最少消费一次的”交付语义。0.11.0.0 版本之后，Kafka producer 支持一个幂等交付功能选项，可以确保消息重发不会导致 Kafka 的消息日志中出现重复的条目：broker 为每个 producer 分配一个 ID，然后基于消息序号来去重。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也是从 0.11.0.0 版本开始，Producer 支持以类事务的语义向多个 topic 分区发送消息：要么所有消息都发送成功，要么都不成功。这个能力主要用于实现 Kafka topic 之间的仅处理一次语义。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从 consumer 角度来看，同一个分区的所有副本，日志数据相同，消费进度也一样。consumer 可以控制自己对分区日志数据的消费位置。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果 consumer 读取消息后，先向 kafka 提交消费位置，再处理消息；如果该 consumer 挂掉或重启，会可能导致丢消息，从而只能满足“最多处理一次”交付语义。&lt;/li&gt;
&lt;li&gt;如果 consumer 读取消息后，是先处理，再提交消费位置；如果该 consumer 挂掉或重启，则可能导致重复消费消息，从而只能满足“最少处理一次”交付语义。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如何实现“仅处理一次”语义？借助 Producer 的事务能力。&lt;/p&gt;
&lt;h2&gt;复制&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;复制的粒度/单元是 topic 分区。Kafka 集群中，每个分区都有一个 leader broker 节点，0个或多个从节点（follower）。分区读写都是由 leader broker 处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如同一个普通的 consumer，从节点从 leader broker 拉取（pull）消息，然后写到自己的消息日志文件中。让从节点以 pull 的方式获取 leader 的消息数据，好处在于批量读写。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 follower 节点而言，“是否存活”的实际含义是“是否顺利地从 leader 同步消息”，leader 节点会追踪“同步中”节点集（ISRs）。如果一个 follower 挂掉了/卡住了/同步落后太多了，则将其从这个 ISRs 中移除。follow 是否卡住或者同步落后太多，依据 &lt;code&gt;replica.lag.time.max.ms&lt;/code&gt; 配置参数判定。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将某消息写到某个分区，如果该分区所有同步中副本都已经将该消息写到自己的消息日志文件中，则可以认为该消息的写操作已提交（committed），也就是真正的写成功。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;只有写提交的消息才会分发给 consumer。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;producer 可以选择是否等待消息写操作提交，在延迟（latency）和持久性（durability）之间权衡。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 集群在某分区的 leader 节点挂掉之后，会快速进行失败转移（a short fail-over period），选举出新的分区 leader 节点，可用性不会受到影响。但如果发生网络分区（network partitions）问题，则无法保证可用性。CAP - C（Consistency）：一致性，A（Availability）：可用性，P（Partition Tolerance）：分区容错性 - 放弃了 分区容错性。&lt;/p&gt;
&lt;h4&gt;日志数据复制：仲裁成员集（Quorums）、同步中副本集（ISRs）和状态机&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（备注：这一节我理解得还不太透彻。）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一类常见的分布式系统是主从模式的，由主节点决定状态变化的顺序（the order of a series of values）。从节点通过日志复制（replicated log）方式同步状态数据。对于提交决策（commit decision）和选主（leader election），通常是基于多数人投票的机制。假设副本个数（注：个人理解包含主节点）为 2f+1，那么只有当 f+1 个副本写入成功，主节点才会将这个写操作标记为已提交（committed）。当主节点挂掉之后，基于 f 个状态最新的副本节点，可以选举出新的主节点，且状态不会有任何丢失。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多数人投票方式，有一个优点：延迟取决于速度快的节点，而不是慢的。缺点是：对于实际的生产系统，抗风险能力还不够，而且不够灵活，不能让使用者做权衡。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 选择仲裁成员集（quorum set）的方式与此不同，而不是基于多数人投票，而是动态维护一组同步中副本（ISR），这些副本与主节点保持同步。只有这组副本中的成员才有资格当选为主节点。ISR 集发生变化时会持久化到 Zookeeper 上。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于 ISR 模型，如果 topic 分区有 f+1 个副本，则可以容忍 f 个节点挂掉，也不会丢失任何已提交的消息。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;与 Kafka ISR 模型实际实现最相近的学术论文是微软的 &lt;a href=&apos;http://research.microsoft.com/apps/pubs/default.aspx?id=66814&apos;&gt;PacificA&lt;/a&gt;。&lt;/p&gt;
&lt;h4&gt;可用性和持久性保证&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：producer 发送消息时设定 &lt;code&gt;acks=all&lt;/code&gt; 并不是要求所有的副本都确认写入成功，而是在当前同步中副本（ISR）都确认写入成功时，分区 leader 就向 producer 响应成功。例如：某个 topic 被设置为 2 个副本，然后其中一个副本节点挂掉，此时要求 &lt;code&gt;acks=all&lt;/code&gt; 的写操作也会成功。如果剩下的副本节点也挂了，那么就会丢消息啦。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了方便用户在 可用性 和 持久性 之间权衡，Kafka 提供两个 topic 级别的配置，用于 持久性 比 可用性 重要的情况：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&apos;http://kafka.apache.org/documentation/#design_uncleanleader&apos;&gt;禁用脏 leader 选举&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;指定一个最小 ISR 集大小（&lt;code&gt;min.insync.replicas&lt;/code&gt; 参数设置）：只有当 ISR 集大小大于设定的最小值，分区 [leader] 才会接受消息写入。这个设置只有当 producer 使用 &lt;code&gt;acks=all&lt;/code&gt; 时才会生效。（注：在我们生产环境中，分区副本数通常申请为 3（包含 leader），那么 &lt;code&gt;min.insync.replicas&lt;/code&gt; 应该设定为 2，但默认是 1。使用 1，那么当分区只有一个副本（即 leader），producer 也能写入成功，但如果这个副本又挂了，就会丢数据。）&lt;/li&gt;&lt;/ol&gt;
&lt;h4&gt;副本管理&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个 Kafka 集群上一般会有多个 topic，每个 topic 又有多个 partition，为了节点之间负载均衡，通常以&lt;strong&gt;循环（round-robin）方式&lt;/strong&gt;在所有节点上分布 partition 和 分区 leader 角色。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，在分区 leader 节点之后重新选出 leader 之前，存在一段不可用的时间窗口，为了缩短这个时间窗口，Kafka 会从所有 broker 中选择一个作为“控制器（controller）”，这个控制器会检测 broker 级别的问题（failures），在发现某个 broker 挂掉之后，负责为受影响的分区指定新的 leader，而不是每个分区自己负责重新选主，这样的选主过程更轻量更快。如果控制器节点挂了，还存活的 broker 中的一个会成为新的控制器。&lt;/p&gt;
&lt;h2&gt;消费者消费进度跟踪&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 为每个消费组（consumer group）指定一个 broker 来存储目标 topic 各个分区的消费进度（offsets），这个 broker 称为 &lt;strong&gt;组协调器（group coordinator）&lt;/strong&gt;。这个消费组中的任一消费者实例都应该将消费进度提交到这个组协调器，或者从这个组协调器获取启动之前上次的消费进度。Kafka 基于消费组的名称为消费组分配协调器。消费者可以向任一 broker 发送 FindCoordinatorRequest 请求来查找自己的协调器，并从 FindCoordinatorResponse 响应中获取协调器的详细信息。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在组协调器接收到一个 OffsetCommitRequest 请求后，会将请求数据写到一个特殊的&lt;a href=&apos;http://kafka.apache.org/documentation/#compaction&apos;&gt;经压实的（compacted）&lt;/a&gt; Kafka topic - &lt;em&gt;__consumer_offsets&lt;/em&gt;。在目标分区的所有副本都确认收到了，协调器才会向消费者发送进度提交成功的响应。这个 topic 的消息日志数据会定期进行压实（compact），因为只需要为每个分区维护最新的消费进度。协调器也会在内存中缓存消费进度，方便快速响应消费进度查询请求。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注：如果消费者/消费组特别多（例如：我们广告引擎服务，读取正排消息 topic，一个机器实例就是一个 consumer group，数量在几百到几千不等），那么组协调器的压力会比较大，那么确保组协调器的角色均匀分配到集群的所有 broker，比较关键。另外，&lt;em&gt;__consumer_offsets&lt;/em&gt; 这个 topic 的分区数量不能太少，最好和 broker 数量相同或者整数倍数量。&lt;/p&gt;</description>
            <pubDate>2019-10-13</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-kafka-design.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-kafka-design.html</guid>
        </item>
        
        <item>
            <title>读文：日志 - 每个软件工程师都应该了解的实时数据统一抽象</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&apos;&gt;The Log: What every software engineer should know about real-time data&apos;s unifying abstraction&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一句话概括，这篇文章细说了 Kafka 的本质原理、解决的问题、适用性等。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Kafka 本质上是提供日志数据流。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;日志是客观世界的事件记录。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;A log is perhaps the simplest possible storage abstraction. It is an append-only, totally-ordered sequence of records ordered by time.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;日志数据的特点是：只增不改，自带时间戳，数据存储的先后顺序即（大致）是实际发生的时间先后顺序。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据库可以基于日志来还原历史操作行为，并最终生成最新状态，主从同步就是这么干的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于分布式系统而言，日志可以解决 2 个问题：按序改变状态和分发数据（ordering changes and distributing data）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;状态机复制原则：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;If two identical, deterministic processes begin in the same state and get the same inputs in the same order, they will produce the same output and end in the same state.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;分布式系统中各个节点可以依据日志来同步状态，达到（最终）一致性。并且，可以依据节点处理到哪行日志即可确定/表达该节点的状态。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;（日志）事件流（events）和数据表（tables）是一体两面（a facinating duality）：数据表的变更操作即是一个日志事件流，基于日志事件流可以生成数据表，并将其状态不断更新到最新，数据表的状态是日志事件流的在某个时间点的切面。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;events -&gt; table -&gt; events = events &lt;-&gt; table&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The magic of the log is that if it is a complete log of changes, it holds not only the contents of the final version of the table, but also allows recreating all other versions that might have existed. It is, effectively, a sort of backup of every previous state of the table.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;源码版本控制系统（比如 git）也是基于日志实现的分布式系统，一次 commit 相当于一次日志记录。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于互联网/金融等行业的公司来说，数据是重要资产，如何尽可能发挥数据的潜在价值为公司增收，至关重要。因为管理、技术上的原因，公司通常分多个业务部门，各业务部门提供若干服务，各个服务都会产出数据，这些数据很可能需要跨部门跨服务流通，流通的速度越快，周期越短，收益越大。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以前，数据的处理方式主要是批处理，并不是因为没有流处理的技术，而是数据流通的基础设施跟不上，没做到持续的数据流。&lt;strong&gt;（注：这个说法，我个人只部分认同，很多时候，批处理的时延和收益可以满足大部分需求，实时流处理的边际效益可能并不明显）&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;流式处理是批处理的泛化形式（stream processing is a generalization of batch processing, and, given the prevalence of real-time data, a very important generalization）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了避免因数据流通导致各个服务之间的直接耦合，新增一个统一的数据通道中间服务，各个服务只管对数据通道进行写入或读出，不用关心数据是哪个服务写入的，或者哪些服务在消费/使用自己产出的数据。&lt;strong&gt;（解耦）&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，消费者消费数据的速率可能不一样，也可能会经历异常重启等情况，让消费者来控制速率，并且多个消费者之间不会相互干扰，会更好。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于数据流通的需求和日志的理念，Linkedin 设计开发了 Kafka。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为日志数据量可能会很大，日志数据本质上是有序串行的，如果支持数据分片，分片之间并行消费，分片内日志数据全局有序，数据流通的吞吐能力就可以无限扩展。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于 Kafka 这类数据管道，服务之间可以实现多级串联。（注：我们现在做的服务就是这么干）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种分布式系统架构中，至少涉及 producer（生产者）、broker（中间人）、consumer（消费者）三个角色，角色之间在某些工作上如何分工也是值得思考的：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;生产者产生的数据应该是什么样的？ - 统一格式/编码、方便解析&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;中间人（kafka）需要解决什么问题？- 对于单个生产者写入的数据，保证按写入顺序有序地分发给消费者；解决数据高可用，高吞吐能力；支持回溯/重复消费（因此数据需要保留指定时间长度），从而消费者出问题后可以从头消费数据恢复状态。因为支持很多消费者消费同一个数据流，所以平均下来，Kafka 服务的成本会比较低。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;消费者按各自的需求进行数据转换存储。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于实现高吞吐能力，除了分片，Kakfa 还充分利用了攒批处理：生产者可以批量发送，中间人将数据攒批写入磁盘日志文件 等等。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此外，由于涉及大量的磁盘文件和网络之间数据读写，Kafka 还充分利用操作系统内核的零拷贝传输能力。&lt;/p&gt;</description>
            <pubDate>2019-10-10</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-the-log-article.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-the-log-article.html</guid>
        </item>
        
        <item>
            <title>读文：Photon - Fault-tolerant and Scalable Joining of Continuous Data Streams</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/41318.pdf&apos;&gt;Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Photon 是谷歌广告系统中用于 join 广告曝光日志流和点击日志流的一套系统。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据流 join 为什么没用 flink 这类通用的流式处理框架？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;数据流 join，特别是广告数据流 join，技术上难在哪里？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;任一条流都可能乱序或延迟，广告点击涉及计费的问题，计费不能多算广告主的钱，也要尽可能避免漏计费，降低广告收入损失。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;该系统在谷歌生产环境中每分钟处理百万级的事件，端到端延迟小于 10 秒（注：对于广告实时竞价的广告主而言，这个延迟的长短很重要）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;广告曝光、点击整体流程为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;用户搜索某个关键词时，谷歌的服务器会返回广告和搜索结果。广告服务器会将广告 query 和结果数据作为日志发送到多个日志数据中心（multiple logs-datacenters），最终持久化存储在 GFS 上。每次 query 都会被赋予一个唯一性 ID &lt;em&gt;query_id&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;对于搜索结果中的广告，用户可能会点击。广告点击会触发一次请求，谷歌的后端服务器将请求重定向到广告主的网站。在重定向之前，谷歌服务器会将点击事件记录到日志中，发送到多个日志数据中心。点击事件日志中包含广告曝光的 query_id，点击事件也会被赋予一个唯一性 ID &lt;em&gt;click_id&lt;/em&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;计费是在点击之后，但计费所需要的广告出价等信息是在曝光请求中记录的，出于数据敏感性、带宽、请求处理延迟等多方面的考量，计费相关的信息并不会返回到用户客户端，也就是说点击请求中不会包含计费直接相关的信息，需要将 点击日志 和 曝光日志 做一次 join，得到一条完整的上下文日志，才方便做后续计费等处理。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/EDOy6VKxeJUcgAW.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;论文中提了到该系统解决了几个技术挑战点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;仅处理一次语义（exactly-once semantics）：实际上达到的是 最多处理一次语义 （At most once），也就是绝对不能多算钱，然后尽可能避免少算钱&lt;/li&gt;
&lt;li&gt;自动化的跨数据中心容错：也就是多数据中心部署，如果有一个数据中心不可用（比如 网络问题），也不会影响系统正常处理数据&lt;/li&gt;
&lt;li&gt;横向扩展性高：也就是加机器就能应对消息量增长&lt;/li&gt;
&lt;li&gt;低时延&lt;/li&gt;
&lt;li&gt;流乱序&lt;/li&gt;
&lt;li&gt;主流延迟（delayed primary stream）：这里说的”主流“是曝光日志流&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在我看来，该系统的亮点主要在前 3 点，后边细说。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为解决 1、2 挑战点，系统引入一个服务模块：IdRegistry，这个服务的功能：提供点击事件 id（&lt;em&gt;click_id&lt;/em&gt;） 的存储和查询，如果某个 click_id 可以从 IdRegistry 中查到，则表示该点击事件已经处理过了，不要再次处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并且，多数据中心都部署一套 Photon，但 IdRegistry 共享一个，多套 Photon 系统的输入相同，那么 IdRegistry 除了提供去重的功能，还提供了负载均衡的功能。正常情况下，假设 N 个数据中心，每个数据中心 Photon join 产出的日志数据量为总量的 1/N。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当某个数据中心的 Photon 不可用时，相当于其负载动态地重新分配到其它数据中心，虽然总体能力上降低了，但只要处理能力有冗余，就不会影响正常处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么很明显，IdRegistry 很可能成为系统的短板；另外，曝光/点击的唯一性 ID 如何生成？如果由一个中心服务来提供唯一性 ID 的生成，那么这个服务也会成为系统的短板。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;所以，系统没有选择一个中心服务来生成唯一性 id，而是将 id 设计为包含3个部分：&lt;em&gt;ServerIP&lt;/em&gt;、&lt;em&gt;ProcessID&lt;/em&gt;、&lt;em&gt;Timestamp&lt;/em&gt;。由于日志文件中行之间大致是按照时间戳有序的，所以 id 中包含时间戳的一个额外好处是：根据 id 即可大致定位日志内容。另外，还有一个和横向扩展性相关的好处，后边细说。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;IdRegistry 的角色至关重要，所以将其实现为一个基于 Paxos 协议的分布式系统，根据 CAP 原则，可用性（此处是指&lt;strong&gt;吞吐能力&lt;/strong&gt;）受限。解决方案是：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1、提高单机处理能力：服务端攒批处理，尽可能减少网络往返次数导致的等待（特别是：由于 IdRegistry 是跨地域分布式，部署上节点之间最大延迟是 100ms 左右）&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2、分片（Sharding）：根据 click_id 进行分片，但如果是固定分片，那么随着以后业务量增大，不好扩展。Photon 使用了一种基于时间段动态分片方案，这个方案基于 click_id 自带时间戳。大致逻辑是：使用一个配置，内容大致如下：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/VRlgr2CoD8zw7Mm.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于每个 click 日志，先根据 click_id 中的时间戳，判断分片数，并计算对应的分片 id。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/JMWyQvrDZCaAEdH.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;系统的模块关系图如下所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/zghk6oVaqZ5uEs3.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Photon 的 Dispatcher 模块并没有以 Kafka 这种消息队列作为输入，而是直接监听文件系统中的日志文件变更，这一点有点奇怪，不是特别理解。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Joiner 负责实际的 join 工作，由于 3、4 都比较耗时，所以为了尽可能减少 Joiner 的工作量，Dispatcher 将点击事件日志发送给 Joiner，会先到 IdRegistry 中查一下该事件是否已被处理过，从而起到过滤作用。因多数据中心部署，实际过滤比为：$ \frac{N-1}{N} $。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了确保 Joiner 高可用，Joiner 是无状态的，向 Dispatcher 提供 RPC 接口，Joiner 内部有限流，以保证不会因为单个 Joiner 负载过大，导致处理时延增大。Dispatcher 调用 Joiner 失败后会重试，重试使用的是指数退避算法。但处理失败的点击事件，是另外存储在 GFS 上，应该是由另外的线程来负责重试，不会影响正常的事件处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当 Joiner 收到一个点击事件的处理请求时，会根据点击日志数据中的 &lt;em&gt;query_id&lt;/em&gt; 从 EventStore 查询曝光日志详情，但因为曝光日志数据流可能会有延迟，所以可能会查不到，查不到且发现 click_id 中的时间戳早于某个阈值（比如是 N天前的一个事件），Joiner 会将该 click_id 标记为不可 join，然后向 Dispatcher 返回成功；如果 click_id 中的时间戳不早于阈值，则向 Dispatcher 返回失败，由 Dispatcher 来重试。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了确保不会多计费，Joiner 在将 join 结果写入 Joined Click Logs 之前，会向 IdRegistry 注册 click_id。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设注册实际上已成功，但因网络原因或 RPC 调用超时 Joiner 未收到成功响应，此时怎么办？Joiner 向 IdRegistry 注册 click_id 时，会附带一个额外的 唯一性 token，也包含3个部分：Joiner 服务器地址、进程 ID、时间戳，IdRegistry 会把这个唯一性 token 作为值存储下来，所以对于这种情况，Joiner 可以重复发注册请求，如果 IdRegistry 根据 token 发现已注册成功的 click_id 和当前收到的 click_id 来自同一个 Joiner，则也会返回注册成功。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设注册成功，合并结果写入异常，异常分为 2 种，需要解决：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;写入之前，Joiner 节点宕机或重启&lt;/li&gt;
&lt;li&gt;合并结果实际写入成功，但因为网络原因，Joiner 未收到响应&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为尽可能减少因某个 Joiner 节点硬件异常导致的 join 结果丢失，IdRegistry 对于单个 Joiner 的请求有限流，这个限流会间接导致 Joiner 对 Dispatcher 限流。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了进一步减少因为上面2种异常情况以及其它异常导致的 Join 结果丢失，Photon 还提供一个校验系统：获取原始点击事件日志，如果该日志 click_id 在 IdRegistry 中存在，但合并结果中不存在，则根据 IdRegistry 存储的对应 click_id 的 token，判断对应的 Joiner 是否存活，如果存活，则交于该 Joiner 重新处理，如果对应的 Joiner 已不存在，则从 IdRegistry 中删除该 click_id 记录，然后交于任一 Joiner 来处理，都一样。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;EventStore 获取原始的曝光日志，向 Joiner 提供查询接口，返回原始的曝光日志内容。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于时间局部性，EventStore 内部分 2 层，第一层为 CacheEventStore - 一个类似 Memcached 的 KV 内存映射，K 是 query_id，V 是曝光日志内容，基于一致性哈希算法根据 query_id 进行分片，缓存几分钟最新的曝光日志数据，可以命中 90% 左右的查询请求。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果 CacheEventStore 查询 miss，则交于第二层 LogsEventStore 来处理。LogsEventStore 对 query_id 和 曝光日志所在的日志文件及目标起始行（因为日志文件数据大致按时间戳有序，根据 query_id 中的时间戳大致可以知道查询的起始行）建立索引（实际存储在 BigTable 中），查询时，先根据 query_id，查到目标日志文件和起始行，然后从日志文件中读取原始曝光日志内容。&lt;/p&gt;</description>
            <pubDate>2019-10-10</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-photon-paper.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-photon-paper.html</guid>
        </item>
        
        <item>
            <title>译文：Lucene 查询解析器语法</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://lucene.apache.org/core/8_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package.description&apos;&gt;Query Parser Syntax&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;概览&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 除了提供 API 方便开发者创建查询请求，还通过一个查询解析器（一个词法分析器，使用 JavaCC 将一个字符串翻译成一个 Lucene 查询）提供一种功能丰富的查询语言。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一般来说，查询解析器支持的语法在不同发布版本之间可能会有变化。当前这个文档页面描述的是当前这个发布版本的语法。如果你正在使用一个不同版本的 Lucene，请参考该版本自带的 docs/queryparsersyntax.html 文档。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在选择使用这个查询解析器之前，请考虑以下 3 点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果你准备以编程的方式生成一个查询字符串，然后使用查询解析器来解析它。那么，你应该认真考虑一下是否应该直接使用查询 API 来构建查询。换句话说，查询解析器专门用于人类输入的文本，而不是程序生成的文本。&lt;/li&gt;
&lt;li&gt;不可分词（untokenized）的域（译者注：抱歉，此处没太理解）最好直接添加到查询中，而不是通过查询解析器来解析。如果一个域的值是通过应用自动生成的，那么应该为这个域自动生成查询子句。分析器（查询解析器所使用的）是专门用于将人类输入的文本转换成一些词（terms），那么程序自动生成的值，也应该由程序自动添加到查询中。&lt;/li&gt;
&lt;li&gt;从查询形式来看，如果域的值是普通文本，则应该使用查询解析器。所有其它值类型，比如：日期范围、关键词等等，最好通过查询 API 直接添加。如果一个域的值仅限于一个有限的集合（可以通过一个下拉菜单指定），则不应该添加到查询字符串（后续会被解析）中，而是应该作为一个 TermQuery 子句添加到查询中。&lt;/li&gt;&lt;/ol&gt;
&lt;h2&gt;词（Terms）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个查询语句可以拆解成 词（terms） 和 操作符（operators）。词又分为两种：单个词（single Terms）和短语（Phrases）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;单个词是指 ”test“ 或 ”Hello“ 这类单词。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;短语是指以双引号包围起来的一组单词，比如：”hello dolly“。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多个词（Multiple terms）可以使用布尔操作符组合在一起，实现一个更加复杂的查询（如下文所示）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;备注：用于创建索引的解析器也会用于解析查询字符串中的词和短语。因此，选择合适的解析器很重要，否则解析器可能会被查询字符串中的词干扰（译者注：这句应该是指英文解析器可能无法对中文进行正确分词的问题）。&lt;/p&gt;
&lt;h2&gt;域（Fields）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持分多个字段/域的数据。搜索时，可以指定一个域，也可以使用默认域。域的名称以及默认域与具体实现相关。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;输入域的名称，后跟一个冒号（:），以及目标搜索词，即可对任意一个域进行搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;举例来说，假设一个 Lucene 索引包含 2 个域：title 和 text，text 是默认域。若想查找标题为 ”The Right Way“ 且文本内容包含 ”don&apos;t go this way“ 的文档，可以输入：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:&amp;amp;quot;The Right Way&amp;amp;quot; AND text:go&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;或者：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:&amp;amp;quot;The Right Way&amp;amp;quot; AND go&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为 text 是默认域，所以域的标志可以省略。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：指定的域仅对紧跟其后的词生效，因此，如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:The Right Way&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将对 title 域仅查找 ”The“，并对默认域（当前这个例子中是指 text 域）查找 ”Right“ 和 ”Way“。&lt;/p&gt;
&lt;h2&gt;词修饰语（Term Modifiers）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持修饰查询词（modifying query terms）来提供多种搜索方式。&lt;/p&gt;
&lt;h3&gt;通配符搜索&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持对单个词(single terms)（不是短语查询 phrase queries）进行单个字符和多个字符的通配搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 &lt;code&gt;?&lt;/code&gt; 符号进行单个字符的通配搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 &lt;code&gt;*&lt;/code&gt; 符号进行多个字符的通配搜索。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;单字符通配搜索用于查找替换单个字符即可匹配的词。举例来说，若要搜索 ”text“ 或 ”test“，可以如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;te?t&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多字符通配搜索用于查找替换0个或多个字符即可匹配的词。举例来说，若要搜索 ”test“、”tests“ 或 ”tester“，可以如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;test*&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以对词的中间部分进行通配搜索：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;te*t&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;备注：不可以将 &lt;code&gt;*&lt;/code&gt; 或 &lt;code&gt;?&lt;/code&gt; 符号用作一次搜索的首个字符。&lt;/p&gt;
&lt;h3&gt;正则表达式搜索&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持正则表达式搜索，匹配斜杠（&lt;code&gt;/&lt;/code&gt;） 之间的模式。正则表达式的语法在不同的发布版本之间可能会有差异，目前支持的语法在 &lt;a href=&apos;http://lucene.apache.org/core/8_2_0/core/org/apache/lucene/util/automaton/RegExp.html?is-external=true&apos;&gt;RegExp&lt;/a&gt; 类文档中有说明。举例来说，查找包含 ”moat“ 或 ”boat“ 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;/[mb]oat/&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;模糊搜索&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持基于 Damerau-Levenshtein 编辑距离的模糊搜索。在单个词的最后添加波浪符（~）即可进行模糊搜索。举例来说，使用模糊搜索查找拼写上近似 ”roam“ 的词：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;roam~&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个查询语句会找到 foam 和 roams 这类词。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;模糊搜索可以通过一个额外（可选）的参数来指定允许的最大编辑次数。这个参数值界于 0 和 2 之间，例如：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;roam~1&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果未指定该参数，则默认使用 2 个编辑距离。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以前，这里还允许使用浮点数。现在这个语法已被考虑弃用，将于 Lucene 5.0 中移除。&lt;/p&gt;
&lt;h3&gt;邻近搜索&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持查找指定距离的邻近词。在短语的最后添加拨浪符（~）即可进行邻近搜索。举例来说，在文档中搜索 ”apache“ 和 ”jakarta“ 相距 10 个词的模式：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot;~10&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;范围搜索&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;范围查询可以要求域的值在范围查询语句指定的上下界之间。范围查询对于上下界可以包含也可以不包含。排序按照字典序进行。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;mod_date:[20020101 TO 20030101]&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个查询语句会查找 mod_date 域的值在 20020101 和 20030101 （包含上下界） 之间的文档。注意：范围查询并不是仅适用于日期域，也可以对非日期的域进行范围查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:{Aida TO Carmen}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个查询语句会查找到 title 域的值在 Aida 和 Carmen （不包含上下界）之间的所有文档。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;包含上下界的范围查询使用方括号来表示。不包含上下界的范围查询使用大括号来表示。&lt;/p&gt;
&lt;h3&gt;词加权（Boosting a term）&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 会基于文档中找到的词对匹配到的文档提供相关性级别（译者疑问：基于向量余弦来计算相关性？）。可以在目标搜索词之后紧接一个脱字符 “^”，后跟一个加权系数（一个数字）来提升该搜索词的相关性权重。加权系统越高，查询命中的文档与该词的相关性越强。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;加权操作允许对词进行加权控制文档的相关性。例如，假设你正在搜索：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;jakarta apache&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然后希望搜索结果和词 ”jakarta“ 更相关一些，则可以使用 ”^“ 符号后跟一个加权系数对这个词进行加权，即如下这样查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;jakarta^4 apache&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这会使得查找到的文档和词 ”jakarta“ 看起来更相关一些。也可以对短语进行加权，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot;^4 &amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;默认，加权系数是 1。加权系统可以小于 1（比如：0.2），但必须大于 0。&lt;/p&gt;
&lt;h2&gt;布尔操作符&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;布尔操作符允许使用逻辑操作符组合多个词。Lucene 支持的布尔操作符包含 &lt;code&gt;AND&lt;/code&gt;、&lt;code&gt;+&lt;/code&gt;、&lt;code&gt;OR&lt;/code&gt;、&lt;code&gt;NOT&lt;/code&gt; 及 &lt;code&gt;-&lt;/code&gt;（备注：布尔操作符必须全部是大写字母）。&lt;/p&gt;
&lt;h3&gt;OR&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“OR” 操作符是默认的连接操作符。这意味着如果两个词之间没有布尔操作符，则使用 “OR” 操作符。OR 操作符链接两个词，并匹配包含其中任意一个词的文档。这相当于集合的并集操作。“||” 符合可用于替代单词 “OR”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句来搜索包含 “jakarta apache” 或仅是 “jakarta” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; jakarta&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;或：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; OR jakarta&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;AND&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&quot;AND&quot; 操作符会匹配文本内容中同时存在两个词（因为 AND 是二元操作符）的文档。这相当于集合的交集操作。“&amp;&amp;” 符号可用于替代单词 “AND”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句来搜索包含 “jakarta apache” 和 “Apache Lucene” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; AND “Apache Lucene”&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;+&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“+”（必需）操作符要求文档的某个域中包含 “+” 符号之后的词。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句来搜索（必须）包含 “jakarta” 以及可能包含 “lucene”（包不包含都可以）的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;+jakarta lucene&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;NOT&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;若文档包含“NOT”之后的词，“NOT” 操作会排查该文档。这相当于集合的差集操作。“!” 符号可用于替代单词 “NOT”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句搜索包含 ”jakarta apache“ 但不包含 ”Apache Lucene“ 的文档”：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; NOT &amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;备注：“NOT” 操作符不可以用于单个词。例如，如下搜索不会返回任何结果：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;NOT &amp;amp;quot;jakarta apache&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;-&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果文档包含”-“符号之后的词，那么”-“（禁止）操作符会排除这些文档。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句来查询包含 ”jakarta apache“ 但不包含 ”Apache Lucene“ 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; -&amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;分组&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持使用圆括号对子句进行分组，构成子查询。如果你想控制一个查询语句的布尔逻辑，这对非常有用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比如，使用如下查询语句来搜索包含 “jakarta” 或 “apache”，以及 “website” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;(jakarta OR apache) AND website&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如此就消除了任何困惑，确保你想表达是：必须存在 “website”，以及可能存在词 “jakarta” 或 “apache”。&lt;/p&gt;
&lt;h2&gt;域分组&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持使用圆括号对单个域的多个子句进行分组。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;例如，若想搜索一个 title 中既包含单词“return”且包含短语“pink panther”，可以使用如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:(+return +&amp;amp;quot;pink panther&amp;amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;特殊字符转义&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Lucene 支持对查询语法使用的特殊字符进行转移。目前这些特殊字符如下列表所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;+ - &amp;amp;amp;&amp;amp;amp; || ! ( ) { } [ ] ^ &amp;amp;quot; ~ * ? : \ /&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在特殊字符之前加 &lt;code&gt;\&lt;/code&gt; 来转义。例如，使用如下查询语句来搜索 &lt;code&gt;(1+1):2&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;\(1\+1\)\:2&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2019-09-04</pubDate>
            <link>https://blog.xiayf.cn/posts/lucene-query-parser-syntax.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/lucene-query-parser-syntax.html</guid>
        </item>
        
        <item>
            <title>一个 Python 小项目的小结</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;前段时间临时接手一个 Python 小项目，这个项目实现的类似一个管控平台，其中核心功能是为算法同学提供机器学习模型训练任务的全流程管理，平台后端基于 Flask 框架实现，前端基于 Ant Design Pro 实现。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;代码稍微有些乱，所以做了部分代码的重构，在此做点经验小结。&lt;/p&gt;
&lt;h3&gt;1、并行化或异步化&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;部分请求处理逻辑，由于比较耗时，故使用线程池来加速，或者使用独立线程异步处理，或者先存储一个中间状态，由后台定时任务来完成实际的处理工作。对于异步处理结果，前端通过轮询来获取。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;线程池的使用，主要使用 map 方法：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from multiprocessing.dummy import Pool

input_list = [...]
pool: Pool = Pool(len(input_list))
pool.map(func, input_list)
pool.close()
pool.join()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;独立线程异步处理：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;import multiprocessing

p = multiprocessing.Process(target=func, args=(...))
p.start()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;定时任务，基于 apscheduler 库实现：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from apscheduler.schedulers.background
import BackgroundScheduler

scheduler = BackgroundScheduler()
scheduler.add_join(func, &amp;amp;apos;interval&amp;amp;apos;, seconds=1)
scheduler.start()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为对于 Python 应用，通常会使用 gunicorn 这种 WSGI HTTP 服务器以多进程启动多个应用实例，提升请求吞吐能力。但是对于定时任务我们希望只有一个实例，对此，如果使用 gunicorn，可以基于它的 preload 机制来实现：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# wsgi.py
import app

if __name__ == &amp;amp;quot;__main__&amp;amp;quot;:
    app.run()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# 注意其中的 --preload 参数
gunicorn --workers=4 --preload --log-level=info --access-logfile=access.log -b 0.0.0.0:8080 wsgi:app&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;preload 机制简单来说，就是 import app 类所在的模块及其依赖的各个模块（import 过程中会执行其中的语句），然后 fork 出多个进程，每个进程都执行 app.run()。&lt;/p&gt;
&lt;h4&gt;2、实现一些通用方案对异常进行捕获或重试&lt;/h4&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def exception_try(times: int = 3, sleep_then_try_seconds=None):
    def decorator(f):
        def wrapper(*args, **kwargs):
            count = 0
            exception = None
            while count &amp;amp;lt; times:
                try:
                    return f(*args, **kwargs)
                except Exception as e:
                    exception = e
                    count += 1
                    logging.exception(&amp;amp;quot;Try {} times&amp;amp;quot;.format(count))
                    if (sleep_then_try_seconds is not None) and count &amp;amp;lt; times:
                        time.sleep(sleep_then_try_seconds)
            raise exception
        return wrapper
    return decorator&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@exception_try(times=3, sleep_then_try_seconds=0.5)
def connect(self):
    return pymysql.connect(host=self.host, user=self.user, password=self.password, db=self.db, charset=self.charset)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个装饰器方法用于实现异常重试，并且可以指定重试的时间间隔，实际使用下来效果较好。而且也不会因为 &lt;code&gt;try...except&lt;/code&gt; 导致大块代码缩进。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;确保数据库连接关闭（其它类似资源也可以这样实现）&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def with_db(db: Connection, exception_callback=None):
    def decorator(f):
        def db_context(*a, **kw):
            try:
                return f(db, *a, **kw)
            except Exception as e:
                logging.exception(str(e))
                if exception_callback is not None:
                    exception_callback(e)
            finally:
                try:
                    db.close()
                except:
                    pass
        return db_context

    return decorator&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 将 conf.db.connect() 对象作为 delete_task_from_job_queue 的第一个参数注入，task_id 这个参数以不定参数的方式传入 delete_task_from_job_queue
with_db(conf.db.connect())(delete_task_from_job_queue)(task_id)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个装饰器方法用于确保数据库连接在异常发生也能正常关闭，防止资源泄露。&lt;/p&gt;
&lt;h4&gt;3、循环等待或超时&lt;/h4&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class TimeoutCondition(object):

    def __init__(self, condition_func, timeout_seconds):
        self.condition = condition_func
        self.timeout = timeout_seconds
        self.begin = None
        self.timeout_false = True
        self.cond_true = True

    def __bool__(self):
        if self.begin is None:
            self.begin = timeit.default_timer()
        self.cond_true = self.condition()
        self.timeout_false = self.timeout &amp;amp;lt;= 0 or (timeit.default_timer() - self.begin) &amp;amp;lt; self.timeout
        return self.cond_true and self.timeout_false

    def is_timeout(self):
        return self.cond_true and not self.timeout_false&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;cond = TimeoutCondition(lambda : len(service_list) == 0, 5)
while cond:
    time.sleep(1)
    service_list = get_service_list()
if cond.is_timeout():
    return None, None&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;TimeoutCondition&lt;/code&gt; 用于实现循环等待某个条件满足，但为了避免死循环，所以加一个超时条件判断。实例化参数第一个是原始的条件判断 lambda 语句，第二个是一个超时设置。另外，借助魔术方法 &lt;code&gt;__bool__&lt;/code&gt;，让 TimeoutCondtion 的实例用起来像是一个布尔变量，调用 &lt;code&gt;is_timeout()&lt;/code&gt; 方法可以区分循环等待退出是因为原始条件满足，还是超时退出的。&lt;/p&gt;
&lt;h4&gt;4、按部署环境配置应用的行为&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;应用在不同的环境（开发、测试、生产）中应该允许加载不同的配置，配置不同的行为。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当前应用处于什么环境，可以通过环境变量来配置，应用初始化时最先检测当前处于什么环境，之后的初始化流程就可以依据环境配置来加载配置，定制应用行为。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# conf/__init__.py
class AppConfig(object):
    app_env = os.getenv(&amp;amp;apos;APP_ENV&amp;amp;apos;, &amp;amp;apos;development&amp;amp;apos;)
    is_prod = app_env == &amp;amp;apos;production&amp;amp;apos;
    is_dev = app_env == &amp;amp;apos;development&amp;amp;apos;
    is_testing = app_env == &amp;amp;apos;testing&amp;amp;apos;
    
    # 其余应用配置项
    ...

conf = AppConfig()


def _load_config_by_env(env: str):
    &amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
    不同环境加载不同的配置文件
    配置目录结构：
    conf/
        __init__.py
        development.py
        production.py
        testing.py
    &amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
    module = importlib.import_module(&amp;amp;apos;conf.{}&amp;amp;apos;.format(env))
    if not hasattr(module, &amp;amp;apos;Config&amp;amp;apos;):
        logging.warning(&amp;amp;apos;Not find {} config&amp;amp;apos;.format(env))
        return
    for name, value in getattr(module, &amp;amp;apos;Config&amp;amp;apos;).__dict__.items():
        if name.startswith(&amp;amp;apos;__&amp;amp;apos;):
            continue
        conf.__dict__[name] = value&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 根据环境配置日志级别
log_level = logging.INFO if conf.is_prod else logging.DEBUG
logging.basicConfig(format=consts.LOG_FORMAT, level=log_level)&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;5、方便排查问题的日志输出&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;日志是问题排查的主要信息来源，所以日志记录得好不好，很关键。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# https://github.com/python/cpython/blob/3.7/Lib/logging/__init__.py#L457
# 日志时间 - 日志级别 - 代码文件路径 - 行号 - 进程 ID - 线程名称 - 日志内容
LOG_FORMAT = &amp;amp;apos;%(asctime)-15s - %(levelname)s - %(pathname)s - %(lineno)d - %(process)d - %(threadName)s - %(message)s&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;6、API 规范与异常提示&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了统一前端 API 响应处理，有必要对 API 响应体的结构指定标准。以我个人的习惯，所有从应用代码中返回的响应，HTTP 状态码都应该是 200，具体当前 API 请求成功还是失败，如果失败，失败的原因是什么都应该包含在响应体中，响应体大致的结构为：&lt;/p&gt;
&lt;pre class=&quot;language-json&quot;&gt;&lt;code&gt;{
    &amp;amp;quot;code&amp;amp;quot;: ...,
    &amp;amp;quot;msg&amp;amp;quot;: &amp;amp;quot;...&amp;amp;quot;,
    &amp;amp;quot;data&amp;amp;quot;: ...
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;code 表示请求处理失败时，data 字段可选，code 表示请求处理成功时，msg 字段可选。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前端配合对响应体进行统一检测和提示：&lt;/p&gt;
&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code&gt;import { notification } from &amp;amp;apos;antd&amp;amp;apos;;

function defaultHTTPCodeHandler(response) {
  if (response.status &amp;amp;gt;= 400) {
    // 注意 clone
    response.clone().text().then(respBody =&amp;amp;gt; {
      notification.error({message: &amp;amp;apos;API 异常响应&amp;amp;apos;, description: `${response.status}, ${respBody}`, duration: null});
      console.log(`${response.status}, ${respBody}`);
    });
  }
}

function defaultMsgCodeHandler(response) {
  if (response.status === 200) {
    // 注意 clone
    response.clone().json().then(jsonBody =&amp;amp;gt; {
      // 0、200、10000 都属于成功响应
      if (jsonBody !== undefined &amp;amp;amp;&amp;amp;amp; jsonBody.code !== undefined &amp;amp;amp;&amp;amp;amp; jsonBody.code !== 0 &amp;amp;amp;&amp;amp;amp; jsonBody.code !== 200 &amp;amp;amp;&amp;amp;amp; jsonBody.code != 10000) {
        notification.error({message: &amp;amp;apos;请求失败&amp;amp;apos;, description: `${jsonBody.code}, ${jsonBody.msg}`, duration: null});
        console.log(`${jsonBody.code}, ${jsonBody.msg}`);
      }
    });
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并且统一封装发起请求的逻辑：&lt;/p&gt;
&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code&gt;export function corsFetch(url, init, httpCodeCallback, msgCodeCallback) {
  const host = myHost();
  let urlPrefix = host;
  // 自带 host，则不额外补充 host 前缀
  if (url.startsWith(&amp;amp;quot;http://&amp;amp;quot;) || url.startsWith(&amp;amp;quot;https://&amp;amp;quot;)) {
    urlPrefix = &amp;amp;apos;&amp;amp;apos;;
  }
  const httpCodeHandler = httpCodeCallback === undefined ? defaultHTTPCodeHandler : httpCodeCallback;
  const msgCodeHandler = msgCodeCallback === undefined ? defaultMsgCodeHandler : msgCodeCallback;
  // 对于线上环境或者测试环境，不跨域
  if (host === PROD_ENV_HOST || host === TEST_ENV_HOST) {
    const promise = fetch(urlPrefix + url, init);
    promise.then((response) =&amp;amp;gt; httpCodeHandler(response));
    promise.then((response) =&amp;amp;gt; msgCodeHandler(response));
    return promise;
  }
  // 对于本地测试环境，跨域访问预发环境 API 数据，方便测试
  let corsInit = {
    credentials: &amp;amp;apos;include&amp;amp;apos;,
    mode: &amp;amp;apos;cors&amp;amp;apos;,
    redirect: &amp;amp;apos;follow&amp;amp;apos;,
  };
  if (init !== undefined) {
    corsInit = { ...corsInit, ...init };
  }
  if (urlPrefix !== &amp;amp;apos;&amp;amp;apos;) {
    urlPrefix = TEST_ENV_HOST;
  }
  const promise = fetch(urlPrefix + url, corsInit);
  promise.then((response) =&amp;amp;gt; httpCodeHandler(response));
  promise.then((response) =&amp;amp;gt; msgCodeHandler(response));
  return promise;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中为了方便本地开发测试，允许本地开发环境跨域访问测试环境（最好不要直接跨越访问生产环境），并且自动区分，corsFetch 调用方无感知。&lt;/p&gt;</description>
            <pubDate>2019-08-14</pubDate>
            <link>https://blog.xiayf.cn/posts/a-python-project-summary.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/a-python-project-summary.html</guid>
        </item>
        
        <item>
            <title>Reactor 官方文档（简译）</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/&apos;&gt;Reactor 3 Reference Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1. 起步&lt;/h2&gt;
&lt;h3&gt;1.1 Reactor 简介&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 是为 JVM 准备的一个完全非阻塞的反应式编程基础组件，支持高效的需求管理（以管理“反压”的形式），直接与 Java 8 的函数式 API 集成，尤其是 &lt;code&gt;CompletableFuture&lt;/code&gt;、&lt;code&gt;Stream&lt;/code&gt; 以及 &lt;code&gt;Duration&lt;/code&gt;，提供可组合的异步序列 API - &lt;code&gt;Flux&lt;/code&gt;（适用于 N 个元素的序列）和 &lt;code&gt;Mono&lt;/code&gt;（适用于 0 或 1个元素的序列）--- 并且全面地（extensively）实现了 &lt;a href=&apos;https://www.reactive-streams.org/&apos;&gt;反应式流（Reative Streams）&lt;/a&gt; 规范。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;借助 &lt;code&gt;reactor-netty&lt;/code&gt; 项目，Reactor 也支持进程间的非阻塞通信，适用于微服务架构。&lt;code&gt;reactor-netty&lt;/code&gt; 为 HTTP（包括 Websockets）、TCP 以及 UDP 提供支持反压的网络引擎，完全支持反应式编码解码。&lt;/p&gt;
&lt;h3&gt;1.2 理解 BOM&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 3 开始采用 BOM （Bill of Materials，物料清单）发布模型（自 &lt;code&gt;reactor-core 3.0.4&lt;/code&gt; 开始，使用 &lt;code&gt;Aluminium&lt;/code&gt;（铝）版本序列），一个版本包含一组相关组件的版本，这些版本组件之间兼容性非常好，允许这些组件采用不同的版本命名方式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;BOM 发布模型本身也是版本化的，以一个代号后接一个修饰词来命名一个版本序列。如下是一个示例列表：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;Aluminium-RELEASE
Californium-BUILD-SNAPSHOT
Aluminium-SR1
Bismuth-RELEASE
Californium-SR32&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;代号等价于常规的 &lt;code&gt;大版本号.小版本号&lt;/code&gt; 形式，通常以字母升序方式取自 &lt;a href=&apos;https://en.wikipedia.org/wiki/Periodic_table#Overview&apos;&gt;元素周期表&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;按照时间顺序，修饰词分别为如下几个：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;BUILD-SNAPSHOT：为开发测试构建的版本。&lt;/li&gt;
&lt;li&gt;M1 .. N：里程碑版本或者开发者预览版本。&lt;/li&gt;
&lt;li&gt;RELEASE：一个代号系列中的首个 GA（General Availability 通用）发行版。&lt;/li&gt;
&lt;li&gt;SR1 .. N：一个代号系列中的后续 GA 发行版 - 相当于一个补丁版本。（SR 代表 “Service Release”（服务版本））&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.3 如何获取 Reactor&lt;/h3&gt;
&lt;h4&gt;1.3.1 以 Maven 管理依赖包&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Maven 原生支持 BOM 模型概念。首先，在你的 &lt;code&gt;pom.xml&lt;/code&gt; 文件添加如下代码片段来引入 BOM：&lt;/p&gt;
&lt;pre class=&quot;language-xml&quot;&gt;&lt;code&gt;&amp;amp;lt;dependencyManagement&amp;amp;gt; 
    &amp;amp;lt;dependencies&amp;amp;gt;
        &amp;amp;lt;dependency&amp;amp;gt;
            &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
            &amp;amp;lt;artifactId&amp;amp;gt;reactor-bom&amp;amp;lt;/artifactId&amp;amp;gt;
            &amp;amp;lt;version&amp;amp;gt;Bismuth-RELEASE&amp;amp;lt;/version&amp;amp;gt;
            &amp;amp;lt;type&amp;amp;gt;pom&amp;amp;lt;/type&amp;amp;gt;
            &amp;amp;lt;scope&amp;amp;gt;import&amp;amp;lt;/scope&amp;amp;gt;
        &amp;amp;lt;/dependency&amp;amp;gt;
    &amp;amp;lt;/dependencies&amp;amp;gt;
&amp;amp;lt;/dependencyManagement&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果顶部标签（&lt;code&gt;dependencyManagement&lt;/code&gt;）已经存在，则只添加上面该标签的内部内容。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来，将依赖包添加到项目中，和一般依赖包一样，不过没有 &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt;，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-xml&quot;&gt;&lt;code&gt;&amp;amp;lt;dependencies&amp;amp;gt;
    &amp;amp;lt;dependency&amp;amp;gt;
        &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
        &amp;amp;lt;artifactId&amp;amp;gt;reactor-core&amp;amp;lt;/artifactId&amp;amp;gt; 
    &amp;amp;lt;/dependency&amp;amp;gt;
    &amp;amp;lt;dependency&amp;amp;gt;
        &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
        &amp;amp;lt;artifactId&amp;amp;gt;reactor-test&amp;amp;lt;/artifactId&amp;amp;gt; 
        &amp;amp;lt;scope&amp;amp;gt;test&amp;amp;lt;/scope&amp;amp;gt;
    &amp;amp;lt;/dependency&amp;amp;gt;
&amp;amp;lt;/dependencies&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;1.3.2 以 Gradle 管理依赖包&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Gradle 核心并不支持 Maven BOM，不过可以借助 Spring 的 &lt;a href=&apos;https://github.com/spring-gradle-plugins/dependency-management-plugin&apos;&gt;gradle-dependency-management&lt;/a&gt; 插件。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;首先，应用插件，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;plugins {
    id &amp;amp;quot;io.spring.dependency-management&amp;amp;quot; version &amp;amp;quot;1.0.6.RELEASE&amp;amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然后使用它来引入 BOM，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;dependencyManagement {
     imports {
          mavenBom &amp;amp;quot;io.projectreactor:reactor-bom:Bismuth-RELEASE&amp;amp;quot;
     }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后将依赖添加到项目中，无需指定版本号，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;dependencies {
     compile &amp;amp;apos;io.projectreactor:reactor-core&amp;amp;apos; 
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;2. 反应式编程简介&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 是反应式编程范式的一个实现。反应式编程的定义归纳起来，如下所示：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;反应式编程是一个异步编程范式，关注数据流和变化的传播。这意味着通过被采用编程语言可以轻松地表达静态（比如 数组）或动态（比如 事件发射器）数据流。 --- https://en.wikipedia.org/wiki/Reactive_programming&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;反应式编程方向的首个重要工作是：微软在 .NET 生态体系中创建了反应式扩展（Rx）库，然后 RxJava 在 JVM 上实现了反应式编程。时光飞逝，经 Reative Streams 的大力推进，Java 社区终于出现了反应式编程标准，该规范定义了一组接口以及 JVM 上反应式编程库之间的交互规则。Java 9 标准库已将这组接口集成到 &lt;code&gt;Flow&lt;/code&gt; 类（译注：见&lt;a href=&apos;https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/Flow.html&apos;&gt;https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/Flow.html&lt;/a&gt;）中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;反应式编程范式在面向对象语言中通常表现为一个观察者设计模式的扩展。你也可以将主流的反应式流模式（reactive streams pattern）和大家熟知的迭代器设计模式做对比，所有这些库中都存在对标于 &lt;code&gt;Iterable&lt;/code&gt; - &lt;code&gt;Iterator&lt;/code&gt; 的概念（译注：比如 发布者-消费者）。主要差别在于：迭代器是基于 pull 方式，反应式流则基于 push 方式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用迭代器是一个命令式编程的模式，即使如何访问数据（accessing values）完全是 &lt;code&gt;Iterable&lt;/code&gt; 的职责，但实际上，何时访问序列中的下一个（&lt;code&gt;next()&lt;/code&gt;）值取决于开发者的选择。在反应式流中，上述 &lt;code&gt;Iterable&lt;/code&gt; - &lt;code&gt;Iterator&lt;/code&gt; 对的等价物为 &lt;code&gt;Publisher&lt;/code&gt; - &lt;code&gt;Subscriber&lt;/code&gt;。不过，在出现新的数据/事件时，由 &lt;code&gt;Publisher&lt;/code&gt; 通知 &lt;code&gt;Subscriber&lt;/code&gt;，这个“推”特性也是实现反应式的关键之处。并且，在被推送的值上应用哪些操作是声明式表达而不是命令式表达的：程序员表达的是计算逻辑而不是描述精确的控制流。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除了“推”的特性，反应式流也良好地定义了如何处理错误和结束流。一个 &lt;code&gt;Publisher&lt;/code&gt; 可以向它的 &lt;code&gt;Subscriber&lt;/code&gt; 推送新的值（通过调用订阅者的 &lt;code&gt;onNext&lt;/code&gt; 方法），也可以推送错误（调用 &lt;code&gt;onError&lt;/code&gt; 方法）或结束（调用 &lt;code&gt;onComplete&lt;/code&gt;方法）信号。错误和结束信号都可以终结事件序列。简而言之，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;onNext x 0..N [onError | onComplete]&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个方式非常灵活。这个模式支持“没有值”、“一个值”或“n个值”（包括值无限的序列，比如时钟的持续滴答事件）的各种使用场景。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是，起初，我们为什么需要这样一个异步的反应式的编程库？&lt;/p&gt;
&lt;h3&gt;2.1 阻塞即是资源浪费&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现代的软件应用，并发用户量非常巨大，即使现代硬件的处理能力一直在提升，软件的性能仍旧是一个关键问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;宽泛来讲，提升一个程序的性能，有两种方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;并行化&lt;/strong&gt; 使用更多的线程和更多的硬件资源。&lt;/li&gt;
&lt;li&gt;对于当前的硬件资源，&lt;strong&gt;寻求更高效的使用方式&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;通常，Java 开发者会使用阻塞性的代码编写程序，这种代码编写方式容易触及性能瓶颈，然后引入更多的线程来运行相似的阻塞性代码。但是，这种资源利用的扩展方式很快就会引发竞态（contention）和并发的问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;更糟糕的是，阻塞就意味着浪费资源。如果你稍加分析，就会发现一旦程序牵涉一些等待延迟（尤其是 I/0 操作，比如等待一个数据库请求或者一个网络调用），资源就会被浪费，因为此时线程（可能是大量线程）是空闲的，等待着数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，并行化方式并非银弹。为了压榨出硬件的全部能力，并行化是必要的，但并行化的代码理解（reason about）起来也非常复杂，实际威力也会因为资源浪费而大打折扣。&lt;/p&gt;
&lt;h3&gt;2.2 异步可以解决问题吗？&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前面提到的第二种方式 - 寻求更高效的使用方式 - 是资源浪费问题的一个解决方案。通过编写异步非阻塞的代码，在发生阻塞等待时，切换执行另一个活跃任务，活跃任务使用的是相同的底层资源，然后在异步处理过程结束后再切回到当前进程来执行。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是我们如何编写在 JVM 上异步执行的代码？ Java 提供了两种异步编程模型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;回调&lt;/strong&gt;：异步方法没有返回值，但接受一个额外的 &lt;code&gt;callback（回调）&lt;/code&gt;参数（一个 lambda 表达式或匿名类），在得到异步处理结果时会调用这个回调。一个众所周知的例子是 Swing 的 &lt;code&gt;EventListener&lt;/code&gt; 派生类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Future&lt;/strong&gt;：这种异步方法在调用时会&lt;em&gt;即刻&lt;/em&gt;返回一个 &lt;code&gt;Future&amp;lt;T&amp;gt;&lt;/code&gt;。这个异步过程会计算出一个 &lt;code&gt;T&lt;/code&gt; 类型的值，不过需要通过 &lt;code&gt;Future&lt;/code&gt; 对象来访问。计算出来的值不能立即可用，可以对 &lt;code&gt;Future&lt;/code&gt; 对象进行探询直到值计算出来。例如：&lt;code&gt;ExecutorService&lt;/code&gt; 运行 &lt;code&gt;Callable&amp;lt;T&amp;gt;&lt;/code&gt; 任务就是提供 &lt;code&gt;Future&lt;/code&gt; 对象来获取异步结果。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么这两种技术方案就足够好了吗？在很多使用场景下并不理想，这两种方式都有局限。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多个回调难以组合使用，容易导致代码难以阅读和维护（就是所谓的“回调地狱”）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;来看一个例子：在界面上为用户显示他最喜爱的5个物件，如果用户还没有任何喜欢的物件，则给出建议物件。这个逻辑涉及3个服务（第一个服务提供物件 ID，第二个服务获取物件的详细信息，第三个服务提供建议物件的详细信息），如下所示：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;回调地域的示例&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorites(userId, new Callback&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt;() { // 1
    public void onSuccess(List&amp;amp;lt;String&amp;amp;gt; list) { // 2
        if (list.isEmpty()) { // 3
            suggestionService.getSuggestions(new Callback&amp;amp;lt;List&amp;amp;lt;Favorite&amp;amp;gt;&amp;amp;gt;() {
                public void onSuccess(List&amp;amp;lt;Favorite&amp;amp;gt; list) { // 4
                    UiUtils.submitOnUiThread(() -&amp;amp;gt; { // 5
                        list.stream()
                            .limit(5)
                            .forEach(uiList::show); // 6
                    })
                }
                
                public void onError(Throwable error) { // 7
                    UiUtils.errorPopup(error);
                }
            });
        } else {
            list.stream() // 8
                .limit(5)
                .forEach(favId -&amp;amp;gt; favoriteService.getDetails(favId, // 9
                    new Callback&amp;amp;lt;Favorite&amp;amp;gt;() {
                        public void onSuccess(Favorite details) {
                            UiUtils.submitOnUiThread(() -&amp;amp;gt; uiList.show(details));
                        }

                        public void onError(Throwable error) {
                            UiUtils.errorPopup(error);
                        }
                    }
                ));
        }
    }
    
    public void onError(Throwable error) {
        UiUtils.errorPopup(error);
    }
})&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;基于回调的服务：&lt;code&gt;Callback&lt;/code&gt; 接口定义了两个方法，异步处理成功时调用其中的 &lt;code&gt;onSuccess&lt;/code&gt;，异步处理发生错误时调用 &lt;code&gt;onError&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;第一个服务以其结果 - 喜爱物件的 ID 列表 - 调用回调方法。&lt;/li&gt;
&lt;li&gt;如果列表为空，则必须转到 &lt;code&gt;suggestionService&lt;/code&gt; 来处理。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;suggestionService&lt;/code&gt; 向第二个回调传递一个 &lt;code&gt;List&amp;lt;Favorite&amp;gt;&lt;/code&gt; 列表。&lt;/li&gt;
&lt;li&gt;对于 UI 渲染，必须让消费数据的代码运行在 UI 的线程中。&lt;/li&gt;
&lt;li&gt;这里我们使用了 Java 8 的 &lt;code&gt;Stream&lt;/code&gt; 将建议物件的数量限制为5个，然后在 UI 中渲染成一个图形化列表。&lt;/li&gt;
&lt;li&gt;在每个回调层级，我们都以相同的方式处理错误：在弹出框中显示错误信息。&lt;/li&gt;
&lt;li&gt;回到 喜爱物件 ID 列表的层级。如果 &lt;code&gt;userService&lt;/code&gt; 服务返回一个不为空的 ID 列表，则转到 &lt;code&gt;favoriteService&lt;/code&gt; 去获取带详细信息的 &lt;code&gt;Favorite&lt;/code&gt; 对象。因为只需要5个喜爱物件，所以先使用流式处理将 ID 数量限制为 5 个。&lt;/li&gt;
&lt;li&gt;再一次，使用一个回调。这一次我们获取到完整的 &lt;code&gt;Favorite&lt;/code&gt; 对象，并在 UI 线程中将其在 UI 上渲染出来。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;看看有多少代码，理解起来也有点困难，其中也有一些重复的代码片段。再来看看使用 Reactor 如何来实现这段逻辑：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;和回调实现方式等价的 Reactor 实现&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorite(userId) // 1
            .flatMap(favoriteService::getDetails) // 2
            .switchIfEmpty(suggestionService.getSuggestions()) // 3
            .take(5) // 4
            .publishOn(UiUtils.uiThreadScheduler()) // 5
            .subscribe(uiList::show, UiUtils::errorPopup); // 6&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;开启一个喜爱物件 ID 的流。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;异步地&lt;/em&gt;将 ID 转换成带详细信息的 &lt;code&gt;Favorite&lt;/code&gt; 对象（&lt;code&gt;flatMap&lt;/code&gt;）。至此我们得到一个 &lt;code&gt;Favorite&lt;/code&gt; 对象流。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;Favorite&lt;/code&gt; 流为空，则切换到备选处理方式 &lt;code&gt;suggestionService&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;我们只关注产出流中的前（最多）5个元素。&lt;/li&gt;
&lt;li&gt;最后，在 UI 线程中处理每份数据。&lt;/li&gt;
&lt;li&gt;真正触发流的处理：描述了如何处理最终的数据（显示为一个 UI 列表），以及在发生错误时如何处理（显示一个弹出框）。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果希望确保在 800ms 以内获取到喜爱物件 ID 列表，如果超时，则从缓存中获取数据，如何实现？基于回调的代码实现，这是一个复杂的任务。使用 Reactor，只需在操作链中添加一个 &lt;code&gt;timeout&lt;/code&gt; 算子就能轻松搞定，如下所示：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;超时回退处理的 Reactor 代码示例&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorites(userId)
            .timeout(Duration.ofMillis(800)) // 1
            .onErrorResume(cacheService.cachedFavoritesFor(userId)) // 2
            .flatMap(favoriteService::getDetails)
            .switchIfEmpty(suggestionService.getSuggestions())
            .take(5)
            .publishOn(UiUtils.uiThreadScheduler())
            .subscribe(uiList::show, UiUtils::errorPopup);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;如果前置处理超过 800ms 还没输出任何事件，则下发一个错误。&lt;/li&gt;
&lt;li&gt;在收到错误事件时，回退到调用 &lt;code&gt;cacheService&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;操作链的余下部分和前一个例子类似。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用 &lt;code&gt;Future&lt;/code&gt; 对象相比回调更好一点，不过组合使用起来也不太方便，尽管 Java 8 引入 &lt;code&gt;CompletableFuture&lt;/code&gt; 改善了这一问题。将多个 &lt;code&gt;Future&lt;/code&gt; 对象组织在一起，可行但并不容易。另外，&lt;code&gt;Future&lt;/code&gt; 还有其它问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;容易碰到另一个阻塞的情况：调用 &lt;code&gt;Future&lt;/code&gt; 对象的 &lt;code&gt;get()&lt;/code&gt; 方法。&lt;/li&gt;
&lt;li&gt;不支持惰性计算。&lt;/li&gt;
&lt;li&gt;对多个值的处理和高级错误处理缺乏支持。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;来看看另一个例子：先获取一个 ID 列表，然后根据 ID 获取一个名字以及获取一个统计数值，再将名字和统计数值组合起来使用，这几个步骤都必须是异步的。如下示例以一组 &lt;code&gt;CompletableFuture&lt;/code&gt; 来实现这个逻辑：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;CompletableFuture&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; ids = ifhIds(); // 1

CompletableFuture&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; results = ids.thenComposeAsync(l -&amp;amp;gt; { // 2
    Stream&amp;amp;lt;CompletableFuture&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; zip = 
            l.stream().map(i -&amp;amp;gt; { // 3
                CompletableFuture&amp;amp;lt;String&amp;amp;gt; nameTask = ifhName(i); // 4
                CompletableFuture&amp;amp;lt;Integer&amp;amp;gt; statTask = ifhStat(i); // 5
                return nameTask.thenCombineAsync(statTask, (name, stat) -&amp;amp;gt; &amp;amp;quot;Name &amp;amp;quot; + name + &amp;amp;quot; has stats &amp;amp;quot; + stat); // 6
            });
    List&amp;amp;lt;CompletableFuture&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; combinationList = zip.collect(Collectors.toList()); // 7
    CompletableFuture&amp;amp;lt;String&amp;amp;gt;[] combinationArray = combinationList.toArray(new CompletableFuture[combinationList.size()]);
    
    CompletableFuture&amp;amp;lt;Void&amp;amp;gt; allDone = CompletableFuture.allOf(combinationArray); // 8
    return allDone.thenApply(v -&amp;amp;gt; combinationList.stream()
                    .map(CompletableFuture::join) // 9
                    .collect(Collectors.toList()));
});

List&amp;amp;lt;String&amp;amp;gt; results = result.join(); // 10
assertThat(results).contains(
		&amp;amp;quot;Name NameJoe has stats 103&amp;amp;quot;,
		&amp;amp;quot;Name NameBart has stats 104&amp;amp;quot;,
		&amp;amp;quot;Name NameHenry has stats 105&amp;amp;quot;,
		&amp;amp;quot;Name NameNicole has stats 106&amp;amp;quot;,
		&amp;amp;quot;Name NameABSLAJNFOAJNFOANFANSF has stats 121&amp;amp;quot;);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;一开始获得一个 &lt;code&gt;Future&lt;/code&gt; 结果 - 为后续处理提供一个 &lt;code&gt;id&lt;/code&gt; 列表。&lt;/li&gt;
&lt;li&gt;一旦获得 &lt;code&gt;id&lt;/code&gt; 列表就可以开始进一步的异步处理。&lt;/li&gt;
&lt;li&gt;逐个处理列表中的元素。&lt;/li&gt;
&lt;li&gt;异步获取关联的名字。&lt;/li&gt;
&lt;li&gt;异步获取关联的统计数值。&lt;/li&gt;
&lt;li&gt;组合两个异步结果。&lt;/li&gt;
&lt;li&gt;至此我们得到一个 &lt;code&gt;Future&lt;/code&gt; 对象列表，表示所有的组合任务。&lt;/li&gt;
&lt;li&gt;将 &lt;code&gt;Future&lt;/code&gt; 对象数组传给 &lt;code&gt;CompletableFuture.allOf&lt;/code&gt; 方法，这个方法会输出一个 &lt;code&gt;Future&lt;/code&gt; 对象，当 &lt;code&gt;Future&lt;/code&gt; 对象数组代表的异步任务都完成时，这个 &lt;code&gt;Future&lt;/code&gt; 对象代表的异步任务也就完成了。&lt;/li&gt;
&lt;li&gt;此处的特殊之处在于：在（&lt;code&gt;allOf&lt;/code&gt; 返回的）&lt;code&gt;CompletableFuture&amp;lt;Void&amp;gt;&lt;/code&gt; 对象表示的异步任务结束时，遍历 &lt;code&gt;Future&lt;/code&gt; 对象列表（combinationList），使用 &lt;code&gt;join()&lt;/code&gt; 方法（此次不会阻塞，因为 &lt;code&gt;allOf&lt;/code&gt; 会确保所有异步任务都已完成）获取收集异步任务结果。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;10. 触发执行整个异步处理流水线（调用 &lt;code&gt;join()&lt;/code&gt; 方法），然而等着异步处理完成并返回一个结果列表，就可以进行断言判断了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 自带了很多组合算子，可以简化这个处理过程的实现，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; ids = ifhrIds(); // 1

Flux&amp;amp;lt;String&amp;amp;gt; combinations = 
        ids.flatMap(id -&amp;amp;gt; { // 2
            Mono&amp;amp;lt;String&amp;amp;gt; nameTask = ifhrName(id); // 3
            Mono&amp;amp;lt;Integer&amp;amp;gt; statTask = ifhrStat(id); // 4
            
            return nameTask.zipWith(statTask, // 5
                    (name, stat) -&amp;amp;gt; &amp;amp;quot;Name &amp;amp;quot; + name + &amp;amp;quot; has stats &amp;amp;quot; + stat);
        });
        
Mono&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; result = combinations.collectList(); // 6

List&amp;amp;lt;String&amp;amp;gt; results = result.block(); // 7
assertThat(results).containsExactly( // 8
    &amp;amp;quot;Name NameJoe has stats 103&amp;amp;quot;,
    &amp;amp;quot;Name NameBart has stats 104&amp;amp;quot;,
    &amp;amp;quot;Name NameHenry has stats 105&amp;amp;quot;,
    &amp;amp;quot;Name NameNicole has stats 106&amp;amp;quot;,
    &amp;amp;quot;Name NameABSLAJNFOAJNFOANFANSF has stats 121&amp;amp;quot;
);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;这次，一开始我们得到一个异步提供的字符串序列（&lt;code&gt;ids&lt;/code&gt;）（一个 &lt;code&gt;Flux&amp;lt;String&amp;gt;&lt;/code&gt; 对象）。&lt;/li&gt;
&lt;li&gt;对于序列中的每个元素，异步处理两次（在 &lt;code&gt;flatMap&lt;/code&gt; 的 lambda 参数值中）。&lt;/li&gt;
&lt;li&gt;获取关联的名字。&lt;/li&gt;
&lt;li&gt;获取关联的统计值。&lt;/li&gt;
&lt;li&gt;异步组合两个值&lt;/li&gt;
&lt;li&gt;在异步处理的结果可用时，将它们聚合到一个 &lt;code&gt;List&lt;/code&gt; 对象中。&lt;/li&gt;
&lt;li&gt;在实际项目中，我们通常会继续异步处理 &lt;code&gt;Flux&lt;/code&gt;，比如：异步组合使用它或者直接订阅它。最可能的是，返回这个 &lt;code&gt;Mono&lt;/code&gt; 类型的 &lt;code&gt;result&lt;/code&gt;。因为这里只是个测试，所以使用了 block，等待处理结束，直接返回值的聚合列表。&lt;/li&gt;
&lt;li&gt;对结果进行断言判断。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用回调和 &lt;code&gt;Future&lt;/code&gt; 对象的问题是类似的，反应式编程以 &lt;code&gt;发布者（Publisher）- 订阅者（Subscriber）&lt;/code&gt; 解决了这些问题。&lt;/p&gt;
&lt;h3&gt;2.3 从命令式到反应式编程&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;反应式编程库，比如 Reactor，目标是解决 JVM 上“经典”异步处理方式的弊端，同时也专注于提供以下几个方面的特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;可组合性&lt;/strong&gt; 和 &lt;strong&gt;代码可读性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将数据视作一个&lt;strong&gt;流&lt;/strong&gt;，并提供丰富的&lt;strong&gt;算子&lt;/strong&gt;来操作流&lt;/li&gt;
&lt;li&gt;在&lt;strong&gt;订阅（subscriber）&lt;/strong&gt;之前不会实际做任何事情&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反压&lt;/strong&gt; 或者说 消费者通知生产者流速过高的能力&lt;/li&gt;
&lt;li&gt;与并发无关（concurrency-agnostic）的&lt;strong&gt;高阶（high level）&lt;/strong&gt;抽象，&lt;strong&gt;适用性强（high value）&lt;/strong&gt;（译注：并发无关是指这种抽象对于并发非并发的场景都适用）&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;3. Reactor 核心特性&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 项目的主要成果是 &lt;code&gt;reactor-core&lt;/code&gt; - 一个遵循&lt;a href=&apos;https://www.reactive-streams.org/&apos;&gt;反应式流&lt;/a&gt;规范并支持 Java 8 的反应式编程库。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 引入 2 个可组合的反应式类型（实现了 &lt;code&gt;Publisher&lt;/code&gt; 接口并且提供丰富的算子）： &lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt;。一个 &lt;code&gt;Flux&lt;/code&gt; 对象代表包含 0 到 N 个元素的反应式序列，&lt;code&gt;Mono&lt;/code&gt; 对象代表单值或空（0或1个元素）的结果。&lt;/p&gt;
&lt;h3&gt;3.1 Flux - 0-N 个值的异步序列&lt;/h3&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/oKMX4rTvUViZRHj.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;h3&gt;3.2 Mono - 包含 0 或 1 个值的异步结果&lt;/h3&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/8WxGgH9UkcQwuX4.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;h3&gt;3.3 创建一个 Flux 或 Mono 并进行订阅的一些简单方法&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 的类中包含大量的工厂方法，上手使用 Reactor 最简单的方式是从中选择一个用起来。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;例如，创建一个 &lt;code&gt;String&lt;/code&gt; 序列，可以逐个列举出这些字符串，或者将这些字符串放到一个集合中，然后基于这个集合创建一个 Flux，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; seq1 = Flux.just(&amp;amp;quot;foo&amp;amp;quot;, &amp;amp;quot;bar&amp;amp;quot;, &amp;amp;quot;foobar&amp;amp;quot;);

List&amp;amp;lt;String&amp;amp;gt; iterable = Arrays.asList(&amp;amp;quot;foo&amp;amp;quot;, &amp;amp;quot;bar&amp;amp;quot;, &amp;amp;quot;foobar&amp;amp;quot;);
Flux&amp;amp;lt;String&amp;amp;gt; seq2 = Flux.fromIterable(iterable);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其它一些工厂方法的使用示例如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Mono&amp;amp;lt;String&amp;amp;gt; noData = Mono.empty();
Mono&amp;amp;lt;String&amp;amp;gt; data = Mono.just(&amp;amp;quot;foo&amp;amp;quot;);
Flux&amp;amp;lt;Integer&amp;amp;gt; numbersFromFiveToSeven = Flux.range(5, 3);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于订阅操作，&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 借助了 Java 8 的 lambda 表达式。有大量 &lt;code&gt;.subscribe()&lt;/code&gt; 的重载方法/变种方法（variants）可选选择使用，使用 lambda 表达式来实现回调的不同组合，如下所示是这些方法的签名：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;Flux 中基于 lambda 表达式的订阅方法变种&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;subscribe();

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer,
          Runnable completeConsumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer,
          Runnable completeConsumer,
          Consumer&amp;amp;lt;? super Subscription&amp;amp;gt; subscriptionConsumer);&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;这些订阅方法都会返回一个订阅操作的引用，当不再需要更多的数据时，可以使用这个引用来取消订阅。一旦取消，数据源就应该停止产出数据，并清理使用的所有资源。这一 “取消并清理” 行为在 Reactor 中以通用的 &lt;code&gt;Disposable&lt;/code&gt; 接口来表现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;3.3.1 lambda 表达式的替代方案：BaseSubscriber&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 提供了一个相比上面那么订阅方法更通用的 &lt;code&gt;subscribe&lt;/code&gt; 方法，其参数是一个完整的 &lt;code&gt;Subscriber&lt;/code&gt; 实例，而不是根据几个 lambda 表达式组合出一个 &lt;code&gt;Subscriber&lt;/code&gt; 实例。为了方便实现这样的一个 &lt;code&gt;Subscriber&lt;/code&gt;，Reactor 提供了一个名为 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的可扩展的抽象类。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面来实现一个，我们将其命名为 &lt;code&gt;SampleSubscriber&lt;/code&gt;。如下示例演示了如何将其应用到一个 &lt;code&gt;Flux&lt;/code&gt; 序列上：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;SampleSubscriber&amp;amp;lt;Integer&amp;amp;gt; ss = new SampleSubscriber&amp;amp;lt;Integer&amp;amp;gt;();
Flux&amp;amp;lt;Integer&amp;amp;gt; ints = Flux.range(1, 4);
//
ints.subscribe(i -&amp;amp;gt; System.out.println(i),
    error -&amp;amp;gt; System.err.println(&amp;amp;quot;Error &amp;amp;quot; + error),
    () -&amp;amp;gt; {System.out.println(&amp;amp;quot;Done&amp;amp;quot;);},
    s -&amp;amp;gt; s.request(10));
//
ints.subscribe(ss);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下示例演示了 &lt;code&gt;SampleSubscriber&lt;/code&gt; 继承自 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的一个最简化实现：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;package io.projectreactor.samples;

import org.reactivestreams.Subscription;
import reactor.core.publisher.BaseSubscriber;

public class SampleSubscriber&amp;amp;lt;T&amp;amp;gt; extends BaseSubscriber&amp;amp;lt;T&amp;amp;gt; {

	public void hookOnSubscribe(Subscription subscription) {
		System.out.println(&amp;amp;quot;Subscribed&amp;amp;quot;);
		request(1);
	}

	public void hookOnNext(T value) {
		System.out.println(value);
		request(1);
	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;BaseSubscriber&lt;/code&gt; 还提供了一个 &lt;code&gt;requestUnbounded()&lt;/code&gt; 方法来切换到无限消费模式（相当于 &lt;code&gt;request(Long.MAX_VALUES)&lt;/code&gt;），另外也提供了一个 &lt;code&gt;cancel()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除了 &lt;code&gt;hookOnSubscribe&lt;/code&gt; 和 &lt;code&gt;hookOnNext&lt;/code&gt;，&lt;code&gt;BaseSubscriber&lt;/code&gt; 还提供了其他钩子方法（方法体为空，提供继承重写）：&lt;code&gt;hookOnComplete&lt;/code&gt;、&lt;code&gt;hookOnError&lt;/code&gt;、&lt;code&gt;hookOnCancel&lt;/code&gt; 以及 &lt;code&gt;hookFinally&lt;/code&gt;（当事件/消息序列（流）终止时，一定会调用该方法，调用时会传入一个 &lt;code&gt;SignalType&lt;/code&gt; 类型参数表示终止的类型）。&lt;/p&gt;
&lt;h4&gt;3.3.2 关于反压和调整请求量的方式&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在 Reactor 中实现反压，是通过向上游算子发送一个 &lt;code&gt;请求（request）&lt;/code&gt;来逐级传播消费者的压力，直到数据源。当前请求的总量有时又称为当前的“需求量” 或者 “待满足（pending）的请求量”。需求量的上限是 &lt;code&gt;Long.MAX_VALUE&lt;/code&gt;，表示一个无限量的请求（意思是“尽快产出数据“ - 反压也就失效了）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最终的订阅者在订阅之前会发出首个请求，订阅所有消息/数据最直接的方式是即刻触发一个无限量（Long.MAX_VALUE）的请求：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;subscribe()&lt;/code&gt; 以及大部分基于 lambda 表达式的变种方法（除了那个接受 &lt;code&gt;Consumer&amp;lt;Subscription&amp;gt;&lt;/code&gt; 类型参数的方法）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;block()&lt;/code&gt;、&lt;code&gt;blockFirst()&lt;/code&gt; 和 &lt;code&gt;blockLast()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;toIterable()&lt;/code&gt; 或 &lt;code&gt;toStream()&lt;/code&gt; 进行遍历&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对首个请求进行定制的最简单方式是以一个 &lt;code&gt;BaseSubscriber&lt;/code&gt; 派生类实例来 &lt;code&gt;subscribe&lt;/code&gt;，派生类重写 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的 &lt;code&gt;hookOnSubscribe&lt;/code&gt; 方法，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .doOnRequest(r -&amp;amp;gt; System.out.println(&amp;amp;quot;request of &amp;amp;quot; + r))
    .subscribe(new BaseSubscriber&amp;amp;lt;Integer&amp;amp;gt;() {

      @Override
      public void hookOnSubscribe(Subscription subscription) {
        request(1);
      }

      @Override
      public void hookOnNext(Integer integer) {
        System.out.println(&amp;amp;quot;Cancelling after having received &amp;amp;quot; + integer);
        cancel();
      }
    });&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上面这个代码片段输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;request of 1
Cancelling after having received 1&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;改变下游需求量的算子&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;谨记：订阅时指定的需求量，上游操作链中的每个算子都可以对其作出调整。一个典型案例是 &lt;code&gt;buffer(N)&lt;/code&gt; 算子：如果它收到一个 &lt;code&gt;request(2)&lt;/code&gt; 请求，它会理解为2个缓冲区的请求量。因为缓冲区需要 N 个元素才认为是满的，所以 &lt;code&gt;buffer&lt;/code&gt; 算子将请求量调整成了 &lt;code&gt;2 x N&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你也许也注意到某些算子存在这样的变种 - 接受一个名为 &lt;code&gt;prefetch&lt;/code&gt; 的 &lt;code&gt;int&lt;/code&gt; 类型参数。这是另外一类修改下游请求量的算子。这类算子（比如 &lt;code&gt;flatMap&lt;/code&gt;）通常是处理内部序列（inner sequences），从每个进入的元素派生出一个 &lt;code&gt;Publisher&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;预取（prefetch）&lt;/code&gt;是调整内部序列请求量的一个方式。如果未指定，多数这类算子会以 32 为初始需求量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这类算子通常也会实现一个&lt;strong&gt;填补优化方案&lt;/strong&gt;：算子一旦看到 25% 的预取请求量已完成，就会向上游再发起 25% 的请求量。这是一个启发式优化，如此这类算子就可以主动地为即将到来的请求量做好准备。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后，再介绍一对直接用于调整请求量的算子：&lt;code&gt;limitRate&lt;/code&gt; 和 &lt;code&gt;limitRequest&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;limitRate(N)&lt;/code&gt; 把下游的请求量拆分成多个更小量的请求向上游传播。例如，一个 &lt;code&gt;100&lt;/code&gt; 的请求传到算子 &lt;code&gt;limitRate(10)&lt;/code&gt;，则会变成 10 次请求，一次请求 10，传播到上游。注意：&lt;code&gt;limitRate&lt;/code&gt; 实际上以这种形式实现了前面提到的填补优化方案。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个算子有一个变种，允许开发者调整预取填补量（即算子变种的 &lt;code&gt;lowTide&lt;/code&gt; 参数）：&lt;code&gt;limitRate(highTide, lowTide)&lt;/code&gt;。&lt;code&gt;lowTide&lt;/code&gt; 参数设定为 &lt;code&gt;0&lt;/code&gt; 时，会导致严格限制一次请求 &lt;code&gt;highTide&lt;/code&gt; 个，而不是经填补策略进一步调整过的一次请求量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此外，&lt;code&gt;limitRequest(N)&lt;/code&gt; 则是限制了下游最大的需求总量。它会累加请求量直到 &lt;code&gt;N&lt;/code&gt;。如果一次请求没有让需求总量超过 &lt;code&gt;N&lt;/code&gt;，则这次请求会完整地传播到上游（译注：意思是如果一次请求让需求总量超过了 &lt;code&gt;N&lt;/code&gt;，这次请求的请求量会被裁剪）。如果数据源发出的数据总量达到了限制的总量，&lt;code&gt;limitRequest&lt;/code&gt; 则认为这个序列可以结束了，向下游发送一个 &lt;code&gt;onComplete&lt;/code&gt; 信号，并取消数据源。&lt;/p&gt;
&lt;h3&gt;3.4 动态地（programmatically）创建一个序列&lt;/h3&gt;
&lt;h4&gt;3.4.1 同步的 generate&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;动态创建一个 &lt;code&gt;Flux&lt;/code&gt; 最简单的方式是借助 &lt;code&gt;generate&lt;/code&gt; 方法，该方法接受一个生成器函数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一方式可以实现&lt;strong&gt;同步的&lt;/strong&gt;且&lt;strong&gt;一个接一个&lt;/strong&gt;地下发数据，这意味着接收方（sink）是一个 &lt;code&gt;SynchronousSink&lt;/code&gt;，其 &lt;code&gt;next()&lt;/code&gt; 方法在一次回调方法调用中最多只能调用一次。可以在其后再调用 &lt;code&gt;error(Throwable)&lt;/code&gt; 或 &lt;code&gt;complete()&lt;/code&gt;，视你的需求而定。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;generate&lt;/code&gt; 方法变种的这个应该是最有用的：允许保持一个状态，在调用接收方的 &lt;code&gt;next&lt;/code&gt; 方法时可以基于这个状态来决定下发什么数据。那么这个生成器函数就成了一个 &lt;code&gt;BiFunction&amp;lt;S, SynchronousSink&amp;lt;T&amp;gt;, S&amp;gt;&lt;/code&gt; 实例，其中 &lt;code&gt;&amp;lt;S&amp;gt;&lt;/code&gt; 即是状态对象的类型。对于初始状态，可以提供一个 &lt;code&gt;Supplier&amp;lt;S&amp;gt;&lt;/code&gt; 来获取，这样生成器函数每轮调用都会返回一个新的状态。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;例如，可以使用一个 &lt;code&gt;int&lt;/code&gt; 实例作为状态：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 基于状态的 generate 方法使用示例
Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    () -&amp;amp;gt; 0, // 1
    (state, sink) -&amp;amp;gt; {
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + state + &amp;amp;quot; = &amp;amp;quot; + 3*state); // 2
        if (state == 10) sink.complete(); // 3
        return state + 1; // 4
    });&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;以 0 作为初始状态。&lt;/li&gt;
&lt;li&gt;基于状态（state）决定下发什么消息/数据。&lt;/li&gt;
&lt;li&gt;基于状态决定何时可以停止流/序列。&lt;/li&gt;
&lt;li&gt;返回一个新状态，下次调用时可以使用（除非在这次调用时已经终止序列）。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以使用一个 &lt;code&gt;&amp;lt;S&amp;gt;&lt;/code&gt; 类型的可变对象。比如，上面的示例可以使用一个 &lt;code&gt;AtomicLong&lt;/code&gt; 实例作为状态来重写，每轮调用都会改变它的值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    AtomicLong::new,
    (state, sink) -&amp;amp;gt; {
        long i = state.getAndIncrement();
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + i + &amp;amp;quot; = &amp;amp;quot; + 3*i);
        if (i == 10) sink.complete();
        return state;
    });&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;如果状态对象在序列终止时需要清理一些资源，则应该使用 &lt;code&gt;generate(Supplier&amp;lt;S&amp;gt;, BiFunction, Consumer&amp;lt;S&amp;gt;)&lt;/code&gt; 变种方法来清理最后的状态实例。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下示例使用的 &lt;code&gt;generate&lt;/code&gt; 方法接受一个 &lt;code&gt;Consumer&lt;/code&gt; 类型参数：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    AtomicLong::new,
    (state, sink) -&amp;amp;gt; {
        long i = state.getAndIncrement();
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + i + &amp;amp;quot; = &amp;amp;quot; + 3*i);
        if (i == 10) sink.complete();
        return state;
    }, (state) -&amp;amp;gt; System.out.println(&amp;amp;quot;state: &amp;amp;quot; + state));&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;3.4.2 异步多线程的 create&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;create&lt;/code&gt; 是动态创建一个 &lt;code&gt;Flux&lt;/code&gt; 的更高级的方式，适用于每轮下发多个数据，甚至是从多个线程中下发数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个方法会向回调方法传入一个 &lt;code&gt;FluxSink&lt;/code&gt; 实例参数，在回调方法体中可以调用这个参数的 &lt;code&gt;next&lt;/code&gt;、&lt;code&gt;error&lt;/code&gt; 和 &lt;code&gt;complete&lt;/code&gt; 方法。与 &lt;code&gt;generate&lt;/code&gt; 不同，它没有基于状态的变种方法。另外，回调方法中，可以多线程地触发事件（trigger multi-threaded events）。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;create&lt;/code&gt; 非常适用于将一个已有的 API （比如：一个基于监听器的异步 API）桥接到反应式上下文中。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;create&lt;/code&gt; 并不会自动并行化执行你的代码，也不会让处理过程自动变成异步的，即使它可以配合异步 API 使用。如果在 &lt;code&gt;create&lt;/code&gt; 的 lambda 表达式中发生阻塞，就会存在死锁或者其它副作用的风险。即使借助 &lt;code&gt;subscribeOn&lt;/code&gt;，也要当心 &lt;code&gt;create&lt;/code&gt; lambda 表达式中长时间的阻塞（比如无限循环调用 &lt;code&gt;sink.next(t)&lt;/code&gt;）锁住流水线处理： （译注：异步的）数据请求可能根本得不到执行，因为（译注：线程池只有一个线程）同一个线程一直被无限循环占用着。使用 &lt;code&gt;subscribeOn(Scheduler, false)&lt;/code&gt; 变种方法：&lt;code&gt;requestOnSeparateThread = false&lt;/code&gt; 将使用 &lt;code&gt;Scheduler&lt;/code&gt; 的线程来执行 &lt;code&gt;create&lt;/code&gt; 方法的回调，在原始的线程中执行 &lt;code&gt;request&lt;/code&gt;，从而让数据仍然可以流动起来。（译注：此处逻辑有点绕，也可能是因为 subscribeOn 方法本身语义就不太直观）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设我们要使用一个基于监听器的 API，它按块处理数据，提供两类事件：（1）来了一块数据，（2）处理可以结束了（终止事件），如下 &lt;code&gt;MyEventListener&lt;/code&gt; 接口定义所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;interface MyEventListener&amp;amp;lt;T&amp;amp;gt; {
    void onDataChunk(List&amp;amp;lt;T&amp;amp;gt; chunk);
    void processComplete();
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们使用 &lt;code&gt;create&lt;/code&gt; 将这个 API 桥接到一个 &lt;code&gt;Flux&amp;lt;T&amp;gt;&lt;/code&gt; 实例上：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.create(sink -&amp;amp;gt; {
    myEventProcessor.register(  // 4
        new MyEventListener&amp;amp;lt;String&amp;amp;gt;() { // 1
            public void onDataChunk(List&amp;amp;lt;String&amp;amp;gt; chunk) {
                for(String s : chunk) {
                    sink.next(s); // 2
                }
            }
            
            public void processComplete() {
                sink.complete(); // 3
            }
        }
    );
});&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;桥接到 &lt;code&gt;MyEventListener&lt;/code&gt; API&lt;/li&gt;
&lt;li&gt;数据块中每个元素都成了 &lt;code&gt;Flux&lt;/code&gt; 中的元素。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;processComplete&lt;/code&gt; 事件转换成了 &lt;code&gt;onComplete&lt;/code&gt; 事件。&lt;/li&gt;
&lt;li&gt;所有这些逻辑都是在 &lt;code&gt;myEventProcessor&lt;/code&gt; 执行时异步完成的。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此外，因为 &lt;code&gt;create&lt;/code&gt; 可以桥接异步 API，并管理反压，通过指定一个 &lt;code&gt;OverflowStrategy&lt;/code&gt; 策略，可以调整如何智能地处理反压：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;IGNORE&lt;/code&gt; 完全忽略下游的反压请求。这一策略在下游的队列满时（when queues get full downstream）会导致 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常抛出。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ERROR&lt;/code&gt; 在下游处理不过来时会下发（onError）一个 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常消息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DROP&lt;/code&gt; 如果下游还没准备好接收当前事件，则直接丢弃。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BUFFER&lt;/code&gt; （默认策略）如果下游处理不过来，则将所有事件放入缓冲区。（缓冲区大小无限制，所以可能会导致内存溢出&lt;code&gt;OutOfMemoryError&lt;/code&gt;）&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Mono&lt;/code&gt; 也有一个 &lt;code&gt;create&lt;/code&gt; 生成器方法。Mono 的 create 方法传入回调的 &lt;code&gt;MonoSink&lt;/code&gt; 参数不允许下发多个消息，在第一个消息之后它会丢弃所有的消息。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;3.4.3 异步单线程的 push&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;push&lt;/code&gt; 的功能介于 &lt;code&gt;generate&lt;/code&gt; 和 &lt;code&gt;create&lt;/code&gt; 之间，适用于处理来自单个生产者的事件。&lt;code&gt;push&lt;/code&gt; 也可以是异步的，也可以使用 &lt;code&gt;create&lt;/code&gt; 支持的超限策略来管理反压，然而，同时（at a time）只能有一个生产线程调用 &lt;code&gt;next&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.push(sink -&amp;amp;gt; {
    myEventProcessor.register(
        new SingleThreadEventListener&amp;amp;lt;String&amp;amp;gt;() { // 1
            
            public void onDataChunk(List&amp;amp;lt;String&amp;amp;gt; chunk) {
                for (String s: chunk) {
                    sink.next(s); // 2
                }
            }
            
            public void processComplete() {
                sink.complete(); // 3
            }
            
            public void processError(Throwable e) {
                sink.error(e); // 4
            }
        }
    );
});&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;桥接到 &lt;code&gt;SingleThreadEventListener&lt;/code&gt; 的 API。&lt;/li&gt;
&lt;li&gt;在单个监听器线程中使用 &lt;code&gt;next&lt;/code&gt; 向下游（sink - 接收方）推送事件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;complete&lt;/code&gt; 事件也是由同一个监听器线程发出的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;error&lt;/code&gt; 事件也是由同一个监听器线程发出的。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;推/拉 混合模型&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;多数 Reactor 算子，比如 &lt;code&gt;create&lt;/code&gt;，都遵从 &lt;strong&gt;推/拉（push/pull）&lt;/strong&gt; 混合模型。这意味着尽管大部分的处理过程都是异步的（暗指“推”的方式），也存在小部分逻辑是 &lt;em&gt;拉（pull）&lt;/em&gt;方式：数据请求。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;消费者从数据源&lt;em&gt;拉取&lt;/em&gt;数据，意指：数据源在消费者首次请求后才会发出数据，然后只有要数据就会推送给消费者，不过数据量不会超过消费者请求的量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;push()&lt;/code&gt; 和 &lt;code&gt;create()&lt;/code&gt; 都可以配置（set up）一个 &lt;code&gt;onRequest&lt;/code&gt; 事件消费者来管理请求量，并且确保仅当存在已发起的请求，数据才会推送给下游。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.create(sink -&amp;amp;gt; {
    myMessageProcessor.register(
        new MyMessageListener&amp;amp;lt;String&amp;amp;gt;() {
            
            public void onMessage(List&amp;amp;lt;String&amp;amp;gt; messages) {
                for (String s: messages) {
                    sink.next(s); // 3
                }
            }
        }
    );
    sink.onRequest(n -&amp;amp;gt; {
        List&amp;amp;lt;String&amp;amp;gt; messages = myMessageProcessor.getHistory(n); // 1
        for (String s: messages) {
            sink.next(s); // 2
        }
    });    
});&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;译者注：上面这个示例有点问题，实际并不存在这样一个 create 方法，并且 sink.onRequest 实际代表一个无限量（n = Long.MAX_VALUE）的请求。&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在请求发起后，拉取消息。&lt;/li&gt;
&lt;li&gt;如果即刻有消息了，则推送给下游。&lt;/li&gt;
&lt;li&gt;后续异步到达的消息也会推送给下游。&lt;/li&gt;&lt;/ol&gt;
&lt;h3&gt;3.5 多线程 和 调度器 （Threading and Schedulers）&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor，与 RxJava 类似，可以认为是&lt;strong&gt;并发无关的&lt;/strong&gt;，也就是说，Reactor 并不强制使用并发（a concurrency&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;model），而是，让开发者按需决定是否使用并发。然而，Reactor 也提供一些功能方便开启并发。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;获取到一个 &lt;code&gt;Flux&lt;/code&gt; 或 &lt;code&gt;Mono&lt;/code&gt; 处理流，并不意味着它在一个专用（dedicated）的线程（&lt;code&gt;Thread&lt;/code&gt;） 中运行。相反，多数算子也是运行在前一个算子运行的线程中。除非特意指定，首个（topmost）算子（数据源）就运行在执行 &lt;code&gt;subscribe()&lt;/code&gt; 方法调用的线程中。如下示例在一个新建线程中运行一个 &lt;code&gt;Mono&lt;/code&gt; 处理流。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;public static void main(String[] args) {
    final Mono&amp;amp;lt;String&amp;amp;gt; mono = Mono.just(&amp;amp;quot;Hello &amp;amp;quot;); // 1
    
    new Thread(() -&amp;amp;gt; mono
        .map(msg -&amp;amp;gt; msg + &amp;amp;quot;thread &amp;amp;quot;)
        .subscribe(v -&amp;amp;gt; // 2 
            System.out.println(v + Thread.currentThread().getName()) // 3
        )
    ).join();
}&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;Mono&amp;lt;String&amp;gt;&lt;/code&gt; 是在主（&lt;code&gt;main&lt;/code&gt;）线程中装配的（assembled）。&lt;/li&gt;
&lt;li&gt;然而， 订阅操作发生在 &lt;code&gt;Thread-0&lt;/code&gt; 线程中。&lt;/li&gt;
&lt;li&gt;因而，&lt;code&gt;map&lt;/code&gt; 和 &lt;code&gt;onNext&lt;/code&gt; 的回调（译注：&lt;code&gt;onNext&lt;/code&gt; 的回调即 subscribe 方法传入的 lambda 表达式）实际上也是在 &lt;code&gt;Thread-0&lt;/code&gt; 上执行。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上述的代码会输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;hello thread Thread-0&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 中，运行模型以及实际的运行过程发生在什么地方由使用什么 &lt;code&gt;Scheduler&lt;/code&gt; 决定。&lt;a href=&apos;https://projectreactor.io/docs/core/release/api/reactor/core/scheduler/Scheduler.html&apos;&gt;Scheduler&lt;/a&gt; 类似于 &lt;code&gt;ExecutorService&lt;/code&gt;，负有调度职责，但具备一个专用的抽象，功能更强大，充当一个时钟的角色，可用的实现更多。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://projectreactor.io/docs/core/release/api/reactor/core/scheduler/Schedulers.html&apos;&gt;Schedulers&lt;/a&gt; 类提供了一些静态方法来访问这些运行上下文：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当前线程（&lt;code&gt;Schedulers.immediate()&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;单个可复用的线程（&lt;code&gt;Schedulers.single()&lt;/code&gt;）。注意：这个方法会为所有调用方（译注：调用 Schedulers.single()）复用同一个线程，指导 &lt;code&gt;Scheduler&lt;/code&gt; 销毁（disposed）。如果期望每次调用返回一个专用线程，则应该使用 &lt;code&gt;Schedulers.newSingle()&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;一个弹性的线程池（&lt;code&gt;Schedulers.elastic()&lt;/code&gt;）。这个 Scheduler 会按需创建新的工作者线程池（worker pool），并复用空闲的工作者线程池。如果工作者线程池空闲时间太长（默认 60s）则会被销毁。对于 I/O 阻塞工作而言这是一个好选择。&lt;code&gt;Schedulers.elastic()&lt;/code&gt; 可以简便地为阻塞处理过程提供独立的线程（its own thread），这样阻塞操作就不会占用（tie up）其他资源。详情请参考 &lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/#faq.wrap-blocking&apos;&gt;如何包装一个同步阻塞的调用？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;固定数量工作者的（译注：我暂时的理解 - 工作者（worker）也是一个线程池）一个池，专门为并行处理工作做过调优（Schedulers.parallel()）。它会创建和 CPU 核心数量相同的工作者。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此外，也可以使用 &lt;code&gt;Schedulers.fromExecutorService(ExecutorService)&lt;/code&gt; 基于已有的 ExecutorService 创建一个 Scheduler。（也可以基于一个 Executor 来创建，但不建议这么干（译注：因为 Executor 不能销毁释放））&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以使用 &lt;strong&gt;newXXX&lt;/strong&gt; 这类方法创建各种调度器（scheduler）类型的全新实例。例如，使用 &lt;code&gt;Schedulers.newElastic(yourScheduleName)&lt;/code&gt; 创建一个名为 &lt;code&gt;yourScheduleName&lt;/code&gt; 的全新的弹性调度器（elastic scheduler）。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;elastic&lt;/code&gt; 调度器用于兼容处理不可避免的历史遗留的阻塞性代码，但 &lt;code&gt;single&lt;/code&gt; 和 &lt;code&gt;parallel&lt;/code&gt; 调度器不行，因而，如果在 &lt;code&gt;single&lt;/code&gt; 或 &lt;code&gt;parallel&lt;/code&gt; 调度器上使用 Reactor 的阻塞性 API（&lt;code&gt;block()&lt;/code&gt;、&lt;code&gt;blockFirst()&lt;/code&gt;、&lt;code&gt;blockLast()&lt;/code&gt;，或者进行 &lt;code&gt;toIterable()&lt;/code&gt; 或 &lt;code&gt;toStream()&lt;/code&gt; 迭代），会导致抛出 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果自定义调度器所创建的线程实例实现了 &lt;code&gt;NonBlocking&lt;/code&gt; 标记性接口（marker interface），那么这个调度器也可以被标记为”仅适用于非阻塞性使用（non blocking only）“。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;某些算子默认会从 &lt;code&gt;Schedulers&lt;/code&gt; 选择一个特定的调度器来使用（通常也支持选择其他的）。例如，调用工厂方法 &lt;code&gt;Flux.interval(Duration.ofMills(300))&lt;/code&gt; 会生成一个 &lt;code&gt;Flux&amp;lt;Long&amp;gt;&lt;/code&gt; 实例 - 每 300 ms 输出一个滴答事件。这个方法底层实现默认使用 &lt;code&gt;Schedulers.parallel()&lt;/code&gt;。如下代码行演示了如何将调度器修改成类似于 &lt;code&gt;Schedulers.single()&lt;/code&gt; 的调度器新实例：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.interval(Duration.ofMillis(300), Schedulers.newSingle(&amp;amp;quot;test&amp;amp;quot;));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor 提供了两种方式来切换反应式链中的执行上下文（或者说 &lt;code&gt;调度器&lt;/code&gt;）：&lt;code&gt;publishOn&lt;/code&gt; 和 &lt;code&gt;subscribeOn&lt;/code&gt;。两者都是接受一个 &lt;code&gt;Scheduler&lt;/code&gt; 类型参数并将执行上下文切换到这个调度器。不过，链中 &lt;code&gt;publishOn&lt;/code&gt; 所处的位置很关键，而 &lt;code&gt;subscribeOn&lt;/code&gt; 处于哪个位置都无所谓。要理解这个差别的原因，得先理解 &lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/#reactive.subscribe&apos;&gt;订阅之前实际什么都没有发生&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Reactor，串接算子，就是将很多 &lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 的实现一个套一个，逐层封装。一旦订阅，就创建了一个 &lt;code&gt;Subscriber&lt;/code&gt; 对象链，沿链回溯即可找到第一个发布者。这些实现细节是隐藏在接口背后，开发者可见的是最外层的那个 &lt;code&gt;Flux&lt;/code&gt;（或 &lt;code&gt;Mono&lt;/code&gt;）以及 &lt;code&gt;Subscription&lt;/code&gt;（译注：Reactor 中 Subscription 是一个接口类型，是 &lt;code&gt;Subscriber&lt;/code&gt; 接口中 &lt;code&gt;onSubscribe&lt;/code&gt; 方法参数的类型 - &lt;code&gt;public void onSubscribe(Subscription s)&lt;/code&gt;，用于向生产者请求数据 或者 取消订阅），但这些算子特定的链中消费者是幕后功臣。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有了上面这些认知，现在我们可以进一步了解 &lt;code&gt;publishOn&lt;/code&gt; 和 &lt;code&gt;subscribeOn&lt;/code&gt; 这两个算子：&lt;/p&gt;
&lt;h4&gt;3.5.1 publishOn 方法&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;publishOn&lt;/code&gt; 和其他算子的用法一样，用在订阅链的中间环节，接收来自上游的信号，然后向下游重放这些信号，不过下发事件回调（&lt;code&gt;onEvent&lt;/code&gt;、&lt;code&gt;onError&lt;/code&gt;、&lt;code&gt;onComplete&lt;/code&gt;）是在关联 &lt;code&gt;Scheduler&lt;/code&gt; 的一个工作者上执行的。因此，这个算子会影响后续算子在哪执行（直到订阅链上又串接了另一个 &lt;code&gt;publishOn&lt;/code&gt;）：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将执行上下文切换到 &lt;code&gt;Scheduler&lt;/code&gt; 选择的一个线程上&lt;/li&gt;
&lt;li&gt;根据规范（as per the specification），&lt;code&gt;onNext&lt;/code&gt; 是按时序依次调用下发事件的，所以是占用一个线程（译注：这句不太理解，onNext happen in sequence, so this uses up a single thread）&lt;/li&gt;
&lt;li&gt;除非算子工作在一个特定的 &lt;code&gt;Scheduler&lt;/code&gt; 上（译注：某些算子的内部实现决定了这一点），&lt;code&gt;publishOn&lt;/code&gt; 之后的算子都是在同一个线程上执行&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Scheduler s = Schedulers.newParallel(&amp;amp;quot;parallel-scheduler&amp;amp;quot;, 4); // 1

final Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux
    .range(1, 2)
    .map(i -&amp;amp;gt; 10 + i) // 2
    .publishOn(s) // 3
    .map(i -&amp;amp;gt; &amp;amp;quot;value &amp;amp;quot; + i); // 4

new Thread(() -&amp;amp;gt; flux.subscribe(System.out::println));&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;创建一个新的 &lt;code&gt;Scheduler&lt;/code&gt;，内含 4 个线程&lt;/li&gt;
&lt;li&gt;第一个 &lt;code&gt;map&lt;/code&gt; 运行在 &lt;第5步&gt; 的匿名线程上&lt;/li&gt;
&lt;li&gt;&lt;code&gt;publishOn&lt;/code&gt; 将整个序列的后续处理切换到从 &lt;第1步&gt; 选出的线程上&lt;/li&gt;
&lt;li&gt;第二个 &lt;code&gt;map&lt;/code&gt; 运行在上面说的从 &lt;第1步&gt; 选出的线程上&lt;/li&gt;
&lt;li&gt;这个匿名线程是 &lt;em&gt;订阅&lt;/em&gt; 操作发生的地方。打印语句发生在 &lt;code&gt;publishOn&lt;/code&gt; 切换的最新执行上下文上&lt;/li&gt;&lt;/ol&gt;
&lt;h4&gt;3.5.2 subscribeOn 方法&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;subscribeOn&lt;/code&gt; 在构造反向链时应用于订阅处理过程（译注：所谓构造反向链时，是指调用 subscribe 方法时）。因此，无论你将 &lt;code&gt;subscribeOn&lt;/code&gt; 放在算子链的何处，&lt;strong&gt;它始终会影响源头下发数据的执行上下文&lt;/strong&gt;。然而，这并不会影响 &lt;code&gt;publishOn&lt;/code&gt; 之后算子调用的行为，它们仍然会切换到 &lt;code&gt;publishOn&lt;/code&gt; 指定的执行上下文。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从订阅操作发生时整个算子链所在的线程切换到新的线程&lt;/li&gt;
&lt;li&gt;从指定 &lt;code&gt;Scheduler&lt;/code&gt; 中选择一个线程&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;只有链中最早的 &lt;code&gt;subscribeOn&lt;/code&gt; 调用会发生实际作用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Scheduler s = Schedulers.newParallel(&amp;amp;quot;parallel-scheduler&amp;amp;quot;, 4); // 1

final Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux
    .range(1, 2)
    .map(i -&amp;amp;gt; 10 + i) // 2
    .subscribeOn(s) // 3
    .map(i -&amp;amp;gt; &amp;amp;quot;value &amp;amp;quot; + i); // 4

new Thread(() -&amp;amp;gt; flux.subscribe(System.out::println)); // 5 &lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;创建一个新的 &lt;code&gt;Scheduler&lt;/code&gt;，内含 4 个线程&lt;/li&gt;
&lt;li&gt;第一个 &lt;code&gt;map&lt;/code&gt; 运行在这 4 个线程中的某个线程上&lt;/li&gt;
&lt;li&gt;...因为 &lt;code&gt;subscribeOn&lt;/code&gt; 将整个序列处理链从订阅操作发生时的执行上下文（第5步）切换到了新的上下文&lt;/li&gt;
&lt;li&gt;第二个 &lt;code&gt;map&lt;/code&gt; 和第一个 &lt;code&gt;map&lt;/code&gt; 运行在同一个线程上&lt;/li&gt;
&lt;li&gt;这个匿名线程是 &lt;em&gt;订阅操作&lt;/em&gt; 一开始发生的地方的，但是 &lt;code&gt;subscribeOn&lt;/code&gt; 即刻将上下文切换到调度器4个线程中的一个上&lt;/li&gt;&lt;/ol&gt;
&lt;h2&gt;4. 高级特性和概念&lt;/h2&gt;
&lt;h3&gt;4.1 使用 ConnectableFlux 将消息广播到多个订阅者&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;以后有空再翻译&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;4.2 3种分批处理方式&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;以后有空再翻译&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;4.3 使用 ParallelFlux 并行化处理&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如今多核架构已是下里巴人，相应地，轻松实现并行化工作的工具手段很关键。Reactor 提供了一个特殊类型 - &lt;code&gt;ParallelFlux&lt;/code&gt; - 帮助实现并行化处理。&lt;code&gt;ParallelFlux&lt;/code&gt; 提供的算子是为并行化工作优化过的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对任意 &lt;code&gt;Flux&lt;/code&gt; 实例调用 &lt;code&gt;parallel()&lt;/code&gt;算子就能得到一个 &lt;code&gt;ParallelFlux&lt;/code&gt; 实例。这个方法本身并不能实现并行化工作，而是将工作负载拆分到多个“轨道”（默认“轨道”数量等于 CPU 核数）&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了告知产出的 ParallelFlux 实例每个“轨道”在哪执行（以及如何并行执行“轨道”），则必须使用 &lt;code&gt;runOn(Scheduler)&lt;/code&gt;。注意：对于并行工作，推荐使用一个专用调度器 - &lt;code&gt;Schedulers.parallel()&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对比如下两个示例，第一个示例的代码如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .parallel(2) // 1
    .subscribe(i -&amp;amp;gt; System.out.println(Thread.currentThread().getName() + &amp;amp;quot; -&amp;amp;gt; &amp;amp;quot; + i));&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;这里强制指定了“轨道”数量，而不依赖于 CPU 核数。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第二个示例的代码如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .parallel(2)
    .runOn(Schedulers.parallel())
    .subscribe(i -&amp;amp;gt; System.out.println(Thread.currentThread().getName() + &amp;amp;quot; -&amp;amp;gt; &amp;amp;quot; + i));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第一个示例输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;main -&amp;amp;gt; 1
main -&amp;amp;gt; 2
main -&amp;amp;gt; 3
main -&amp;amp;gt; 4
main -&amp;amp;gt; 5
main -&amp;amp;gt; 6
main -&amp;amp;gt; 7
main -&amp;amp;gt; 8
main -&amp;amp;gt; 9
main -&amp;amp;gt; 10&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第二个示例正确地在两个线程上实现了并行化，输入如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;parallel-1 -&amp;amp;gt; 1
parallel-2 -&amp;amp;gt; 2
parallel-1 -&amp;amp;gt; 3
parallel-2 -&amp;amp;gt; 4
parallel-1 -&amp;amp;gt; 5
parallel-2 -&amp;amp;gt; 6
parallel-1 -&amp;amp;gt; 7
parallel-1 -&amp;amp;gt; 9
parallel-2 -&amp;amp;gt; 8
parallel-2 -&amp;amp;gt; 10&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果数据序列&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt;已经在并行化处理，而你又想将其转回一个 “常规的” &lt;code&gt;Flux&lt;/code&gt; 实例，然后串行执行算子链余下的部分，则可以使用 &lt;code&gt;ParallelFlux&lt;/code&gt; 的 &lt;code&gt;sequential()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：如果直接使用一个 &lt;code&gt;Subscriber&lt;/code&gt; 类型参数而不是 lambda 表达式来调用 &lt;code&gt;subscribe&lt;/code&gt; 方法，那么内部实现会隐式地调用 &lt;code&gt;sequential()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由此也要注意：&lt;code&gt;subscribe(Subscriber&amp;lt;T&amp;gt;)&lt;/code&gt; 会合并所有数据“轨道”，而 &lt;code&gt;subscribe(Consumer&amp;lt;T&amp;gt;)&lt;/code&gt; 是运行所有的数据“轨道”。如果以 lambda 表达式调用 &lt;code&gt;subscribe&lt;/code&gt; 方法，那么每个 lambda 表达式都会被复制成多个实例（数量等于“轨道”数量）去执行&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[3]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;&lt;ol&gt;&lt;li id=&quot;fn:1&quot;&gt;&lt;p&gt;译注：这里的“轨道”其实不太直白。在实现上，&lt;code&gt;ParallelFlux&lt;/code&gt; 会将最后 &lt;code&gt;subscribe&lt;/code&gt; 的 onNext 回调按并行度（默认等于 CPU 核数 N）复制成 N 个，那么最终调用 ParallelFlux 的 N 个 Subscriber，从 ParallelFlux 实例到一个 Subscriber 的数据流路径可以理解为一个“轨道”，ParallelFlux 在接收到上游消息后按照 round-robin 方式选择一个 Subscriber 调用其 &lt;code&gt;onNext&lt;/code&gt; 下发消息，但 &lt;code&gt;onNext&lt;/code&gt; 是运行在什么线程上，是由 runOn 算子决定的，如果不使用 runOn 算子，那么所有 Subscriber 的 &lt;code&gt;onNext&lt;/code&gt; 方法调用都是同步运行在主线程上的。&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:2&quot;&gt;&lt;p&gt;译注：原文中用了多个词来表达相近的意思：sequence（序列）、stream（流）、flow（流），阅读时可以相互替代理解。此外，还有 event（事件）、data（数据）、message（消息），在当前上下文中，可以看成是等价的。&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:3&quot;&gt;&lt;p&gt;译注：这话写得真蠢。详细解释见脚注 1。&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</description>
            <pubDate>2019-06-26</pubDate>
            <link>https://blog.xiayf.cn/posts/simplified-reactor-doc-zh.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/simplified-reactor-doc-zh.html</guid>
        </item>
        
        <item>
            <title>Java 单测伴侣 - mockito</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;其实工作以来，我很少写测试/单测代码，一方面是大部分互联网公司团队对测试的要求不高，另一方面是想写好测试代码还挺难的，挺花时间，其中最麻烦的是待测代码可能会访问外部资源（比如数据库、HTTP API），如果不能方便地进模拟访问这些外部资源，那么测试起来会非常麻烦。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但，对于复杂逻辑，如果不经过严格测试，发布到生产环境，又有些不放心，没底气，或者在代码重构时，如果没有覆盖全面的测试，很难评估代码变动带来的影响。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;直到遇到 &lt;a href=&apos;https://site.mockito.org/&apos;&gt;mockito&lt;/a&gt;，我才觉得是时候认真写写测试代码了。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;https://site.mockito.org/&apos;&gt;mockito&lt;/a&gt; 提供两种对象模拟方式：&lt;strong&gt;mock&lt;/strong&gt; 和 &lt;strong&gt;spy&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;简单来说，mock 模拟的对象是一个完全假的对象，只是具备指定类型的接口，以 &lt;code&gt;java.util.List&lt;/code&gt; 为例：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.mock;

List mockedList = mock(List.class);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽然 List 是一个 interface，也可以模拟出一个对象实例，这个 mockedList 对象具备 List 接口定义的所有方法，但所有方法都不具备实际的行为操作，对于有返回值的方法，则默认返回方法返回类型的默认值，没有返回值的方法，则纯粹是一个空方法。比如：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// mockedList 并不会真的把 1 存下来
mockedList.add(1);
// 所以，size() 返回默认值，输出 0
System.out.println(mockedList.size());
// 输出 null
System.out.println(mockedList.get(0));
// 输出 null
System.out.println(mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于模拟出来的对象，可以任意指定其方法的返回值，比如：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.when;

// 调用 size() 方法时，返回 10
when(mockedList.size()).willReturn(10);
when(mockedList.get(0)).willReturn(&amp;amp;quot;Hello World!&amp;amp;quot;);
when(mockedList.get(1)).thenReturn(&amp;amp;quot;您好！&amp;amp;quot;);

// 输出 10
System.out.println(mockedList.size());
// 输出 Hello World!
System.out.println(mockedList.get(0));
// 输出 您好！
System.out.println(mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当然我们写测试代码时，并不会使用 System.out.println，然后看输出，而是使用&lt;strong&gt;断言&lt;/strong&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.junit.Assert.assertEquals;

assertEquals(10, mockedList.size());
assertEquals(&amp;amp;quot;Hello World!&amp;amp;quot;, mockedList.get(0));
assertEquals(&amp;amp;quot;您好！&amp;amp;quot;, mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;断言方法非常多，不仅仅只是 assertEquals。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于同一个方法，可以模拟多次调用返回不同的值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 会覆盖之前 mock 的行为：when(mockedList.size()).willReturn(10);
// 或者这么写：when(mockedList.size()).willReturn(0, -1, 10);
when(mockedList.size()).thenReturn(0).thenReturn(-1).thenReturn(10);
assertEquals(0, mockedList.size());
assertEquals(-1, mockedList.size());
assertEquals(10, mockedList.size());
// 第 3 次之后的 mockedList.size() 调用都返回 10
assertEquals(10, mockedList.size());

Iterator iterator = mock(Iterator.class);
// 或者这么写：when(iterator.next()).thenReturn(0, 1, 10, 1000);
when(iterator.next()).thenReturn(0).thenReturn(1).thenReturn(10).thenReturn(1000);
assertEquals(0, iterator.next());
assertEquals(1, iterator.next());
assertEquals(10, iterator.next());
assertEquals(1000, iterator.next());
// 第 4 次之后的 iterator.next() 调用都返回 1000
assertEquals(1000, iterator.next());&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;还可以模拟异常抛出：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List mockedList = mock(List.class);

when(mockedList.get(-1000)).thenThrow(new RuntimeException(&amp;amp;quot;参数异常！&amp;amp;quot;));
try {
    mockedList.get(-1000);
} catch (Exception e) {
    assertTrue(e instanceof RuntimeException);
    assertEquals(&amp;amp;quot;参数异常！&amp;amp;quot;, e.getMessage());
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以基于复杂的逻辑来构造返回值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.invocation.InvocationOnMock;
import org.mockito.stubbing.Answer;

List&amp;amp;lt;Integer&amp;amp;gt; mockedList = mock(List.class);
when(mockedList.get(anyInt())).thenAnswer(new EchoAnswer());

assertTrue(1 == mockedList.get(1));
assertTrue(10 == mockedList.get(10));

public class EchoAnswer implements Answer&amp;amp;lt;Integer&amp;amp;gt; {

    public Integer answer(InvocationOnMock var) {
        return var.getArgument(0);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除了 &lt;code&gt;when(...).thenReturn(...)&lt;/code&gt; 风格的测试模拟方式，还有 BDD（Behavior Driven Development 行为驱动开发）风格的：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.BDDMockito.given;

// given
given(mockedList.get(0)).willReturn(100);
// when
int v = (int) mockedList.get(0);
// then
assertEquals(100, v);&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果方法没有返回值，或者其它奇葩的需求，则没法使用 when.thenReturn / willReturn 这样的模拟方法，可以使用 &lt;code&gt;doReturn(...).when(...)...&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.doThrow;
import static org.mockito.Mockito.doReturn;

ArrayList mockedList = mock(ArrayList.class);
// clear 方法无返回值
doThrow(new RuntimeException(&amp;amp;quot;清除失败&amp;amp;quot;)).when(mockedList).clear();

try {
    mockedList.clear();
} catch (Exception e) {
    assertTrue(e instanceof RuntimeException);
    assertEquals(&amp;amp;quot;清除失败&amp;amp;quot;, e.getMessage());
}

// 没有意义，因为没法使用 断言 来验证，实际运行时会抛异常
doReturn(10).when(mockedList).clear();&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从示例代码可以看出，&lt;code&gt;doReturn(...).when(...)....&lt;/code&gt; 不会做类型校验，mockedList.clear() 返回值类型为 void，但我们模拟让其返回 10；所以，正常情况应该尽可能使用 &lt;code&gt;when(...).thenReturn(...)&lt;/code&gt; 或 &lt;code&gt;given(...).willReturn(...)&lt;/code&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前述代码示例中，模拟方法的参数都做了硬编码，实际情况通常都不是这么测试，而是模拟方法的参数符合一定的要求即可，比如：在某个范围之内、符合类型的任何值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.anyInt;

/*
以任何 int 类型的参数调用 mockedList.get 方法，都返回 100

如果写成 when(mockedList.get(0)).thenReturn(100)，则只有以 0 为参数调用 mockedList.get 方法，才会返回100，其他参数值，返回的都是默认值 0
*/
when(mockedList.get(anyInt())).thenReturn(100);

assertEquals(100, mockedList.get(0));
assertEquals(100, mockedList.get(1000));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可用的参数匹配器，见 org.mockito.ArgumentMatchers 类的静态方法列表，也可以自己实现 ArgumentMatcher 接口：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;package org.mockito;

public interface ArgumentMatcher&amp;amp;lt;T&amp;amp;gt; {
    boolean matches(T var1);
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.ArgumentMatcher;
import static org.mockito.Mockito.intThat;

when(mockedList.get(intThat(new LimitedInt()))).thenReturn(10);

assertEquals(null, mockedList.get(-1));
assertEquals(10, mockedList.get(1));
assertEquals(10, mockedList.get(99));
assertEquals(null, mockedList.get(100));

public class LimitedInt implements ArgumentMatcher&amp;amp;lt;Integer&amp;amp;gt; {

    public boolean matches(Integer var) {
        return var &amp;amp;gt; 0 &amp;amp;amp;&amp;amp;amp; var &amp;amp;lt; 100;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果被模拟的方法包含多个参数，那么这些参数要么全部使用匹配器，要么全部不使用。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;模拟某些类（A）的方法，通常会将 mock 出来的对象注入到依赖该类实例的其他类（B）中，来替代真实的依赖，这种方式的目的是为了测试类 B 的行为是否符合预期。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另一个测试需求是，测试某个类 A&apos; 在某个上下文环境中的行为是否符合预期，比如： A&apos; 的某个方法是否被调用过、调用过几次、调用参数是否符合预期、几个方法之间的调用次序是否符合预期、方法调用耗时是否符合预期等等。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.times;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.verifyZeroInteractions;

List mocked = mock(List.class);

Caller caller = new Caller();
caller.setList(mocked);

// 调用 0 次
caller.run(0);
// 验证是否从来没调用过 mocked.size()
verify(mocked, never()).size();
// 验证 没有和 mocked 产生过任何交互
// 因为 Caller.run 中调用了 list.isEmpty()，实际产生了交互，所以这行测试会失败
verifyZeroInteractions(mocked);

// 调用 10 次
caller.run(10);
// 验证是否调用 mocked.size() 10 次
verify(mocked, times(10)).size();

// 再调用一次
caller.run(1);
// 所以是 11 次了
verify(mocked, times(11)).size();

@Data
public class Caller {
    List list;

    public void run(int count) {
        for (int idx=0; idx &amp;amp;lt; count; idx++) {
            list.size();
        }
        //
        list.isEmpty();
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List mocked = mock(List.class);

mocked.add(1);
mocked.add(2);

verify(mocked).add(1);

// 是否有其他交互没有验证过？因为 mocked 还调用过 mocked.add(2)，所以这句测试会失败
verifyNoMoreInteractions(mocked);&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.InOrder;

// 也可以验证调用次序
List mocked1 = mock(List.class);
List mocked2 = mock(List.class);

mocked1.size();
mocked1.isEmpty();
mocked2.isEmpty();

// 会记录 mocked1、mocked2 中方法的调用/交互次序，要求：与 mocked1 的交互先于 mocked2
InOrder inOrder = inOrder(mocked1, mocked2);
// mocked1、mocked2 的交互顺序必须和 inOrder.verify 之间的顺序一致
inOrder.verify(mocked1).size();
inOrder.verify(mocked1).isEmpty();
inOrder.verify(mocked2).isEmpty();&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以验证某个方法被调用时所使用的参数是否符合预期：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.ArgumentCaptor;

List mockedlist = mock(List.class);

Caller caller = new Caller();
caller.setList(mockedlist);
caller.run();

// 捕获 mockedList.add 的调用参数
ArgumentCaptor&amp;amp;lt;Integer&amp;amp;gt; argumentCaptor = ArgumentCaptor.forClass(Integer.class);
verify(mockedlist).add(argumentCaptor.capture());
assertTrue(100 == argumentCaptor.getValue());

@Data
public class Caller {
    List list;

    public void run() {
        list.add(100);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前面的内容都是以 mock 为例，我们再来说说 spy，与 mock 的区别：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;mock 出来的对象是一个完全假的对象，但 spy 通常是基于一个具体的类或类实例，对其篡改某些方法，对于被篡改方法之外的方法，其行为都和调用真实对象的方法一样，不过并没有调用真实对象的方法，也不会对真实对象产生影响：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 基于一个实际的类实例
List&amp;amp;lt;Integer&amp;amp;gt; realList = new ArrayList&amp;amp;lt;&amp;amp;gt;(10);
List&amp;amp;lt;Integer&amp;amp;gt; spy = spy(realList);
        
spy.add(1);

// 被窃听的对象并没有发生变化
assertEquals(0, realList.size());
// 间谍对象确实将 1 存了下来
assertEquals(1, spy.size());
// 这句会抛出 java.lang.IndexOutOfBoundsException，因为 realList 还是为空
assertTrue(1 == realList.get(0));
assertTrue(1 == spy.get(0));&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以基于一个具体的类来构造 spy，但这样无法使用带参数的构造方法，也无法指定类型参数：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List&amp;amp;lt;Integer&amp;amp;gt; = spy(ArrayList.class);
assertEquals(0, spy.size());
spy.add(100);
assertEquals(1, spy.size());
assertTrue(100 == spy.get(0));

// 篡改方法
when(spy.size()).thenReturn(-1);
assertEquals(-1, spy.size());&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实际上，mock 也可以基于具体的类来构造，这时可以指定某些方法实际调用具体类的方法。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;除了使用 mock、spy 方法来构造模拟对象，还可以通过注解来构造，但这样的话得指定 JUnit 的 Runner 为 &lt;code&gt;org.mockito.junit.MockitoJUnitRunner&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.Mock;
import org.mockito.Spy;
import org.mockito.junit.MockitoJUnitRunner;

import java.util.ArrayList;
import java.util.List;

import static org.mockito.Mockito.when;
import static org.junit.Assert.assertTrue;

@RunWith(MockitoJUnitRunner.class)
public class testTester {

    @Mock
    private List&amp;amp;lt;Integer&amp;amp;gt; mocked;

    @Spy
    private ArrayList&amp;amp;lt;Integer&amp;amp;gt; spyed;

    @Test
    public void test() {
        when(mocked.isEmpty()).thenReturn(false);
        when(spyed.isEmpty()).thenReturn(false);

        assertTrue(!mocked.isEmpty());
        assertTrue(!spyed.isEmpty());

        mocked.add(0);
        spyed.add(0);

        assertTrue(0 == mocked.size());
        assertTrue(1 == spyed.size());
    }
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2019-06-17</pubDate>
            <link>https://blog.xiayf.cn/posts/mockito.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/mockito.html</guid>
        </item>
        
        <item>
            <title>《Python 编程之美》译者序</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;从毕业至今，在互联网行业从事软件研发工作，将近五年。这五年间，做过后端开发、前端开发、大数据处理等，使用过的编程语言包括：Python、PHP、Go、Java、JavaScript 等。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽说编程语言各异，但我使用它们来写各种项目的代码却一直坚持两点：代码可读性和自解释性/自文档性（self-documentation）。这很大程度上应该是受到 Python 语言设计哲学的影响 - 追求简单易读易懂的代码。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很多人可能会认为这两点其实是一点 - 代码可读性，但我想做点区分：代码可读性突出对代码阅读者视觉上的影响，是否存在不必要的理解干扰，比如：必要的空行、变量定义与使用之间的距离、函数体/逻辑分支是否过长、逻辑表达是否直观等等。可读性高的代码通常都非常漂亮、赏心悦目。自解释性代码则更突出语义层面，比如：变量名称/函数名称/类名是否恰当、函数/方法/API 是否单一职责、工程目录结构/包/模块拆分是否符合“高内聚低耦合”原则等等。长期追求这两点，可以极大地提升个人，特别是团队的工作效率和工作质量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本书作者 Kenneth Reitz 于 2011 年发布 Requests 这个 HTTP 请求工具库，提出“for humans”的理念，强调软件/工具库应该对人类友好易用，这一理念本质上是对 Python 哲学（特别是上述两点）的一种引申和发扬。之后 Reitz 在一些 Python大会上做技术分享，宣扬“for humans”理念，对 Python 社区产生巨大影响。我在第一次用过 Requests 库之后，便很少使用 Python 标准库中的 urllib 和 urllib2，现在标准库文档中也特别建议开发者使用 Requests。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为对“for humans”理念的认同，也因为经常使用 Requests，所以当 Reitz 在 Github 上邀请我翻译 Requests 文档中文版时，我欣然接受，和另一个 Python 开发者共同翻译了 Requests 文档的首个官方中文翻译版。这“另一个 Python 开发者”也就是本书的另一个译者。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在 Reitz 发起 “The Hitchhiker&apos;s Guide to Python!” 项目（也就是本书的社区开源版）后，我一直持续跟进阅读，收获巨大。后来得知这本开源书籍正式出版，欣喜若狂，辗转咨询多人，联系到刘皎老师 ，申请了本书的翻译工作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是，后来发现翻译的工作量远远超出预估，除了个人的一些主观原因，主要因为本书内容的广度和深度：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;广度：本书由 Python 社区数百人共同创作而成，可以视作 Python 小百科全书。1-3章指导读者按照自己的需求选择安装配置 Python 版本/发行版、开发环境等。7-11章则针对不同的应用场景，从多个维度甄选对比了大量的 Python 库，读者可以“按图索骥”地做出自己的选择，从而节约大量的时间精力。因为译者的 Python 开发经验主要集中在 Web 开发和数据处理，对于很多应用场景下的 Python 库不太熟悉，所以翻译之前花费了大量时间来学习理解。&lt;/li&gt;
&lt;li&gt;深度：针对 Python 中手的核心需求，本书探讨了大量的最佳实践。其中4-5章通过大量示例具体地阐释了“Python 之禅”的句句箴言，如何编写高质量的 Python 代码，并精选若干高质量的知名 Python 开源项目，详细介绍如何通过阅读源码来提升编程技术水平。虽说 Python 社区几乎人人皆知“Python 之禅”，但如何落地到开发实践估计极少有人说得清楚。对照书中的实例阐释，译者几经调整推敲“Python 之禅”的译文，最终敲定的译文也不是特别令自己满意。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;相比原计划，本书最终延期近一年才得以翻译完成。除了歉意，我内心满是感谢：感谢邦杰中途友情加入，帮忙翻译了4-6章初稿，这三章的难度和长度都非常大；感谢编辑老师刘皎对我拖稿的次次容忍和耐心等待；感谢妻儿的理解，我对你们缺少了太多的陪伴。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽说我已尽自己所能地保证译文质量，但错误瑕疵难免，在此也请读者原谅。希望你们阅读愉快！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;至此，我如释重负。&lt;/p&gt;
&lt;p class=&quot;text-align-right&quot;&gt;&lt;em&gt;夏永锋&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-right&quot;&gt;&lt;em&gt;写于上海&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2018-04-01</pubDate>
            <link>https://blog.xiayf.cn/posts/the-python-guide.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-python-guide.html</guid>
        </item>
        
        <item>
            <title>《精通Python设计模式》译者序</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;在我读大学那几年，设计模式可谓火极一时，各大公司校招面试也几乎都会考设计模式，反观现在，则似乎很少有人聊设计模式的话题。是因为设计模式过时了吗？还是只是一个错误的概念？从个人这几年的开发经验来看，答案是否定的，设计模式并未过时，更不是一个错误的概念。从曾经的“红极一时”到如今的“门可罗雀”，只是说明软件开发行业以更加客观理性的态度来看待设计模式。软件开发领域的技术概念也似乎总是遵循这样的流行度变迁，最终一次又一次地证明不存在“银弹”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;正确看待设计模式的前提是明白什么是设计模式。正如本书一开始就强调的：“设计模式的本质是在已有的方案之上发现更好的方案（而不是全新发明）”，这是一种务实的态度，设计模式并非是一种高大上或者神秘的东西，而是一些常见的软件工程设计问题的最佳实践方案。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么应该如何学习设计模式？个人认为软件开发技术的学习都应该以实践为前提，只有理解实践过程中遇到的种种问题，才能明白那些技术的本质和目的是什么，每种新技术都是因某个/某些问题而出现的，软件开发高手一般都反对新手一开始就一股脑地学习设计模式。有些新手学了点设计模式的理论后，甚至在软件开发过程中生搬硬套，结果是适得其反。因此，软件开发人员应该在积累了一定的开发经验，再系统地学习设计模式，效果往往也能事半功倍。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在有些积累一定开发经验的软件开发人员，在谈起设计模式时，一脸鄙夷。我想这也不是一种客观务实的态度。软件开发不是简单的累积代码，在实现业务功能的同时应该仔细考虑如何控制软件的复杂度。软件的复杂度分为两个层面：业务逻辑复杂度和代码实现复杂度。对同一个业务系统，不同的软件开发人员会有不同的实现，复杂度也不同，相应地实现的易理解性、可维护性、可扩展性也不同。软件开发人员应该不断学习如何控制软件的复杂度，学习并恰当地使用设计模式是应对软件复杂度的有效方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然而，设计模式并非是固定不变的（如，《设计模式-可复用面向对象软件的基础》一书总结的23种模式），使用不同的编程语言来编写代码，需要学习的设计模式也不一样。一方面因为软件开发领域迅猛发展，一些新的软件工程问题也随之出现，另一方面则是新的语言新的平台会把一些常见设计模式吸收为内置特性。所以，软件开发人员因以实际问题为驱动，不断更新设计模式方面的知识。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本书以Python编程语言为例，针对目前的软件开发领域，分三大类讲解了16种常用设计模式。使用Python语言编写示例代码，我认为作者主要是考虑到Python的抽象层次高、应用范围广，读者不会被一些实现细节的干扰，从而能快速直接地掌握模式的要领。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;全书始终保持务实的态度，列举了大量现实生活的例子和软件开发的例子，并为每个模式提供完整可运行的示例代码。虽然看起来在书中完整地给出所有示例代码，似乎没什么必要，但个人认为作者的用意是希望读者能动手照示例代码写一遍并运行起来看结果，实践为王，加强学习的效果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽然是示例，作者还是坚持以地道的Python风格编写代码，以此说明不同语言不同平台要求软件开发人员学习的设计模式也有所不同。另外，开发人员也能从示例代码中学习到一些Python语言的高级特性，所以把本书当做Python开发进阶书籍也无不可。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本书是个人正式翻译的第一本书。虽然以前翻译过很多文章，有些译文还有点影响，但毕竟与正式出版的有些不同，所以接手本书的翻译工作，我内心是有些忐忑的。我把翻译过程分为以下几个阶段进行：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;大致地预读一遍全书，整体上把握原书内容&lt;/li&gt;
&lt;li&gt;将原书翻译成初稿，此阶段基本保证译文的正确性&lt;/li&gt;
&lt;li&gt;通读审校初稿，此阶段确保译文的流畅性，以及用词和逻辑的一致性&lt;/li&gt;
&lt;li&gt;对着译稿，翻译相关图表中的单词；整理示例代码，并确保运行无误&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;希望通过这种方式基本保证译稿的质量。但因为个人精力有限能力不足，译稿中可能还是有些疏漏甚至错误之处，敬请原谅，也请将问题反馈给出版社，以便在下一版本中更正。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，本书的示例代码已经存到Github的一个代码库（见&lt;a href=&apos;https://github.com/youngsterxyf/mpdp-code&apos;&gt;https://github.com/youngsterxyf/mpdp-code&lt;/a&gt;）中，如有需要，可下载。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因个人私事，本书推延了一段时间才得以翻译完成，感谢图灵朱巍老师的体谅。译书是件费时费力的事情，感谢妻子郑荣的体谅和支持，也感谢公司领导贾磊和同事的支持，谢谢！&lt;/p&gt;
&lt;p class=&quot;text-align-right&quot;&gt;&lt;em&gt;夏永锋&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-right&quot;&gt;&lt;em&gt;于上海百度研发中心&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2016-07-01</pubDate>
            <link>https://blog.xiayf.cn/posts/mpdp.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/mpdp.html</guid>
        </item>
        
        <item>
            <title>Base64 编码原理与应用</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;2015年，我们在青云平台上实现了“百度云观测”应用。青云应用本质上是一个iframe，在向iframe服务方发送的请求中会携带一些数据，青云平台会使用&lt;code&gt;Base64 URL&lt;/code&gt;对这些数据进行编码，其提供的编码解码算法示例如下：&lt;/p&gt;
&lt;pre class=&quot;language-php&quot;&gt;&lt;code&gt;// php版本
function base64_URL_encode($data) {
  return rtrim(strtr(base64_encode($data), &amp;amp;apos;+/&amp;amp;apos;, &amp;amp;apos;-_&amp;amp;apos;), &amp;amp;apos;=&amp;amp;apos;);
}
function base64_URL_decode($data) {
  return base64_decode(str_pad(strtr($data, &amp;amp;apos;-_&amp;amp;apos;, &amp;amp;apos;+/&amp;amp;apos;), 
                            strlen($data) % 4, &amp;amp;apos;=&amp;amp;apos;, STR_PAD_RIGHT));
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以看出，&lt;code&gt;Base64 URL&lt;/code&gt; 是标准Base64编码的一个变种，分别用 &lt;code&gt;-&lt;/code&gt;、&lt;code&gt;_&lt;/code&gt; 替换标准Base64编码结果中的 &lt;code&gt;+&lt;/code&gt; 、 &lt;code&gt;/&lt;/code&gt; ，并删除结果最后的 &lt;code&gt;=&lt;/code&gt; 。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在实现 “百度云观测” 青云应用时，我在想：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为什么要使用Base64编码？&lt;/li&gt;
&lt;li&gt;Base64编码算法是什么样的？&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文是围绕这两个问题思考和实践的结果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我认为，理解Base64或其他类似编码的关键有两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;计算机最终存储和执行的是01二进制序列，这个二进制序列的含义则由解码程序/解释程序决定&lt;/li&gt;
&lt;li&gt;很多场景下的数据传输要求数据只能由简单通用的字符组成，比如HTTP协议要求请求的首行和请求头都必须是ASCII编码&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以青云应用为例，简单解释这两点。青云平台通过POST一个表单来获取iframe，表单有 &lt;code&gt;payload&lt;/code&gt; 和 &lt;code&gt;signature&lt;/code&gt; 两项， &lt;code&gt;payload&lt;/code&gt; 原本是一个JSON对象，其中的键值可能包含一些特殊字符，比如 &lt;code&gt;&amp;amp;&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt; 等，由于青云设计的一种通用的请求交互方案，需要考虑iframe服务方服务器端的各种可能实现，有些服务器端实现没有考虑表单值有这些特殊字符，或者POST请求被中间服务器转换成GET请求再次发出，对于URL来说，&lt;code&gt;&amp;amp;&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt;都是具有特殊含义的字符，所以需要对请求数据进行特殊编码避免这些字符出现 - 数据发送方对数据按规则进行编码，接收方对应地按规则解码数据。&lt;/p&gt;
&lt;h2&gt;Base64编码原理&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Base64编码之所以称为Base64，是因为其使用64个字符来对任意数据进行编码，同理有Base32、Base16编码。标准Base64编码使用的64个字符为：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/XHFMRvxfez4OVtr.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这64个字符是各种字符编码（比如ASCII编码）所使用字符的子集，基本，并且可打印。唯一有点特殊的是最后两个字符，因对最后两个字符的选择不同，Base64编码又有很多变种，比如Base64 URL编码。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Base64编码本质上是一种将二进制数据转成文本数据的方案。对于非二进制数据，是先将其转换成二进制形式，然后每连续6比特（2的6次方=64）计算其十进制值，根据该值在上面的索引表中找到对应的字符，最终得到一个文本字符串。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;假设我们要对 &lt;code&gt;Hello!&lt;/code&gt; 进行Base64编码，按照ASCII表，其转换过程如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/tJnClQsjc4WMGhB.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可知 &lt;code&gt;Hello!&lt;/code&gt; 的Base64编码结果为 &lt;code&gt;SGVsbG8h&lt;/code&gt; ，原始字符串长度为6个字符，编码后长度为8个字符，每3个原始字符经Base64编码成4个字符，编码前后长度比4/3，这个长度比很重要 - 比原始字符串长度短，则需要使用更大的编码字符集，这并不我们想要的；长度比越大，则需要传输越多的字符，传输时间越长。Base64应用广泛的原因是在字符集大小与长度比之间取得一个较好的平衡，适用于各种场景。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;是不是觉得Base64编码原理很简单？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但这里需要注意一个点：Base64编码是每3个原始字符编码成4个字符，如果原始字符串长度不能被3整除，那怎么办？使用0值来补充原始字符串。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以 &lt;code&gt;Hello!!&lt;/code&gt; 为例，其转换过程为：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/5URB8nVis9ljwYe.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;注：图表中蓝色背景的二进制0值是额外补充的。&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Hello!!&lt;/code&gt; Base64编码的结果为 &lt;code&gt;SGVsbG8hIQAA&lt;/code&gt; 。最后2个零值只是为了Base64编码而补充的，在原始字符中并没有对应的字符，那么Base64编码结果中的最后两个字符 &lt;code&gt;AA&lt;/code&gt; 实际不带有效信息，所以需要特殊处理，以免解码错误。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;标准Base64编码通常用 &lt;code&gt;=&lt;/code&gt; 字符来替换最后的 &lt;code&gt;A&lt;/code&gt;，即编码结果为 &lt;code&gt;SGVsbG8hIQ==&lt;/code&gt;。因为 &lt;code&gt;=&lt;/code&gt; 字符并不在Base64编码索引表中，其意义在于结束符号，在Base64解码时遇到 &lt;code&gt;=&lt;/code&gt; 时即可知道一个Base64编码字符串结束。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果Base64编码字符串不会相互拼接再传输，那么最后的 &lt;code&gt;=&lt;/code&gt; 也可以省略，解码时如果发现Base64编码字符串长度不能被4整除，则先补充 &lt;code&gt;=&lt;/code&gt; 字符，再解码即可。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了理解Base64编码解码过程，个人实现了一个非常简陋的Base64编码解码程序，见：&lt;a href=&apos;https://github.com/youngsterxyf/xiaBase64&apos;&gt;youngsterxyf/xiaBase64&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由于Base64应用广泛，所以很多编程语言的标准库都内置Base64编码解码包，如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;PHP：&lt;a href=&apos;http://php.net/manual/en/function.base64-encode.php&apos;&gt;base64_encode&lt;/a&gt;、&lt;a href=&apos;http://php.net/manual/en/function.base64-decode.php&apos;&gt;base64_decode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Python：&lt;a href=&apos;https://docs.python.org/2/library/base64.html&apos;&gt;base64包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go：&lt;a href=&apos;https://golang.org/pkg/encoding/base64/&apos;&gt;encoding/base64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;Base64编码应用&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文开始提到的青云应用例子只是Base64编码的应用场景之一。由于Base64编码在字符集大小与编码后数据长度之间做了较好的平衡，以及Base64编码变种形式的多样，使得Base64编码的应用场景非常广泛。下面举2个常用常见的例子。&lt;/p&gt;
&lt;h3&gt;HTML内嵌Base64编码图片&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;前端在实现页面时，对于一些简单图片，通常会选择将图片内容直接内嵌在页面中，避免不必要的外部资源加载，增大页面加载时间，但是图片数据是二进制数据，该怎么嵌入呢？&lt;a href=&apos;http://caniuse.com/#search=Data%20URI&apos;&gt;绝大多数现代浏览器&lt;/a&gt;都支持一种名为 &lt;code&gt;Data URLs&lt;/code&gt; 的特性，允许使用Base64对图片或其他文件的二进制数据进行编码，将其作为文本字符串嵌入网页中。以百度搜索首页为例，其中语音搜索的图标是个背景图片，其内容以 &lt;code&gt;Data URLs&lt;/code&gt; 形式直接写在css中，这个css内容又直接嵌在HTML页面中，如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/oa6rsPSwgMzv87l.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Data URLs&lt;/code&gt; 格式为：&lt;code&gt;url(data:文件类型;编码方式,编码后的文件内容)&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当然，也可以直接基于image标签嵌入图片，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-html&quot;&gt;&lt;code&gt;&amp;amp;lt;img alt=&amp;amp;quot;Embedded Image&amp;amp;quot; src=&amp;amp;quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIA...&amp;amp;quot; /&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但请注意：如果图片较大，图片的色彩层次比较丰富，则不适合使用这种方式，因为其Base64编码后的字符串非常大，会明显增大HTML页面，影响加载速度。&lt;/p&gt;
&lt;h3&gt;MIME（多用途互联网邮件扩展）&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们的电子邮件系统，一般是使用SMTP（简单邮件传输协议）将邮件从客户端发往服务器端，邮件客户端使用POP3（邮局协议，第3版本）或IMAP（交互邮件访问协议）从服务器端获取邮件。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;SMTP协议一开始是基于纯ASCII文本的，对于二进制文件（比如邮件附件中的图像、声音等）的处理并不好，所以后来新增MIME标准来编码二进制文件，使其能够通过SMTP协议传输。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;举例来说，我给自己发封邮件，正文为空，带一个名为hello.txt的附件，内容为 &lt;code&gt;您好！世界！&lt;/code&gt;。导出邮件源码，其关键部分如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/c8wIeoij9HWt4Ph.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;MIME-Version: 1.0&lt;/code&gt;：表示当前使用MIME标准1.0版本。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Content-Type: text/plain; name=&amp;quot;hello.txt&amp;quot;&lt;/code&gt;：表示附件文件名为 &lt;code&gt;hello.txt&lt;/code&gt; ，格式为纯文本。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;Content-Transfer-Encoding: base64&lt;/code&gt;：表示附件文件内容使用base64编码后传输。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;5oKo5aW977yM5LiW55WM77yB&lt;/code&gt;：则是文件内容 &lt;code&gt;您好，世界！&lt;/code&gt; Base64编码后的结果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;不过，MIME使用的不是标准Base64编码。&lt;/p&gt;
&lt;h2&gt;切忌误用&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可能会有人在不理解Base64编码的情况下，将其误用于数据加密或数据校验。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Base64是一种数据编码方式，目的是让数据符合传输协议的要求。标准Base64编码解码无需额外信息即完全可逆，即使你自己自定义字符集设计一种类Base64的编码方式用于数据加密，在多数场景下也较容易破解。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于数据加密应该使用专门的&lt;strong&gt;目前还没有有效方式快速破解的&lt;/strong&gt;加密算法。比如：对称加密算法&lt;code&gt;AES-128-CBC&lt;/code&gt;，对称加密需要密钥，只要密钥没有泄露，通常难以破解；也可以使用非对称加密算法，如 &lt;code&gt;RSA&lt;/code&gt;，利用极大整数因数分解的计算量极大这一特点，使得使用公钥加密的数据，只有使用私钥才能快速解密。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于数据校验，也应该使用专门的消息认证码生成算法，如 &lt;code&gt;HMAC&lt;/code&gt; - 一种使用单向散列函数构造消息认证码的方法，其过程是不可逆的、唯一确定的，并且使用密钥来生成认证码，其目的是防止数据在传输过程中被篡改或伪造。将原始数据与认证码一起传输，数据接收端将原始数据使用相同密钥和相同算法再次生成认证码，与原有认证码进行比对，校验数据的合法性。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么针对各大网站被脱库的问题，请问应该怎么存储用户的登录密码？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;答案是：在注册时，根据用户设置的登录密码，生成其消息认证码，然后存储用户名和消息认证码，不存储原始密码。每次用户登录时，根据登录密码，生成消息认证码，与数据库中存储的消息认证码进行比对，以确认是否为有效用户，这样即使网站被脱库，用户的原始密码也不会泄露，不会为用户使用的其他网站带来账号风险。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当然，使用的消息认证码算法其哈希碰撞的概率应该极低才行，目前一般在HMAC算法中使用SHA256。对于这种方式需要注意一点：防止用户使用弱密码，否则也可能会被暴力破解。现在的网站一般要求用户密码6个字符以上，并且同时有数字和大小写字母，甚至要求有特殊字符。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，也可以使用加入随机salt的哈希算法来存储校验用户密码。这里暂不细述。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Base64兼顾字符集大小和编码后数据长度，并且可以灵活替换字符集的最后两个字符，以应对多样的需求，使其适用场景非常广泛。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当然，很多场景下有多种编码方式可选择，并非Base64编码不可，视需求，权衡利弊而定。&lt;/p&gt;</description>
            <pubDate>2016-01-24</pubDate>
            <link>https://blog.xiayf.cn/posts/base64-encoding.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/base64-encoding.html</guid>
        </item>
        
        <item>
            <title>基于 Github 的 pull request 流程做开源贡献</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;最近给 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;beego&lt;/a&gt; 提了几个 pull request （简称PR），都已被接受。在使用pull request的过程中，遇到了一点小问题，才知以前并非真的理解这个流程，故在此做点记录整理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我以 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;beego&lt;/a&gt; 为例，将pull request的整体使用流程绘图如下：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/yFkLXVAHKxmwjq9.jpg&apos; title=&apos;fork-pull-request&apos; alt=&apos;fork-pull-request&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;beego代码库有两个长期分支 &lt;code&gt;master&lt;/code&gt; 和 &lt;code&gt;develop&lt;/code&gt;，&lt;code&gt;master&lt;/code&gt;为稳定分支，&lt;code&gt;develop&lt;/code&gt;为开发分支，所有PR都要求提交到 &lt;code&gt;develop&lt;/code&gt; 分支。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;先将 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 代码库 fork 一份到自己的名下（如我的 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; clone 到本地机器上做开发。因为PR要提到 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 develop 分支，所以最好对应地在你fork的代码库的 develop 分支做开发。在本地开发测试完成后，将commit push到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;在 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 页面点击 “New pull request”，会跳转到 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 创建一个新的PR，在页面中需要选择&lt;code&gt;base fork&lt;/code&gt;的目标分支（这里为 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 develop 分支）和&lt;code&gt;head fork&lt;/code&gt;的目标分支（这里为 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 develop 分支）。PR提交后，等待 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 代码库的协作者来review我的PR。&lt;/li&gt;
&lt;li&gt;如果其他人也给 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 提了PR（或者直接在 develop 上做了变更），我会把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 develop 分支同步到最新状态，便于我进行新的开发，同步的流程为：
&lt;ol&gt;&lt;li&gt;在本地代码库添加一个新的remote，名为 &lt;code&gt;beego&lt;/code&gt; ： &lt;code&gt;git remote add beego https://github.com/astaxie/beego.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在 &lt;code&gt;develop&lt;/code&gt; 分支上执行 &lt;code&gt;git pull beego develop&lt;/code&gt;，这会获取 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; develop 分支最新的状态，并 merge 到本地代码库的 develop 分支&lt;/li&gt;
&lt;li&gt;将本地代码库的 develop 分支 push 到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; ：&lt;code&gt;git push origin develop&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;在发布新的版本时, &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 &lt;code&gt;develop&lt;/code&gt; 分支会先 merge 到其 master 分支，然后打上新的 tag 。这时我也会把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 master 分支同步到最新状态，流程与 develop 分支相同。&lt;/li&gt;&lt;/ol&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在第3步中，如果发现&lt;code&gt;base fork&lt;/code&gt;的目标分支和&lt;code&gt;head fork&lt;/code&gt;的目标分支之间有代码冲突，则需要先在本地代码库对应的分支上解决这个冲突，然后 push 到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; ，再提PR。&lt;/p&gt;</description>
            <pubDate>2016-01-18</pubDate>
            <link>https://blog.xiayf.cn/posts/github-fork-pull-request.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/github-fork-pull-request.html</guid>
        </item>
        
        <item>
            <title>又一次系统故障</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;上周五早上9点多，我还在上班的路上，接到技术 leader 的电话：线上突然出故障了；接着发来一张故障信息页面截图：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/L4fVgPGAb3Whznr.png&apos; title=&apos;system-fault-err-page&apos; alt=&apos;system-fault-err-page&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;截图包含的信息是：数据库中没找到数据表&lt;code&gt;Users&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但同事检查过数据库，Users 数据表是存在的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我快速地回忆了一下最近的代码发布和环境变更 - 前一天有个同事对线上机器做了点改动。因此，让同事赶紧检查一下之前的改动是否有问题，经检查确认改动没有问题，而且稍微思考一下就应该明白不是配置的问题，如果是配置的问题，那么问题应该早就出现了，而不是在早上9点多时候才发生。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我翻了翻手机中最近收到的几条告警短信，去除重复告警短信，只有两条告警：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;某台Web服务器上出现大量的500错误&lt;/li&gt;
&lt;li&gt;某台数据库服务器的磁盘使用率为98.99%&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由此可以推测两个故障原因：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;那台Web服务器上应用的数据库配置有问题 - 但检查之后确认没有问题&lt;/li&gt;
&lt;li&gt;由于那台数据库服务器磁盘满导致的问题，虽然一时还想不到其中的关联 - 同事在检查之后，确认那台机器的磁盘确实已满，但通过内网的数据库管理后台，可以正常访问数据库，所以认为应该不是磁盘满导致的问题&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如此，一时我也没想明白故障的原因。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接着，同事发来消息：只有登录用户才会遇到这个问题！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这时，基于之前的线索，基本能断定故障原因是 - 数据库服务器磁盘满。为什么呢？&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;数据库管理后台默认是&lt;strong&gt;只读&lt;/strong&gt;：读数据表列表、数据表结构、单个表的若干条数据&lt;/li&gt;
&lt;li&gt;我们应用在实现上有这样的逻辑：登录用户的每次访问需要登录权限的页面都会自动更新用户的最新的访问时间，即Users数据表的updated_time字段，也即会写Users数据表。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由于磁盘已满，所以写会失败，故障信息提示“数据库中找不到Users数据表”，估计和MySQL的写实现有关。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;之后清理了磁盘，故障立即恢复。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我一直认为：排除故障/解决问题时，我们就像侦探一样 - 收集信息、思考信息之间的关联、透过现象看本质。故障现象很多时候会导致迷惑，如何能破除迷惑？- 全面地掌握系统的信息并作出思考。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是，故障发生时，我们首先要考虑的是恢复故障，尽可能减小对SLA的影响。大多数时候，我们都暂时无法找到故障原因，而且“找到故障原因”并非是“故障恢复”的必要条件，所以故障发生时，不要只顾着查找原因，先看看如何恢复故障。比如：本文所述的这个故障，如果没有想明白原因，可以先把排查过程中发现的所有异常 - 磁盘满 - 都解决了。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;再来说说这个故障的原因 - 磁盘满。个人认为这个故障原因是比较低级的，可见我们监控运维的缺失。为什么磁盘使用率到了98.88%才告警？大量占用磁盘的日志文件是否可以定期自动清理？后来，我们&lt;strong&gt;将磁盘告警的阈值修改为85%，并且定期删除一段时间之前的日志文件&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;故障解决之后，我了解到数据库服务器上占用磁盘最多的竟然是&lt;strong&gt;数据库代理服务的日志&lt;/strong&gt;。数据库代理服务会将每个网络请求的信息记录在日志中，在网络请求量大时，日志会快速增长 &lt;em&gt;（这样的日志信息除了在故障发生时帮助排查故障，没有其他用处，完全可以定期清除）&lt;/em&gt; 。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么数据库服务、数据库代理服务是如何部署的呢？前一篇文章给出了一张系统架构图，其中数据库代理服务和数据库服务我们运维的同学实际上是这样部署的：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/H1MhZn6Nj52moiR.png&apos; title=&apos;db-proxy-deployment&apos; alt=&apos;db-proxy-deployment&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样的部署徒增别人的迷惑，增大故障排除的难度，而且主MySQL与数据库代理服务之间会存在资源竞争，特别是在数据量访问量大的时候。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;导致这种低级故障和部署混乱的原因又是什么呢？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在我们团队中，运维同事是与另一个业务部门共享的，由于另一个业务部门做的是公司的重点业务，运维同事的KPI是根据它们业务来定，也就是说运维同事在我们这完全是友情支持，又能花多少时间来帮我们做运维呢？&lt;/p&gt;</description>
            <pubDate>2015-11-16</pubDate>
            <link>https://blog.xiayf.cn/posts/another-system-fault.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/another-system-fault.html</guid>
        </item>
        
        <item>
            <title>记一次系统故障</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;前段时间，工作中遭遇一次故障，虽然不算什么“疑难杂症”，倒也花了不少时间才真正找到故障的原因，故也值得记录一下。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为方便读者快速理解故障，先给出系统大致的架构图：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/2ZBQgfPqMUnhVzY.png&apos; title=&apos;gxt-tech-arch&apos; alt=&apos;gxt-tech-arch&apos; width=&apos;800&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其中，&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;每台Web服务器上开启12个PHP-FPM实例，并配置到Nginx的upstream，每个实例最多可以开启10个子进程&lt;/li&gt;
&lt;li&gt;“Database Proxy”的代理规则为：写操作及事务中的所有SQL操作都交给主MySQL处理，其余的读操作都交给任意一台从MySQL处理&lt;/li&gt;&lt;/ol&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;故障所表现的现象包括：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;大量请求响应为502，但每次故障发生时，错误响应一般集中在一台Web服务器，如下图所示：&lt;/li&gt;&lt;/ol&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/cPmFMn8gKZdzVoB.png&apos; title=&apos;nginx-502-error&apos; alt=&apos;nginx-502-error&apos; width=&apos;400&apos;/&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/CSRj4ILYVlU21Es.jpg&apos; title=&apos;nginx-server-502-count&apos; alt=&apos;nginx-server-502-count&apos; width=&apos;600&apos;/&gt;
&lt;ol&gt;&lt;li&gt;（一台或多台）MySQL数据库服务器CPU使用率飙升（但并非总是一起表现故障），如下图所示：&lt;/li&gt;&lt;/ol&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/H5gqL8BeQpKXOla.png&apos; title=&apos;mysql-slave-server-idle&apos; alt=&apos;mysql-slave-server-idle&apos; width=&apos;600&apos;/&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;故障刚开始出现时，重启/关闭出现故障现象的MySQL服务，或将出现故障的Web服务器上所有PHP-FPM重启，也能解一时的问题，但治不了本，故障还是频繁出现。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在故障发生时，从相关服务器上收集到的信息如下所示：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;出现故障现象的Web服务器 - CPU使用率、内存使用率等系统指标均正常，但PHP-FPM子进程数达到上限（12 x 10 = 120），并且PHP-FPM进程与数据库代理服务器之间的网络连接数量较多（与PHP-FPM子进程数大致相当）&lt;/li&gt;&lt;/ol&gt;
&lt;ol&gt;&lt;li&gt;出现故障现象的MySQL服务器 - CPU使用率飙升，主要为MySQL进程占用；MySQL进程与数据库代理服务器之间的网络连接较多&lt;/li&gt;&lt;/ol&gt;
&lt;ol&gt;&lt;li&gt;继而，对出现故障现象的MySQL服务器上的数据库执行命令&lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;（查看当前MySQL实例运行着哪些线程），结果如下所示（截图只是一部分结果）：&lt;/li&gt;&lt;/ol&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/jLbvVOZEKlCdkgI.png&apos; title=&apos;mysql-show-processlist&apos; alt=&apos;mysql-show-processlist&apos; width=&apos;800&apos;/&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;先来分析一下&lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;的执行结果：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Command&lt;/strong&gt;字段，表示当前线程正在执行的任务类型&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;db&lt;/strong&gt;字段，表示当前线程所执行任务涉及的数据库是哪个&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;State&lt;/strong&gt;字段，表示当前线程所处的状态&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Time&lt;/strong&gt;字段，表示当前线程处于State字段持续的时间，单位为秒&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;字段，表示如果当前线程是在执行查询操作（Query），那么查询的语句是什么样的，如非查询操作，则该字段为NULL&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;结果中，有两种任务线程：“Binlog Dump”和“Query”，其中“Query”数量占绝大多数（和MySQL进程与数据库代理服务器之间的网络连接数大致相当）：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1、Binlog Dump：该任务线程表明当前MySQL实例为主 MySQL，并且其状态表明主从同步已顺利完成。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2、Query：表明当前线程正在执行一次 SQL 查询操作。该 SQL 为:&lt;/p&gt;
&lt;pre class=&quot;language-sql&quot;&gt;&lt;code&gt;SELECT h.host, p.result, p.update_time FROM PIXIU p join Host h using(host_id) WHERE ...&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;线程所处状态为“Sorting result”（正在创建排序索引），持续时间为86-99秒左右。很明显，这句SQL语句花费的时间过长，存在问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;综合上面所述，可以引出一个猜测：由于这条SQL查询需耗费较长时间，并且被频繁执行，涉及该SQL的请求需要较长时间完成，大量SQL线程排队无响应，阻塞了大量PHP-FPM进程，在某些时候会达到PHP-FPM并发子进程数上限（更何况某个会被频繁访问的页面请求涉及该SQL，导致情况更糟），PHP-FPM无法处理新的请求，对于已有的请求也会因为超时导致Nginx响应502。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么针对该猜测，可以做两个优化来解决故障：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;优化这条 SQL&lt;/li&gt;
&lt;li&gt;使用缓存&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这条SQL的完整语句为：&lt;/p&gt;
&lt;pre class=&quot;language-sql&quot;&gt;&lt;code&gt;SELECT h.host,p.result,p.update_time FROM Pixiu p 
    JOIN Host h USING(host_id) 
    WHERE result!=&amp;amp;apos;[]&amp;amp;apos;
    ORDER BY update_time DESC&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;字段 p.result 的类型为 &lt;code&gt;mediumtext NOT NULL&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;字段 p.update_time 的类型为：&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-sql&quot;&gt;&lt;code&gt;timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;由于业务逻辑并不要求该SQL的结果是排序的，所以我们将该SQL中的排序条件&lt;code&gt;order by update_time desc&lt;/code&gt;删除，经测试发现查询时间大幅度降低到9ms左右（原来的平均查询时间为600多-700ms左右），另外，由于业务逻辑对于该条SQL涉及的数据的实时性要求不高，我们使用Memcached缓存了该SQL的查询结果。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;重新部署，压测，并线上运行观察，之后故障再未发生。事后回想，故障也确实是在涉及该SQL的功能模块上线之后才发生的。&lt;/p&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://dev.mysql.com/doc/refman/5.6/en/show-processlist.html&apos;&gt;MySQL官方文档 - SHOW PROCESSLIST Syntax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://dev.mysql.com/doc/refman/5.6/en/thread-commands.html&apos;&gt;MySQL官方文档 - Thread Command Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://dev.mysql.com/doc/refman/5.6/en/master-thread-states.html&apos;&gt;MySQL官方文档 - Replication Master Thread States&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://dev.mysql.com/doc/refman/5.6/en/general-thread-states.html&apos;&gt;MySQL官方文档 - General Thread States&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://www.nginx.cn/102.html&apos;&gt;nginx+php-fpm出现502 bad gateway错误解决方法&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2015-10-02</pubDate>
            <link>https://blog.xiayf.cn/posts/note-of-a-system-fault.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/note-of-a-system-fault.html</guid>
        </item>
        
        <item>
            <title>译文：一行式并行方案</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://chriskiehl.com/article/parallelism-in-one-line&apos;&gt;Parallelism in one line&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在并行处理能力方面，Python的声名并不太好。不考虑关于线程和GIL（多数情况下是合理的）的标准论据，我认为Python中关于并行的真正问题并不是一个技术问题，而是教学问题。围绕Python线程和多进程的常见教程，一般都写得不错，但也令人乏味 - 激烈非凡，对日常真正有用的东西却很少涉及。&lt;/p&gt;
&lt;h3&gt;沿袭的例子&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在DuckDuckGo（DDG）中搜索“Python多线程教程”，简单调查一下排在前面的结果，就会发现它们给出的都是同样基于Class + Queue的示例。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;介绍threading/multiprocessing、生产者/消费者的真实示例代码：&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# coding: utf-8
# Example.py
&amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
标准的多线程生产者/消费者模式
&amp;amp;apos;&amp;amp;apos;&amp;amp;apos;

import time 
import threading 
import Queue 

class Consumer(threading.Thread): 
  def __init__(self, queue): 
    threading.Thread.__init__(self)
    self._queue = queue 

  def run(self):
    while True: 
      # queue.get() 会阻塞当前线程，直到获取到一个数据项
      msg = self._queue.get() 
      # 检查当前消息是否是个“毒药丸”
      if isinstance(msg, str) and msg == &amp;amp;apos;quit&amp;amp;apos;:
        # 如果是，则退出循环
        break
      # “处理” (这里是打印)从队列中取出的数据项
      print &amp;amp;quot;I&amp;amp;apos;m a thread, and I received %s!!&amp;amp;quot; % msg
    # 我始终是这么的友好
    print &amp;amp;apos;Bye byes!&amp;amp;apos;


def Producer():
  # Queue用于在线程之间共享数据项
  queue = Queue.Queue()

  # 创建一个工作实例
  worker = Consumer(queue)
  # start方法会调用内部的run()方法来开启线程
  worker.start() 

  # 变量，用于追踪开始的时间
  start_time = time.time() 
  # 在5秒之内
  while time.time() - start_time &amp;amp;lt; 5: 
    # “生产”一块工作，放入队列中，由消费者来处理
    queue.put(&amp;amp;apos;something at %s&amp;amp;apos; % time.time())
    # 睡眠一会儿，以避免过多的消息
    time.sleep(1)

  # 这是杀死线程的“毒药丸”方式
  queue.put(&amp;amp;apos;quit&amp;amp;apos;)
  # 等待线程关闭
  worker.join()


if __name__ == &amp;amp;apos;__main__&amp;amp;apos;:
  Producer()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;嗯...闻闻，代码中一股子Java的气息。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我不想让大家觉得好像我认为生产者/消费者是处理线程/多进程的错误方式 - 因为确实不是。实际上，对多种问题来说，这种方式非常适合。然而，我认为：对于日常的脚本程序来说，这种方式并非是最有用的。&lt;/p&gt;
&lt;h3&gt;问题（我认为的）&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;其一，为了做点有用的事情，你得搞一个公式化的类；其二，你得维护一个队列（Queue），用于传送对象；这些齐备之后，在队列管道的两端还得准备方法来做真正的工作（如果希望有两种方式来通信或者准备存储结果，可能还得引入另一个队列）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;更多的工作者，更多的问题&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;基于此，下一件你想要做的事情就是搞一个工作者类的池，来加速你的Python程序。在关于线程的IBM教程中，给出了一个示例代码，以下是其变种。这是一个常见的应用场景 - 在多个线程上分配获取网页的任务。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# coding: utf-8
# Example2.py
&amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
一个更加实际的线程池示例
&amp;amp;apos;&amp;amp;apos;&amp;amp;apos;

import time 
import threading 
import Queue 
import urllib2 

class Consumer(threading.Thread): 
  def __init__(self, queue): 
    threading.Thread.__init__(self)
    self._queue = queue 

  def run(self):
    while True: 
      content = self._queue.get() 
      if isinstance(content, str) and content == &amp;amp;apos;quit&amp;amp;apos;:
        break
      response = urllib2.urlopen(content)
    print &amp;amp;apos;Bye byes!&amp;amp;apos;


def Producer():
  urls = [
    &amp;amp;apos;http://www.python.org&amp;amp;apos;, &amp;amp;apos;http://www.yahoo.com&amp;amp;apos;
    &amp;amp;apos;http://www.scala.org&amp;amp;apos;, &amp;amp;apos;http://www.google.com&amp;amp;apos;
    # 等等... 
  ]
  queue = Queue.Queue()
  worker_threads = build_worker_pool(queue, 4)
  start_time = time.time()

  # 加入待处理的URL
  for url in urls: 
    queue.put(url)
  # 加入毒药丸
  for worker in worker_threads:
    queue.put(&amp;amp;apos;quit&amp;amp;apos;)
  for worker in worker_threads:
    worker.join()

  print &amp;amp;apos;Done! Time taken: {}&amp;amp;apos;.format(time.time() - start_time)

def build_worker_pool(queue, size):
  workers = []
  for _ in range(size):
    worker = Consumer(queue)
    worker.start() 
    workers.append(worker)
  return workers

if __name__ == &amp;amp;apos;__main__&amp;amp;apos;:
  Producer()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;奏效了，但是你看看这些代码！准备（setup）方法、一组要追踪的线程，最糟糕的是，若有任何地方易发生死锁，就会产生一堆的join状态说明。自此，一切只会更复杂！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;到目前为止，完成了些什么？啥都没有。上面的代码纯粹只是把所有东西像用纸糊起来一样（Just about everything in the above code is pure plumbing，如何翻译？）。这是另一种公式化的写法，也易发生错误（嘿，在写这个代码时，我甚至忘了在队列对象上调用task_done()（我懒得去解决这个问题然后再搞个截图）），付出很多，得到的却很少。幸运的是，我们有更好的方式。&lt;/p&gt;
&lt;h2&gt;引入：Map&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Map是一个酷酷的小东西，也是在Python代码轻松引入并行的关键。对此不熟悉的人会认为map是从函数式语言（如Lisp）借鉴来的东西。map是一个函数 - 将另一个函数映射到一个序列上。例如：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;urls = [&amp;amp;apos;http://www.yahoo.com&amp;amp;apos;, &amp;amp;apos;http://www.reddit.com&amp;amp;apos;]
results = map(urllib2.urlopen, urls)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这段代码在传入序列的每个元素上应用方法&lt;em&gt;urlopen&lt;/em&gt;，并将所有结果存入一个列表中。大致与下面这段代码的逻辑相当：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;results = []
for url in urls: 
    results.append(urllib2.urlopen(url))&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Map会为我们处理在序列上的迭代，应用函数，最后将结果存入一个方便使用的列表。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这为什么重要呢？因为利用恰当的库，map让并行处理成为小事一桩！&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/kqumnip3B7M2dcQ.png&apos; title=&apos;map-function&apos; alt=&apos;map-function&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python标准库中&lt;em&gt;multiprocessing&lt;/em&gt;模块，以及极少人知但同样出色的子模块&lt;em&gt;multiprocessing.dummy&lt;/em&gt;，提供了map函数的并行版本。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;题外话：这是啥？你从未听说过这名为dummy的mulprocessing模块的线程克隆版本？我也是最近才知道的。在multiprocessing文档页中仅有一句提到这个子模块，而这句话基本可以归结为“哦，是的，存在这样一个东西”。完全低估了这个模块的价值！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Dummy是multiprocessing模块的精确克隆，唯一的区别是：multiprocessing基于进程工作，而dummy模块使用线程（也就带来了常见的Python限制）。因此，任何东西可套用到一个模块，也就可以套用到另一个模块。在两个模块之间来回切换也就相当容易，当你不太确定一些框架调用是IO密集型还是CPU密集型时，想做探索性质的编程，这一点会让你觉得非常赞！&lt;/p&gt;
&lt;h3&gt;开始&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了访问map函数的并行版本，首先需要导入包含它的模块：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 以下两行引入其一即可
from multiprocessing import Pool
from multiprocessing.dummy import Pool as ThreadPool&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并实例化池对象：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 译注：这里其实是以dummy模块为例
pool = ThreadPool()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一句代码处理了example2.py中7行的&lt;em&gt;build_worker_pool&lt;/em&gt;函数完成的所有事情。如名所示，这句代码会创建一组可用的工作者，启动它们来准备工作，并将它们存入变量中，方便访问。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;pool对象可以有若干参数，但目前，只需关注第一个：进程/线程数量。这个参数用于设置池中的工作者数目。如果留空，默认为机器的CPU核数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一般来说，如果为CPU密集型任务使用进程池（multiprocessing pool），更多的核等于更快的速度（但有一些注意事项）。然而，当使用线程池（threading）处理网络密集型任务时，情况就很不一样了，因此最好试验一下池的最佳大小。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;pool = ThreadPool(4) # 将池的大小设置为4&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果运行了过多的线程，就会浪费时间在线程切换上，而不是做有用的事情，所以可以把玩把玩直到找到最适合任务的线程数量。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在池对象创建好了，简单的并行也是弹指之间的事情了，那来重写example2.py吧。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;import urllib2 
from multiprocessing.dummy import Pool as ThreadPool 

urls = [
  &amp;amp;apos;http://www.python.org&amp;amp;apos;, 
  &amp;amp;apos;http://www.python.org/about/&amp;amp;apos;,
  &amp;amp;apos;http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/doc/&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/download/&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/getit/&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/community/&amp;amp;apos;,
  &amp;amp;apos;https://wiki.python.org/moin/&amp;amp;apos;,
  &amp;amp;apos;http://planet.python.org/&amp;amp;apos;,
  &amp;amp;apos;https://wiki.python.org/moin/LocalUserGroups&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/psf/&amp;amp;apos;,
  &amp;amp;apos;http://docs.python.org/devguide/&amp;amp;apos;,
  &amp;amp;apos;http://www.python.org/community/awards/&amp;amp;apos;
  # 等等...
  ]

# 创建一个工作者线程池
pool = ThreadPool(4) 
# 在各个线程中打开url，并返回结果
results = pool.map(urllib2.urlopen, urls)
#close the pool and wait for the work to finish
# 关闭线程池，等待工作结束
pool.close() 
pool.join()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;看看！真正做事情的代码仅有4行，其中3行只是简单的辅助功能。&lt;em&gt;map&lt;/em&gt;调用轻松搞定了之前示例40行代码做的事情！觉得好玩，我对两种方式进行了时间测量，并使用了不同的池大小。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 译注：我觉得与串行处理方式对比意义不大，应该和队列的方式进行性能对比
results = [] 
for url in urls:
  result = urllib2.urlopen(url)
  results.append(result)

# # ------- 对比 ------- # 


# # ------- 池的大小为4 ------- # 
pool = ThreadPool(4) 
results = pool.map(urllib2.urlopen, urls)

# # ------- 池的大小为8 ------- # 

pool = ThreadPool(8) 
results = pool.map(urllib2.urlopen, urls)

# # ------- 池的大小为13 ------- # 

pool = ThreadPool(13) 
results = pool.map(urllib2.urlopen, urls)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;结果：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;单线程: 14.4 秒
池大小为4时：3.1 秒
池大小为8时：1.4 秒
池大小为13时：1.3秒&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;真是呱呱叫啊！也说明了试验不同的池大小是有必要的。在我的机器上，池的大小大于9后会导致性能退化（译注：咦，结果不是显示13比8的性能要好么？）。&lt;/p&gt;
&lt;h2&gt;现实中的Example 2&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为千张图片创建缩略图。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;来做点CPU密集型的事情！对于我，在工作中常见的任务是操作大量的图片目录。其中一种图片转换是创建缩略图。这项工作适于并行处理。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;基本的单进程设置&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from multiprocessing import Pool 
from PIL import Image

SIZE = (75,75)
SAVE_DIRECTORY = &amp;amp;apos;thumbs&amp;amp;apos;

def get_image_paths(folder):
  return (os.path.join(folder, f) 
      for f in os.listdir(folder) 
      if &amp;amp;apos;jpeg&amp;amp;apos; in f)

def create_thumbnail(filename): 
  im = Image.open(filename)
  im.thumbnail(SIZE, Image.ANTIALIAS)
  base, fname = os.path.split(filename) 
  save_path = os.path.join(base, SAVE_DIRECTORY, fname)
  im.save(save_path)

if __name__ == &amp;amp;apos;__main__&amp;amp;apos;:
  folder = os.path.abspath(
    &amp;amp;apos;11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840&amp;amp;apos;)
  os.mkdir(os.path.join(folder, SAVE_DIRECTORY))

  images = get_image_paths(folder)

  for image in images: 
    create_thumbnail(image)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;示例代码中用了一些技巧，但大体上是：向程序传入一个目录，从目录中获取所有图片，然后创建缩略图，并将缩略图存放到各自的目录中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在我的机器上，这个程序处理大约6000张图片，花费27.9秒。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果使用一个并行的map调用来替换&lt;em&gt;for&lt;/em&gt;循环：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from multiprocessing import Pool 
from PIL import Image

SIZE = (75,75)
SAVE_DIRECTORY = &amp;amp;apos;thumbs&amp;amp;apos;

def get_image_paths(folder):
  return (os.path.join(folder, f) 
      for f in os.listdir(folder) 
      if &amp;amp;apos;jpeg&amp;amp;apos; in f)

def create_thumbnail(filename): 
  im = Image.open(filename)
  im.thumbnail(SIZE, Image.ANTIALIAS)
  base, fname = os.path.split(filename) 
  save_path = os.path.join(base, SAVE_DIRECTORY, fname)
  im.save(save_path)

if __name__ == &amp;amp;apos;__main__&amp;amp;apos;:
  folder = os.path.abspath(
    &amp;amp;apos;11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840&amp;amp;apos;)
  os.mkdir(os.path.join(folder, SAVE_DIRECTORY))

  images = get_image_paths(folder)

  pool = Pool()
  pool.map(create_thumbnail, images)
  pool.close() 
  pool.join()&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;5.6秒！&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;仅修改几行代码就能得到巨大的速度提升。这个程序的生产环境版本通过切分CPU密集型工作和IO密集型工作并分配到各自的进程和线程（通常是死锁代码的一个因素），获得更快的速度。然而，由于map性质清晰明确，无需手动管理线程，以干净、可靠、易于调试的方式混合匹配两者（译注：这里的“两者”是指什么？CPU密集型工作和IO密集型工作？），也是相当容易的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;就是这样了。（几乎）一行式并行解决方案。&lt;/p&gt;</description>
            <pubDate>2015-09-11</pubDate>
            <link>https://blog.xiayf.cn/posts/parallelism-in-one-line.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/parallelism-in-one-line.html</guid>
        </item>
        
        <item>
            <title>编程名言集锦（译）</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://quotes.cat-v.org/programming/&apos;&gt;Programming Quotes&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;译者：&lt;a href=&apos;https://github.com/youngsterxyf&apos;&gt;youngsterxyf&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;C.A.R. Hoare, The 1980 ACM Turing Award Lecture&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;There are two ways of constructing a software design: One way is to make it so simple that there are obviously no deficiencies and the other way is to make it so complicated that there are no obvious deficiencies.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有两种软件设计的方式：一种是使它足够简单以致于明显没有缺陷，另一种则是使它足够复杂以致于没有明显的缺陷。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;E.W.Dijkstra&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The computing scientist&apos;s main challenge is not to get confused by the complexities of his own making.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;计算科学家的主要挑战是不要被他自己造成的复杂性搞糊涂了。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Gordon Bell&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The cheapest, fastest, and most reliable components are those that aren&apos;t there.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最廉价，最快速，并且最可靠的部件是那些还没被使用的。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://genius.cat-v.org/ken-thompson/&apos;&gt;Ken Thompson&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;One of my most productive days was throwing away 1000 lines of code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我最多产的一天抛弃了1000行代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://genius.cat-v.org/ken-thompson/&apos;&gt;Ken Thompson&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;When in doubt, use brute force.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;若无把握，暴力破解。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Jeff Sickel&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Deleted code is debugged code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;需要调试的代码都应该删除。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan, P. J. Plauger&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;调试的难度两倍于一开始的写代码。因此，如果你尽可能巧妙地编写代码，根据定义，说明你还不具备足够的智商来调试它。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The most effective debugging tool is still careful thought, coupled with judiciously placed print statements.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最有效的调试工具是静下心来仔细思考，辅之审慎地放置打印语句。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Controlling complexity is the essence of computer programming.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;计算机编程的本质是控制复杂度。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;David Gelernter&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Beauty is more important in computing than anywhere else in technology because software is so complicated. Beauty is the ultimate defence against complexity.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;相比其他技术领域，美对于计算来说更为重要，因为软件超乎寻常的复杂，而美是对复杂性的一种终极防御。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Doug Gwyn&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;UNIX was not designed to stop its users from doing stupid things, as that would also stop them from doing clever things.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;UNIX并不会阻止用户干蠢事，因为那样也会阻碍用户做些聪明的事情。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Carmack&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;If you&apos;re willing to restrict the flexibility of your approach, you can almost always do something better.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;限制方法的灵活性几乎总会让你把事情做得更好。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Osterhout&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;A program that produces incorrect result twice as fast is infinitely slower.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;结果不对，程序再快都顶个屁用。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Geer et al.&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The central enemy of reliability is complexity.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可靠的最大敌人是复杂。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Edsger W. Dijkstra&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Simplicity is prerequisite for reliability.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;简单是可靠的先决条件。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Peter Deutsch&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The Eight Fallacies of Distributed Computing&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Essentially everyone, when they first build a distributed application, makes the following eight assumptions. All prove to be false in the long run and all cause big trouble and painful learning experiences.&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1. The network is reliable&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2. Latency is zero&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;3. Bandwidth is infinite&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;4. The network is secure&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;5. Topology doesn&apos;t change&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;6. There is one administrator&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;7. Transport cost is zero&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;8. The network is homogeneous&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;分布式计算的八大谬误&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实际上，每个人，当他第一次构建分布式应用时，都会作出如下八个假设。长远来看，这些假设都被证明是错误的，并且都造成了巨大的麻烦和沉痛的经验教训。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;网络可靠&lt;/li&gt;
&lt;li&gt;零延迟&lt;/li&gt;
&lt;li&gt;带宽无限&lt;/li&gt;
&lt;li&gt;安全网络&lt;/li&gt;
&lt;li&gt;拓扑不变&lt;/li&gt;
&lt;li&gt;有个管理者&lt;/li&gt;
&lt;li&gt;传输代价为零&lt;/li&gt;
&lt;li&gt;网络同构&lt;/li&gt;&lt;/ol&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Jon Bentley, Doug Mcllroy&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The key to performance is elegance, not battalions of special cases.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;性能的关键是优雅，而不是大堆的特殊情况。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Bill Gates&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Measuring programming progress by lines of code is like measuring aircraft building progress by weight.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以代码行数来衡量程序设计的进度，就好比以重量来衡量飞机的制造进度。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Johnson&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;First, solve the problem. Then, write the code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;首先，解决问题。而后，编写代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Ken Thompson&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;You can&apos;t trust code that you did not totally create yourself.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你不能信任非你完全自己写的代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Sean Parent&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Good code is short, simple, and symmetrical - the challenge is figuring out how to get there.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;好的代码，短小、简洁，并且匀称 - 而真正的挑战在于弄清如何达到这些目标。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Voltaire&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The best is the enemy of the good.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;追求完美是优秀软件的敌人。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Dr. Pamela Zave&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;The purpose of software engineering is to control complexity, not to create it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;软件工程的目标是控制复杂度，而不是增加复杂性。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Olin Shivers&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;I object to doing things that computers can do.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我反对去做那些计算机可以做的事情。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;merb motto&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;No code is faster than no code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;没有什么代码会比没有代码速度更快。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Dave Parnas&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;As a rule, software systems do not work well until they have been used, and have failed repeatedly, in real applications.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一般说来，软件系统只有得到实际应用，并且经历多次失败，才能工作得很好。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;RnRS&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;程序语言的设计不应该是特性的堆叠，而应该去除那些使得额外的特性显得必要的弱点和局限。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Ryan Singer&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;So much complexity in software comes from trying to make one thing do two things.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;软件中如此多的复杂性皆来自于想在做一件事的同时多做几件事。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;未完待续&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2015-06-02</pubDate>
            <link>https://blog.xiayf.cn/posts/programming-quotes.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/programming-quotes.html</guid>
        </item>
        
        <item>
            <title>译文：Go 并发编程基础</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://www.nada.kth.se/~snilsson/concurrency/&apos;&gt;Fundamentals of concurrent programming&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;译注：原文章链接已失效，作者重新写了一篇内容相近的文章 &lt;a href=&apos;https://yourbasic.org/golang/concurrent-programming/&apos;&gt;Concurrent programming&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文是一篇并发编程方面的入门文章，以&lt;a href=&apos;http://golang.org/&apos;&gt;Go语言&lt;/a&gt;编写示例代码，内容涵盖：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;运行期并发线程（goroutines）&lt;/li&gt;
&lt;li&gt;基本的同步技术（管道和锁）&lt;/li&gt;
&lt;li&gt;Go语言中基本的并发模式&lt;/li&gt;
&lt;li&gt;死锁和数据竞争&lt;/li&gt;
&lt;li&gt;并行计算&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在开始阅读本文之前，你应该知道如何编写简单的Go程序。如果你熟悉的是C/C++、Java或Python之类的语言，那么 &lt;a href=&apos;http://tour.golang.org/welcome/1&apos;&gt;Go语言之旅&lt;/a&gt; 能提供所有必要的背景知识。也许你还有兴趣读一读 &lt;a href=&apos;http://code.google.com/p/go-wiki/wiki/GoForCPPProgrammers&apos;&gt;为C++程序员准备的Go语言教程&lt;/a&gt; 或 &lt;a href=&apos;http://www.nada.kth.se/~snilsson/go_for_java_programmers/&apos;&gt;为Java程序员准备的Go语言教程&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;1. 运行期线程&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Go允许使用&lt;code&gt;go&lt;/code&gt;语句开启一个新的运行期线程，即 &lt;a href=&apos;http://golang.org/ref/spec#Go_statements&apos;&gt;goroutine&lt;/a&gt;，以一个不同的、新创建的goroutine来执行一个函数。同一个程序中的所有goroutine共享同一个地址空间。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Goroutine非常轻量，除了为之分配的栈空间，其所占用的内存空间微乎其微。并且其栈空间在开始时非常小，之后随着堆存储空间的按需分配或释放而变化。内部实现上，goroutine会在多个操作系统线程上多路复用。如果一个goroutine阻塞了一个操作系统线程，例如：等待输入，这个线程上的其他goroutine就会迁移到其他线程，这样能继续运行。开发者并不需要关心/担心这些细节。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面所示程序会输出“Hello from main goroutine”。也可能会输出“Hello from another goroutine”，具体依赖于两个goroutine哪个先结束。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    go fmt.Println(&amp;amp;quot;Hello from another goroutine&amp;amp;quot;)
    fmt.Println(&amp;amp;quot;Hello from main goroutine&amp;amp;quot;)

    // 至此，程序运行结束，
    // 所有活跃的goroutine被杀死
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;接下来的这个程序，多数情况下，会输出“Hello from main goroutine”和“Hello from another goroutine”，输出的顺序不确定。但还有另一个可能性是：第二个goroutine运行得极其慢，在程序结束之前都没来得及输出相应的消息。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    go fmt.Println(&amp;amp;quot;Hello from another goroutine&amp;amp;quot;)
    fmt.Println(&amp;amp;quot;Hello from main goroutine&amp;amp;quot;)

    time.Sleep(time.Second)        // 等待1秒，等另一个goroutine结束
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面则是一个相对更加实际的示例，其中定义了一个函数使用并发来推迟触发一个事件。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// 函数Publish在给定时间过期后打印text字符串到标准输出
// 该函数并不会阻塞而是立即返回
func Publish(text string, delay time.Duration) {
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
    }()    // 注意这里的括号。必须调用匿名函数
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你可能会这样使用&lt;code&gt;Publish&lt;/code&gt;函数：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    Publish(&amp;amp;quot;A goroutine starts a new thread of execution.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Let’s hope the news will published before I leave.&amp;amp;quot;)

    // 等待发布新闻
    time.Sleep(10 * time.Second)

    fmt.Println(&amp;amp;quot;Ten seconds later: I’m leaving now.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个程序，绝大多数情况下，会输出以下三行，顺序固定，每行输出之间相隔5秒。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run publish1.go
Let’s hope the news will published before I leave.
BREAKING NEWS: A goroutine starts a new thread of execution.
Ten seconds later: I’m leaving now.&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一般来说，通过睡眠的方式来编排线程之间相互等待是不太可能的。下一章节会介绍Go语言中的一种同步机制 - 管道，并演示如何使用管道让一个goroutine等待另一个goroutine。&lt;/p&gt;
&lt;h3&gt;2. 管道（channel）&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/sushi-conveyor-belt.jpg&apos; title=&apos;Sushi conveyor belt&apos; alt=&apos;Sushi conveyor belt&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://golang.org/ref/spec#Channel_types&apos;&gt;管道&lt;/a&gt;是Go语言的一个构件，提供一种机制用于两个goroutine之间通过传递一个指定类型的值来同步运行和通讯。操作符&lt;code&gt;&amp;lt;-&lt;/code&gt;用于指定管道的方向，发送或接收。如果未指定方向，则为双向管道。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;chan Sushi        // 可用来发送和接收Sushi类型的值
chan&amp;amp;lt;- float64    // 仅可用来发送float64类型的值
&amp;amp;lt;-chan int        // 仅可用来接收int类型的值&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;管道是引用类型，基于make函数来分配。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ic := make(chan int)    // 不带缓冲的int类型管道
wc := make(chan *Work, 10)    // 带缓冲的Work类型指针管道&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果通过管道发送一个值，则将&lt;code&gt;&amp;lt;-&lt;/code&gt;作为二元操作符使用。通过管道接收一个值，则将其作为一元操作符使用：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ic &amp;amp;lt;- 3        // 往管道发送3
work := &amp;amp;lt;-wc    // 从管道接收一个指向Work类型值的指针&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果管道不带缓冲，发送方会阻塞直到接收方从管道中接收了值。如果管道带缓冲，发送方则会阻塞直到发送的值被拷贝到缓冲区内；如果缓冲区已满，则意味着需要等待直到某个接收方获取到一个值。接收方在有值可以接收之前会一直阻塞。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;关闭管道（Close）&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://golang.org/ref/spec#Close&apos;&gt;close&lt;/a&gt; 函数标志着不会再往某个管道发送值。在调用&lt;code&gt;close&lt;/code&gt;之后，并且在之前发送的值都被接收后，接收操作会返回一个零值，不会阻塞。一个多返回值的接收操作会额外返回一个布尔值用来指示返回的值是否发送操作传递的。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ch := make(chan string)
go func() {
    ch &amp;amp;lt;- &amp;amp;quot;Hello!&amp;amp;quot;
    close(ch)
}()
fmt.Println(&amp;amp;lt;-ch)    // 输出字符串&amp;amp;quot;Hello!&amp;amp;quot;
fmt.Println(&amp;amp;lt;-ch)    // 输出零值 - 空字符串&amp;amp;quot;&amp;amp;quot;，不会阻塞
fmt.Println(&amp;amp;lt;-ch)    // 再次打印输出空字符串&amp;amp;quot;&amp;amp;quot;
v, ok := &amp;amp;lt;-ch        // 变量v的值为空字符串&amp;amp;quot;&amp;amp;quot;，变量ok的值为false&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个带有&lt;code&gt;range&lt;/code&gt;子句的&lt;code&gt;for&lt;/code&gt;语句会依次读取发往管道的值，直到该管道关闭：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    // 译注：要想运行该示例，需要先定义类型Sushi，如type Sushi string
    var ch &amp;amp;lt;-chan Sushi = Producer()
    for s := range ch {
        fmt.Println(&amp;amp;quot;Consumed&amp;amp;quot;, s)
    }
}

func Producer() &amp;amp;lt;-chan Sushi {
    ch := make(chan Sushi)
    go func(){
        ch &amp;amp;lt;- Sushi(&amp;amp;quot;海老握り&amp;amp;quot;)    // Ebi nigiri
        ch &amp;amp;lt;- Sushi(&amp;amp;quot;鮪とろ握り&amp;amp;quot;) // Toro nigiri
        close(ch)
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;3. 同步&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下一个示例中，我们让&lt;code&gt;Publish&lt;/code&gt;函数返回一个管道 - 用于在发布text变量值时广播一条消息：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// 在给定时间过期时，Publish函数会打印text变量值到标准输出
// 在text变量值发布后，该函数会关闭管道wait
func Publish(text string, delay time.Duration) (wait &amp;amp;lt;-chan struct{}) {
    ch := make(chan struct{})
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
        close(ch)    // 广播 - 一个关闭的管道都会发送一个零值
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：我们使用了一个空结构体的管道：&lt;code&gt;struct{}&lt;/code&gt;。这明确地指明该管道仅用于发信号，而不是传递数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们可能会这样使用这个函数：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    wait := Publish(&amp;amp;quot;Channels let goroutines communicate.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Waiting for the news...&amp;amp;quot;)
    &amp;amp;lt;-wait
    fmt.Println(&amp;amp;quot;The news is out, time to leave.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个程序会按指定的顺序输出以下三行内容。最后一行在新闻（news）一出就会立即输出。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run publish2.go
Waiting for the news...
BREAKING NEWS: Channels let goroutines communicate.
The news is out, time to leave.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4. 死锁&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/traffic-jam.jpg&apos; title=&apos;traffic jam&apos; alt=&apos;traffic jam&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在我们在&lt;code&gt;Publish&lt;/code&gt;函数中引入一个bug：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func Publish(text string, delay time.Duration) (wait &amp;amp;lt;-chan struct{}) {
    ch := make(chan struct{})
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
        // 译注：注意这里将close函数调用注释掉了
        //close(ch)
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;主程序还是像之前一样开始运行：输出第一行，然后等待5秒，这时&lt;code&gt;Publish&lt;/code&gt;函数开启的goroutine会输出突发新闻（breaking news），然后退出，留下主goroutine独自等待。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    wait := Publish(&amp;amp;quot;Channels let goroutines communicate.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Waiting for the news...&amp;amp;quot;)
    // 译注：注意下面这一句
    &amp;amp;lt;-wait
    fmt.Println(&amp;amp;quot;The news is out, time to leave.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此刻之后，程序无法再继续往下执行。众所周知，这种情形即为死锁。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;死锁是线程之间相互等待，其中任何一个都无法向前运行的情形。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Go语言对于运行时的死锁检测具备良好的支持。当没有任何goroutine能够往前执行的情形发生时，Go程序通常会提供详细的错误信息。以下就是我们的问题程序的输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;Waiting for the news...
BREAKING NEWS: Channels let goroutines communicate.
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan receive]:
main.main()
    .../goroutineStop.go:11 +0xf6

goroutine 2 [syscall]:
created by runtime.main
    .../go/src/pkg/runtime/proc.c:225

goroutine 4 [timer goroutine (idle)]:
created by addtimer
    .../go/src/pkg/runtime/ztime_linux_amd64.c:73&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;大多数情况下找出Go程序中造成死锁的原因都比较容易，那么剩下的就是如何解决这个bug了。&lt;/p&gt;
&lt;h3&gt;5. 数据竞争（data race）&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;死锁也许听起来令人挺忧伤的，但伴随并发编程真正灾难性的错误其实是数据竞争，相当常见，也可能非常难于调试。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;当两个线程并发地访问同一个变量，并且其中至少一个访问是写操作时，数据竞争就发生了。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面的这个函数就有数据竞争问题，其行为是未定义的。例如，可能输出数值1。代码之后是一个可能性解释，试图搞清楚这一切是如何发生得。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func race() {
    wait := make(chan struct{})
    n := 0
    go func() {
        // 译注：注意下面这一行
        n++ // 一次访问: 读, 递增, 写
        close(wait)
    }()
    // 译注：注意下面这一行
    n++ // 另一次冲突的访问
    &amp;amp;lt;-wait
    fmt.Println(n) // 输出：未指定
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;代码中的两个goroutine（假设命名为&lt;code&gt;g1&lt;/code&gt;和&lt;code&gt;g2&lt;/code&gt;）参与了一次竞争，我们无法获知操作会以何种顺序发生。以下是诸多可能中的一种：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 从 &lt;code&gt;n&lt;/code&gt; 中获取值0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 从 &lt;code&gt;n&lt;/code&gt; 中获取值0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 将值从0增大到1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 将1写到 &lt;code&gt;n&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 将值从0增大到1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 将1写到 &lt;code&gt;n&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;程序输出 n 的值，当前为1&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“数据竞争（data race）”这名字有点误导的嫌疑。不仅操作的顺序是未定义的，其实根本没有任何保证（no guarantees whatsoever）。编译器和硬件为了得到更好的性能，经常都会对代码进行上下内外的顺序变换。如果你看到一个线程处于中间行为状态时，那么当时的场景可能就像下图所示的一样：&lt;/p&gt;
&lt;img src=&apos;https://yourbasic.org/golang/mid-action.jpg&apos; title=&apos;mid action&apos; alt=&apos;mid action&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;避免数据竞争的唯一方式是线程间同步访问所有的共享可变数据。有几种方式能够实现这一目标。Go语言中，通常是使用管道或者锁。（&lt;a href=&apos;http://golang.org/pkg/sync/&apos;&gt;sync&lt;/a&gt;和&lt;a href=&apos;http://golang.org/pkg/sync/atomic/&apos;&gt;sync/atomic&lt;/a&gt;包中还有更低层次的机制可供使用，但本文中不做讨论）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Go语言中，处理并发数据访问的推荐方式是使用管道从一个goroutine中往下一个goroutine传递实际的数据。有格言说得好：“不要通过共享内存来通讯，而是通过通讯来共享内存”。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func sharingIsCaring() {
    ch := make(chan int)
    go func() {
        n := 0 // 仅为一个goroutine可见的局部变量.
        n++
        ch &amp;amp;lt;- n // 数据从一个goroutine离开...
    }()
    n := &amp;amp;lt;-ch   // ...然后安全到达另一个goroutine.
    n++
    fmt.Println(n) // 输出: 2
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以上代码中的管道肩负双重责任 - 从一个goroutine将数据传递到另一个goroutine，并且起到同步的作用：发送方goroutine会等待另一个goroutine接收数据，接收方goroutine也会等待另一个goroutine发送数据。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://golang.org/ref/mem&apos;&gt;Go语言内存模型&lt;/a&gt; - 要保证一个goroutine中对一个变量的读操作得到的值正好是另一个goroutine中对同一个变量写操作产生的值，条件相当复杂，但goroutine之间只要通过管道来共享所有可变数据，那么就能远离数据竞争了。&lt;/p&gt;
&lt;h3&gt;6. 互斥锁&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/lock.jpg&apos; title=&apos;lock&apos; alt=&apos;lock&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有时，通过显式加锁，而不是使用管道，来同步数据访问，可能更加便捷。Go语言标准库为这一目的提供了一个互斥锁 - &lt;a href=&apos;http://golang.org/pkg/sync/#Mutex&apos;&gt;sync.Mutex&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;要想这类加锁起效的话，关键之处在于：所有对共享数据的访问，不管读写，仅当goroutine持有锁才能操作。一个goroutine出错就足以破坏掉一个程序，引入数据竞争。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此，应该设计一个自定义数据结构，具备明确的API，确保所有的同步都在数据结构内部完成。下例中，我们构建了一个安全、易于使用的并发数据结构，&lt;code&gt;AtomicInt&lt;/code&gt;，用于存储一个整型值。任意数量的goroutine都能通过&lt;code&gt;Add&lt;/code&gt;和&lt;code&gt;Value&lt;/code&gt;方法安全地访问这个数值。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// AtomicInt是一个并发数据结构，持有一个整数值
// 该数据结构的零值为0
type AtomicInt struct {
    mu sync.Mutex // 锁，一次仅能被一个goroutine持有。
    n  int
}

// Add方法作为一个原子操作将n加到AtomicInt
func (a *AtomicInt) Add(n int) {
    a.mu.Lock() // 等待锁释放，然后持有它
    a.n += n
    a.mu.Unlock() // 释放锁
}

// Value方法返回a的值
func (a *AtomicInt) Value() int {
    a.mu.Lock()
    n := a.n
    a.mu.Unlock()
    return n
}

func lockItUp() {
    wait := make(chan struct{})
    var n AtomicInt
    go func() {
        n.Add(1) // 一个访问
        close(wait)
    }()
    n.Add(1) // 另一个并发访问
    &amp;amp;lt;-wait
    fmt.Println(n.Value()) // 输出: 2
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;7. 检测数据竞争&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;竞争有时非常难于检测。下例中的这个函数有一个数据竞争问题，执行这个程序时会输出&lt;code&gt;55555&lt;/code&gt;。尝试一下，也许你会得到一个不同的结果。（&lt;a href=&apos;http://golang.org/pkg/sync/#WaitGroup&apos;&gt;sync.WaitGroup&lt;/a&gt;是Go语言标准库的一部分；用于等待一组goroutine结束运行。）&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func race() {
    var wg sync.WaitGroup
    wg.Add(5)
    // 译注：注意下面这行代码中的i++
    for i := 0; i &amp;amp;lt; 5; i++ {
        go func() {
            // 注意下一行代码会输出什么？为什么？
            fmt.Print(i) // 6个goroutine共享变量i
            wg.Done()
        }()
    }
    wg.Wait() // 等待所有（5个）goroutine运行结束
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于输出&lt;code&gt;55555&lt;/code&gt;，一个貌似合理的解释是：执行&lt;code&gt;i++&lt;/code&gt;的goroutine在其他goroutine执行打印语句之前就完成了5次&lt;code&gt;i++&lt;/code&gt;操作。实际上变量&lt;code&gt;i&lt;/code&gt;更新后的值为其他goroutine所见纯属巧合。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个简单的解决方案是：使用一个局部变量，然后当开启新的goroutine时，将数值作为参数传递：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func correct() {
    var wg sync.WaitGroup
    wg.Add(5)
    for i := 0; i &amp;amp;lt; 5; i++ {
        go func(n int) { // 使用局部变量
            fmt.Print(n)
            wg.Done()
        }(i)
    }
    wg.Wait()
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这次代码就对了，程序会输出期望的结果，如：&lt;code&gt;24031&lt;/code&gt;。注意：goroutine之间的运行顺序是不确定的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;仍旧使用闭包，但能够避免数据竞争也是可能的，必须小心翼翼地让每个goroutine使用一个独有的变量。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func alsoCorrect() {
    var wg sync.WaitGroup
    wg.Add(5)
    for i := 0; i &amp;amp;lt; 5; i++ {
        n := i // 为每个闭包创建一个独有的变量
        go func() {
            fmt.Print(n)
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;数据竞争自动检测&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一般来说，不太可能能够自动检测发现所有可能的数据竞争情况，但Go（从版本1.1开始）有一个强大的&lt;a href=&apos;http://tip.golang.org/doc/articles/race_detector.html&apos;&gt;数据竞争检测器&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个工具用起来也很简单：只要在使用&lt;code&gt;go&lt;/code&gt;命令时加上&lt;code&gt;-race&lt;/code&gt;标记即可。开启检测器运行上面的程序会给出清晰且信息量大的输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run -race raceClosure.go
Race:
==================
WARNING: DATA RACE
Read by goroutine 2:
    main.func·001()
      ../raceClosure.go:22 +0x65

Previous write by goroutine 0:
    main.race()
        ../raceClosure.go:20 +0x19b
    main.main()
        ../raceClosure.go:10 +0x29
    runtime.main()
        ../go/src/pkg/runtime/proc.c:248 +0x91

Goroutine 2 (running) created at:
    main.race()
      ../raceClosure.go:24 +0x18b
    main.main()
      ../raceClosure.go:10 +0x29
     runtime.main()
      ../go/src/pkg/runtime/proc.c:248 +0x91

==================
55555
Correct:
01234
Also correct:
01324
Found 1 data race(s)
exit status 66&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;该工具发现一处数据竞争，包含：一个goroutine在第20行对一个变量进行写操作，跟着另一个goroutine在第22行对同一个变量进行了未同步的读操作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注意：竞争检测器只能发现在运行期确实发生的数据竞争（译注：我也不太理解这话，请指导）&lt;/p&gt;
&lt;h3&gt;8. Select语句&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://golang.org/ref/spec#Select_statements&apos;&gt;select语句&lt;/a&gt;是Go语言并发工具集中的终极工具。select用于从一组可能的通讯中选择一个进一步处理。如果任意一个通讯都可以进一步处理，则从中随机选择一个，执行对应的语句。否则，如果又没有默认分支（default case），select语句则会阻塞，直到其中一个通讯完成。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以下是一个玩具示例，演示&lt;code&gt;select&lt;/code&gt;语句如何用于实现一个随机数生成器：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// RandomBits函数 返回一个管道，用于产生一个比特随机序列
func RandomBits() &amp;amp;lt;-chan int {
    ch := make(chan int)
    go func() {
        for {
            select {
            case ch &amp;amp;lt;- 0: // 注意：分支没有对应的处理语句
            case ch &amp;amp;lt;- 1:
            }
        }
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面是相对更加实际一点的例子：如何使用select语句为一个操作设置一个时间限制。代码会输出变量news的值或者超时消息，具体依赖于两个接收语句哪个先执行：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;select {
case news := &amp;amp;lt;-NewsAgency:
    fmt.Println(news)
case &amp;amp;lt;-time.After(time.Minute):
    fmt.Println(&amp;amp;quot;Time out: no news in one minute.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;函数 &lt;a href=&apos;http://golang.org/pkg/time/#After&apos;&gt;time.After&lt;/a&gt; 是Go语言标准库的一部分；它会在等待指定时间后将当前的时间发送到返回的管道中。&lt;/p&gt;
&lt;h3&gt;9. 综合所有示例&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;花点时间认真研究一下这个示例。如果你完全理解，也就对Go语言中并发的应用方式有了全面的掌握。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这个程序演示了如何将管道用于被任意数量的goroutine发送和接收数据，也演示了如何将select语句用于从多个通讯中选择一个。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    people := []string{&amp;amp;quot;Anna&amp;amp;quot;, &amp;amp;quot;Bob&amp;amp;quot;, &amp;amp;quot;Cody&amp;amp;quot;, &amp;amp;quot;Dave&amp;amp;quot;, &amp;amp;quot;Eva&amp;amp;quot;}
    match := make(chan string, 1) // 为一个未匹配的发送操作提供空间
    wg := new(sync.WaitGroup)
    wg.Add(len(people))
    for _, name := range people {
        go Seek(name, match, wg)
    }
    wg.Wait()
    select {
    case name := &amp;amp;lt;-match:
        fmt.Printf(&amp;amp;quot;No one received %s’s message.\n&amp;amp;quot;, name)
    default:
        // 没有待处理的发送操作
    }
}

// 函数Seek 发送一个name到match管道或从match管道接收一个peer，结束时通知wait group
func Seek(name string, match chan string, wg *sync.WaitGroup) {
    select {
    case peer := &amp;amp;lt;-match:
        fmt.Printf(&amp;amp;quot;%s sent a message to %s.\n&amp;amp;quot;, peer, name)
    case match &amp;amp;lt;- name:
        // 等待某个goroutine接收我的消息
    }
    wg.Done()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;示例输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run matching.go
Cody sent a message to Bob.
Anna sent a message to Eva.
No one received Dave’s message.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;10. 并行计算&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;并发的一个应用是将一个大的计算切分成一些工作单元，调度到不同的CPU上同时地计算。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将计算分布到多个CPU上更多是一门艺术，而不是一门科学。以下是一些经验法则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个工作单元应该花费大约100微秒到1毫秒的时间用于计算。如果单元粒度太小，切分问题以及调度子问题的管理开销可能就会太大。如果单元粒度太大，整个计算也许不得不等待一个慢的工作项结束。这种缓慢可能因为多种原因而产生，比如：调度、其他进程的中断或者糟糕的内存布局。（注意：工作单元的数目是不依赖于CPU的数目的）&lt;/li&gt;
&lt;li&gt;尽可能减小共享的数据量。并发写操作的代价非常大，特别是如果goroutine运行在不同的CPU上。读操作之间的数据共享则通常不会是个问题。&lt;/li&gt;
&lt;li&gt;数据访问尽量利用良好的局部性。如果数据能保持在缓存中，数据加载和存储将会快得多得多，这对于写操作也格外地重要。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面的这个示例展示如何切分一个开销很大的计算并将其分布在所有可用的CPU上进行计算。先看一下有待优化的代码：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;type Vector []float64

// 函数Convolve 计算 w = u * v，其中 w[k] = Σ u[i]*v[j], i + j = k
// 先决条件：len(u) &amp;amp;gt; 0, len(v) &amp;amp;gt; 0
func Convolve(u, v Vector) (w Vector) {
    n := len(u) + len(v) - 1
    w = make(Vector, n)

    for k := 0; k &amp;amp;lt; n; k++ {
        w[k] = mul(u, v, k)
    }
    return
}

// 函数mul 返回 Σ u[i]*v[j], i + j = k.
func mul(u, v Vector, k int) (res float64) {
    n := min(k+1, len(u))
    j := min(k, len(v)-1)
    for i := k - j; i &amp;amp;lt; n; i, j = i+1, j-1 {
        res += u[i] * v[j]
    }
    return
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;思路很简单：确定合适大小的工作单元，然后在不同的goroutine中执行每个工作单元。以下是并发版本的 &lt;code&gt;Convolve&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func Convolve(u, v Vector) (w Vector) {
    n := len(u) + len(v) - 1
    w = make(Vector, n)

    // 将 w 切分成花费 ~100μs-1ms 用于计算的工作单元
    size := max(1, 1&amp;amp;lt;&amp;amp;lt;20/n)

    wg := new(sync.WaitGroup)
    wg.Add(1 + (n-1)/size)
    for i := 0; i &amp;amp;lt; n &amp;amp;amp;&amp;amp;amp; i &amp;amp;gt;= 0; i += size { // 整型溢出后 i &amp;amp;lt; 0
        j := i + size
        if j &amp;amp;gt; n || j &amp;amp;lt; 0 { // 整型溢出后 j &amp;amp;lt; 0
            j = n
        }

        // 这些goroutine共享内存，但是只读
        go func(i, j int) {
            for k := i; k &amp;amp;lt; j; k++ {
                w[k] = mul(u, v, k)
            }
            wg.Done()
        }(i, j)
    }
    wg.Wait()
    return
}&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;工作单元定义之后，通常情况下最好将调度工作交给运行时和操作系统。然而，对于 &lt;code&gt;Go 1.*&lt;/code&gt; 你也许需要告诉运行时希望多少个goroutine来同时地运行代码。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func init() {
    numcpu := runtime.NumCPU()
    runtime.GOMAXPROCS(numcpu) // 尝试使用所有可用的CPU
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2015-05-20</pubDate>
            <link>https://blog.xiayf.cn/posts/fundamentals-of-concurrent-programming.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/fundamentals-of-concurrent-programming.html</guid>
        </item>
        
        <item>
            <title>又是一年</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;又是一年，依照惯例，得写一篇总结和计划。当然计划更多的只是一种自我鼓励，现实总是一次又一次地证明“计划赶不上变化”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我的2014，可能用三个关键词就能概括：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;结婚&lt;/li&gt;
&lt;li&gt;换工作&lt;/li&gt;
&lt;li&gt;众成技术聚乐部&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;结婚&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;继13年领证，14年把婚礼也办了。由于两家离得远，婚礼也就分两次办。之间还补拍了婚纱照。虽然于我这些流程显得有点折腾，但重要的是大家都是很开心，也不希望老婆以后会有丁点遗憾。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;希望以后的日子总能努力让老婆开心幸福。&lt;/p&gt;
&lt;h3&gt;换工作&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;工作的时间并不长，本没想这么快换工作，何况我还是一个挺念旧的人。但还是那句话“计划赶不上变化”，不得已主动离职跳槽。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于目前的工作还比较满意，能做些自己喜欢做的事情，工作氛围也还不错。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于自己的要求就是踏踏实实做工作搞技术，不急不躁。&lt;/p&gt;
&lt;h3&gt;&lt;a href=&apos;http://happytechgroup.github.io/&apos;&gt;众成技术聚乐部&lt;/a&gt;&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;参加过各种大大小小的会议，总觉得水太多，但如果始终自己一个人蒙头研究技术，也有可能落得个“闭门造车”、“目光短浅”的下场，技术的“理”也是越辩越明，所以找了三五同学朋友搞起自己的技术沙龙，&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;名为“众成技术聚乐部”，之所以为“众成”，是希望&lt;strong&gt;众人成就众人&lt;/strong&gt;，大家相互成就，之所以为“聚乐部”而不是“俱乐部”，是认为大家一起讨论分享技术应该是一件乐呵的事情，不要搞得那么严肃苦逼。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;聚乐部至今已搞了5次聚会，一个月一次，从我个人的角度来看，效果不错，虽然很多地方还有待改进。感谢所有成员的付出！&lt;/p&gt;
&lt;h3&gt;其他&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;技术上，相比上一年，有了些许进步 - 借着“众成”的技术分享，简单阅读了leveldb（Go语言版）的源码、Memcached源码等；为了把工作做得更好，又仔细地阅读了Yii框架源码，并写了&lt;a href=&apos;http://youngsterxyf.github.io/tag/yii.html&apos;&gt;系列文章&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在写博客一事上，2014年我也不算太偷懒，共写了26篇，虽然文章质量不咋地，远远未达到自己的要求，但一切贵在坚持，不是么？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;阅读方面，书目如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;淘宝技术这十年 （3星，成为大牛也是要看机遇的）&lt;/li&gt;
&lt;li&gt;Web容量规划的艺术 （4星）&lt;/li&gt;
&lt;li&gt;世界是数字的 （5星，计算机科普）&lt;/li&gt;
&lt;li&gt;三体（三册）（1、2册5星，第3册4星）&lt;/li&gt;
&lt;li&gt;20个月赚130亿 - YouTube创始人陈士骏自传 （4星，好吧，这翻译的书名真俗气，但其实是本挺不错的书）&lt;/li&gt;
&lt;li&gt;PHP精粹-编写高效PHP代码 （3星，仔细阅读了前半部分，快速浏览了后半部分）&lt;/li&gt;
&lt;li&gt;MacTalk - 人生元编程 (3星，电子书，大致过了一遍）&lt;/li&gt;
&lt;li&gt;编写高质量代码：改进Python程序的91个建议 （4星，需再读一遍）&lt;/li&gt;
&lt;li&gt;文明之光（两册，5星，有态度的浓缩的世界文明史）&lt;/li&gt;
&lt;li&gt;了不起的Node.js（2星，浏览了一遍）&lt;/li&gt;
&lt;li&gt;Pro Git （4星，Git资料中的No.1）&lt;/li&gt;
&lt;li&gt;演讲之禅：一位技术演讲家的自白 （4星，每个技术人都应该多演讲，所以推荐每个技术人都读一下这本书）&lt;/li&gt;
&lt;li&gt;高性能PHP应用开发 （3星）&lt;/li&gt;
&lt;li&gt;翻译漫谈：怎样翻译更地道 （4星，未读完）&lt;/li&gt;
&lt;li&gt;最璀璨的银河：刘慈欣经典作品集 （4星，读完三体，意犹未尽，故找来大刘的中短篇集读读）&lt;/li&gt;
&lt;li&gt;数据之巅 （5星，数据思维，有点震撼到我，推荐，需再读一遍）&lt;/li&gt;
&lt;li&gt;大型网站技术架构:核心原理与案例分析 (4星，虽然没什么新东西，但系统地科普了Web架构方面的东西，还是值得一读的)&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从书目可以看出，技术相关的还是缺乏深度和专注。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;2015 ...&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;做好工作，多思考，多做实在的事情&lt;/li&gt;
&lt;li&gt;继续搞好众成技术聚乐部&lt;/li&gt;
&lt;li&gt;坚持写博客，向深度发展&lt;/li&gt;
&lt;li&gt;选择一两个优秀开源项目，读源码、写博客、做分享，旨在提高系统设计能力和编码能力&lt;/li&gt;
&lt;li&gt;读有想法、有深度的书&lt;/li&gt;
&lt;li&gt;考驾照 （别笑，哈哈）&lt;/li&gt;
&lt;li&gt;以讲师的身份参加一次技术会议&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;（额，“计划”本不该多说，但貌似还是说多了点...）&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2015-01-03</pubDate>
            <link>https://blog.xiayf.cn/posts/the-2014-is-gone.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-2014-is-gone.html</guid>
        </item>
        
        <item>
            <title>面向分布式系统工程师的分布式系统理论（译）</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer/&apos;&gt;Distributed systems theory for the distributed systems engineer&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Gwen Shapira，大腕级的解决方案架构师（SA），如今 Cloudera 的全职工程师，在&lt;a href=&apos;https://twitter.com/gwenshap/status/497203248332165121&apos;&gt; Twitter 上提的一个问题&lt;/a&gt;引起了我的思考。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果是以前，我可能会回答“嗯，这里有篇 FLP 论文，这里有篇 Paxos 论文，这里还有篇拜占庭将军问题的论文...”，我会罗列一箩筐重要的材料，如果你一头扎进去，至少花费 6 个月的时间才能过一遍这些材料。然而我已逐渐明白推荐大量的理论性的论文通常恰恰是着手学习分布式系统理论的错误方式（除非你在做一个 PhD 项目）。论文通常比较深入难懂，需要认真地研习，通常还需要&lt;em&gt;大量的时间投入（significant experience）&lt;/em&gt;来理清这些论文的重要贡献，以及在整个理论体系中的位置。要求工程师具备这样的专业水平又有多大的意义呢？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是，很遗憾，对分布式系统理论方面的重大研究成果和思想进行概括、归纳、背景分析的‘导引’性质的优秀材料非常缺乏；特别是没有居高临下态度的材料。对这块空白区域的思考让我想到了另一个有趣的问题：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;一个分布式系统工程师应该知道些什么分布式系统理论？&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在这种情况下，一知半解（a little theory）并不会是一件多危险的事情。因此我尝试整理一个列表，罗列出作为一个分布式系统工程师的我认为能够直接应用于我日常工作的一些基本概念；或者让分布式系统工程师完全有能力设计一个新系统的“筹码”。如果你认为我漏掉了一些东西，请联系我。&lt;/p&gt;
&lt;h4&gt;入门第一步&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以下 4 篇材料出色地解释了构建分布式系统会遇到的一些挑战，共同概述了一系列分布式系统工程师必须要解决的技术上的难题，为之后章节中更深入的研究做好准备。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://book.mixu.net/distsys/&apos;&gt;好玩又实在的分布式系统理论&lt;/a&gt;是一本简短的书籍，其内容覆盖了分布式系统领域的一些基本议题，包括时间的作用及不同的复制策略。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/&apos;&gt;为分布式系统领域新人整理的笔记&lt;/a&gt; - 不是理论对理论地讲述，而是做一个非常好非常实用的平衡，让你对其余材料的阅读能够落地。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628&apos;&gt;分布式系统研究综述报告&lt;/a&gt; - 一篇经典的论文，解释了为什么不能将所有远程交互都模拟成和本地对象一样。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing&apos;&gt;关于分布式计算的若干谬论&lt;/a&gt; - 分布式计算方面的8点谬论，提醒系统设计者可能会忘记的几类事情。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;失败和时间&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;分布式系统工程师需要面对的许多困难最终都可以归咎于两个潜在的原因：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;进程可能会失败&lt;/li&gt;
&lt;li&gt;不存在一种好的方式来周知目前为止进程已经做了些什么&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;进程之间对于&lt;em&gt;时间&lt;/em&gt;的认知能共享些什么？哪些失败的场景是能够检测到？什么算法和原语可能被正确地实现？这三个问题有着非常深层的联系。多数时候，我们会假设两个不同节点之间对于时间概念或时间以什么样的速度逝去没有任何可共享的认知。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你应该知道：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;失败模式的（部分）分层：&lt;a href=&apos;http://www.cse.psu.edu/~gcao/teach/513-00/c7.pdf&apos;&gt;崩溃停止-&gt;排除（omission）&lt;/a&gt;-&gt;&lt;a href=&apos;http://en.wikipedia.org/wiki/Byzantine_fault_tolerance&apos;&gt;拜占庭容错&lt;/a&gt;。你应该理解：在高层次上可能发生的问题在低层次上肯定可能发生，在低层次上不可能发生的问题在高层次上也肯定不可能发生。&lt;/li&gt;
&lt;li&gt;在没有任何共享时钟的情况下如何判断在另一个事件之前是否产生了某事件。这意味着你需要理解 &lt;a href=&apos;http://web.stanford.edu/class/cs240/readings/lamport.pdf&apos;&gt;Lamport 时钟&lt;/a&gt;及其一般化的&lt;a href=&apos;http://en.wikipedia.org/wiki/Vector_clock&apos;&gt;向量时钟&lt;/a&gt;，也需要阅读一下&lt;a href=&apos;http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&apos;&gt;这篇 Dynamo 论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;单个失败发生的可能性对于我们实现正确的分布式系统到底会有多大的影响（请阅读下面关于 FLP 结果的笔记）？&lt;/li&gt;
&lt;li&gt;不同的时间模型：同步、部分同步和异步（若我找到好的参考文献会添加链接）&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;容错的基本矛盾&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个系统，若要不降级而容忍某些错误的发生，就必须能够好像那些错误没有发生一样地运作。这通常意味着系统的这些部分必须能够冗余地工作，但是非绝对必要地做更多的工作通常会在性能和资源耗用方面产生一些消耗。这是为系统添加容错带来的基本矛盾。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你应该知道：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;确保单拷贝可串行化（single-copy serialisability）的仲裁（quorum）技术。可阅读 &lt;a href=&apos;https://ecommons.library.cornell.edu/bitstream/1813/6323/1/82-483.pdf&apos;&gt;Skeen 的原始论文&lt;/a&gt;，但可能更建议阅读&lt;a href=&apos;http://en.wikipedia.org/wiki/Quorum_(distributed_computing&apos;&gt;这个 Wikipedia 词条&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;关于&lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit/&apos;&gt;两阶段提交&lt;/a&gt;、&lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-three-phase-commit/&apos;&gt;三阶段提交&lt;/a&gt;和 &lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-paxos/&apos;&gt;Paxos&lt;/a&gt; 算法，以及为什么它们有不同的容错性质。&lt;/li&gt;
&lt;li&gt;最终一致性，及其他技术是如何以弱化对系统行为的保证为代价来尝试避免这种矛盾的。这篇 &lt;a href=&apos;http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&apos;&gt;Dynamo 论文&lt;/a&gt;是一个很好的起点，同时 Pat Helland 的经典之作 &lt;a href=&apos;http://www.ics.uci.edu/~cs223/papers/cidr07p15.pdf&apos;&gt;Life Beyond Transactions&lt;/a&gt; 也是必读的。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;基本的原语&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;分布式系统中很少有大家一致认同的基本构建块，但越来越多地在出现。你应该以下的问题是什么，以及在哪可以找到它们的解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;群首选举（leader election）（例如 &lt;a href=&apos;http://en.wikipedia.org/wiki/Bully_algorithm&apos;&gt;Bully 算法&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;一致的快照（例如 Chandy 和 Lamport 所写的&lt;a href=&apos;http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf&apos;&gt;经典论文&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;共识（阅读上文提到的关于 2PC 和 Paxos 的博文）&lt;/li&gt;
&lt;li&gt;分布式状态机复制（看看 &lt;a href=&apos;http://en.wikipedia.org/wiki/State_machine_replication&apos;&gt;Wikipedia&lt;/a&gt; 就可以，但 &lt;a href=&apos;http://research.microsoft.com/en-us/um/people/blampson/58-Consensus/Acrobat.pdf&apos;&gt;Lampson 的论文&lt;/a&gt;更权威，只是枯燥了点）。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;基础结论&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;某些客观事实是需要内化于心的，以下是几个关键点（a flavour）（当然还有更多）：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果进程之间可能丢失某些消息，那么不可能在实现一致性存储的同时能响应所有的请求。这就是 &lt;a href=&apos;http://lpd.epfl.ch/sgilbert/pubs/BrewersConjecture-SigAct.pdf&apos;&gt;CAP 定理&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;以这样一种方式（a.始终是正确的、b.始终能终止-若在一个可能因失败崩溃停止（crash-&lt;code&gt;*&lt;/code&gt; stop failures）的异步系统中有（甚至仅）一台机器失效时（FLP 的结果））。我希望在&lt;a href=&apos;http://www.slideshare.net/HenryRobinson/pwl-nonotes&apos;&gt;洛杉矶题为 Papers We Love 报告&lt;/a&gt;的第一部分幻灯片-进行证明之前-已经合理地解释了这个结论。&lt;em&gt;建议：没有实际的必要理解这个证明。&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;一般而言，消息交互少于两轮是不可能达成共识（Consensus）。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;真实系统&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最重要的练习是重复地阅读新兴的、真实系统的描述，并尝试评价它们的设计决策。一遍又一遍地这样去做。一些建议：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Google:&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/gfs-sosp2003.pdf&apos;&gt;GFS&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/spanner-osdi2012.pdf&apos;&gt;Spanner&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41344.pdf&apos;&gt;F1&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/chubby-osdi06.pdf&apos;&gt;Chubby&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/bigtable-osdi06.pdf&apos;&gt;BigTable&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41378.pdf&apos;&gt;MillWheel&lt;/a&gt;、&lt;a href=&apos;http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Schwarzkopf.pdf&apos;&gt;Omega&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/36356.pdf&apos;&gt;Dapper&lt;/a&gt;、&lt;a href=&apos;http://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf&apos;&gt;Paxos Made Live&lt;/a&gt;、&lt;a href=&apos;http://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/abstract&apos;&gt;The Tail At Scale&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;Not Google:&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;a href=&apos;http://research.microsoft.com/en-us/projects/dryad/eurosys07.pdf&apos;&gt;Dryad&lt;/a&gt;、&lt;a href=&apos;https://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf&apos;&gt;Cassandra&lt;/a&gt;、&lt;a href=&apos;http://ceph.com/papers/weil-ceph-osdi06.pdf&apos;&gt;Ceph&lt;/a&gt;、&lt;a href=&apos;https://ramcloud.stanford.edu/wiki/display/ramcloud/RAMCloud+Papers&apos;&gt;RAMCloud&lt;/a&gt;、&lt;a href=&apos;http://hyperdex.org/papers/&apos;&gt;HyperDex&lt;/a&gt;、&lt;a href=&apos;http://www.mpi-sws.org/~druschel/courses/ds/papers/cooper-pnuts.pdf&apos;&gt;PNUTS&lt;/a&gt;&lt;/p&gt;</description>
            <pubDate>2014-08-10</pubDate>
            <link>https://blog.xiayf.cn/posts/ds-4-dse.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/ds-4-dse.html</guid>
        </item>
        
        <item>
            <title>仓库作业机器监控系统设计与实现</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;近期在参与一个仓库作业机器监控项目。该项目的需求背景是：公司的电商业务在全国各地有多处或大或小的仓库，仓库的作业人员（没有IT技术背景）经常反馈/投诉作业机器断网、断电、连不了服务等问题。实际情况经常与反馈的不一致，但运维侧并没有数据可以证明，所以才有了这个项目的需求。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;该项目第一期的目标仅是&lt;em&gt;收集、展示作业机器某些监控指标数据，以便在快速定位解决问题，或至少有数据可查&lt;/em&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为了避免大量监控数据上报影响到生产系统的网络服务，系统采用如下结构：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/EfLNUvneo3D1trl.png&apos; title=&apos;inner_warehouse_monitor&apos; alt=&apos;inner_warehouse_monitor&apos; width=&apos;600&apos;/&gt;
&lt;ol&gt;&lt;li&gt;实现一个 agent 用于在仓库作业 PC 或作业 PDA 上获取机器的监控数据；&lt;/li&gt;
&lt;li&gt;在仓库本地服务器上实现一个数据收集处理服务，提供 API 给 agent 上传监控数据；数据收集处理服务会将接收到的数据持久化到数据库，提供给仓库本地服务器上的 webApp 进行数据展示等；&lt;/li&gt;
&lt;li&gt;中心服务器可以调用各个仓库本地服务器上的 webApp 提供的数据查询接口（数据用于定位、发现问题）；定期按需对各个仓库本地服务器上的数据进行归档。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这样，主要的工作都集中在&lt;strong&gt;作业机器上的 agent&lt;/strong&gt; 和&lt;strong&gt;数据收集处理服务、webApp&lt;/strong&gt;。这其中最关键的又是&lt;strong&gt;数据收集处理服务&lt;/strong&gt;。考虑到需要多地部署运维仓库本地服务器，而且某些大仓库作业机器的数目目前已多达800-1000，我们做了如下技术选型：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Golang 实现 agent、数据收集处理服务、webApp；&lt;/li&gt;
&lt;li&gt;以 SQLite 作为数据库来存储agent上报的所有数据；&lt;/li&gt;
&lt;li&gt;以 &lt;a href=&apos;http://bitly.github.io/nsq/&apos;&gt;NSQ&lt;/a&gt; 作为异步消息队列中间件；&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;选用 Golang 的理由是：可以静态编译，部署简单，只需将编译好的可执行二进制程序丢到服务器上跑起来就可以了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;选用 SQLite 的理由是：不必像 MySQL 那样安装 server 程序，无需额外部署维护。当然 SQLite 的文件锁会大大影响数据库读写性能，我们通过尽可能拆分数据库，将不同的指标数据存储在不同的 SQLite DB 文件中，甚至将每台作业机器每个指标的每天的数据分别存储在不同的 DB 文件中，来尽可能减小文件锁的性能影响，目前看来效果还不错。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;选择 NSQ 的理由是：Golang 实现、分布式、伸缩性好、性能高、支持 HTTP/TCP 协议、自带web管理界面等。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;详细的系统结构图如下所示：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/OwhHWZbmcofzRue.png&apos; title=&apos;inner_warehouse_monitor-arch&apos; alt=&apos;inner_warehouse_monitor-arch&apos; width=&apos;600&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;NSQ 支持多 topic（不同 topic 的数据不同），topic 又可以有多个 channel（同一个 topic 的所有channel中的数据相同，以多播的方式实现，每个 channel 在 client 中有一个对应的处理流程来处理 channel 中的数据）。我们将作业机器不同的监控指标数据作为不同 topic 传入 NSQ，多数指标数据只需持久化到数据库以备后用，所以这些 topic 仅需一个 channel。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;webApp 基于 Beego 框架实现，避免重复造轮子、工作量小。webApp中的数据展示采用 HighCharts、Raphael 实现，兼容性好。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于机器指标数据，其实不应该使用关系型数据库来存储，因为这种数据的特点是：写入之后只读不改、时间序列的、几乎没有关系型的读取操作、连续批量数据读取，所以开源监控系统如 Cacti、Ganglia 等均使用 RRDtool 来读写指标数据。所以如上所述，我们将指标数据的存储尽可能地拆分成多个文件以提高读写性能而不会造成其他问题。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;系统的工作流程如下所述：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;作业机器上的 agent 启动后会先向 NSQ 的 register topic 发送一个注册消息，NSQ Client 根据该注册消息在 register 数据表中将该作业机器的状态改为“正常运行中”；&lt;/li&gt;
&lt;li&gt;然后，agent 定期上报监控数据到 NSQ，NSQ Client 中各种数据的处理流程将数据持久化到 SQLite 数据库文件；&lt;/li&gt;
&lt;li&gt;用户访问/中心服务器调用API时，webApp 读取 SQLite 数据库；&lt;/li&gt;
&lt;li&gt;有一个 Goroutine 针对注册过的作业机器定期检测3分钟以内是否收到过其上报的心跳数据，若未收到，则将机器状态从“正常运行中”改成“运行异常”，若收到，则将“运行异常”改为“正常运行中”；&lt;/li&gt;
&lt;li&gt;作业机器在正常关机时会向 NSQ 的 register topic 发送一个正常关机的消息，Client 读取到该消息后，会将该机器在 register 数据表中的状态改为“已正常关机”。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;目前，系统工作良好。之后会对系统做压测，如果出现瓶颈，估计可能还是数据存储，这样的话我们可能会尝试 RRDtool 或 &lt;a href=&apos;http://influxdb.org/&apos;&gt;InfluxDB&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-11-29</pubDate>
            <link>https://blog.xiayf.cn/posts/inner-warehouse-monitor-system.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/inner-warehouse-monitor-system.html</guid>
        </item>
        
        <item>
            <title>读书：Just For Fun - The Story of an Accidental Revolutionary</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;前些天偶然在图灵社区上看到&lt;a href=&apos;http://www.ituring.com.cn/book/1115?q=%E8%B6%8A%E7%8E%A9%E8%B6%8A%E5%A4%A7&apos;&gt;这本书的出版计划&lt;/a&gt;，才猛然想起之前看过一两个章节，遂再次找到该书的&lt;a href=&apos;http://ishare.iask.sina.com.cn/f/14439267.html&apos;&gt;中文电子版&lt;/a&gt;（&lt;em&gt;原谅我&lt;/em&gt;）（关于该电子版，我不清楚其来源。中国青年出版社出过该书的中文版，译名为《乐者为王》，不知该电子版即为该中文版，还是开源爱好者自己翻译。不过翻译质量不高，应该不是正式出版的），花了一天左右时间看完。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本书由 Linus Torvalds 和 David Diamond 合著，书写方式是 Linus 自述，穿插 David Diamond 的一些采访旁白，主要讲述 Linus 如何偶然地成为信息时代的一个革命者（The Story of an Accidental Revolutionary）。Linus 在书中表达了对 Linux 这一伟大的开源项目的看法、对于人生意义、事物发展规律等问题的个人理解。以下是书中让我印象比较深刻的几处内容：&lt;/p&gt;
&lt;h2&gt;生活的意义&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于这一哲学性的问题，估计现在很多人见到都会发笑。本书以这个问题的讨论开始，并以这个问题结尾。Linus并没有直接地回答，而是举例说明人类社会的事物发展都必然经过三个阶段---生存、社会秩序、娱乐，那么生活的意义就是促成这一发展过程：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;李纳斯：这个答案基本上简单而漂亮。 它不会给你的生活以任何意义，但可以告诉你将发生什么。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有三件事具有生命的意义。它们是你生活当中所有事情的动机，包括你所做的任何事情和一个生命体该做的所有事情。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第一是生存，第二是社会秩序，第三是娱乐。生活中所有的事情都是按这个顺序发展的。娱乐之后便一无所的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此从某种意义上说，这意味着生活的意义就是要达到第三个阶段。你一旦达到了第三个阶段，就算成功了。但首先要越过前两个阶段。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我认为这一理解是非常漂亮的。对于该问题（我为什么而活？），以前我也思考了很多，但最后的答案竟然是---活着本来就是没有意义的，一切意义都是人为地赋予。答案很悲观，Linus 的答案本质上也是如此，只不过避免了直接面对该问题，以顺从事物发展规律作为生活的意义，对我有所启发，也让我多了些生活的“正能量”。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于未来的预言，特别是计算机行业的发展，Linus 同样并没有直接回答问题，同样地以此作为回答：人们并不是真的需要计算机（包含网络等等），而是需要基于计算机实现生存、社会秩序、娱乐三个目标，那么未来的一切、计算机行业的发展必然是更好地帮助人们实现这三个目标。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;关于娱乐，有本书《娱乐至死》表达了对人类社会发展泛娱乐化、特别是教育趋向娱乐化的担忧。从另一角度佐证了 Linus 的看法，只不过一消极悲观，一积极乐观。&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;与Andrew S. Tanenbaum的争论&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一事件在 Wikipedia 上还有专门的词条-&lt;a href=&apos;http://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate&apos;&gt;Tanenbaum-Torvalds debate&lt;/a&gt;。以前也关注过该事件，但把问题的重心放在了“微内核（Micro kernel）”和“宏内核（Monolithic kernel）”的优缺点上，看了该书之后才真正理解 Linus 的选择，并赞同他的看法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一争论的原文见&lt;a href=&apos;https://groups.google.com/forum/#!topic/comp.os.minix/wlhw16QWltI%5B1-25-false%5D&apos;&gt;邮件列表&lt;/a&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于 Tanenbaum 提出的问题，Linus 做了如下回答：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;安德鲁塔南鲍姆写道：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;我在美国待了几个星期，所以没来得及对Linux做多少评论(不是说如果我在，我就会说什么)。但是，Linux 确实值得一评。我现在就有话要说。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;正如你们所知，MINIX 只是我的爱好，每当晚上我写烦了书，如果当时没有什么战争、 革命、 直播的参议院听政会，我就会摆弄 MINIX。我的真正职业是大学教授和操作系统领域中的研究人员。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你用这个作为 MINIX 局限性的借口？对不起，但是你输了。我的借口比你的还多，而 Linux 在很多领域还是胜 MINIX 一筹。更别说 MINIX 的大部分似乎是由布鲁斯?伊文斯编写的了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;反驳一：你说你把 MINIX 当作爱好来玩――那么，请问是谁在拿 MINIX 挣钱呢？又是谁在免费发送 Linux 呢？再来谈谈爱好。让 MINIX 能免费获得，我对 MINIX 的最大抱怨就会消失。Linux 在很大程度上对我是一个爱好(但是一个很严肃的爱好，最棒的一种爱好)。我没有从我的爱好中赚一分钱，它也不是我在大学要修的课程之一。我是纯粹用我自己的时间，在自己的机器上做出来的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;反驳二：你是教授和研究人员。这真是一个 MINIX 出现核心缺陷的好借口。我只能希望 Amoeba 不会像 MINIX 那样垮掉。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;1.微内核对 Monolithic system&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;没错，Linux 是 Monolithic 的，我同意微内核是好一点儿。 如果不是你的话题有争议性，我可能会同意你的大部分意见。从理论角度(及审美角度)而言，Linux 输了。如果 GNU 的 kernel 在去年春天就已完善的话，我可能就不会开始这个工程。而事实是，GNU 还没有完善，也远非如此。如果现在就已实现的这一点而论，Linux才大获全胜。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;MINIX 是一个基于微内核的系统。Linux 是 Monolithic 的系统。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果这是判断一个 kernel 好坏的唯一标准，你的观点就对了。但你没提到的是，MINIX 在微内核方面的表现并不出色，而且对核内真正的多任务操作仍存在着问题。 如果我做的是一个在多线程文件系统上有问题的 OS 的话，我就不会这么快来责备别人。而事实上，我竭尽所能来使人们忘记软件设计者在此问题上的惨败。(是的，我知道 MINIX 拥有众多黑客支持者，但他们只是黑客。而布鲁斯?伊文斯告诉我有很多可以竞争的机会。)&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&gt;2.可移植性&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;“可移植性是给那些写不出新程序的人们准备的。”&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;――我，现在刚说的，口出狂言&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;事实上，Linux 比 MINIX 更具有可移植性。 “你说什么？”我听见你说。 是真的――但却不是在你所说的意义上。我使 Linux 尽量符合标准(我当时手边并没有 POSIX 标准)。 把程序移植到 Linux 上比到 MINIX 上要容易得多。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我同意，可移植性是个好东西，但是只有在它确实有意义的地方才是个令人向往的特性。没有必要专门使一个操作系统太具有可移植性：能粘到可移植的 API 上就行了。操作系统的实质就是利用硬件的特点，并将其隐藏在一层高级的系统调用后面。而 Linux 就是如此，它比任何 kernel 都更多地利用了386的特性。当然这使得kernel确实不可移植，但是这也使设计大为简化，是一个可以接受的权宜之计，因为这首先保证了 Linux 的诞生。我也同意，Linux 又太不具有可移植性了。去年一月我拥有了自己的386，而 Linux 系统的创建在一定程度上成为了一个让我认识386的项目。如果要成为一个真正的项目，必须能够在可移植性方面做一些事情。 但是，我最初的设计思想就是没有考虑到可移植性，如果我这样说并不是太过分地为自己辩护。去年四月我开始这个项目时，认为不会有什么人会真的使用它。我很高兴我的这个想法错了。 随着我对源代码的发布，每个人都可以免费来装截 Linux，哪怕还不是很方便。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;李纳斯&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;附：很抱歉我有时言辞过激。如果你没有其他的操作系统可供选择的话，MINIX 已经挺好的了。如果你有五到十个386机器闲着没用，那么 Amoeba 也会不错，只是我确定无疑是没有的。我一般不会勃然大怒，但是在涉及到 Linux 的问题时，我是有点容易感情用事。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一反驳非常精彩，并且有说服力！特别是对于“可移植性”问题的说明，值得每个程序员阅读。&lt;/p&gt;
&lt;h2&gt;知识产权&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于知识产权，通常有两种截然不同的观点：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;有些人认为，专利和劳动保险形式的知识产权法规是自由世界的祸害，信息提供者(IP)法规并不仅仅是训导，实际上简直就是罪恶，应该尽快地加以铲除。 另一些人认为整个世界经济实际上是由知识产权所驱动的。这些人想通过他们的努力来加强IP法规的法律地位。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;而 Linus 是这么认为：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;对于许多人，包括对我自己而言，知识产权是有关人类的创造活动的规则，是关于那些使我们成为人类――而不是动物(当然，这本身是一件好事)的活动的规则。正是在这个意义上，“知识产权”这一名称本身就是一种侮辱。 它并不是如有形财产那样可以出售，它是创造性活动本身，这是人类所能够做到的最伟大的事情。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;那种创造――不管它是以绘画、 音乐、 雕塑、 菱或是程序的方式出现，都应当受到尊重：创造者和他所创造的事物之间有着你所无法切断的密切联系。这就像母亲与孩子之间的联系，或者如同中国菜与味精之间的联系。 但是与此同时，它却又是世界上每一个人都应当分享的事物，因为它是属于人类共同的。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;你拥有你所创造的东西就意味着你可以控制它的使用。 例如，你有权将这一艺术成果出售给其他人，而且在这个问题上，除了美国国税局以外，任何人都不会说什么。 但是，它其实并不仅仅是钱的问题，而是其他人在同样的问题上陷于困惑时帮他们解决了问题，省却了时间与精力。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;许多要求加强知识产权立法的讨论是基于这样一种观点，即：给创造者和艺术家以更多的“保护”。而人们似乎不曾、或者说是从未意识到，这样一种强有力的权利导致一些人剥夺了另一些人的权利。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;我热爱版权。我只是认为没必要将版权所有者的权利无限扩大。不要扩大到将消费者的权利都被剥夺殆尽。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;很显然，只有极少的个人获得了专利。 另一方面，公司却获得了大量的专利。这些专利是他们用来对付其他公司的有力武器，可以威胁别人因专利侵权而要面临起诉。现今的专利系统基本上可以说是信息提供者这间的冷战，而不是他们之前的核战争。目前这种情况也不见得比过去的冷战好。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;如果你想避免专利申请过程中的麻烦，你可以采用更为厉害的手段：商业秘密。商业秘密的优点在于，你不必担心什么商业秘密办公室或者类似的机构：你只需要将其封存起来，然后就不必顾虑那么多了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;过去人们一直是这样做的，实际上这也就是法规之所以被引入的原因所在。为了鼓励个人和公司公开其秘密，专利法允许在一定期限内保护市场――如果你公开你所拥有的秘密的话。一个针锋相对的基本形式是：你告诉大家你是如何做成某事的，那么我们就允许你拥有一定年限的特殊权利。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;在专利产生之前，人们会充满猜忌地保守他们自己的技术优势，一直到将它们带入坟墓。很显然，那是不利于技术进步的，因为有前途的技术从来没有向其他人公开过。对于专利特权的承诺使得专利成为将秘密告诉大家的一种强有力的刺激，因为你再也不用担心你的竞争对手会发现你在做什么了。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;然而，那是过去，现在情形不同了。 如今，即使是商业秘密也有了法律保护，尽管它们的理由世人无法理解。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;很大程度上，在这场知识产权战争中寻求和平的解决之道正是公开源代码所努力的目标。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;同一事物的另一面在于，的确，知识产权可能是不公平的，的确，知识产权法规在很大程度上将其目标定位于大公司而不是消费者权利，甚至也不是个人著作者或创新者。 然而其主体是积极有利的。知识产权集中于强有力的权利之上，与之相对应的事实是这一强有力的武器在市场上是如此的有效。 核武器是冷战时代的终极力量，同样的原因使得知识产权在技术战争时代里大受欢迎。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;虽然大量的新措施使非法使用他人的知识产权变得更加困难，但同时也使得合法使用他人的知识产权变得更加困难。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;em&gt;原谅我喋喋不休地摘录了这么多内容，但其实书中这部分的内容还有很多精彩之处。&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;知识产权本来的目的是保护创造者的基本权利，以促进创新和分享，但知识产权如果走过了头（例如如今的专利战争）就会导致创新难以普及，他人无法合法合理地使用这些创新。开源运动则鼓励充分地开放分享创新，同时通过各种形式许可证来保护创造者的基本权利，这也就意味着开源运动的理念不仅只是影响计算机行业，也会对所有行业产生巨大的正面影响。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;人类社会的发展是一个积累的过程，创新知识的分享越充分，积累也就越快，人类社会的发展也就越快。这也是我欣赏支持黑客精神和开源运动的缘由。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;关于书名的翻译&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这本书的书名，中国青年出版社的版本是译为《乐者为王》，而将要出版的人民邮电出版社的版本貌似要译为《越玩越大-我和 Linux 的故事》（正式出版前的暂译名？）。对于这两个译名我都不满意。原书取名《Just For Fun --- The Story of an Accidental Revolutionary》，我想应该是考虑了两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Linus 非常看重尊重自己的兴趣。其实 Linux 就是始于它的个人兴趣，也因此 Linux 到如今的发展及其造成的广泛影响也是当初Linus没有料想也不可能料想到的，人生往往如此，很多事情都是 Accidental 的；&lt;/li&gt;
&lt;li&gt;Linus 认为任何人类社会事物发展的终极阶段就是---娱乐，那么生活的意义就是不断努力为达到这一终极阶段而贡献自己的一份力量。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于第二点，该书的最后一节中作者做了明确的说明：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;对了，就是这三件事：生存、你在社会中的位置、还有快乐。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这三件事就是我们正在做着的事情。 任何其他的事物，都是社会学家可能会称之为“突发行为”的东西，它们源于那些规则更为简单的行为模式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然而事情不仅仅是“这就是激励人生活的事物”。如果情形是这样的话，那它们也就不会成为关于生命的理论了。令人感兴趣的，这三种激励因素有着内在的次序，而这一次序表明了生命的所在。事情并不仅仅是，我们人类被这三种事物所驱使――对于人类以外的其他生命行为也是如此。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;这一次序是：生存；社会交往；寻找乐趣。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;它也是进化的次序。这就是我们选择了“Just for Fun”作为本书名称的原因。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为我们曾经所做的一切事情，似乎最终都是为了我们自己的乐趣。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;译名《乐者为王》虽然简练，却不能明确地表达这两层意思。《越玩越大-我和Linux的故事》则跟闹着玩似的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;为什么不直译为《只为乐趣》呢？&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于本书，阮一峰也写过一篇阅读笔记，见&lt;a href=&apos;http://www.ruanyifeng.com/blog/2012/09/linus_torvalds.html&apos;&gt;《Linus Torvalds 自传》摘录&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-11-07</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-just-for-fun.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-just-for-fun.html</guid>
        </item>
        
        <item>
            <title>搭建高可用负载均衡组件及缓存 DNS</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;该项工作，如题所示，主要分为两部分：高可用负载均衡组件、缓存 DNS。&lt;/p&gt;
&lt;h2&gt;高可用负载均衡组件&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;需求：优化业务系统架构中某些关键环节，针对 TCP 层数据流量进行负载均衡，并保证服务的高可用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;技术选型：HAProxy + Keepalived，这对组合比较常见成熟。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;另外，由于 HAProxy 的负载均衡任务可能比较多，靠人工修改配置来增删改任务不方便可靠，所以实现了一个简单的 HAProxy 管理系统，&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以后经实际使用验证和完善会开放源码。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/lY67ipAcb12TnBS.png&apos; title=&apos;high availability load balancer&apos; alt=&apos;high availability load balancer&apos; width=&apos;100%&apos;/&gt;
&lt;h2&gt;缓存 DNS&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;先以 www.qq.com 为例，解释一下域名解析过程：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/1cyVpdBQSoAq9b6.jpg&apos; title=&apos;resolve qq.com&apos; alt=&apos;resolve qq.com&apos; width=&apos;600&apos;/&gt;
&lt;ol&gt;&lt;li&gt;用户向 Local DNS 发起 &lt;code&gt;www.qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;Local DNS 向根服务器发起 &lt;code&gt;com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;根服务器向 Local DNS 返回 &lt;code&gt;com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS 向 &lt;code&gt;com.&lt;/code&gt; 权威服务器发起 &lt;code&gt;qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.&lt;/code&gt; 权威服务器向 Local DNS 返回 &lt;code&gt;qq.com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS向 &lt;code&gt;qq.com.&lt;/code&gt; 权威服务器发起 &lt;code&gt;www.qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;qq.com.&lt;/code&gt; 权威服务器向 Local DNS 返回 &lt;code&gt;www.qq.com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS 向用户返回 &lt;code&gt;www.qq.com&lt;/code&gt; 解析记录。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Local DNS 一般由网络运营商（如电信、网通等）提供。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;缓存 DNS 处于用户端（这是一个相对的概念）与 local DNS 之间，利用 DNS 服务器软件的缓存功能以及缓存 DNS 与用户端的近距离特点来加速域名解析。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也可以在缓存 DNS 上按需求进行域名劫持。运营商为了牟利，也会在 local DNS 上进行域名劫持，这对于各大互联网公司对外提供的服务来说是个很大的问题。&lt;/p&gt;
&lt;hr&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在完成该工作后，我编写了一份安装配置文档，方便其他同事参考。文档见： &lt;a href=&apos;../assets/high-availability-load-balancer-and-dns.pdf&apos;&gt;HAProxy+HAProxyConsole+Keepalived+BIND安装配置文档.pdf&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-10-16</pubDate>
            <link>https://blog.xiayf.cn/posts/ha-lb-and-dns.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/ha-lb-and-dns.html</guid>
        </item>
        
        <item>
            <title>译文：通过示例学习 Git 内部构造</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://teohm.github.io/blog/2011/05/30/learning-git-internals-by-example/&apos;&gt;Learning Git Internals by Example&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;状态：草稿&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;计划修订本文，未来可能会简化一些...&lt;/p&gt;
&lt;h2&gt;动机&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从 Subversion 和 Mercuria l切换到 Git 之后的几个月，我始终觉得 Git 在本质上是不同于 Subversion 和 Mercurial 的，但没法确切地说出区别。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我经常在 Github上 看到 tree、parent 等术语，也搞不清楚它们确切的含义。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因此我决定花些时间学学Git。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我会尝试概述，并阐述一路走来学到的关于Git的关键信息...但这仅是有助于我回答Git与其他源码控制工具区别的Git内部构造基本知识。&lt;/p&gt;
&lt;h2&gt;实体、引用、索引（Objects，References，The Index）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;要理解 Git内部构造的核心，我们应理解三个东西： &lt;strong&gt;实体&lt;/strong&gt;、&lt;strong&gt;引用&lt;/strong&gt;、 &lt;strong&gt;索引&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我发现这个模型非常优雅。用一个小小的图表就能完全展现，也易于理解记忆。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/DZipXYwEqnguCF9.png&apos; title=&apos;Big Picture&apos; alt=&apos;Big Picture&apos; width=&apos;500&apos;/&gt;
&lt;h3&gt;实体&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你提交到一个Git代码仓库中的所有文件，包括每个提交的说明信息（the commit info）都在目录 &lt;code&gt;.git/objects/&lt;/code&gt;中存储为&lt;strong&gt;实体&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个实体以一个40字符长度的字符串（该实体内容的SHA1哈希值）来标识。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实体有&lt;strong&gt;4类&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;em&gt;blob&lt;/em&gt; - 存储文件内容。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tree&lt;/em&gt; - 存储目录结构和文件名。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;commit&lt;/em&gt; - 存储提交的说明，组成Git的提交图谱。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tag&lt;/em&gt; - 存储带注释的标签（tag）。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下文的示例会阐明这些实体是如何相互关联的。&lt;/p&gt;
&lt;h3&gt;引用&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Git中，一个&lt;em&gt;分支（branch）&lt;/em&gt;、&lt;em&gt;远程分支（remote branch）&lt;/em&gt;或一个&lt;em&gt;标签（tag）&lt;/em&gt;（也称为轻量标签）仅是&lt;strong&gt;指向一个实体的一个指针&lt;/strong&gt;，这里的实体通常是一个commit实体。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这些引用以文本文件的形式存储在目录&lt;code&gt;.git/refs/&lt;/code&gt;中。&lt;/p&gt;
&lt;h4&gt;符号引用（Symbolic References）&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Git有一种特殊的引用，称为&lt;em&gt;符号引用&lt;/em&gt;。它并不直接指向一个实体，而是&lt;strong&gt;指向另一个引用&lt;/strong&gt;。举例来说，&lt;code&gt;.git/HEAD&lt;/code&gt;就是一个符号引用。它指向你正在工作的当前分支。&lt;/p&gt;
&lt;h3&gt;索引&lt;/h3&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;索引是一个暂存区，以二进制文件的形式存储为文件&lt;code&gt;.git/index&lt;/code&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当&lt;code&gt;git add&lt;/code&gt;一个文件，Git将该文件的信息添加到索引中。当&lt;code&gt;git commit&lt;/code&gt;，Git仅提交索引文件中列出的文件。&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们来演练一个简单的示例，创建一个Git代码仓库，提交一些文件，看看幕后&lt;code&gt;.git&lt;/code&gt;目录中都发生了些什么。&lt;/p&gt;
&lt;h3&gt;初始化新的代码仓库&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git init canai&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/8cQagykr73UeENP.png&apos; title=&apos;初始化代码仓库后&apos; alt=&apos;初始化代码仓库后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了空目录&lt;code&gt;.git/objects/&lt;/code&gt;和&lt;code&gt;.git/refs/&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;还没有索引（Index）文件。&lt;/li&gt;
&lt;li&gt;创建了符号索引文件&lt;code&gt;HEAD&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/HEAD
ref: refs/heads/master&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加新文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ echo &amp;amp;quot;A roti canai project.&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; README
$ git add README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/8nJVFwti7TpLRXG.png&apos; title=&apos;添加新文件后&apos; alt=&apos;添加新文件后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了索引（Index）文件。它有一个SHA1哈希值指向一个blob实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 5f89c6f016cad2d419e865df380595e39b1256db 0 README&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个blob实体。README文件的内容存储在该blob中。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/5f/89c6f016cad2d419e865df380595e39b1256db
$ git cat-file blob 5f89c6
A roti canai project.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;首次提交&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git commit -m&amp;amp;apos;first commit&amp;amp;apos;
[master (root-commit) d9976cf] first commit
1 files changed, 1 insertions(+), 0 deletions(-)
create mode 100644 README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/b3uUpRsyiJBwQrX.png&apos; title=&apos;首次提交后&apos; alt=&apos;首次提交后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了分支‘master’引用，指向‘master’分支中最新的commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/heads/master 
d9976cfe0430557885d162927dd70186d0f521e8&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了第一个commit实体，指向代码仓库根目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/d9/976cfe0430557885d162927dd70186d0f521e8
$ git cat-file commit d9976cf
tree 0ff699bbafc5d17d0637bf058c924ab405b5dcfe
author Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306739524 +0800
committer Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306739524 +0800

first commit&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了tree实体。该tree代表目录“canai”。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/0f/f699bbafc5d17d0637bf058c924ab405b5dcfe
$ git ls-tree 0ff699
100644 blob 5f89c6f016cad2d419e865df380595e39b1256db  README&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个修改过的文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ echo &amp;amp;quot;Welcome everyone.&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; README
$ git add README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/HV2OvpxglEh94fR.png&apos; title=&apos;添加一个修改过的文件后&apos; alt=&apos;添加一个修改过的文件后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了索引（Index）文件。注意到了吗？它记录了一个新blob。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 1192db4c15e019da7fc053225d09dea14bc3ac07 0 README&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的blob实体。README的整个内容被存入一个新的blob。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/11/92db4c15e019da7fc053225d09dea14bc3ac07
$ git cat-file blob 1192db
A roti canai project.
Welcome everyone.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;向子目录中添加文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ mkdir doc
$ echo &amp;amp;quot;[[TBD]] manual toc&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; doc/manual.txt
$ git add doc&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/GkF3I2gZpNJtuqx.png&apos; title=&apos;向子目录添加文件后&apos; alt=&apos;向子目录添加文件后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了索引（Index）文件。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 1192db4c15e019da7fc053225d09dea14bc3ac07 0 README
100644 ea283e4fb22719fad512405d41dffa050cd16f9a 0 doc/manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的blob实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/ea/283e4fb22719fad512405d41dffa050cd16f9a
$ git cat-file blob ea283
[[TBD]] manual toc&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;第二次提交&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git commit -m&amp;amp;apos;second commit&amp;amp;apos;
[master 556eaf3] second commit
 2 files changed, 2 insertions(+), 0 deletions(-)
 create mode 100644 doc/manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/p8sMkec5PlWzVEi.png&apos; title=&apos;第二次提交后&apos; alt=&apos;第二次提交后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了分支“master”引用，指向该分支中最新的commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/heads/master 
556eaf374886d4c07a1906b9fdcaba195292b96&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了第二个commit实体。注意它的“parent”是指向首个commit实体。这样形成了一个提交图谱。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git cat-file commit 556e
tree 7729a8b15b747bce541a9752a8f10d57daf221b6
parent d9976cfe0430557885d162927dd70186d0f521e8
author Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306743598 +0800
committer Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306743598 +0800

second commit&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的代码仓库根目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-tree 7729
100644 blob 1192db4c15e019da7fc053225d09dea14bc3ac07  README
040000 tree 6ff17d485bf857514f299f0bde0e2a5c932bd055  doc&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的子目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-tree 6ff1
100644 blob ea283e4fb22719fad512405d41dffa050cd16f9a  manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个注释标签（annotated tag）&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git tag -a -m&amp;amp;apos;this is annotated tag&amp;amp;apos; v0.1 d9976&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/M3ElNd58kHbDS9v.png&apos; title=&apos;添加一个注释标签后&apos; alt=&apos;添加一个注释标签后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了一个标签引用，指向一个tag实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/tags/v0.1 
c758f4820f02acf20bb3f6d7f6098f25ee6ed730&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个tag实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git cat-file tag c758
object d9976cfe0430557885d162927dd70186d0f521e8
type commit
tag v0.1
tagger Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306744918 +0800

this is annotated tag&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个新的（轻量的）标签&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git tag root-commit d9976&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;https://s2.loli.net/2025/05/24/ZdV1ijg8DwaxSpG.png&apos; title=&apos;添加一个新的轻量标签后&apos; alt=&apos;添加一个新的轻量标签后&apos; width=&apos;500&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了一个标签引用，指向一个commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/tags/root-commit 
d9976cfe0430557885d162927dd70186d0f521e8&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;补充阅读&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://book.git-scm.com/index.html&apos;&gt;Git社区书&lt;/a&gt;“第7章：内部构造探究”&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://progit.org/book/ch9-0.html&apos;&gt;Pro Git&lt;/a&gt;“第9章：Git内部构造”。&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;接下来做什么呢？&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;寻找适合分布式团队、长期项目的一个最小化git工作流。&lt;/p&gt;</description>
            <pubDate>2013-09-28</pubDate>
            <link>https://blog.xiayf.cn/posts/learning-git-internals-by-example.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/learning-git-internals-by-example.html</guid>
        </item>
        
        <item>
            <title>工作中的技术人</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;工作入职半个月，有些事情不太顺利，还没有正式上手工作，也许大公司的节奏便是如此，但我内心是比较急的，希望能尽快地上手做实际的工作，而不是学习和等待。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这半个月里，主要是熟悉工作环境，学习了解工作相关的技术。虽说学习，但其实大部分相关技术以前都了解或使用过，只是经验还不够。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第一周，除了常规的入职事宜，搭建了开发测试环境，并阅读理解工作中使用的web框架。对于这个框架，有太多的吐槽点，严格地说算不上是个框架，可能是因为写得比较早。对于框架，我认为最重要的是为多人协作完成一件事情提供实现上的规范，其次是代码复用，减少工作量。但这个框架除了一些供复用的代码，就啥都没有了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第二周，学习巩固PHP基础，一直没认真地学习过PHP，只是在实习的时候做了一些开发，稍微了解了下Yii框架和Zend框架，觉得太复杂了点。除此之外，初步了解组内的运维工作，特别是整个系统的架构。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;经过一番思考，基于自己的理解，昨天编写了一个玩具性质的MVC web框架原型&lt;a href=&apos;https://github.com/youngsterxyf/minibean&apos;&gt;minibean&lt;/a&gt;，该框架以路由转发和控制器为核心，所有非静态文件请求的处理都以Application类对象为入口，按照一定规则对请求URI经路由转发找到对应的控制器类，控制器对象中调用模型与视图的类对象等。以后随着开发经验的增加以及对其他开源成熟框架的学习，会不断地完善该框架。在编写该框架的过程中，深感自己经验的不足，特别是对于Model层，以后可能会刻意阅读某些开源框架的Model层实现。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;目前组内开发工作还很初步，还没有一个正规的开发流程，也没有明确的开发规范。这样虽然没法从已有的工作中学习很多，但也许有机会参与到这些事情创造过程中，收获会更大。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;经过和老同事讨论，以后开发工作涉及的语言和工具包括：Nginx、MySQL、PHP、Redis/Memcached、SVN等，对于这些东西，我都是需要深入学习加强的（当然首先是要解决业务需求）。另外，鉴于原有的那个框架实在不怎么样，以后新的工作可能会选择Zend Framework作为开发框架。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于工作环境，我觉得不太满意的地方主要是技术氛围不太浓厚，以后有机会和大家一起建立起好的技术氛围，搞搞技术分享讨论什么的。另外，有点憋屈的是，觉着自己被小看了，老同事老觉得应届毕业生啥的不懂，所以也不急着分配具体的工作给我，老让我学习学习再学习。个人认为最好的学习方式是给个具体的需求，具体的问题让我去解决，有经验的同事只需对结果把把关就可以。当我在这过程中遇到搞不定的问题再向他们请教，以这种方式来上手熟悉工作也许更好。我个人也比较喜欢直接丢个实际的问题让我去解决。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于今后的自己，我有两点忠告：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;1、时刻警惕迷失&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽然工作很重要，要解决业务需求，工作所涉及的技术也应该扎实掌握，深入理解，但不能把自己局限在此，也不能让自己迷失在过于细节的地方。公司提供了一个完善的平台，但这个平台在我看来自足得有些封闭，所以需警惕，要不断地和同事，和公司外面的人交流学习。要经常自我反思，回顾自己走过的路，要让自己的大脑空闲下来花些时间整体规划即将要做的事情。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2、保持锐气&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;初步觉着有些同事没什么工作生活技术的激情，可能是长时间工作的缘故，也可能是因为我还太年轻。但目前我还不愿意自己进入那种状态。自己以后应该更加主动积极地对待工作。我喜欢称呼自己为“技术人”，因为“技术人”不仅是搞技术的，更重要的是对技术有热情，有使命感。&lt;/p&gt;</description>
            <pubDate>2013-04-23</pubDate>
            <link>https://blog.xiayf.cn/posts/technical-person.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/technical-person.html</guid>
        </item>
        
        <item>
            <title>弄清问题，再求解决</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;今天同事问我：是否有什么python库或工具能够将网页内容转换成图片格式的。他在做这方面的事情，还没有好的方法，因为觉得我对python比较熟悉，所以问一下。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但是我从一开始我就犯错误了。其实我至少应该问一下：为什么要解决这个问题？也就是业务需求是什么？并且稍微一想这个问题其实比较含糊。现在的web页面可以很简单，也可能很复杂。那么这个问题里的“网页”是什么样的网页呢？是任何可能的网页么？目的是需要通过图片来展示网页的哪个部分的信息还是整个网页？这些问题我都没问，也没仔细考虑。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在没有明确需求的情况下，我就认为是将任何形式的网页完整地转换成图片，但又没弄清如果是这种情况问题的难度有多大。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在听完问题后，我就想到可能有两种方法：1. 先将网页转换成pdf，然后转换成图片，因为我对于将网页转换成pdf格式的方法有点印象；2.可能存在python实现的工具直接将网页转换成图片格式。你是否发现我的思路有个误区：问题的解决方案需要python代码实现，我假设了需要将这个功能嵌入到一个大的程序中。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然后我就开始蒙头google找方案。经过一番“艰苦卓绝”的查找，发现：1.确实有如xhtml2pdf等工具能将网页转换成pdf格式，但貌似对于中文的支持不是很好；2.没有好的python库或工具能够直接将网页转换成图片格式，有的方案要收费，有的方案需要调用第三方API，而公司的数据明显是不能让第三方获得的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在查找解决方案的过程中，我也逐步意识到上述的那些问题，特别是若假设需要将任何形式的网页转换成图片格式，这个难度非常大，为什么呢？因为现在很多网页的部分内容都是由JS生成的，若你的程序只是简单地从服务器获取网页，该网页含有的JS代码并不会执行，将该网页转换成图片格式，图片所包含的信息与浏览器中展示的并不相同。所以你的程序起码需要包含一个JS解释器。OK，难度一下子就上去了。在我逐步了解其中的难度后，我开始尝试换个角度来考虑问题，反思同事所要解决的业务需求是什么。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在与他的进一步沟通之后，我才知道：一些总结汇报邮件中需要添加数据统计图，而原有的数据统计图在Web监控页面中，由Raphaeljs库绘制成SVG矢量图。由于无法期望邮件的接收者是从网页版邮箱阅读邮件（他们很可能使用各种邮件客户端如Outlook查看邮件），所以发送带有JS的HTML格式的邮件是没用的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在了解业务需求后，我们就明白了其实问题本质上不是要将网页转换成图片，而是要获得&lt;strong&gt;图片格式的数据可视化结果&lt;/strong&gt;。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么问题就简单多了，可能从以下三个角度寻找解决方案：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;将网页完整地转换成图片格式&lt;/li&gt;
&lt;li&gt;将网页中的SVG内容转换成图片格式&lt;/li&gt;
&lt;li&gt;使用本地的数据可视化工具将统计数据源，即Raphaeljs绘制SVG矢量图的JSON数据源绘制成图片&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这三种方案中第二种最佳，为什么呢？因为第一种需要做一些额外的转换工作，自己实现的难度较大，第三种方案与Web监控页面所使用的是不同的数据可视化工具，所以产生的结果一般是不相同的，除非Raphaeljs支持图片格式的输出，那么应该就可以使用nodejs来实现。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;经过网络查找，发现第一种方案与第二种方案都有现成的工具。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第一种方案：&lt;a href=&apos;https://github.com/ariya/phantomjs&apos;&gt;phantomjs&lt;/a&gt;可以完成，phantomjs包含了webkit，所以解释JS什么的就不再是个问题了，它有个&lt;a href=&apos;https://github.com/ariya/phantomjs/wiki/Screen-Capture&apos;&gt;Screen Capture&lt;/a&gt;的功能模块支持将网页完整地转换成图片格式，但由于要做很多额外的工作，所以效率比较低。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;第二种方案是从Highcharts的&lt;a href=&apos;http://www.highcharts.com/demo/&apos;&gt;Demo&lt;/a&gt;中挖掘出来的，如图所示：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/05/xEYJUhXFuIBHMzb.png&apos; title=&apos;highchartjs_demo&apos; alt=&apos;highchartjs_demo&apos; width=&apos;100%&apos;/&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Demo中可以输出多种图片格式，通过chrome浏览器的开发者工具可以发现其实现是向服务器export.highcharts.com发送一个请求，请求中包含网页中生成的SVG矢量图数据、目标图片格式等信息，服务器对该请求进行处理后返回目标格式图片。那么服务器端是如何将SVG转换成图片格式的呢？在Highcharts的&lt;a href=&apos;http://docs.highcharts.com/&apos;&gt;文档&lt;/a&gt;中有个名为&lt;code&gt;Export module&lt;/code&gt;的部分，其中说明了实现原理以及如何搭建这样的一个格式转换服务器。从文档可以看出这个实现方法的核心是借助了&lt;a href=&apos;http://xmlgraphics.apache.org/batik/tools/rasterizer.html&apos;&gt;batik-rasterizer.jar&lt;/a&gt;这个Java工具包，它能将SVG转换成图片或PDF格式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从上述该问题解决方案的寻找过程可以看出，&lt;strong&gt;很多时候并不是问题有多复杂或有多难，而是我们根本没有明确业务需求，没有搞清楚真正需要解决的问题，而对模糊的问题描述自以为是地作出一些假设，然后蒙头去解决错误的问题，从而浪费了很多时间&lt;/strong&gt;。&lt;/p&gt;</description>
            <pubDate>2013-04-09</pubDate>
            <link>https://blog.xiayf.cn/posts/understand-before-solve.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/understand-before-solve.html</guid>
        </item>
        
        <item>
            <title>译文：数据压缩理论简介</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://imrannazar.com/An-Introduction-to-Compression&apos;&gt;A introduction to compression&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最近我在思考 GIF 和 JPEG 图片格式之间的不同：为什么某些图片存储为 GIF 格式所占的磁盘空间更大，而另一些图片以 JPEG 格式存储要占用更大的磁盘空间？事实证明，这是因为不同的图片格式使用了不同的压缩方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;压缩是一组程序的简便说法，这些程序能够将数据装进更小的存储空间中，也能将数据从压缩编码中重新取回。这是一个双向的过程：输入文件能够产生经过压缩的输出，并且算法根据压缩后的输出能够重新给你一个输入的拷贝。&lt;/p&gt;
&lt;h2&gt;冗余：行程长度编码（Run-Length Encoding）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使压缩成为可能的是冗余：事实表明大多数的数据都以某种方式重复自己。例如，在一个文档中可能多次使用同一个单词，或者一张图片的多处包含相同的颜色。一个非常简单的冗余数据片段的示例如下所示：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Redundancy: Before compression&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;AAAAABBWWWWWWWWWPPPPQZMMMMVVV&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在这种情况下，冗余是明显的；整个样本中重复出现了一系列字母。压缩这种数据的一种简单方式是通过重复次数来代表重复出现的字母，从而削减了样本的总长度。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Redundancy: After compression&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;A5B2W9P4Q1Z1M4V3&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;算法读取样本编码后的版本将能够完美地重现原来的数据：&quot;A&quot; 5次，&quot;B&quot; 2次，等等。这个简单算法的使用非常广泛，被称为行程长度编码（RLE）：写下字符的每次行程有多长。以古老的 PCX 图像格式为例来说明一种广泛使用的标准 RLE。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/akRiNIUmeCKHjyc.png&apos; title=&apos;compression-stripes.png&apos; alt=&apos;compression-stripes.png&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图1：条纹 &lt;a href=&apos;http://www.thisisnotparis.com/&apos;&gt;Gottschal&lt;/a&gt;/&lt;a href=&apos;http://www.gluecksbazillus.de/&quot;&apos;&gt;Schuster&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;图1中有很多单色的实心方块。这张图片宽500个像素，高190个像素；作为一张原始位图，使用一个字节来表示一个像素，那么这张图片就产生 95kB 的数据。PCX 算法计算图片中每行像素的行程长度，为相同颜色的连续像素保存行程长度：以这种方式，图片的大小减到了 52kB。&lt;/p&gt;
&lt;h2&gt;频率：哈夫曼（Huffman）编码&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;RLE 的一个主要问题是它处理的是数据中的连续值：图1中，RLE 算法对图片的每个水平行进行独立的处理，然而其实所有的行都是相同的。这个问题可以通过整体地看待数据来缓解，构建一个表来记录在整个数据集中每个值出现的次数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;哈夫曼编码是一种借助这种“频率表”的方法，这种表记录着每个值出现的频率，并且为每一项分配一个编码。频率越高的项编码越短，较少出现的项也就得到长的编码。在计算中，这些编码一般是二进制编码，然后就可以组合成字节进行文件存储。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用上面的例子，一个哈夫曼编码的过程如下所示：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Huffman encoding: Before compression&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;AAAAABBWWWWWWWWWPPPPQZMMMMVVV&lt;/p&gt;&lt;/blockquote&gt;
&lt;table class=&quot;table table-bordered&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th style=&quot;text-align: center&quot;&gt;值&lt;/th&gt;
&lt;th style=&quot;text-align: center&quot;&gt;频率&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;编码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;Q&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;000000&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;Z&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;000001&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;B&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;2&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;00001&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;V&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;3&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;0001&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;P&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;4&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;001&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;M&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;4&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;011&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;A&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;5&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;01&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;W&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;p class=&quot;text-align-center&quot;&gt;9&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;表1：频率和哈夫曼表&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;Huffman encoding: After compression&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;01 01 01 01 01 00001 00001 1 1 1 1 1 1 1 1 1 001 001 001 001 000000 000001 011 011 011 011 0001 0001 0001&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;此处省略了一行乱码，避免渲染异常...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用哈夫曼编码，数据从29个字符减少到10个字节。当然这没包含频率与编码表，这个表必须和压缩后的数据一起存储才有意义；本例中，频率表比压缩后的数据还要大，但在多数情况下，频率表的大小是微不足道的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当然，将 RLE 和哈夫曼编码结合使用是可能的，首先执行 RLE，然后将压缩后的结果交给哈夫曼算法处理。对于简单的图片，这会产生特别好的结果：上面的图1通过使用GIF文件格式可以从一个95kB的位图压缩成一个 4kB 的文件，GIF 文件格式就是结合使用了 RLE，哈夫曼编码以及其他算法。&lt;/p&gt;
&lt;h2&gt;感知：有损编码&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上述方法可以用于以一种能够完美重现的方式对数据进行压缩。这种压缩的用例包括文档和软件程序，对于这种用例来说，任意值的丢失或损坏都可能使得文件不再有价值。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在特定情况下，对于需要处理的数据进行完美重现是不必要的：一个近似的结果就足够了。通常，这些情况出现在多媒体应用中：超出人类听觉范围的声音不需要记录，人眼无法识别的颜色与梯度的细微之处也无需重现。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;一个经典的示例是 MPEG 音频标准---通过去除高频声音相关的额外数据来降低音频文件的大小。这个标准的 Layer-3 规格允许多种去除数据的设定，这样渐进地从音频样本中去除更多的信息。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/fOKA1Qqg4LZmy8r.gif&apos; title=&apos;compression-mp3.gif&apos; alt=&apos;compression-mp3.gif&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图2：经 MPEG 音频 Layer-3 编码的 Yardım Et (&lt;a href=&apos;http://www.morveotesi.com/&apos;&gt;Mor ve Ötesi&lt;/a&gt;, &quot;Dünya Yalan Söylüyor&quot;)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上图2中，两个波形叠加在一起：红色的为原来的歌曲波形，覆盖在其上的蓝色是经充分压缩的变体。展示的样本长度为1.5秒；作为原来波形文件的一部分，这段样本存储为 160kB 的数据。经压缩的变体，长度相同，但仅占用48kB的空间。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这是通过 MPEG 音频压缩算法得到的，调整歌曲的频率属性，去除超出人类听力范围（高至大约20kHz）的部分。这样，如上可见，并未显著地影响产生的波形，因此经压缩的声音不会明显地不同于原有的声音。&lt;/p&gt;
&lt;h2&gt;扔掉数据：视觉有损编码&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;正如声音文件的高频部分人耳无法辨别，图片也有高频部分：颜色的变化之处不足以人眼区分，或者由黑到白的渐变过程是如此的迅速导致无法看到渐变的部分。与声音处理一样，也可以从图片中去除这些高频部分；这就是JPEG图片格式的前提。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;JPEG 应用了 MPEG 音频所使用算法的一种变种，从包含于图片的频率部分抽取一个二维映射；该算法继而裁剪到这个频率部分，并重新合成图片。如下所示是这个过程的一个例子。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/I764aQWydBZgfew.gif&apos; title=&apos;compression-jpeg-sharp.gif&apos; alt=&apos;compression-jpeg-sharp.gif&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图3：JPEG压缩应用于一张块状图&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;图3中，一张由4个16x16像素方块构成的图片，与该图片经JPEG编码后的图片进行比较。颜色或亮度上的尖锐变化被定义为高视觉频率的结果。这正是 JPEG 要去除的地方。结果，编码后图片的边缘比较模糊。4个方块的接触点特别模糊。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但JPEG的强大之处并不是编码具有尖锐变化边沿和角落的图片，而是低视觉频率的图片；照片就是其中的一个典型例子。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/lfpyiLuRmbG2PSh.gif&apos; title=&apos;compression-jpeg-photo.gif&apos; alt=&apos;compression-jpeg-photo.gif&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图4：JPEG压缩应用于一张照片&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;图4中，一张安塔利亚港的300x300图片，经过JPEG编码。原来的位图为270kB，经去除尖锐边缘和颜色变化，JPEG 能够产生一张22kB的图片。对于人眼而言，图片的变化很小；即使像素有所改变，图片所展示的景色也完好无损。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这就是有损编码背后的主要概念：确切的数据并不重要，重要的是数据所呈现的信息。将 JPEG 算法用于编码软件程序是不明智的，但当数据表达了不必要的过多信息之时，有损编码就派上用场了。&lt;/p&gt;
&lt;h2&gt;感知冗余：视频编码&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;说到视频剪辑，通过结合无损和有损编码背后的原则，进一步压缩数据是有可能的。构建一个视频剪辑片段的最简单最幼稚的方法是合并连续的图片，作为视频帧来看待： MJPEG 视频文件格式就是将一系列的 JPEG 图片看到独立的视频帧。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种方法忽视了视频片段中固有的数据冗余：一个给定帧中包含的大多数信息同样会包含于其前一帧中。任何特定帧中仅有一小部分是新的信息；通过计算这部分信息所处的位置，然后仅存储这部分信息数据，那么就有可能大大地缩减视频帧的数据大小。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/z3KPQkNi2XY9WlG.gif&apos; title=&apos;compression-mpeg-diff.gif&apos; alt=&apos;compression-mpeg-diff.gif&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图5：连续视频帧，以及它们的不同之处（&lt;a href=&apos;http://jpl.nasa.gov/&quot;&apos;&gt;NASA JPL&lt;/a&gt;）&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;图5中，较之第一帧，视频的第二帧显示的变化非常小：仅仅航天飞机的排气羽流有显著的运动。事实上，发射塔后面的航天飞机固体助推器（SRB）(译注：见Wikipedia词条&lt;a href=&apos;http://zh.wikipedia.org/wiki/%E8%88%AA%E5%A4%A9%E9%A3%9E%E6%9C%BA%E5%9B%BA%E4%BD%93%E5%8A%A9%E6%8E%A8%E5%99%A8&apos;&gt;航天飞机固体助推器&lt;/a&gt;)和天空在两帧之间完全没有变化。那么就不用存储图片的这些部分，可能存储一个值：“没有变化”就可以了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;MPEG视频标准利用了这种内在的冗余作为算法的一部分。理论上，仅仅拍摄（a shot）的初始帧需要完整存储：拍摄的任何运动部分都可以作为与前一帧的相异之处来存储。初始帧，也称为一个内帧，存储为一张标准的 JPEG 图片，而后续的差异帧被称为间帧，或预测帧。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;实际上，MPEG视频标准是以“流”来设计的，这样就能够从拍摄（a shot）的中间开始观看视频片段。但若仅提供视频的一个内帧（I-帧），那么预测帧（P-帧）是不可能插入它们的差异的。所以，通常会把I-帧每隔一定时间插入到视频片段中，而不管拍摄的场景（a shot）是否变化。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2025/06/23/ogWmUIQFOqe8TBc.gif&apos; title=&apos;compression-mpeg-graph.gif&apos; alt=&apos;compression-mpeg-graph.gif&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;图6：一个4秒的MPEG视频片段的帧大小（&lt;a href=&apos;http://news.bbc.co.uk/&quot;&apos;&gt;BBC News&lt;/a&gt;）&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上图6中，视频片段每间隔25帧或一秒插入I-帧。后续的每个P-帧都比I-帧小得多，由于政治家在接受采访时一般都不会频繁移动，因此不同视频帧之间的不同之处更少。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;图6使用的例子是一个4秒的400x224视频片段。以原始位图形式粗糙农户，生成文件的大小有26.7MB；通过结合使用有损编码和冗余的技术，MPEG 视频标准能够将视频大小缩减到300kB，减小了99%。&lt;/p&gt;
&lt;h2&gt;总结：什么情况下可以有损编码&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本文所列举的有损编码的例子都是应用于特殊情况的：音频，视频，图片。仅对于这些或者其他相关的东西，感知才是压缩过程中的一个重大因素。对于其他压缩目标，比如文档或软件程序，数据是什么样的就保存为什么样，非常重要。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;人们一直在开发更加高级的特殊压缩方法，但数据压缩的多数常见实现都是基于本文讲述的技术：去除冗余和重复信息。当存在大量冗余数据时，数据压缩会表现得非常好，所以不要试图去压缩一个已经压缩过的文件。&lt;/p&gt;</description>
            <pubDate>2013-02-27</pubDate>
            <link>https://blog.xiayf.cn/posts/a-introduction-to-compression.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/a-introduction-to-compression.html</guid>
        </item>
        
        <item>
            <title>译文：Python 格式字符串</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://mkaz.com/solog/python-string-format&apos;&gt;Python String Format&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;每次使用Python的格式字符串（string formatter），2.7及以上版本的，我都会犯错，并且有生之年，我想我都理解不了它们的文档。我非常习惯于更老的 &lt;code&gt;%&lt;/code&gt; 方法。所以着手编写自己的格式字符串手册。若你有一些其他好的示例请告知我。&lt;/p&gt;
&lt;h2&gt;格式字符串手册&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;数字格式化&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面的表格展示了使用 Python 的后起新秀 &lt;code&gt;str.format()&lt;/code&gt; 格式化数字的多种方法，包含浮点数格式化与整数格式化示例。可使用 &lt;code&gt;print(&amp;quot;FORMAT&amp;quot;.format(NUMBER));&lt;/code&gt; 来运行示例，因此你可以运行： &lt;code&gt;print(&amp;quot;{:.2f}&amp;quot;.format(3.1415926));&lt;/code&gt; 来得到第一个示例的输出。&lt;/p&gt;
&lt;table class=&quot;table table-bordered&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th style=&quot;text-align: left&quot;&gt;数字&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;格式&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;输出&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;3.1415926&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:.2f}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;3.14&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;保留小数点后两位&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;3.1415926&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:+.2f}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;+3.14&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;带符号保留小数点后两位&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;-1&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:+.2f}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;-1.00&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;带符号保留小数点后两位&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;2.71828&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:.0f}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;3&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;不带小数&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;5&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:0&amp;gt;2d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;05&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;数字补零 (填充左边, 宽度为2)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;5&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:x&amp;lt;4d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;5xxx&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;数字补x (填充右边, 宽度为4)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;10&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:x&amp;lt;4d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;10xx&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;数字补x (填充右边, 宽度为4)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;1000000&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:,}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;1,000,000&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;以逗号分隔的数字格式&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;0.25&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:.2%}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;25.00%&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;百分比格式&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;1000000000&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:.2e}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;1.00e+09&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;指数记法&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;13&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:10d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;13&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;右对齐 (默认, 宽度为10)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;13&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:&amp;lt;10d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;13&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;左对齐 (宽度为10)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;13&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&lt;code&gt;{:^10d}&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;13&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;p class=&quot;text-align-left&quot;&gt;中间对齐 (宽度为10)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;code&gt;string.format()&lt;/code&gt; 基础&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下是两个基本字符串替换的示例，符号 &lt;code&gt;{}&lt;/code&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;是替换变量的占位符。若没有指定格式，则直接将变量值作为字符串插入。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;s1 = &amp;amp;quot;so much depends upon {}&amp;amp;quot;.format(&amp;amp;quot;a red wheel barrow&amp;amp;quot;)
s2 = &amp;amp;quot;glazed with {} water beside the {} chickens&amp;amp;quot;.format(&amp;amp;quot;rain&amp;amp;quot;, &amp;amp;quot;white&amp;amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你也可以使用变量的位置数值，在字符串中改变它们，进行格式化时，会更加灵活。如果搞错了顺序，你可以轻易地修正而不需要打乱所有的变量。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;s1 = &amp;amp;quot; {0} is better than {1} &amp;amp;quot;.format(&amp;amp;quot;emacs&amp;amp;quot;, &amp;amp;quot;vim&amp;amp;quot;)
s2 = &amp;amp;quot; {1} is better than {0} &amp;amp;quot;.format(&amp;amp;quot;emacs&amp;amp;quot;, &amp;amp;quot;vim&amp;amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;更老的格式字符串符号&quot;%&quot;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python 2.6 之前，格式字符串的使用方法相对更简单些，虽然其能够接收的参数数量有限制。这些方法在 Python 3.3 中仍然有效，但已有含蓄的警告称将完全淘汰这些方法，目前还没有明确的时间进度表。&lt;a href=&apos;http://www.python.org/dev/peps/pep-3101/&apos;&gt;PEP-3101&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;格式化浮点数：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;pi = 3.14159
print(&amp;amp;quot; pi = %1.2f &amp;amp;quot;, % pi)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;多个替换值&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;s1 = &amp;amp;quot;cats&amp;amp;quot;
s2 = &amp;amp;quot;dogs&amp;amp;quot;
s3 = &amp;amp;quot; %s and %s living together&amp;amp;quot; % (s1, s2)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;没有足够的参数&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用老的格式化方法，我经常犯错“TypeError: not enough arguments for formating string”，因为我数错了替换变量的数量，编写如下这样的代码很容易漏掉变量。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;set =  (%s, %s, %s, %s, %s, %s, %s, %s) &amp;amp;quot; % (a,b,c,d,e,f,g,h,i)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于新的Python格式字符串，可以使用编号的参数，这样你就不需要统计有多少个参数。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;set = set = &amp;amp;quot; ({0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}) &amp;amp;quot;.format(a,b,c,d,e,f,g)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;更多&lt;code&gt;.format()&lt;/code&gt;的格式字符串方法&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;format()&lt;/code&gt; 函数提供了相当多的附加特性和功能，如下是一些有用的使用 &lt;code&gt;.format()&lt;/code&gt; 的技巧。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;命名参数&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你可以将新的格式字符串用作模板引擎，使用命名参数，这样就不要求有严格的顺序。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;madlib = &amp;amp;quot; I {verb} the {object} off the {place} &amp;amp;quot;.format(verb=&amp;amp;quot;took&amp;amp;quot;, object=&amp;amp;quot;cheese&amp;amp;quot;, place=&amp;amp;quot;table&amp;amp;quot;)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I took the cheese off the table&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;多次复用同一个变量&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用&lt;code&gt;%&lt;/code&gt; 格式字符串，要求变量有严格的次序，而&lt;code&gt;.format()&lt;/code&gt;方法允许如上所示那样任意排列参数，也允许复用。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;str = &amp;amp;quot;Oh {0}, {0}! wherefore art thou {0}?&amp;amp;quot;.format(&amp;amp;quot;Romeo&amp;amp;quot;)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; Oh Romeo, Romeo! wherefore art thou Romeo?&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;将数值转换为不同的进制&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以使用如下字母来将数字转换成字母代表的进制，&lt;strong&gt;d&lt;/strong&gt;ecimal，he&lt;strong&gt;x&lt;/strong&gt;，&lt;strong&gt;o&lt;/strong&gt;ctal, &lt;strong&gt;b&lt;/strong&gt;inary。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;print(&amp;amp;quot;{0:d} - {0:x} - {0:o} - {0:b} &amp;amp;quot;.format(21))
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; 21 - 15 - 25 -10101&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;将格式作为函数来使用&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;可以将&lt;code&gt;.format()&lt;/code&gt;用作函数，这就允许在代码中将普通文本和格式区分开来。例如，你可以在程序的开头包含所有需要使用的格式，然后在后面使用。这也是一种处理国际化的好方法，国际化不仅要求不同的文本，且常常要求不同的数字格式。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;## 定义格式
email_f = &amp;amp;quot;Your email address was {email}&amp;amp;quot;.format
### 在另一个地方使用
print(email_f(email=&amp;amp;quot;bob@example.com&amp;amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;感谢 &lt;a href=&apos;http://www.reddit.com/r/Python/comments/174e1i/python_string_format_cookbook/c82ot0h&apos;&gt;earthboundkid&lt;/a&gt; 在 reddit 上提供这一技巧。&lt;/p&gt;
&lt;h2&gt;其他技巧&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;转义大括号&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用&lt;code&gt;str.format()&lt;/code&gt;时，若你需要使用大括号，只要写两次就可以了：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;print(&amp;amp;quot; The {} set is often represented as { {0} } &amp;amp;quot;.format(&amp;amp;quot;empty&amp;amp;quot;))
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The empty set is often represented as {0}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://docs.python.org/3/library/string.html&apos;&gt;Python String Library&lt;/a&gt; - 标准库文档&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2013-01-26</pubDate>
            <link>https://blog.xiayf.cn/posts/python-string-format.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/python-string-format.html</guid>
        </item>
        
        <item>
            <title>回顾2012，展望2013</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;过去的一年里发生了很多事情，很大一部分原来就已在&lt;a href=&apos;http://youngsterxyf.github.io/2012/01/01/2011-summary/&apos;&gt;2011年终-回顾与展望&lt;/a&gt;一文中提及---实习、找工作、毕业，除此之外还有：我和女朋友定亲了，总算朝着婚姻近了一步，哈哈。&lt;/p&gt;
&lt;h2&gt;实习&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于实习有太多的话想说。7个月的时间里浓缩了太多的欢乐，太欢乐了。原本以为我的读书生涯就要这么平淡无奇地结束了，没想到在这个结尾处竟然给了我个大惊喜，所谓惊喜并不是这份实习有多牛逼，而是遇到了一群欢乐的人，一群“重口味”的人，一群彪悍的人，而其中绝大部分是女人，噢，女生更恰当些。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在G1C1，我快乐地写代码，上班是种享受，我想以后很可能不会再有这样的享受了。在G1C1，我逐步地发展成为一个吃货，所以毫无疑问地胖了，原本我以为自己会一直瘦下去。另外，我也黑了，因为经过了无数次地“被黑”，但她们说我应该高兴才对，她们“黑”我是因为“爱”我。关于“黑”这件事情，刚入职的时候，我是很同情wenbin的，因为见他被“黑”得体无完肤的，可我也没逃脱作为一个G1C1码农的宿命，wenbin走后，替代了他的角色，而我走后，comen则替代了我的角色，可惜之后就不会再有了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;吃，是Google的特色，故在G1C1也不例外。因为G1C1不与其他部门在一起，所以没法吃食堂。但我们也不亏，老大带着我们吃遍了办公室方圆几里地叫得出名的饭店，吃饱吃好，并且一天一换。并且吃饭的场景实在不得不让码农感到幸福，男女比例经常是6：1，与“交大男女七比一，一对情侣三对基”的情形那是恰好相反，而且我们实验室甚至比七比一的情况还严重。所以我一直来回感受两种极端。又由于女生的食量多半偏小，作为男生，最后“扫盘”的工作那自然是义不容辞的，胖也就必然的结果了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为工作内容比较多元化，所以G1C1实习生的专业背景与就读学校覆盖面很大，可以说是“一锅大杂烩”。专业不同，并没有妨碍交流，反而使工作氛围更加活跃，具备专业特色的阐述方式与内容相互碰撞交融。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很想逐个介绍我所知道的G1C1er们，可苦于胸无半点墨水，只好作罢。但你们应知道，应相信，现在，以后，我都会一直念着你们，想着你们。感谢和你们一起度过的美好青春时光。&lt;/p&gt;
&lt;h2&gt;找工作&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我的求职经历并不顺利，主要原因是对于求职的“求”字在认识上有所偏差。我不喜欢“求”，我认为找工作就和找对象一样，我想找你，你认可我，才行。我就这样，你不要我，拉倒。这种想法导致我并没有认真准备笔试面试。其实找工作和学校里的应试是一样一样的，所以你得做题，各种应试的题目，除了一流的公司，一般公司考的都是老题目或者类似的题目。另外，要注意找工作的目标不是向公司证明你的能力，而是拿到offer，“不择手段”地拿到offer。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对自己未来几年做了基本的定位之后，我没有参加银行、国企一类公司的招聘，集中应聘技术型的私企外企大小公司，由于裸考裸面，结果多半不太理想。这里对于应聘的公司不做评价，求职的具体过程也不详述，只是真心感谢那些认可我赏识我的人，还有虽然拒了我但真心帮助我的人，谢谢你们。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最后，腾讯收了我，虽然待遇和职位的工作内容不是很理想，但我想应该是个不错的机会，值得以后好好努力工作，感谢当时的几个面试官，也就是我以后的同事，当然还要特别感谢yuye同学，你也算是一个“奇葩”吧，哈哈，没有任何贬义哦。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我之所以选择技术作为我的职业目标，一方面当然是因为我本来学的就是技术，但更重要的是因为做技术比较纯粹，我希望自己以后心里能一直很踏实安心。&lt;/p&gt;
&lt;h2&gt;毕业&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;说到毕业论文，一个字足以概括---“水”。哈哈，但幸好顺利毕业了，虽然过程很痛苦，很煎熬。现在的我无所事事，坐等毕业，哈哈。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这次毕业与本科毕业有什么本质区别呢？那就是这次我是真的要结束读书的生活了，正式进入社会，需要承担的责任也是完全不相同的，并且以后我应该不会继续深造求学了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;回顾十几年的读书生涯，实在难舍。&lt;/p&gt;
&lt;h2&gt;定亲&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;和女朋友相关的文字，我写得很少，自己也觉得有点对不住女朋友。其原因一方面是从我们认识到现在4年多的时间里，我正逐步地趋向沉默，文字表达越来越少；另一方面是我觉得幸福其实是一件挺私密的事情，不能多晒。所以，我不说并不是因为我不幸福，其实我一直幸福得偷着乐呢，哈哈。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;定亲的过程并没有想的那么顺利，要考虑很多问题，要和双方父母亲人沟通，特别是要和女朋友沟通，从恋爱逐步走向婚姻，会遇到很多很多现实的细节。面对现实，会产生矛盾，但没有什么大不了的，相爱的人请记住，矛盾没有什么大不了的，不要夸张了问题而放弃了情感。&lt;/p&gt;
&lt;h2&gt;谈谈自己&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;回顾从大一到现在的几年时间，我的变化应该算是蛮大的，我逐步地不再关注那些大层面上的事情，不去想那些形而上的问题。那些事情，那些问题，想不透，看不穿，也不会真的有解。这辈子，我们能做的其实很少很少，做些力所能及的事情也算是不浪费生命吧。也许有人认为这是“认命”了，认为我在逐渐成为一个“单向度”的人，但其实我还是想趁活着多扑腾几下的，按照自己的想法去活，只不过想法换了个方面。&lt;/p&gt;
&lt;h2&gt;未来一年&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也得为这新的一年做点规划，定点目标啥的。可以从工作、健康、情感、技术等几个方面来谈吧。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;对于工作，我希望自己能够踏实些，逐步精通工作相关的技术，多认识一些人，对所处的技术行业有个更清晰的认识。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;身心健康应该始终放在第一位，要多运动锻炼，坚持跑步什么的，多出去走走，断然拒绝“宅”的习惯，特别是要多和女朋友出去玩，这个可以做个详细的计划。时间是靠自己安排的，理由也会有千万，但都不应接受其成为不注意身心健康的原因。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;情感方面，希望自己能够一如既往，并且更加耐心，细心，注意交流沟通。另外，要尽快完成婚姻的流程。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;说到技术，还是老毛病，有太多东西想学，不过现在学习方式在逐步进入良性循环，心态上也不会那么盲目了。接下来的一年里，自己必须不避重就轻，要攻关把核心技术练扎实，多写代码，多整理总结。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;过去的一年里，书籍阅读不多，也不见得是件坏事。不过新的一年里，应该要精读一些书，包括文史与技术类的，多思考。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上述也说不上是规划，只是对自己提点要求和期望，希望自己在各方面都有所进步。&lt;/p&gt;</description>
            <pubDate>2013-01-18</pubDate>
            <link>https://blog.xiayf.cn/posts/review12-lookinto13.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/review12-lookinto13.html</guid>
        </item>
        
        <item>
            <title>译文：装饰器与函数式 Python</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文：&lt;a href=&apos;http://www.brianholdefehr.com/decorators-and-functional-python&apos;&gt;Decorators and Functional Python&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;装饰器是Python的一大特色。除了在语言中的原本用处，还帮助我们以一种有趣的方式（函数式）进行思考。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我打算自底向上解释装饰器如何工作。首先解释几个话题以帮助理解装饰器。然后，深入一点探索几个简单的装饰器以及它们如何工作。最后，讨论一些更高级的使用装饰器的方式，比如：传递可选参数给装饰器或者串接几个装饰器。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;首先以我能想到的最简单的方式来定义Python函数是什么。基于该定义，我们可以类似的简单方式来定义装饰器。&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;函数是一个完成特定任务的可复用代码块。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;好的，那么装饰器又是什么呢？&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;装饰器是一个修改其他函数的函数。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在在装饰器的定义上进行详述，先解释一些先决条件。&lt;/p&gt;
&lt;h2&gt;函数是一等对象&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python中，所有东西都是对象。这意味着可以通过名字引用函数，以及像其他对象那样传递。例如：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def traveling_function():
    print &amp;amp;quot;Here I am!&amp;amp;quot;

function_dict = {
    &amp;amp;quot;func&amp;amp;quot;: traveling_function
}

trav_func = function_dict[&amp;amp;apos;func&amp;amp;apos;]
trav_func()
# &amp;amp;gt;&amp;amp;gt; Here I am!&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;traveling_function&lt;/code&gt; 被赋值给 &lt;code&gt;function_dict&lt;/code&gt; 字典中键 &lt;code&gt;func&lt;/code&gt; 的值，仍旧可以正常调用。&lt;/p&gt;
&lt;h2&gt;一等函数允许高阶函数&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们可以像其他对象那样传递函数。可以将函数作为值传递给字典，放在列表中，或者作为对象的属性进行赋值。那为什么不能作为参数传给另一个函数呢？当然可以！如果一个函数接受另一个函数作为其参数或者返回另一个函数，则称之为高阶函数。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def self_absorbed_function():
    return &amp;amp;quot;I&amp;amp;apos;m an amazing function!&amp;amp;quot;

def printer(func):
    print &amp;amp;quot;The function passed to me says: &amp;amp;quot; + func()

# Call `printer` and give it `self_absorbed_function` as an argument
printer(self_absorbed_function)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function passed to me says: I&amp;amp;apos;m an amazing function!&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在你也看到函数可以作为参数传给另一个函数，而且传给函数的函数还可以调用。这允许我们创建一些有意思的函数，例如装饰器。&lt;/p&gt;
&lt;h2&gt;装饰器基础&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;本质上，装饰器就是一个以另一个函数为参数的函数。大多数情况下，它们会返回所包装函数的一个修改版本。来看个我们能想到的最简单的装饰器---同一性（identity）装饰器，或许对我们理解装饰器的工作原理有所帮助。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def identity_decorator(func):
    def wrapper():
        func()
    return wrapper

def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

# `decorated_function` 是 `identity_function` 返回的函数，也就是嵌套函数 `wrapper`
decorated_function = identity_function(a_function)

# 如下调用 `identity_function` 返回的函数
decorated_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这里， &lt;code&gt;identity_decorator&lt;/code&gt; 根本没有修改它包装的函数，只是简单地返回一个函数（wrapper），这个函数在被调用之时，会去调用原来作为 &lt;code&gt;identity_decorator&lt;/code&gt; 参数的函数。这是个没有用处的装饰器！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;关于 &lt;code&gt;identity_decorator&lt;/code&gt; 的有趣之处是 &lt;code&gt;wrapper&lt;/code&gt; 能够访问变量 &lt;code&gt;func&lt;/code&gt; ，即使 &lt;code&gt;func&lt;/code&gt; 并非是它的参数。这归因于闭包。&lt;/p&gt;
&lt;h2&gt;闭包&lt;/h2&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;闭包是一个花哨的术语，意为声明一个函数时，该函数会维持一个指向声明所处词法环境的引用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上例中定义的函数 &lt;code&gt;wrapper&lt;/code&gt; 能够在其局部作用域（local scope）中访问 &lt;code&gt;func&lt;/code&gt;。这意味着在 &lt;code&gt;wrapper&lt;/code&gt; （返回并赋值给变量 &lt;code&gt;decorated_function&lt;/code&gt; ）的整个生命周期内，它都可以访问 &lt;code&gt;func&lt;/code&gt; 变量。一旦 &lt;code&gt;identity_decorator&lt;/code&gt;返回，那么访问 &lt;code&gt;func&lt;/code&gt; 的唯一方式就是通过 &lt;code&gt;decorated_function&lt;/code&gt; 。 &lt;code&gt;func&lt;/code&gt; 只作为一个变量存在于 &lt;code&gt;decorated_function&lt;/code&gt; 作用域环境的内部。&lt;/p&gt;
&lt;h2&gt;一个简单的装饰器&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在我们来创建一个确实有点用的装饰器。这个装饰器所做的就是记录它所修改的函数被调用了多少次。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def logging_decorator(func):
    def wrapper():
        wrapper.count += 1
        print &amp;amp;quot;The function I modify has been called {0} time(s)&amp;amp;quot;.format(wrapper.count)
        func()
    wrapper.count = 0
    return wrapper

def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

modified_function = logging_decorator(a_function)

modified_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function I modify has been called 1 time(s).
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.

modified_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function I modify has been called 2 time(s).
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们说装饰器会修改函数，这样来想对理解也是有帮助的。但如例子所见， &lt;code&gt;logging_decorator&lt;/code&gt; 返回的是一个类似于 &lt;code&gt;a_function&lt;/code&gt; 的新函数，只是多了一个日志特性。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;上例中， &lt;code&gt;logging_decorator&lt;/code&gt; 不仅接受一个函数作为参数，并且返回一个函数， &lt;code&gt;wrapper&lt;/code&gt; 。每次 &lt;code&gt;logging_decorator&lt;/code&gt; 返回的函数得到调用，它就对 &lt;code&gt;wrapper.count&lt;/code&gt; 的值加1，打印出来，然后调用 &lt;code&gt;logging_decorator&lt;/code&gt; 包装的函数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你也许正疑惑为什么我们的计数器是 &lt;code&gt;wrapper&lt;/code&gt; 的一个属性而不是一个普通的变量。难道 &lt;code&gt;wrapper&lt;/code&gt; 的闭包环境不是让我们访问在其局部作用域中声明的任意变量么？是的，但有个问题。Python中，闭包允许对其函数作用域链中任一变量的进行任意读操作，但只允许对可变对象（列表、字典、等等）进行写操作。整数在Python中是非可变对象，因此我们不能修改 &lt;code&gt;wrapper&lt;/code&gt; 内部整型变量的值。相反，我们将计数器作为 &lt;code&gt;wrapper&lt;/code&gt; 的一个属性---一个可变对象，因此可以随我们自己增大它的值。&lt;/p&gt;
&lt;h2&gt;装饰器语法&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在前一个例子中，我们看到可以将一个函数作为参数传给装饰器，从而使用装饰器函数对该函数进行包装。然而，Python还有一个语法模式使得这一切更加直观，更容易阅读，一旦你熟悉了装饰器。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# In the previous example, we used our decorator function by passing the
# function we wanted to modify to it, and assigning the result to a variable
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m happiest when decorated.&amp;amp;quot;

# Here we will make the assigned variable the same name as the wrapped function
some_function = logging_decorator(some_function)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# We can achieve the exact same thing with this syntax:
@logging_decorator
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m happiest when decorated&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用装饰器语法，鸟瞰其中发生的事情：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;解释器到达被装饰的函数，编译 &lt;code&gt;some_function&lt;/code&gt;，并将其命名为 &apos;some_function&apos;。&lt;/li&gt;
&lt;li&gt;然后将该函数传递给装饰行中指定的装饰器函数（ &lt;code&gt;logging_function&lt;/code&gt; ）。&lt;/li&gt;
&lt;li&gt;装饰器函数（通常是用来包装原函数的另一个函数）的返回值取代原来的函数（&lt;code&gt;some_function&lt;/code&gt; ），绑定到变量名 &lt;code&gt;some_function&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;将这些步骤记住，让我们来更清晰地解释 &lt;code&gt;identity_decorator&lt;/code&gt; 。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def identity_decorator(func):
    # Everything here happens when the decorator LOADS and is passed
    # the function as decribed in step 2 above
    def wrapper():
        # Things here happen each time the final wrapped function gets CALLED
        func()
    return wrapper&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;希望那些注释有助于理解。每次调用被包装的函数，仅执行装饰器返回的函数中的指令。返回函数之外的指令仅执行一次---上述步骤2中描述的：装饰器首次接收到传递给它的待包装函数之时。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;在观察更多的有意思的装饰器之前，我想再解释一样东西。&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;*args&lt;/code&gt; 与 &lt;code&gt;**kwargs&lt;/code&gt;&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;以前你也许有时会把这两者相混淆了。让我们一次性地讨论它们。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;通过在形参列表中使用 &lt;code&gt;*args&lt;/code&gt; 语法，python函数能够接收可变数量的位置参数(positional arguments)。 &lt;code&gt;*args&lt;/code&gt; 会将所有没有关键字的参数放入一个参数元组中，在函数里可以访问元组中的参数。相反，将 &lt;code&gt;*args&lt;/code&gt; 用于函数调用时的实参列表之时，它会将参数元组展开成一系列的位置参数。&lt;/li&gt;&lt;/ul&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def function_with_many_arguments(*args):
    print args

# `args` within the function will be a tuple of any arguments we pass
# which can be used within the function like any other tuple
function_with_many_arguments(&amp;amp;apos;hello&amp;amp;apos;, 123, True)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; (&amp;amp;apos;hello&amp;amp;apos;, 123, True)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def function_with_3_parameters(num, boolean, string):
    print &amp;amp;quot;num is &amp;amp;quot; + str(num)
    print &amp;amp;quot;boolean is &amp;amp;quot; + str(boolean)
    print &amp;amp;quot;string is &amp;amp;quot; + string

arg_list = [1, False, &amp;amp;apos;decorators&amp;amp;apos;]

# arg_list will be expanded into 3 positional arguments by the `*` symbol
function_with_3_parameters(*arg_list)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; num is 1
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; boolean is False
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; string is decorators&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;重述一遍：在形参列表中， &lt;code&gt;*args&lt;/code&gt;会将一系列的参数压缩进一个名为&apos;args&apos;的元组，而在实参列表中， &lt;code&gt;*args&lt;/code&gt; 会将一个可迭代的参数数据结构展开为一系列的位置实参应用于函数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如你所见在实参展开的例子中， &lt;code&gt;*&lt;/code&gt; 符号可与&apos;args&apos;之外的名字一起使用。当压缩/展开一般的参数列表，使用 &lt;code&gt;*args&lt;/code&gt; 的形式仅仅是一种惯例。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;**kwargs&lt;/code&gt; 与 &lt;code&gt;*args&lt;/code&gt; 的行为类似，但用于关键字参数而非位置参数。如果在函数的形参列表中使用 &lt;code&gt;**kwargs&lt;/code&gt; ，它会收集函数收到的所有额外关键字参数，放入一个字典中。如果用于函数的实参列表，它会将一个字典展开为一系列的关键字参数。&lt;/li&gt;&lt;/ul&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def funtion_with_many_keyword_args(**kwargs):
    print kwargs

function_with_many_keyword_args(a=&amp;amp;apos;apples&amp;amp;apos;, b=&amp;amp;apos;bananas&amp;amp;apos;, c=&amp;amp;apos;cantalopes&amp;amp;apos;)
# &amp;amp;gt;&amp;amp;gt; {&amp;amp;apos;a&amp;amp;apos;:&amp;amp;apos;apples&amp;amp;apos;, &amp;amp;apos;b&amp;amp;apos;:&amp;amp;apos;bananas&amp;amp;apos;, &amp;amp;apos;c&amp;amp;apos;:&amp;amp;apos;cantalopes&amp;amp;apos;}&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def multiply_name(count=0, name=&amp;amp;apos;&amp;amp;apos;):
    print name * count

arg_dict = {&amp;amp;apos;count&amp;amp;apos;: 3, &amp;amp;apos;name&amp;amp;apos;: &amp;amp;apos;Brian&amp;amp;apos;}

multiply_name(**arg_dict)
# &amp;amp;gt;&amp;amp;gt; BrianBrianBrian&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;既然你理解了 &lt;code&gt;*args&lt;/code&gt; 与 &lt;code&gt;**kwargs&lt;/code&gt; 的工作原理，那么我们就继续研究一个你会发现很有用的装饰器。&lt;/p&gt;
&lt;h2&gt;缓存制表（Memoization）&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;缓存制表是避免潜在的昂贵的重复计算的一种方法，通过缓存函数每次执行的结果来实现。这样，下一次函数以相同的参数执行，就可以从缓存中获取返回结果，不需要再次计算结果。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

def memoize(func):
    cache = {}

    @wraps(func)
    def wrapper(*args):
        if args not in cache:
            cache[args] = func(*args)
        return cache[args]
    return wrapper

@memoize
def an_expensive_function(arg1, arg2, arg3):
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你可能注意到了示例代码中一个奇怪的 &lt;code&gt;@wraps&lt;/code&gt; 装饰器。在完整地讨论 &lt;code&gt;memoize&lt;/code&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;之前我将简要地解释这个装饰器。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用装饰器的一个副作用是被包装的函数失去了本来有的 &lt;code&gt;__name__&lt;/code&gt; ， &lt;code&gt;__doc__&lt;/code&gt; ， 以及 &lt;code&gt;__module__&lt;/code&gt; 属性。 &lt;code&gt;wraps&lt;/code&gt; 函数是一个包装另一个装饰器返回的函数的装饰器，将那三个属性的值恢复为函数未装饰之时的值。例如： 如果不使用 &lt;code&gt;wraps&lt;/code&gt; 装饰器， &lt;code&gt;an_expensive_function&lt;/code&gt; 的名字（通过 &lt;code&gt;an_expensive_function.__name__&lt;/code&gt; 可以看到）将是 &apos;wrapper&apos; 。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我认为 &lt;code&gt;memoize&lt;/code&gt; 是一个很好的装饰器用例。它服务于一个很多函数都需要的目的，通过将它创建为一个通用装饰器，我们可以将它的功能应用于任一能够从其中获益的函数。这就避免了在多种不同的场合重复实现这个功能。因为不需要重复自己，所以我们的代码更容易维护，并且更容易阅读和理解。只要读一个单词你就能立刻理解函数使用了缓存制表。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;需要提醒的是：缓存制表仅适用于纯函数。也就是说给定一个特定的参数设置，函数确定总会产生相同的结果。如果函数依赖于不作为参数传递的全局变量、I/O、或者其它任意可能影响返回值的东西，缓存制表会产生令人迷惑的结果！并且，一个纯函数不会有任何副作用。因此，如果你的函数会增大一个计数器，或者调用另一个对象的方法，或者其它任意不在函数的返回结果中表示的东西，当结果是从缓存中返回时，副作用操作并不会得到执行。&lt;/p&gt;
&lt;h2&gt;类的装饰器&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;最初，我们说装饰器是一个修改另一个函数的函数，但其实它们可以用于修改类或者方法。对类进行装饰并不常见，但某些情况下作为元类(metaclass)的一个替代，类的装饰器是一个有用的工具。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;foo = [&amp;amp;apos;important&amp;amp;apos;, &amp;amp;apos;foo&amp;amp;apos;, &amp;amp;apos;stuff&amp;amp;apos;]

def add_foo(klass):
    klass.foo = foo
    return klass


@add_foo
class Person(object):
    pass

brian = Person()

print brian.foo
# &amp;amp;gt;&amp;amp;gt; [&amp;amp;apos;important&amp;amp;apos;, &amp;amp;apos;foo&amp;amp;apos;, &amp;amp;apos;stuff&amp;amp;apos;]&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在，类 &lt;code&gt;Person&lt;/code&gt; 的任一对象都有一个超级重要的 &lt;code&gt;foo&lt;/code&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;属性！注意，因为我们装饰的是一个类，所以装饰器返回的不是一个函数，而是一个类。更新一下装饰器的定义：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;装饰器是一个修改函数、或方法、或类的函数。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;装饰器类&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;事实证明我早先对你隐瞒了一些其它事情。不仅装饰器可以装饰一个类，并且装饰器也可以是一个类！对于装饰器的唯一要求就是它的返回值必须可调用(callable)。这意味着装饰器必须实现 &lt;code&gt;__call__&lt;/code&gt; 魔术方法，当你调用一个对象时，会隐式调用这个方法。函数当然是隐式设置这个方法的。我们重新将 &lt;code&gt;identity_decorator&lt;/code&gt; 创建为一个类来看看它是如何工作的。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class IdentityDecorator(object):
    def __init__(self, func):
        self.func = func

    def __call__(self):
        self.func()


@IdentityDecorator
def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

a_function()
# &amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如下是上例中发生的事情：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当 &lt;code&gt;IdentityDecorator&lt;/code&gt; 装饰 &lt;code&gt;a_function&lt;/code&gt; 时，它的行为就和装饰器函数一样。这个代码片段等价于上例中的装饰器语法： &lt;code&gt;a_function = IdentityDecorator(a_function)&lt;/code&gt; 。调用（实例化）该装饰器类时，需将其装饰的函数作为一个实参传递给它。&lt;/li&gt;
&lt;li&gt;实例化 &lt;code&gt;IdentityDecorator&lt;/code&gt; 之时，会以被装饰的函数作为实参调用初始化函数 &lt;code&gt;__init__&lt;/code&gt; 。本例中，初始化函数所做的事情就是将被装饰函数赋值给一个属性，这样之后就可以通过其它方法进行调用。&lt;/li&gt;
&lt;li&gt;最后，调用 &lt;code&gt;a_function&lt;/code&gt; （实际上是返回的包装了 &lt;code&gt;a_function&lt;/code&gt; 的 &lt;code&gt;IdentityDecorator&lt;/code&gt; 对象）之时，会调用对象的 &lt;code&gt;__call__&lt;/code&gt; 方法。这仅是一个同一性装饰器，所以方法只是简单地调用了该类所装饰的函数。&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;再次更新一下我们对装饰器的定义！&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;装饰器是一个修改函数、方法或者类的可调用对象。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;带参数的装饰器&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有时，需要根据不同的情况改变装饰器的行为。你可以通过传参来做到这一点。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

def argumentative_decorator(gift):
    def func_wrapper(func):
        @wraps(func)
        def returned_wrapper(*args, **kwargs):
             print &amp;amp;quot;I don&amp;amp;apos;t like this &amp;amp;quot; + gift + &amp;amp;quot;you gave me!&amp;amp;quot;
             return func(gift, *args, **kwargs)
        return returned_wrapper
    return func_wrapper

@argumentative_decorator(&amp;amp;quot;sweater&amp;amp;quot;)
def grateful_function(gift):
    print &amp;amp;quot;I love the &amp;amp;quot; + gift + &amp;amp;quot;!Thank you!&amp;amp;quot;

grateful_function()
# &amp;amp;gt;&amp;amp;gt; I don&amp;amp;apos;t like this sweater you gave me!
# &amp;amp;gt;&amp;amp;gt; I love the sweater! Thank you!&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们来看看如果不使用装饰器语法这个装饰器函数是如何工作的：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# If we tried to invoke without an argument:
grateful_function = argumentative_function(grateful_function)

# But when given an argument, the pattern changes to:
grateful_function = argumentative_decorator(&amp;amp;quot;sweater&amp;amp;quot;)(grateful_function)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;需要注意的地方是：当给定参数，首先仅以那些参数调用装饰器---被包装的函数并不在参数中。装饰器调用返回后，装饰器要包装的函数被传递给装饰器初始调用返回的函数（本例中，为 &lt;code&gt;argumentative_decorator(&amp;quot;sweater&amp;quot;)&lt;/code&gt; 的返回值）。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;逐步地：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;解释器到达被装饰函数之处，编译 &lt;code&gt;grateful_function&lt;/code&gt; ，并将其绑定到名字&apos;grateful_function&apos;。&lt;/li&gt;
&lt;li&gt;传递参数&quot;sweater&quot;调用 &lt;code&gt;argumentative_decorator&lt;/code&gt; ，返回 &lt;code&gt;func_wrapper&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;以 &lt;code&gt;grateful_function&lt;/code&gt; 为参调用 &lt;code&gt;func_wrapper&lt;/code&gt; ，返回 &lt;code&gt;returned_wrapper&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;最后， &lt;code&gt;returned_wrapper&lt;/code&gt; 取代原来的函数 &lt;code&gt;grateful_function&lt;/code&gt; ，并绑定到名字&apos;grateful_function&apos; 。&lt;/li&gt;&lt;/ol&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我想这一过程相比没有装饰器参数理解起来更难一点，但是如果你花些时间将其理解通透，我希望是有意义的。&lt;/p&gt;
&lt;h2&gt;带可选参数的装饰器&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有多种方式让装饰器接受可选参数。根据你是想使用位置参数、关键字参数还是两者皆是，需要使用稍微不同的模式。如下我将展示一种接受一个可选关键字参数的方式：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

GLOBAL_NAME = &amp;amp;quot;Brian&amp;amp;quot;

def print_name(function=None, name=GLOBAL_NAME):
    def actual_decorator(function):
        @wraps(function)
        def returned_func(*args, **kwargs):
            print &amp;amp;quot;My name is &amp;amp;quot; + name
            return function(*args, **kwargs)
        return returned_func

    if not function:    # User passed in a name argument
        def waiting_for_func(function):
            return actual_decorator(function)
        return waiting_for_func

    else:
        return actual_decorator(function)

@print_name
def a_function():
    print &amp;amp;quot;I like the name!&amp;amp;quot;

@print_name(name=&amp;amp;apos;Matt&amp;amp;apos;)
def another_function():
    print &amp;amp;quot;Hey, that&amp;amp;apos;s new!&amp;amp;quot;

a_function()
# &amp;amp;gt;&amp;amp;gt; My name is Brian
# &amp;amp;gt;&amp;amp;gt; I like that name!

another_function()
# &amp;amp;gt;&amp;amp;gt; My name is Matt
# &amp;amp;gt;&amp;amp;gt; Hey, that&amp;amp;apos;s new!&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果我们传递关键字参数 &lt;code&gt;name&lt;/code&gt; 给 &lt;code&gt;print_name&lt;/code&gt;，那么它的行为就与前一个例子中的 &lt;code&gt;argumentative_decorator&lt;/code&gt; 相似。即，首先以 &lt;code&gt;name&lt;/code&gt; 为参调用 &lt;code&gt;print_name&lt;/code&gt; 。然后，将待包装的函数传递给首次调用返回的函数。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果我们没有提供 &lt;code&gt;name&lt;/code&gt; 实参， &lt;code&gt;print_name&lt;/code&gt; 的行为就与前面我们看到的不带参数的装饰器一样。装饰器仅以待包装的函数作为唯一的参数进行调用。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;print_name&lt;/code&gt; 支持两种可能性。它会检查是否收到作为参数的被包装函数。如果没有，则返回函数&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;code&gt;waiting_for_func&lt;/code&gt;，该函数可以被包装函数作为参数进行调用。如果收到被包装函数作为参数，则跳过中间步骤，直接调用 &lt;code&gt;actual_decorator&lt;/code&gt; 。&lt;/p&gt;
&lt;h2&gt;串接装饰器&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;现在来探索一下今天要讲的最后一个装饰器的特性：串接。你可以在任意给定的函数之上堆叠使用多个装饰器， 这种构建函数的方式与使用多重继承构建类相类似。不过最好不要疯狂使用这种特性。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@print_name(&amp;amp;apos;Sam&amp;amp;apos;)
@logging_decorator
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m the wrapped function!&amp;amp;quot;

some_function()
# &amp;amp;gt;&amp;amp;gt; My name is Sam
# &amp;amp;gt;&amp;amp;gt; The function I modify has been called 1 time(s).
# &amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m the wrapped function!&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;当你串接使用装饰器时，它们堆叠的顺序是自底向上的。将被包装的函数 &lt;code&gt;some_function&lt;/code&gt; 经编译后传递给它之上的第一个装饰器（ &lt;code&gt;logging_decorator&lt;/code&gt; ）。然后第一个装饰器的返回值被传递给第二个装饰器。依此逐个应用链上每个装饰器。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;因为我们使用的两个装饰器都是 &lt;code&gt;print&lt;/code&gt; 一个值，然后执行传递给它们的函数，这意味着当调用被包装函数时，链中的最后一个装饰器 &lt;code&gt;print_name&lt;/code&gt; 打印输出中的第一行。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我认为装饰器最大的好处之一在于让你能够从更高的抽象层次进行思考。假如你开始阅读一个函数定义，看到有一个 &lt;code&gt;memoize&lt;/code&gt; 装饰器，你立刻就能明白你正在看的是一个使用缓存制表的函数。如果缓存制表的代码包含在函数体内，就会需要额外的脑力进行解析，并且会有引入误解的可能。使用装饰器也允许代码复用，从而节省时间、简化调试，并且使得重构更加容易。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;玩玩装饰器也是一种很好的学习函数式概念（如高阶函数与闭包）的方式。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我希望本文阅读起来很愉快，并且内容翔实。&lt;/p&gt;</description>
            <pubDate>2013-01-04</pubDate>
            <link>https://blog.xiayf.cn/posts/decorators-and-functional-python.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/decorators-and-functional-python.html</guid>
        </item>
        
        <item>
            <title>译文：Python 装饰器入门</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;原文: &lt;a href=&apos;http://www.thumbtack.com/engineering/a-primer-on-python-decorators/&apos;&gt;A primer on Python decorators&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python允许你，作为程序员，使用函数完成一些很酷的事情。在Python中，函数是&lt;a href=&apos;http://en.wikipedia.org/wiki/First-class_function&apos;&gt;一等对象(first-class object)&lt;/a&gt;，这就意味着你可以像使用字符串，整数，或者任何其他对象一样使用函数。例如，你可以将函数赋值给变量:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def square(n):
...     return n * n;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; square(4)
16
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; alias = square
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; alias(4)
16&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然而，一等函数的真正威力在于你可以把函数传给其他函数，或者从其他函数中返回函数。Python的内置函数map利用了这种能力：给map传个函数以及一个列表，它会依次以列表中每个元素为参数调用你传给它的那个函数，从而生成一个新的列表。如下所示的例子中应用了上面的那个square函数:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; number = [1, 2, 3, 4, 5]
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; map(square, numbers)
[1, 4, 9, 16, 25]&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如果一个函数接受其他函数作为参数，以及/或者返回一个函数，那么它就被称为&lt;a href=&apos;http://en.wikipedia.org/wiki/Higher-order_function&apos;&gt;高阶函数&lt;/a&gt; 。虽然map函数只是简单地使用了我们传给它的函数，而没有改变这个函数，但我们也可以使用高阶函数去改变其他函数的行为。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;例如，假设有这样一个函数，会被调用很多次，以致运行代价非常昂贵:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def fib(n):
...      &amp;amp;quot;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;quot;
...      return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们一般会保存计算过程中每次递归调用的结果，这样，对于函数调用树中经常出现某个n，当需要计算n对应的结果时，就不需要重复计算了。有多种方式可以做到这点。例如，我们可以将这些结果存在一个字典中，当以某个值为参数调用fib函数时，就先到这个字典去查一下其结果是否已经计算出来了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但这样的话，每次我们想要调用fib函数，都需要重复那段相同的字典检查样板式代码。相反，如果让fib函数自己在内部负责存储其结果，那么在其他代码中调用fib，就非常方便，只要简单地调用它就行了。这样一种技术被称为&lt;a href=&apos;http://en.wikipedia.org/wiki/Memoization&apos;&gt;memoization&lt;/a&gt;(注意没有字母r的哦)。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我们可以把这种memoization代码直接放入fib函数，但是Python为我们提供了另外一种更加优雅的选择。因为可以编写修改其他函数的函数，那么我们可以编写一个通用的memoization函数，以一个函数作为参数，并返回这个函数的memoization版本:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def memoize(fn):
    stored_results = {}

    def memoized(*args):
        try:
            # try to get the cached result
            return stored_results[args]
        except KeyError:
            # nothing was cached for those args. let&amp;amp;apos;s fix that.
            result = stored_results[args] = fn(*args)
            return result
    return memoized&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;如上， &lt;code&gt;memoize&lt;/code&gt; 函数以另一个函数作为参数，函数体中创建了一个字典对象用来存储函数调用的结果：键为被memoized包装后的函数的参数，值为以键为参数调用函数的返回值。 &lt;code&gt;memoize&lt;/code&gt; 函数返回一个新的函数，这个函数会首先检查在 &lt;code&gt;stored_results&lt;/code&gt; 字典中是否存在与当前参数对应的条目；如果有，对应的存储值会被返回；否则，就调用经过包装的函数，存储其返回值，并且返回给调用者。memoize返回的这种新函数常被称为&quot;包装器&quot;函数，因为它只是另外一个真正起作用的函数外面的一个薄层。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很好，现在有了一个memoization函数，我们可以把fib函数传给它，从而得到一个经过包装的fib，这个版本的fib函数不需要重复以前那样的繁重工作:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
fib = memoize(fib)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;通过高阶函数memoize，我们获得了memoization带来的好处，并且不需要对fib函数自己做出任何改变，以免夹杂着memoization的代码而模糊了函数的实质工作。但是，你也许注意到上面的代码还算有点别扭，因为我们必须写3遍fib。由于这种模式-传递一个函数给另一个函数，然后将结果返回给与原来那个函数同名的函数变量-在使用包装器函数的代码中极为常见，Python为其提供了一种特殊的语法：装饰器:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memoize
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n -1)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这里，我们说memoize函数装饰了fib函数。需要注意的是这仅是一种语法上的简便写法(译注：就是我们常说的&quot;语法糖&quot;)。这段代码与前面的代码片段做的是同样的事情：定义一个名为fib的函数，把它传给memoize函数，将返回结果存为名为fib的函数变量。特殊的(看起来有点奇怪的)@语法只是减少了冗余。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;你可以将多个装饰器堆叠起来使用，它们会自底向上地逐个起作用。例如，假设我们还有另一个用来帮助调试的高阶函数:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def make_verbose(fn):
    def verbose(*args):
        # will print (e.g.) fib(5)
        print &amp;amp;apos;%s(%s)&amp;amp;apos; % (fb.__name__, &amp;amp;apos;, &amp;amp;apos;.join(repr(arg) for arg in args))
        return fn(*args)   # actually call the decorated function

    return verbose&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;下面的两个代码片段做的是同样的事情:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memoize
@make_verbose
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
fib = memoize(make_verbose(fib))&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;有趣的是，Python并没有限制你在@符号后只能写一个函数名：你也可以调用一个函数，从而能够高效地传递参数给装饰器。假设我们并不满足于简单的memoization，还想将函数的结果存储到&lt;a href=&apos;http://memcached.org/&apos;&gt;memcached&lt;/a&gt;中。如果你已经写了一个 &lt;code&gt;memcached&lt;/code&gt; 装饰器函数，那么可以(例如)传递一个服务器地址给它:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memcached(&amp;amp;apos;127.0.0.1:11211&amp;amp;apos;)
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;非装饰器语法的写法会如下展开:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;fib = memcached(&amp;amp;apos;127.0.0.1:11211&amp;amp;apos;)(fib)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python配备有一些作为装饰器使用的非常有用的函数。例如，Python有一个 &lt;code&gt;classmethod&lt;/code&gt; 函数，可以创建大致类似于java的静态方法:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class Foo(object):
    SOME_CLASS_CONSTANT = 42

    @classmethod
    def add_to_my_constant(cls, value):
        # Here, `cls` will just be Foo, buf if you called this method on a
        # subclass of Foo, `cls` would be that subclass instead.
        return cls.SOME_CLASS_CONSTANT + value

Foo.add_to_my_constant(10)  # =&amp;amp;gt; 52

# unlike in Java, you can also call a classmethod on an instance
f = Foo()
f.add_to_my_constant(10)    # =&amp;amp;gt; 52&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;旁注：文档字符串&lt;/h2&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python函数可以包含更多的信息，而不仅仅是代码：它们也包含有用的帮助信息，比如函数名称，文档字符串:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def fib(n):
...     &amp;amp;quot;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;quot;
...     return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
...
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;fib&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__
&amp;amp;apos;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;Python内置函数&lt;a href=&apos;http://docs.python.org/library/functions.html#help&apos;&gt;help&lt;/a&gt;输出的就是这些信息。但是，当函数被包装之后，我们看到就是包装器函数的名称和文档字符串了:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib = memoized(fib)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;memoized&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那样的信息并没有什么用处。幸运的是，Python包含一个名为 &lt;code&gt;functools.wraps&lt;/code&gt; 的助手函数，能够把函数的帮助信息拷贝到其包装器函数:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;import functools
def memoize(fn):
    stored_results = {}
        
    @functools.wraps(fn)
    def memoized(*args):
        # (as before)

    return memoized&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;使用装饰器帮助你编写装饰器会使很多事情令人非常满意。现在，如果使用更新过的memoize函数重试前面的代码，我们将会看到得到保留的文档:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib = memoized(fib)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;fib&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__
&amp;amp;apos;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2012-07-30</pubDate>
            <link>https://blog.xiayf.cn/posts/a-primer-on-python-decorators.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/a-primer-on-python-decorators.html</guid>
        </item>
        
        <item>
            <title>关于技术的学习方法</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;关于学习，时间短与效果好始终是一对矛盾的统一体。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;很多时候，要想在最短的时间内完成一件事情，最好的方法就是依葫芦画瓢，但这样的话，即使完成了事情，也只是知其然而不知其所以然，长久来看，对于学习者的能力不会有多大的提高。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从长远来看，要想自己基础扎实，能力强，那就得一步一步的来，从基础知识开始，一点一点的搞懂，但这种方式需要花费很多时间，短时间内效果不明显。而且，可能效果没有预期的那么好。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么，如果做个权衡呢？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;我想，也许最好的学习方式是：先依葫芦画瓢地实践，获得一些直观感受，最好还有一些疑问。在实践完成之后，在整理自己的疑问，以及实践中涉及的知识要点，通过查阅图书或者网络资料，逐个知识点巩固，逐个解决疑问，并整理成文。这个整理总结的过程可能需要较长的时间。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这种方式的优势在于：1.能让你快速地完成事情；2.实践中用到的知识多半会在以后的实践中经常用到，掌握的就是一些最重要的东西，而不会学习一些很少使用的深奥偏门知识。&lt;/p&gt;</description>
            <pubDate>2012-05-11</pubDate>
            <link>https://blog.xiayf.cn/posts/about-method-of-learning-technology.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/about-method-of-learning-technology.html</guid>
        </item>
        
        <item>
            <title>学习的"道"与"术"</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;读研以来，一直觉得自己的学习方法不够高效。试图将要学习的东西进行分类，然后以不同的方法学习之。那么该如何分类呢？我觉得以&quot;道&quot;与&quot;术&quot;区分之比较合适。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;何为&quot;道 &quot;？汉语辞典中有两条解释：&lt;strong&gt;1.指法则、规律；2.学术或宗教的思想体系&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;何为&quot;术&quot;？：&lt;strong&gt;技艺&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;字面理解，“术”更为具体，是完成一件事情的具体过程。而“道”者则是指导实践的思想，是能够举一反三的事物规律。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么是否“道”比“术”更重要呢？我想未必。任何理论，任何“道”都最终来源于“术”的实践过程，也最终需要在“术”上得到实施，才能体现其价值。“道”与“术”两者相辅相成。那么在我们学习一门学问的过程中，就存在一个“道”与“术”何者为先的问题，即从“道”还是“术”入手学习？&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;孟岩说过这么一段话：&lt;/p&gt;
&lt;blockquote&gt;&lt;p class=&quot;text-align-justify&quot;&gt;我主张,在具备基础之后,学习任何新东西,都要抓住主线,突出重点。对于关键理论的学习,要集中精力,速战速决。而旁枝末节和非本质性的知识内容,完全可以留给实践去零敲碎打。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;原因是这样的,任何一个高级的知识内容,其中都只有一小部分是有思想创新、有重大影响的,而其它很多东西都是琐碎的、非本质的。因此,集中学习时必须把握住真正重要那部分,把其它东西留给实践。对于重点知识,只有集中学习其理论,才能确保体系性、连贯性、正确性,而对于那些旁枝末节,只有边干边学能够让你了解它们的真实价值是大是小,才能让你留下更生动的印象。如果你把精力用错了地方,比如用集中大块的时间来学习那些本来只需要查查手册就可以明白的小技巧,而对于真正重要的、思想性东西放在平时零敲碎打,那么肯定是事倍功半,甚至适得其反。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;虽然这段话并没有明确区分学习的“道”与“术”，以及何者为先的问题。但却大致说明了何为正确的学习方法。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;从“道”与“术”的角度来理解，那关键的，核心的，创新的部分即为“道”，“大道”。而那细节的则是“术”的部分，是需要长时间的实践的，也许只有在实践中遇到的细节才是有意义的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;但那“具备基础之后”的“基础”是什么呢？我想应该是：1.明确问题是什么。这一点是再怎么强调都不为过的。要解决一个问题却没有真正明确问题到底是什么，那你努力多半是白费的。2.这东西是用来干什么用的，是用来解决什么问题的？对于工科学生来说，学习新东西的时候，这一点是需要首先明确的，只有明确了“干什么用的”，才能抓住学习的重点，提高学习的效率。3. 与以前的类似的东西相比，其区别是什么？一样东西，一种理论其价值往往在于对前人的突破，这突破的地方才是我们真正要掌握的。在学习一样东西之前，不妨多问问自己为什么要学这个，这东西对自己有多大的提升？不断地重复学习类似的东西，多半是没有意义的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;具备了基础之后，对于关键理论的学习，是不是只要抱着书本，理论对理论的学习就行呢？我想这是万万不可的。特别是对于着重于实践性的学问，比如编程，理论对理论地学习，只会让你吃力不讨好。绝大多数的创新理论，核心理论，都不是一下子就能理解的，特别是当你对这一领域的学问并不熟悉的情况下，它需要在反复的实践中逐步地加深理解。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;那么对于关键内容的学习，我觉得这样学习会比较合适：先快速地，在尽可能短的时间内把关键内容浑沦吞枣地过一遍，能理解多少是多少，目的是为了获得一个理论的一个Big Picture，明确理论的各个部分之间的大致关系。然后对于每个部分，以及部分之间的关系，逐个地通过实践来验证你的理解，但这个实践过程并不属于“术”，因为它不是为了技艺，而只是为了验证自己对理论的理解。这一验证过程结束之后，你应该就能够对关键理论有个整体的正确的理解了。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;然后，你就放开手去干吧，去解决那些现实中的问题！&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;也许，你会说，不用这么复杂吧？是的，如果你只是为了解决一个实际的问题，而这个问题也存在相近的解决方案，你不想也不需要弄懂这个问题，好吧，那你就直接去找解决方案吧。但你解决这个问题之后，你学到了什么呢？当你再次遇到一个本质上一样的问题的时候，你还是能快速地解决么？没有真正弄懂问题，没有弄懂问题背后的知识，那你就准备着为类似的问题重复地去寻找解决方案吧。恩，看起来有点傻哦。&lt;/p&gt;</description>
            <pubDate>2012-03-31</pubDate>
            <link>https://blog.xiayf.cn/posts/dao-and-shu-about-learning.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/dao-and-shu-about-learning.html</guid>
        </item>
        
        <item>
            <title>Python 学习路线(针对具备一定编程经验者)</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;相比C,C++,JAVA等编程语言，Python是易学的。但要想深入地理解Python，并熟练地编写Python风格的Python代码。我想还是有一长段路程要走的。下面即是我的一点经验总结，主要是为了整理自己学习的思路。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;花1-2天的时间阅读一本好的Python入门书籍，并在亲手实践书中的代码。推荐入门书籍：《A byte of Python》(中文翻译《简明Python教程》)或《Practical Programming:An Introduction to Computer Science Using Python》(中文翻译《Python实践教程》)或者其他的比较薄的入门书籍。&lt;/li&gt;
&lt;li&gt;抛开书籍，用Python去写一切你想写的程序。这时最好的参考文档即为：(1).Python命令解释器中的help(),dir()辅助方法；(2).Python官网文档：&lt;a href=&apos;http://docs.python.org/&apos;&gt;http://docs.python.org/&lt;/a&gt; 。遇到不清楚的地方就用这两个方法查，再不行就去google一下。&lt;/li&gt;
&lt;li&gt;两三个月之后，积累一点的代码量，再重新找本讲解比较详细的书，重新梳理一下自己对Python的理解，纠正自己实践中一些不好的方式。推荐书籍：《Beginning Python: From Novice to Professional》(中文翻译《Python基础教程》)，《Learning Python》(中文翻译《Python学习手册》)，《Dive into Python》，《Core Python Programming》等。另外，也应该在编码的过程中重复地去查阅Python标准函数库，标准库里已有模块实现的功能就不要自己实现。&lt;/li&gt;
&lt;li&gt;之后，根据实际需要，去了解使用一下Python的各个方面的函数库(比如http://docs.python.org/modindex.html中罗列出来的，以及matplotlib, numpy等用于科学计算，图形图像处理的)，特别是诸多的Web框架(django, web2py, cherrypy, tornado等)，可以先从简单的开始。如果是对Python的底层实现感兴趣，那么就该去看看Python源码，阅读一下《Python源码剖析》; 如果对文本处理感兴趣，可以阅读一下《Text processing in Python》等； 如果对网络感兴趣，可以阅读《Foundations of Python Network Programming》，尝试实现一个简单的web server ...&lt;/li&gt;
&lt;li&gt;Python相关的开源函数库非常非常的多，各个方面的都有，所以学习者应该尝试着去用它们，了解它们，而不是啥都要自己来实现。因为Python擅长的就是快速开发，而且站在前人的肩膀上，我们才能站得更高，看得更远。当然如果你想加深自己对某个方面的理解，也可以尝试去实现一些简单的模块。&lt;/li&gt;
&lt;li&gt;总之一句话：学习Python的关键就是用！而且是要多用别人的。动手实践才是王道！那么多优秀的开源函数库不要浪费了！&lt;/li&gt;&lt;/ol&gt;</description>
            <pubDate>2012-02-21</pubDate>
            <link>https://blog.xiayf.cn/posts/the-path-of-learning-python.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-path-of-learning-python.html</guid>
        </item>
        
        <item>
            <title>2011年终-回顾与展望</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;昨晚实验室聚餐，和师兄们喝醉了，明年的这个时候，我也就和他们一样将要毕业。时间，总是往前看觉得很漫长，可回过头去看看，一年也就是瞬间的事情。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2011，我从研一走向研二，2012，我将从研二走向研三，继而毕业，工作。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;回顾过去一年，于我自己而言，过得很平淡，也许是大学以来最平淡的一年，只能说也许，因为对于2011，我记不得太多的事情。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，我，一个技术男，比以前更宅，话也相对少了很多，直接表现为QQ空间或者校内上的文字写得很少。很少和别人谈论自己，因为我觉得纠结于那个“小我”是件很“小青年”的事情。人与人之间不可避免的隔膜导致了个人的事情不管多大在别人眼里都是微不足道的，在别人的心里掀不起半点波澜，说过了也就忘了。所以那些关于自己的，还是放在心里比较好，毋须说些没意义的。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，我想得挺多，但真正做了或者说做好的却很少。这是件严重的事情。特别在技术上，东看西看，东学西学，眼界确实开阔很多，也养成了较为良好的技术趣味。但从技术能力上来说，真不好说，我都不知道自己有几斤几两。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，最大的收获，也许是对“学习”的重新认识，以及试图从“学知识”向“做事情”转变(这里的“做事情”特指“解决实际问题”)，以前的自己太喜欢太沉迷于学东西，而忽略了自主地做事情。“生有涯，而知无涯”的无奈是必须面对的，对于有限的人生来说，知识必须对自己有用才值得学，特别是技术相关的知识，那怎么知道哪些知识对自己有用呢？得“边用边学”，需要用的时候再学。所以应多做事情，应找实际的问题，尝试去解决，在解决问题的过程中学习。解决实际问题才是根本，才是目的，而不是学习。学生时代习惯了学，习惯了边学边用，但对于研究生，对于以后的工作来说，光顾着学是没用的，而且一味的学也是非常难以深入的，要对某个方面有个深入的理解，必须通过做事情，发现问题，解决问题。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一转变过程让我非常纠结，而且到目前为止还算不上成功。可能对于很多人来说，这个过程可能很简单，但对于我来说，好奇心强，喜欢学东西的来说，确实极其艰难的。每做一件事情，都很可能陷入学习的状态，而不会及时地适可而止。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一过程希望在2012年有个很好的进展。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，我逐步意识到自己存在的另一个大问题---不够自信，其外在表现为和别人一起时，极其容易将自己的观点让位于别人的观点，即使我并不认为自己的观点存在什么问题，或者别人的观点比我的更正确。我只是不想凌驾于别人之上，不想让自己影响到别人。这听起来似乎不关乎自信，但我想本质上是的。“不够自信”这看起来也似乎不是什么大问题，但我想对于一个成年人，特别是一个男人，自信是非常重要的，对于事业也是件非常重要的事情。以前自己活得太谨慎，不喜欢在公共场合表现自己，觉得提高自己的内在修为才是重要的。但其实活在社会中，适时适当地表现自己，表达自己的观点，坚持自己的看法是非常重要的。有个词叫“内圣外王”，以后我得更加注重“外王”，内外兼修。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，我活得又很随性(和“活得谨慎”矛盾而共存)，不太注意自己的言行，脏话口头禅也比较多，虽然在我看来，我的脏话全是在表达一种情绪，仅此而已。但我想在别人来看，其感受也许并不是这样的。我们年轻人还是要注意自己的形象的，呵呵。另外，尽量少评论别人，特别是别人的缺点。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;这一年里，我很懒散，自己都有些看不过去了，“这样的日子，再好的，没有了”，我想不是件好事情。能够自我安慰点是还读了点书，整理一下：&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;社科文艺类&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;佛祖在一号线&lt;/li&gt;
&lt;li&gt;书虫小札&lt;/li&gt;
&lt;li&gt;复杂性思想导论&lt;/li&gt;
&lt;li&gt;人生&lt;/li&gt;
&lt;li&gt;给研究生的学术建议&lt;/li&gt;
&lt;li&gt;边城&lt;/li&gt;
&lt;li&gt;朱镕基答记者问&lt;/li&gt;
&lt;li&gt;窗里窗外&lt;/li&gt;
&lt;li&gt;联大八年&lt;/li&gt;
&lt;li&gt;笑谈大先生&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;&lt;strong&gt;技术类&lt;/strong&gt; (部分是按需选取章节阅读)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Shell脚本学习指南&lt;/li&gt;
&lt;li&gt;Linux内核设计与实现&lt;/li&gt;
&lt;li&gt;鸟哥的Linux私房菜&lt;/li&gt;
&lt;li&gt;PHP和MySQL Web开发（原书第3版）&lt;/li&gt;
&lt;li&gt;分布式处理实践&lt;/li&gt;
&lt;li&gt;Java Collections&lt;/li&gt;
&lt;li&gt;可爱的Python&lt;/li&gt;
&lt;li&gt;浪潮之巅&lt;/li&gt;
&lt;li&gt;CSS Web设计快速上手&lt;/li&gt;
&lt;li&gt;编程人生&lt;/li&gt;
&lt;li&gt;C陷阱与缺陷&lt;/li&gt;
&lt;li&gt;调试九法&lt;/li&gt;
&lt;li&gt;黑客与画家&lt;/li&gt;
&lt;li&gt;Python UNIX 和Linux 系统管理指南&lt;/li&gt;
&lt;li&gt;版本控制之道&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;比较而言，数量上不算少，也不算多，但主要问题还是质量上，觉得自己有些浑沦吞枣，读得太匆忙。这是以后的阅读需要注意的，克制焦躁的心理，慢慢阅读消化。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;新的一年，具体来说，我需要面对的几件大事情，大致包括:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;小论文&lt;/li&gt;
&lt;li&gt;实习&lt;/li&gt;
&lt;li&gt;毕业论文，包括答辩&lt;/li&gt;
&lt;li&gt;找工作&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;2012年底，我将要毕业了(虽然，形式上是2013年毕业)，我就要工作了，这也许是和高考相当的一件大事，希望自己能够举重若轻，踏实准备，顺利应对。(再具体点是不是应该说多多coding，多做事情！哈哈)&lt;/p&gt;</description>
            <pubDate>2012-01-01</pubDate>
            <link>https://blog.xiayf.cn/posts/2011-summary.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/2011-summary.html</guid>
        </item>
        
        <item>
            <title>Linux 添加定时任务</title>
            <description>&lt;p class=&quot;text-align-justify&quot;&gt;在 Linux 下如果希望某个任务定时地执行，一般是使用cron服务器，将任务添加到cron任务列表中。&lt;/p&gt;
&lt;h4&gt;启动，关闭，重启cron(需超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;/etc/init.d/cron start
/etc/init.d/cron stop
/etc/init.d/cron restart&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;注:archlinux下为/etc/rc.d/crond start|stop|restart&lt;/p&gt;
&lt;h4&gt;查看用户设置的定时任务列表&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab [-u xxx] -l       #  xxx为用户名&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;编辑用户的定时任务列表(超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab -u xxx -e&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;删除用户的定时任务列表(超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab -u xxx -r&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;定时任务的编辑规则&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;cron的定时任务由两部分组成：（1）设置的时间（2）该时间下要执行的任务命令。&lt;/p&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;时间分5个部分，依次为：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;minute              0-59
hour                0-23 
day of month        1-31
month               1-12
day of week         0-7 (0 or 7 is Sun, or use names)&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;示例（每天临晨2点备份数据库）&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;0 2 * * * mysqldump -hhostname -uusername -ppassword databasename &amp;amp;gt; backupfile.sql&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;使设置生效&lt;/h4&gt;
&lt;p class=&quot;text-align-justify&quot;&gt;设置完成后，重启cron即可使设置的计划任务定时执行了&lt;/p&gt;
&lt;h3&gt;详细内容参考&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://fanqiang.chinaunix.net/system/linux/2005-06-13/3306.shtml&apos;&gt;http://fanqiang.chinaunix.net/system/linux/2005-06-13/3306.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://fanqiang.chinaunix.net/adm/storage/2005-03-23/2985.shtml&apos;&gt;http://fanqiang.chinaunix.net/adm/storage/2005-03-23/2985.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://now-code.com/archives/196&apos;&gt;http://now-code.com/archives/196&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2011-12-07</pubDate>
            <link>https://blog.xiayf.cn/posts/cron-usage.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/cron-usage.html</guid>
        </item>
        
    </channel>
</rss>