<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>BitPacking</title>
        <description>精进，求诸己身</description>
        <link>https://blog.xiayf.cn/</link>
        <atom:link href="https://blog.xiayf.cn/rss.xml" rel="self" type="application/rss+xml"/>
        <pubDate>2025-05-01T22:43:23.225268+08:00</pubDate>
        <lastBuildDate>2025-05-01T22:43:23.225268+08:00</lastBuildDate>
        <generator>LingDong</generator>
        
        <item>
            <title>标量量化入门（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;https://www.elastic.co/search-labs/blog/scalar-quantization-101&apos;&gt;Scalar quantization 101&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;p&gt;多数嵌入（embedding）模型会输出 $float32$ 数值精度的向量。这个精度虽然提供了信息高保真，但在真正重要的信息之外也带来一些资源浪费。对于给定的数据集，嵌入不可能在单个维度需要20亿种取值，特别是对于高维度向量而言（比如：386维及以上）。量化以一种有损的方式对向量进行编码，轻微降低信息保真而明显地降低存储空间占用。&lt;/p&gt;
&lt;h2&gt;理解标量量化的分桶&lt;/h2&gt;
&lt;p&gt;标量量化使用更小的数据类型对向量每一维的取值进行分桶。本文的余下部分将假设将 $float32$ 量化到 $int8$ 。为了准确地对值进行分桶，不能简单地将值四舍五入到最近的整数。许多模型输出向量的维度取值空间为 $[-1.0, 1.0]$，如果简单粗暴地四舍五入处理，那么 0.123 和 0.321 这两个不同的向量维度取值都会向下取整到 0。最终，一个向量仅会使用 $int8$ 可用 255 个桶中的2个桶，这样就丢失太多信息了。&lt;/p&gt;
&lt;img src=&apos;../assets/float32-to-int8-buckets.jpeg&apos; title=&apos;float32-to-int8-buckets.jpeg&apos; alt=&apos;float32-to-int8-buckets.jpeg&apos; width=&apos;500&apos;/&gt;
&lt;blockquote&gt;&lt;p&gt;图1：量化目标图解 - 将 -1.0 到 1.0 之间的连续值分桶到离散的 $int8$ 数值。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这种数值转换背后的数学原理并不太复杂。我们可以先计算浮点数取值区间的最小和最大值，然后使用 &lt;a href=&apos;https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization&apos;&gt;最小-最大归一化&lt;/a&gt;) 对值进行线性变换（linearly shift）。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$int8\approx \frac{127}{max-min} \  \times \left( float32-min \right)$$&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$float32\approx \frac{max-min}{127} \times int8+min$$&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;图2：$int8$ 和 $float32$ 之间的变换公式。注意：这两个变换是有损的，并不是精确变换。下面的例子中，仅使用 $int8$ 取值空间的正数部分。Lucene 的实现也是这样的。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;标量量化的统计视角&lt;/h2&gt;
&lt;p&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/Quantile&apos;&gt;分位点（quantile）&lt;/a&gt; 是指数值分布的一个切片，这个切片包含一定数量比例的值。例如：一种浮点数取值分布下 99% 的值落在 $[-0.75, 0.86]$ 这个分位点区间内，小于 $-0.75$ 和大于 $0.86$ 的值都被视为离群值/异常值（outliers），因此将 $-0.75$ 和 $0.86$ 分别视为实际的最小值和最大值。如果量化时将离群值包含在内，就意味着那些最常见的值可用的桶偏少了，可用桶少了也就意味着精度更差，信息损失更多。&lt;/p&gt;
&lt;img src=&apos;../assets/quantile.jpeg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;blockquote&gt;&lt;p&gt;图3:图解 99%  &lt;a href=&apos;https://en.wikipedia.org/wiki/Confidence_interval&apos;&gt;置信区间(confidence interval)&lt;/a&gt;及对应的分位点数值，即 99% 的值落在 $[-0.75, 0.86]$ 这个范围内。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;不错，我们现在知道如何对浮点值进行量化了，那么又应该如何计算两个量化后向量的距离呢？就像常规的&lt;a href=&apos;https://en.wikipedia.org/wiki/Dot_product&apos;&gt;点积&lt;/a&gt;计算一样简单吗？&lt;/p&gt;
&lt;h2&gt;标量量化的代数视角&lt;/h2&gt;
&lt;p&gt;目前为止仍然缺失关键的一块拼图 - 如何计算两个量化后向量之间的距离。本文并没有有意避开数学公式，下面也会出现更多数学内容。拿出你的铅笔，回忆一下&lt;a href=&apos;https://en.wikipedia.org/wiki/Polynomial&apos;&gt;多项式&lt;/a&gt; 和基础代数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;https://en.wikipedia.org/wiki/Dot_product&apos;&gt;点积&lt;/a&gt;和&lt;a href=&apos;https://en.wikipedia.org/wiki/Cosine_similarity&apos;&gt;余弦相似度&lt;/a&gt;的计算逻辑是将两个向量对应维度上的浮点值相乘，然后将所有维度上的结果相加。我们已经知道如何在 $float32$ 和 $int8$ 值之间做变换，那么应用变换后的乘法公式是什么样的呢？&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$float32_{i}\times float32_{i}^{\prime}\approx \left( \frac{max-min}{127} \times int8_{i}+min \right) \times \left( \frac{max-min}{127} \times int8_{i}^{\prime}+min \right)$$&lt;/p&gt;
&lt;p&gt;将这个乘法公式展开后（为了简化，以 $\alpha$ 替代 $\frac{max-min}{127}$），如下所示：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$\alpha^{2} \times int8_{i}\times int8_{i}^{\prime}+\alpha \times int8_{i}\times min+\alpha \times int8_{i}^{\prime}\times min+min^{2}$$&lt;/p&gt;
&lt;p&gt;接下来就更有意思了 - 这个算式中仅有一个部分要求同时提供两个变量值。然而，点积并不只是两个浮点数相乘，而是两个向量的每一维对应的浮点值相乘。假设向量的维度为 $dim$，那么以下部分算式都可以提前计算好存下来。&lt;/p&gt;
&lt;p&gt;$dim\times \alpha^{2}$ 即 $dim\times \left( \frac{max-min}{127} \right)^{2}$ ，可以提前计算好存为单个浮点数。&lt;/p&gt;
&lt;p&gt;$\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}$ 和 $\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}^{\prime}$ 都可以分别提前计算好存为单个浮点数，或者在检索时计算一次。&lt;/p&gt;
&lt;p&gt;$dim\times min^{2}$ 也可以提前计算好存为单个浮点数。&lt;/p&gt;
&lt;p&gt;那么：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dim\times \alpha^{2} \times dotProduct\left( int8,int8^{\prime} \right) +\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}+\sum_{i=0}^{dim-1} min\times \alpha \times int8_{i}^{\prime}+dim\times min^{2}$$&lt;/p&gt;
&lt;p&gt;点积的整个算式中仅 $dotProduct\left( int8,int8^{\prime} \right)$ 部分需要在检索时计算，加上其他提前计算好的部分就能得到结果。&lt;/p&gt;
&lt;h2&gt;量化的精度保证&lt;/h2&gt;
&lt;p&gt;那么，这样量化计算的准确性如何？量化后损失信息没有？是的，损失了一些信息，不过量化正是基于我们事实上并不需要所有信息的假设。对于训练得到的嵌入模型，向量各个维度的值分布通常不存在&lt;a href=&apos;https://en.wikipedia.org/wiki/Fat-tailed_distribution&apos;&gt;厚尾性(fat-tails)&lt;/a&gt;。这意味着值分布存在一定的局部性和一致性。此外，量化对每一维度引入的误差是相互独立的，这意味着对于向量的典型运算（比如点积），误差一定程序上会抵消。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;哟，一写就写了一堆内容。现在你应该很好地理解了量化的技术优势，其背后的数学原理，以及如何将线性变换考虑在内计算向量之间的距离。&lt;/p&gt;</description>
            <pubDate>2025-01-13</pubDate>
            <link>https://blog.xiayf.cn/posts/scalar-quantization-101.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/scalar-quantization-101.html</guid>
        </item>
        
        <item>
            <title>k-NN 乘积量化器教程-第2部分（译）</title>
            <description>&lt;p&gt;&lt;a href=&apos;http://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/&apos;&gt;本教程的第1部分&lt;/a&gt; 讲解了乘积量化器的最基础形式。本文将讲解 &lt;a href=&apos;https://github.com/facebookresearch/faiss/wiki/Getting-started-tutorial&apos;&gt;FAISS 库的 IndexIVFPQ 索引&lt;/a&gt;，该索引类型使用一个乘积量化器以及 &lt;a href=&apos;https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf&apos;&gt;2011 年发表的这篇论文&lt;/a&gt;介绍的一些额外的技术。&lt;/p&gt;
&lt;p&gt;下面先简要介绍一下该索引引入的两个特性，之后会再详细解释。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;倒排文件索引（IVF）&lt;/em&gt;  - IVF 就是一种数据集预过滤的技术，避免对所有向量进行穷举搜索。它的原理相当直观 - 使用 k-means 聚类算法提前将数据集聚类成一定数量的数据集分区，然后在检索时，先将查询向量与每个分区的质心做比较，找到最近的若干个聚类，然后只在这些聚类分区内做向量搜索。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;残差编码&lt;/em&gt; - 这是对乘积量化器基础形式的一种增强方式 - 加入 IVF 步骤的一些信息。对于每个数据库向量，不再使用 PQ 编码原始的数据库向量，而是对向量相对于所属分区的质心的偏移量（offset）进行编码。后续章节会解释其原理和收益。&lt;/p&gt;
&lt;h2&gt;倒排文件索引（Inverted File Index）&lt;/h2&gt;
&lt;p&gt;计算机科学领域，特别是信息检索领域，一个“倒排索引”是指将词汇表中的每个单词映射到数据库中所有文档中该单词出现的所有位置，它非常类似于课本中后面的索引表 - 将单词或概念映射到页号，所以大家将这种数据结构称为“倒排索引”让我有些困扰（因为于我而言它就是一种普通的索引！）。&lt;/p&gt;
&lt;p&gt;不管怎样，在当前上下文中，这个技术实际就是使用 k-means 聚类对数据集做分割，这样就可以仅对部分分区做搜索而忽略其余的。&lt;/p&gt;
&lt;p&gt;构建索引时，使用 k-means 聚类算法将数据集聚类成一定数量的分区。数据集中每个向量仅会被归属到一个聚类/分区中。每个分区包含归属于它的一组向量（也就是 FAISS 作者说的“倒排文件列表”）。也由此得到所有分区的质心组成的一个矩阵，用于计算应该对哪些分区进行搜索。&lt;/p&gt;
&lt;p&gt;按照这种方式对数据集进行分割，并不完美，因为如果一个查询向量实际位于最近聚类的边缘位置，那么查询向量的最近邻居可能实际位于多个附近的聚类中。这个问题的解决方案是简单地多搜索几个分区。搜索多个附近的分区显然会占用更多的检索时间，但是准确性也会更好。&lt;/p&gt;
&lt;p&gt;搜索的时候，将查询向量与所有分区的质心做比较，找到最近的若干个分区质心，实际的数量可以配置。一旦找到了最近的若干个分区质心，就可以仅对这些分区的数据库向量使用乘积量化器做 k-NN 搜索。&lt;/p&gt;
&lt;p&gt;注意该索引类型中使用的如下术语：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“probe（搜寻）” 这个动词，在当前上下文中，是指选定待搜索的目标分区。因此在代码中你会看到索引参数“nprobe” - 意思就是“待搜寻的分区数量”。&lt;/li&gt;
&lt;li&gt;FAISS 的作者们喜欢使用“Voronoi 单元（cells）”这个词语，而不是我在本文中使用的“数据集分区（dataset partitions）”。一个 Voronoi 单元就是属于一个聚类的空间区域，也就是，这个空间区域涵盖了对应聚类的所有点，这些点的向量与这个聚类的质心的距离，比其他聚类的质心都要近。&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;残差编码（Encoding Residuals）&lt;/h2&gt;
&lt;p&gt;这个特性也是相对比较直观的，不过如果你没有理解的话可能会觉得有点奇怪。其想法是将 IVF 阶段的一些信息加入到乘积量化器中，借此提升准确性（因此这个概念是建立在数据集分区技术之上的）。&lt;/p&gt;
&lt;p&gt;先定义一下什么是“残差”向量。暂时抛开乘积量化器不谈（因为它会增大理解的困难，后面我们再把它加回来）。假设我们要做标准的暴力 k-NN 搜索，不过是用数据集分区技术来削减待搜索向量的数量。&lt;/p&gt;
&lt;p&gt;假设我们是用 k-means 将数据集聚类成 100 个聚类（或者叫“数据集分区”）。给定数据集中的一个向量，其残差即是它相对于所属分区的质心的偏移（offset）。也就是，将数据集中的这个向量与其所属聚类的质心的向量相减。质心即是聚类的均值，那么对一组点均减去它们的均值会发生什么？现在这些点就围绕着 0 点了。如下是一个简单的二维示例：&lt;/p&gt;
&lt;img src=&apos;../assets/residuals_one_partition.png&apos; title=&apos;residuals_one_partition.png&apos; alt=&apos;residuals_one_partition.png&apos; width=&apos;800&apos;/&gt;
&lt;p&gt;开始有趣起来了。假设将一个数据集分区中的所有向量都替换为各自的残差向量，怎么从这个数据集分区中找到查询向量的最近邻？先计算查询向量的残差（相对于分区质心的偏移），然后对这个数据集分区的所有残差向量做最近邻搜索，得到的结果与使用原始向量做搜索是一样的！&lt;/p&gt;
&lt;p&gt;基于上面的图示，凭直觉可能就能理解，不过还是再看看下面的等式加深理解。&apos;x&apos; 和 &apos;y&apos; 这两个向量的长度为 &apos;n&apos;，它们的 L2 距离计算公式为：&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dist_{L2}\left( x,y \right) =\sqrt{\sum_{i}^{n} \left( x_{i}-y_{i} \right)^{2}}$$&lt;/p&gt;
&lt;p&gt;如果对 &apos;x&apos; 和 &apos;y&apos; 都减去质心向量 &apos;c&apos;，看起来是什么样的？&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;$$dist_{L2}\left( x-c,y-c \right) =\sqrt{\sum_{i}^{n} \left( (x_{i}-c_{i})-(y_{i}-c_{i}) \right)^{2}} =\sqrt{\sum_{i}^{n} \left( x_{i}-y_{i} \right)^{2}}$$&lt;/p&gt;
&lt;p&gt;质心部分被抵消掉了！&lt;/p&gt;
&lt;p&gt;注意使用残差计算出来的距离不只是相对而言（比如距离的序）是相等的，并且确实是正确地计算出了向量之间的 L2 距离。&lt;/p&gt;
&lt;p&gt;可能你之前就使用过这种等价关系，均值归一化（对向量减去均值）是一种常见的预处理技术。&lt;/p&gt;
&lt;p&gt;不过目前为止说的都是单个分区内的计算。将不同分区内的向量做比较又会是什么情况呢？仍然管用，只要针对每个分区分别计算查询向量的残差即可。&lt;/p&gt;
&lt;p&gt;下面这个图解中包含两个数据集分区。计算残差之后，两个分区的所有点都围绕在 0 点周围了。不过现在是有两个查询向量的残差 - 一个是与蓝色点集（分区 1）比较得到的，另一个是与绿色点集（分区 2）比较得到的。&lt;/p&gt;
&lt;img src=&apos;../assets/residuals_two_partitions.png&apos; title=&apos;residuals_two_partitions.png&apos; alt=&apos;residuals_two_partitions.png&apos; width=&apos;800&apos;/&gt;
&lt;p&gt;前面解释过查询向量和数据库向量之间的距离，使用原始向量计算和使用残差向量计算，结果是一样的，还记得吧？&lt;/p&gt;
&lt;p&gt;很有意思，不过目前为止还是无用功 - 尚未改变结果的准确性也没有减少计算成本。现在将 PQ 重新放进来一起考虑，就会发现好处在哪了。&lt;/p&gt;
&lt;p&gt;在训练乘积量化器之前，先计算数据集所有分区所有向量的残差向量。残差向量集合保持原有分区（不会合并在一起），不过现在所有残差向量都围绕着 0 点，相对紧凑地聚集在一起。我们抛弃掉原始的数据集向量，只存储残差向量集。&lt;/p&gt;
&lt;p&gt;在所有这些残差向量之上训练习得一个乘积量化器，不再使用原始向量。那有什么不同之处吗？回想一下：乘积量化器的训练过程是先将向量分割成子向量，在每部分子向量之上进行 k-means 聚类，学习到一组原型/质心（或者叫“码本”）用于表征所有向量。使用对应的残差向量来替换原始向量，能够降低数据集中向量的多样性（the variety in the dataset）（论文中，将此描述为：相对于原始向量，残差向量“包含更小的能量（have less energy）”）。之前，聚类存在于空间的各个区域，现在聚类都围绕着 0 点，并且相互之间还存在部分重合。降低了数据集中向量的多样性，就可能使用更少的原型/质心（或者说“代码”）来有效地表征向量！或者，换个角度来说，PQ 中数量有限的代码现在更加准确了，因为这些代码所要描述的向量，相比之前，相互之间区别更小了（less distinct）。我们得到了更多的回报（more bang for our buck）！&lt;/p&gt;
&lt;p&gt;不过，也是有代价的。回想一下：乘积量化器的魔力在于仅需要将查询向量分块与码本代码之间的部分距离计算出来存为一个相对比较小的表 - 剩下的操作就是查表和加法。&lt;/p&gt;
&lt;p&gt;现在，使用残差向量，对于每个数据集分区而言，查询向量都是不同的 - 对于每个数据集分区，查询向量对应的残差向量都需要基于分区的质心重新计算。因此，对于待搜寻的每个分区，都必须单独计算一个距离表！&lt;/p&gt;
&lt;p&gt;不过，这个取舍显然是值得的，实际应用中，IndexIVFPQ 索引的表现都很不错。&lt;/p&gt;
&lt;p&gt;就是这样。虽然数据库向量都被各自的残差向量替代了，不过对于乘积量化器来说，没什么不同。&lt;/p&gt;
&lt;p&gt;注意：数据集分区并不会考虑（factor in to）码本训练，我们仍然跨越分区使用所有数据集向量为每部分子向量习得一个码本。你也可以为每个数据集分区单独训练一个 PQ，不过 FAISS 库的作者不赞成这样做，因为分区的数量通常比较大，那么存储这些码本的内存开销会是一个问题。所以，跨分区在所有数据库向量之上训练习得一个 PQ 更好一些。&lt;/p&gt;</description>
            <pubDate>2025-01-10</pubDate>
            <link>https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-2.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-2.html</guid>
        </item>
        
        <item>
            <title>k-NN 乘积量化器教程-第1部分（译）</title>
            <description>&lt;p&gt;乘积量化器是一种“向量量化器”（后面我会解释这是啥意思），可以用于加速近似最近邻检索。&lt;/p&gt;
&lt;p&gt;2017年3月发布的 &lt;a href=&apos;https://code.facebook.com/posts/1373769912645926/faiss-a-library-for-efficient-similarity-search/&apos;&gt;Facebook AI 相似性检索（FAISS）库&lt;/a&gt;，风靡一时，乘积量化器是其核心组件，吸引了很多人关注。&lt;/p&gt;
&lt;p&gt;本教程的第一部分将解释乘积量化器的最基础形式，ANN 检索中通常是这样实现。第二部分将解释 FAISS 中的 “IndexIVFPQ” 索引，这种索引在基础形式的乘积量化器上添加了不少特性。&lt;/p&gt;
&lt;h2&gt;近似距离穷举搜索&lt;/h2&gt;
&lt;p&gt;不同于 ANN 使用的基于树的索引，单独使用乘积量化器的 k-NN 检索仍然是一种“穷举搜索”，这意味着乘积量化器仍然需要将查询向量（query vector）和数据库中所有向量做比较。乘积量化器的核心是近似地且显著地简化向量的距离计算。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;注意：FAISS 中的 IndexIVFPQ 索引在使用乘积量化器之前会预先过滤数据集 - 第二部分会解释。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;以示例解释&lt;/h2&gt;
&lt;p&gt;乘积量化器方法的作者们是信号处理和压缩技术背景的，所以如果你是机器学习方向的，可能对他们的用词和术语比较陌生。不过，如果你熟悉 k-means 聚类（且摒弃所有压缩命名法的词汇），使用一个示例你就能轻松理解乘积量化器的基础知识。之后，我们再回头来看压缩技术相关术语。&lt;/p&gt;
&lt;h2&gt;数据集压缩&lt;/h2&gt;
&lt;p&gt;假设你有一个 50,000 张的图片集，使用一个卷积神经网络（CNN）完成一些特征的抽取。这样你现在就得到一个 50,000个特征向量的数据集，每个特征向量有 1024 维。&lt;/p&gt;
&lt;img src=&apos;../assets/image_vectors.png&apos; title=&apos;image_vectors.png&apos; alt=&apos;image_vectors.png&apos; width=&apos;300&apos;/&gt;
&lt;p&gt;我们要做的第一件事情就是压缩数据集。向量的数量保持不变，但是可以减少每个向量需要的存储空间。注意：我们要做的事情不同于“降维（dimensionality reduction）”！这是因为压缩后的向量中的值其实是符号而不是数值，所以不能直接比较压缩后的向量。&lt;/p&gt;
&lt;p&gt;压缩数据集有两大好处：（1）内存访问耗时通常是处理速度的限制因素，（2）对大数据集而言内存容量是个问题。&lt;/p&gt;
&lt;p&gt;压缩的原理如下所述：对于我们的示例数据集，将所有向量一起切成8个子向量，每个子向量的长度为 128（8个子向量 $\times$ 每个子向量128维 = 原始向量的 1024 维）。这样就将数据集分成8个矩阵，每个矩阵大小为 $[50K \times 128]$。&lt;/p&gt;
&lt;img src=&apos;../assets/vector_slice.png&apos; title=&apos;vector_slice.png&apos; alt=&apos;vector_slice.png&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;然后对这8个矩阵的每一个单独进行 k-means 聚类，k = 256。这样，对于向量的8个子段的每1个都存在256个质心 - 一共8组质心，每组包含256个质心。&lt;/p&gt;
&lt;img src=&apos;../assets/kmeans_clustering.png&apos; title=&apos;kmeans_clustering.png&apos; alt=&apos;kmeans_clustering.png&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;这些质心类似于“原型”。它们代表数据集子向量中最常见的模式。&lt;/p&gt;
&lt;p&gt;可以使用这些质心来压缩向量数据集 - 使用最接近/最相似的置信来替代向量中对应的每个子部分，从而得到一个不同于原始向量的一个新向量，不过它们之间应该还是相近的。&lt;/p&gt;
&lt;p&gt;这样我们就能更加高效地存储这些向量 - 不用存储原始的浮点数值，只要存储聚类中心 ID 即可 - 对每个子向量，找到最近的质心，存储该质心的 ID。每个向量也就被替换为8个质心 ID 的一个序列。&lt;/p&gt;
&lt;p&gt;注意：对于8个子部分矩阵的每一个学习到的质心集合是不同的。使用最近质心 id 替换子向量时，只能与对应子部分的 256 个质心做比较。&lt;/p&gt;
&lt;p&gt;每个子部分只有 256 个质心，所以仅需 8 比特就能存储一个质心 ID。每个向量，原本包含 1024 个 32 浮点数（4,096 字节），现在仅是 8 个 8 比特整数的序列（每个向量只要8字节的存储空间！）。&lt;/p&gt;
&lt;img src=&apos;../assets/compression.png&apos; title=&apos;compression.png&apos; alt=&apos;compression.png&apos; width=&apos;100%&apos;/&gt;
&lt;h2&gt;最近邻搜索&lt;/h2&gt;
&lt;p&gt;很棒！向量经过压缩了。不过无法对经过压缩的向量直接计算 L2 距离 - 质心 ID 之间的距离是任意且没有实际意义的！（这就是压缩与降维的不同之处）&lt;/p&gt;
&lt;p&gt;接下来说说怎么进行最近邻搜索，虽仍是穷举搜索（与所有向量计算距离并排序），不过可以更高效地计算距离 - 只需进行表查找以及某种加法即可。&lt;/p&gt;
&lt;p&gt;假设我们有一个查询向量，期望找到它的最近邻居。&lt;/p&gt;
&lt;p&gt;一种不太聪明的方式是先解压缩数据集向量，然后计算 L2 距离。也就是，通过串接不同维度的质心重建出向量。下面我们也会这样干，不过比实际地解压缩所有向量在计算上要高效得多。&lt;/p&gt;
&lt;p&gt;首先，对查询向量的每个子向量，与该子段的 256 个质心中每一个计算 L2 距离的平方。&lt;/p&gt;
&lt;p&gt;这意味着要构建一个子向量距离表，这个表有 256 行（一个质心对应一行） 8 列（一个子段对应一列）。构建这个表成本有多大？相当于计算查询向量与 256 个数据集向量的 L2 距离所需要的数学运算次数。&lt;/p&gt;
&lt;p&gt;一旦有了这个表，就可以开始计算查询向量与 50k 个数据库向量中每一个的近似距离了。&lt;/p&gt;
&lt;p&gt;每个数据库向量现在只是 8 个质心  ID 的序列。因此要计算一个数据库向量与查询向量之间的相似距离，只需使用这些质心 ID 从表中查找出对应的部分距离，并将它们加和在一起。&lt;/p&gt;
&lt;p&gt;只需要将这些部分值加起来就完成了？是的！记住我们在处理的是 L2 距离的平方，所以无需平方根操作。计算 L2 的平方，就是将每个子部分的差平方（squared differences）相加，这些加法操作的次序也无关紧要。&lt;/p&gt;
&lt;p&gt;这种查表方式，与对解压缩向量计算距离的方式，得到的结果是一样的，但是计算成本要小得多。&lt;/p&gt;
&lt;p&gt;最后一步，与常规的最近邻搜索一样 - 对距离进行排序后找到最小的距离，对应的这些数据库向量就是最近的邻居。打完收工！&lt;/p&gt;
&lt;h2&gt;压缩技术相关术语&lt;/h2&gt;
&lt;p&gt;我们理解了 PQ 的逻辑原理，现在回过头来学习相关术语就简单了。&lt;/p&gt;
&lt;p&gt;广义上而言，量化器就是能够减少变量取值空间（the number of possible values that a variable has）的一种东西。构建一个查找表来减少一张图片的颜色数量（the number of colors），应该是一个不错的例子 - 找到图片中最常见的 256 个颜色数值，放到一张表中，将 24 比特 RGB 色值映射到一个 8 比特整数。&lt;/p&gt;
&lt;p&gt;我们获取所有数据库向量的开始 128 个值（8个子段中第1个），对这些 128 个值（数量 $50k \times 128$）进行聚类训练，得到 256 个质心，这 256 个质心就构成了我们所说的“码本（codebook）”。每个质心（一个包含128个浮点数的向量）被称为一个“代码（code）”。&lt;/p&gt;
&lt;p&gt;这些质心是用来表征数据库向量的，因此这些代码也可称之为“再生产值（reproduction values）” 或“重建值（reconstruction values）”。将质心 ID 对应的代码串接成序列就能创建一个数据库向量。&lt;/p&gt;
&lt;p&gt;8 个子段是分别进行 k-means 聚类的，所以实际创建了 8 个独立的码本。&lt;/p&gt;
&lt;p&gt;基于这 8 个码本，组合代码能够创建 $256^8$ 种可能的向量！因此，实际上我们创建一个非常巨大的码本，包含 $256^8$ 个代码。直接习得并存储如此大的单个码本是不可能的事情，由此可见乘积量化器的魔力。&lt;/p&gt;
&lt;h2&gt;预过滤&lt;/h2&gt;
&lt;p&gt;&lt;a href=&apos;http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/&apos;&gt;本教程的第2部分&lt;/a&gt;中，我们将学习 FAISS 库中的 IndexIVFPQ 索引，这种索引在使用乘积量化器之前将数据集先分割为多个分区，这样对于每个查询仅需要搜索部分分区。FAISS 发布于 2017 年，IndexIVFPQ 索引使用的乘积量化器方法技术首次见于 &lt;a href=&apos;https://www.irisa.fr/texmex/people/jegou/papers/jegou_searching_with_quantization.pdf&apos;&gt;2011 年的这篇论文&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2025-01-09</pubDate>
            <link>https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-1.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/product-quantizer-tutorial-part-1.html</guid>
        </item>
        
        <item>
            <title>Arrow 列存格式-序列化与进程间通信（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;https://arrow.apache.org/docs/format/Columnar.html#serialization-and-interprocess-communication-ipc&apos;&gt;Arrow Columnar Format-Serialization and Interprocess Communication (IPC)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;序列化与进程间通信(IPC)&lt;/h2&gt;
&lt;p&gt;本列存格式定义中，序列化数据的基本单元是“成批记录（record batch）”。语义上，一个成批记录是若干数组的一个有序集合，一个数组对应一个字段列（field），这些数组的长度相同，但数据类型可能不同。一个成批记录中字段列的名称和类型信息共同形成该批的 &lt;em&gt;schema&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;本小节，我们将定义一种协议，约定如何将若干记录批序列化成一个二进制载荷的流，以及如何无需内存拷贝就能从这些载荷重建出记录批。&lt;/p&gt;
&lt;p&gt;本列存进程间通信协议使用如下这些类型的二进制消息格式来构建一个单向流的定义：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Schema&lt;/li&gt;
&lt;li&gt;RecordBatch&lt;/li&gt;
&lt;li&gt;DictionaryBatch&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;这种我们称之为进程间通信密封消息的格式，包含一个经序列化的 Flatbuffer 类型元数据，后接一个可选的消息体。在描述如何序列化如上三种进程间通信消息类型之前，我们先定义清楚这种消息格式。&lt;/p&gt;
&lt;h3&gt;密封消息格式&lt;/h3&gt;
&lt;p&gt;对于简单的流式序列化和基于文件的序列化，我们为进程间通信定义一种“密封的”消息格式。这种消息，仅需检查消息的元数据，就能“被反序列化”成内存中的 Arrow 数组对象，无需对实际数据进行拷贝或移动。&lt;/p&gt;
&lt;p&gt;这种密封二进制消息格式如下所述：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个 32 比特长度的再开始标识。其值为 &lt;code&gt;0xFFFFFFFF&lt;/code&gt;，表示重新开始一个有效消息。这一部分是在版本 0.15.0 引入的，部分原因是为了解决 Flatbuffers 要求8字节对齐的问题。&lt;/li&gt;
&lt;li&gt;消息元数据部分的大小，32 比特长度，小端编码。&lt;/li&gt;
&lt;li&gt;消息元数据，类型为 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Message.fbs&quot;&apos;&gt;Message.fbs&lt;/a&gt;文件中定义的 &lt;code&gt;Message&lt;/code&gt; 类型。&lt;/li&gt;
&lt;li&gt;消息体，其长度必须是8字节的倍数。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;语义上，消息格式形如：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;再开始标识: 0xFFFFFFFF&amp;amp;gt;
&amp;amp;lt;元数据大小: int32&amp;amp;gt;
&amp;amp;lt;flatbuffer 序列化的元数据: bytes&amp;amp;gt;
&amp;amp;lt;填充&amp;amp;gt;
&amp;amp;lt;消息体&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;经序列化的完整消息，长度必须是8字节的倍数，这样消息可以跨多个流实现内存重定位（译注：怎么理解？）。否则，元数据和消息体之间填充量是不确定的。&lt;/p&gt;
&lt;p&gt;“元数据大小” 等于 &lt;code&gt;Message&lt;/code&gt; 类型的大小加上填充的大小。“flatbuffer 序列化的元数据”即是一个 Flatbuffer &lt;code&gt;Message&lt;/code&gt; 类型的值序列化后的结果，其内部包含如下部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;版本号&lt;/li&gt;
&lt;li&gt;特定的消息类型值（&lt;code&gt;Schema&lt;/code&gt;、&lt;code&gt;RecordBatch&lt;/code&gt;、&lt;code&gt;DictionaryBatch&lt;/code&gt; 三者之一）&lt;/li&gt;
&lt;li&gt;消息体的大小&lt;/li&gt;
&lt;li&gt;应用设置的“自定义元数据”字段。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;在读取一个输入流时，通常先解析 &lt;code&gt;Message&lt;/code&gt; 元数据，经验证后获取到消息体的大小，然后读取消息体。&lt;/p&gt;
&lt;h3&gt;Schema 消息&lt;/h3&gt;
&lt;p&gt;&lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Schema.fbs&quot;&apos;&gt;Schema.fbs&lt;/a&gt; 这个 Flatbuffers 文件包含所有内置类型的定义，以及用于表达一个给定成批记录 schema 的 &lt;code&gt;Schema&lt;/code&gt; 元数据类型。schema 是若干字段列（&lt;code&gt;Field&lt;/code&gt;）定义的有序序列，每个字段列定义包含列名称和列数据类型。&lt;code&gt;Schema&lt;/code&gt; 类型的值经序列化后不会包含任何数据缓冲区，仅包含类型元数据。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Field&lt;/code&gt; 这个 Flatbuffers 类型包含单个数组的的元数据，包括如下信息：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;字段列的名称&lt;/li&gt;
&lt;li&gt;字段列的数据类型&lt;/li&gt;
&lt;li&gt;该字段列语义上是否可以为 null。这个和数组的物理内存布局无关，一些系统会明确区分可为 null 的字段列和不可为 null 的字段列，我们希望保留这个元数据以便完整无缺地表达 schema&lt;/li&gt;
&lt;li&gt;对于嵌套类型，还包含一组子类型 &lt;code&gt;Field&lt;/code&gt; 元数据&lt;/li&gt;
&lt;li&gt;一个名为 &lt;code&gt;dictionary&lt;/code&gt; 的属性，标识当前字段列是否字典编码过的。如果是的话，会有一个字典“id” 赋值于此，如此便可为这个字段列匹配后续的字典编码的 IPC 消息。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;另外，我们还提供 schema 级别和字段列级别的 &lt;code&gt;custom_metadata&lt;/code&gt; 属性字段，方便应用系统插入自己的应用元数据，以此自定义行为。&lt;/p&gt;
&lt;h3&gt;RecordBatch 消息&lt;/h3&gt;
&lt;p&gt;一个 RecordBatch 消息包含若干实际的数据缓冲区，其物理内存布局由 schema 决定。这种消息的元数据提供了每个缓冲区的位置和大小信息，如此，使用指针计算就能重建出那些数组数据结构，也无需内存拷贝。&lt;/p&gt;
&lt;p&gt;成批记录的序列化后形式如下所示：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“消息头部”部分，定义见 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/Message.fbs&quot;&apos;&gt;Message.fbs&lt;/a&gt; 中的 &lt;code&gt;RecordBatch&lt;/code&gt; 类型。&lt;/li&gt;
&lt;li&gt;“消息体”部分，若干内存缓冲区的一个平铺序列，依次逐个写入，中间加上适当的填充以确保8字节对齐。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;数据头部包含如下信息：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;成批记录中，每个平铺字段列的长度和 null 值的数量。&lt;/li&gt;
&lt;li&gt;成批记录消息体中每个“缓冲区”的内存偏移位置和长度。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;这些字段列信息和缓冲区是对成批记录中的字段列按照原有顺序进行深度优先遍历平铺得到的。例如，我们来看看如下 schema：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;col1: Struct&amp;amp;lt;a: Int32, b: List&amp;amp;lt;item: Int64&amp;amp;gt;, c: Float64&amp;amp;gt;
col2: Utf8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其平铺版本如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;FieldNode 0: Struct name=&amp;amp;apos;col1&amp;amp;apos;
FieldNode 1: Int32 name=&amp;amp;apos;a&amp;amp;apos;
FieldNode 2: List name=&amp;amp;apos;b&amp;amp;apos;
FieldNode 3: Int64 name=&amp;amp;apos;item&amp;amp;apos;
FieldNode 4: Float64 name=&amp;amp;apos;c&amp;amp;apos;
FieldNode 5: Utf8 name=&amp;amp;apos;col2&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对应生成的缓冲区平铺序列，则如下所示（参考上面的表定义）：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;buffer 0: field 0 validity
buffer 1: field 1 validity
buffer 2: field 1 values
buffer 3: field 2 validity
buffer 4: field 2 offsets
buffer 5: field 3 validity
buffer 6: field 3 values
buffer 7: field 4 validity
buffer 8: field 4 values
buffer 9: field 5 validity
buffer 10: field 5 offsets
buffer 11: field 5 data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Buffer&lt;/code&gt; 的 Flatbuffers 值描述了每块内存的位置和大小，按照前文定义的密封消息格式进行解析。&lt;/p&gt;
&lt;h3&gt;可变数量缓冲区（Variadic buffers）&lt;/h3&gt;
&lt;blockquote&gt;&lt;p&gt;Arrow 列存格式 1.4 版本新增。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;诸如 Utf8View 这些类型，使用不定数量的缓冲区来表现。按照预先顺序拍平的逻辑 schema 中的这类字段列在 RecordBatch 的&lt;code&gt;variadicBufferCounts&lt;/code&gt; 属性中都对应一个值来表示当前 RecordBatch 中属于那个字段列的缓冲区的数量。&lt;/p&gt;
&lt;p&gt;例如，来看看如下 schema：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;col1: Struct&amp;amp;lt;a: Int32, b: BinaryView, c: Float64&amp;amp;gt;
col2: Utf8View&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中有两个字段列是有可变数量缓冲区的，因此 RecordBatch 的 &lt;code&gt;variadicBufferCounts&lt;/code&gt; 属性中对应有2个值。若该 schema 的一个 RecordBatch 中 &lt;code&gt;variadicBufferCounts = [3, 2]&lt;/code&gt;，那么平铺的缓冲区序列如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;buffer 0:  col1    validity
buffer 1:  col1.a  validity
buffer 2:  col1.a  values
buffer 3:  col1.b  validity
buffer 4:  col1.b  views
buffer 5:  col1.b  data
buffer 6:  col1.b  data
buffer 7:  col1.b  data
buffer 8:  col1.c  validity
buffer 9:  col1.c  values
buffer 10: col2    validity
buffer 11: col2    views
buffer 12: col2    data
buffer 13: col2    data&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;压缩&lt;/h3&gt;
&lt;p&gt;对于成批记录的消息体缓冲区内容有3种压缩方式可选：不压缩、使用 &lt;code&gt;lz4&lt;/code&gt; 压缩、使用 &lt;code&gt;zstd&lt;/code&gt; 压缩。消息体中平铺的缓冲区序列，每个缓冲区需要使用相同的压缩编码方式单独压缩。压缩处理后的缓冲区序列中某些缓冲区可能没有被压缩（例如，某些缓冲区经压缩后其大小不会明显变小）。&lt;/p&gt;
&lt;p&gt;RecordBatch “消息头”中的 &lt;code&gt;compression&lt;/code&gt; 属性用于标记使用的压缩类型，该属性可选，默认值为不压缩。&lt;/p&gt;
&lt;p&gt;对缓冲区进行压缩或不进行压缩，区别之处在：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果 &lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#ipc-recordbatch-message&quot;&apos;&gt;RecordBatch 消息&lt;/a&gt;中缓冲区经过压缩
&lt;ul&gt;&lt;li&gt;“消息头”中除了包含成批记录消息体中每个压缩过的缓冲区的大小和内存偏移量之外，还会包含使用的压缩类型。&lt;/li&gt;
&lt;li&gt;“消息体”包含经过压缩的缓冲区平铺序列，序列中每个缓冲区的起始8个字节存储缓冲区未经压缩时的长度，这个长度是小端字节序编码的64比特有符号整数。如果这个长度为 &lt;code&gt;-1&lt;/code&gt;，则表示当前 buffer 实际未经压缩。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;如果 &lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#ipc-recordbatch-message&quot;&apos;&gt;RecordBatch 消息&lt;/a&gt;中缓冲区未经压缩
&lt;ul&gt;&lt;li&gt;“消息头”中仅包含成批记录消息体中每个未经压缩缓冲区的大小和内存偏移量。&lt;/li&gt;
&lt;li&gt;“消息体”则简单地包含未经压缩缓冲区的平铺序列。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;&lt;a href=&apos;&quot;https://en.wikipedia.org/wiki/Endianness&quot;&apos;&gt;字节序&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Arrow 列存格式默认使用小端序字节编码。&lt;/p&gt;
&lt;p&gt;Schema 序列化后的元数据中包含一个 &lt;code&gt;endianness&lt;/code&gt; 属性，表示成批记录使用哪种字节序编码。通常就是生成该 RecordBatch 的系统使用的字节序。该属性的主要用处是确保在使用相同字节序的系统之间传输成批记录数据。如果系统在读取 Schema 时发现字节序和自己不匹配，则应该报错。&lt;/p&gt;
&lt;h3&gt;IPC 流式编码格式&lt;/h3&gt;
&lt;p&gt;我们为成批记录序列提供了一种流式编码协议或者说“格式”，其表现为一个密封消息序列，每个密封消息都遵循前文所属的格式。流中，先放入 schema，后面放入的所有成批记录 schema 都是同一个。如果 schema 中任一字段列使用字典编码，那么流中会包含一个或多个 &lt;code&gt;DictionaryBatch&lt;/code&gt; 消息。&lt;code&gt;DictionaryBatch&lt;/code&gt; 消息和 &lt;code&gt;RecordBatch&lt;/code&gt; 消息可能会交织出现，但是 &lt;code&gt;RecordBatch&lt;/code&gt; 中使用的所有字典 id 都应该在其前面的 &lt;code&gt;DictionaryBatch&lt;/code&gt; 消息中定义好。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY k - 1&amp;amp;gt;
&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY x DELTA&amp;amp;gt;
...
&amp;amp;lt;DICTIONARY y DELTA&amp;amp;gt;
...
&amp;amp;lt;RECORD BATCH n - 1&amp;amp;gt;
&amp;amp;lt;EOS [optional]: 0xFFFFFFFF 0x00000000&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p&gt;注解：&lt;/p&gt;
&lt;p&gt;字典和数据成批记录交织出现的规则有一个特殊情况 - 如果字典成批记录中的向量完全为空，那么数据列所使用的字典可能会出现首个数据成批记录的后面。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;实现一个流读取器，在读取每条消息后，需要先读取接下来的8个字节来确定流是否继续以及下一条消息的元数据大小。一旦读到了消息的 flatbuffer 编码元数据，就可以继续读取消息体部分了。&lt;/p&gt;
&lt;p&gt;流写入器，可以写入 4字节的再开始标识（&lt;code&gt;0xFFFFFFFF&lt;/code&gt;）拼接上4字节的元数据长度 0（&lt;code&gt;0x00000000&lt;/code&gt;） 来标识流结束（EOS），或者简单关闭流接口。对于流格式，我们推荐使用 “.arrows” 文件扩展名，虽然许多情况下流并不会存为文件。&lt;/p&gt;
&lt;h3&gt;IPC 文件格式&lt;/h3&gt;
&lt;p&gt;我们定义一种支持随机访问的“文件格式”，作为流式编码格式的一种扩展。文件的起始和末尾均是一个魔术字符串 &lt;code&gt;ARROW1&lt;/code&gt;(加上填充)。起始魔术字符串之后紧跟是流式编码格式的内容，之后在末尾魔术字符串之前，先写入一个尾部（footer） - 包含 schema（流式编码格式的一部分） 的一个拷贝，加上文件中每个数据块的内存偏移量和大小信息。这样就能够随机访问文件中的任一成批记录。可以查看 &lt;a href=&apos;&quot;https://github.com/apache/arrow/blob/main/format/File.fbs&quot;&apos;&gt;File.fbs&lt;/a&gt; 文件了解文件尾部的定义细节。&lt;/p&gt;
&lt;p&gt;语义上，文件格式如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;magic number &amp;amp;quot;ARROW1&amp;amp;quot;&amp;amp;gt;
&amp;amp;lt;empty padding bytes [to 8 byte boundary]&amp;amp;gt;
&amp;amp;lt;STREAMING FORMAT with EOS&amp;amp;gt;
&amp;amp;lt;FOOTER&amp;amp;gt;
&amp;amp;lt;FOOTER SIZE: int32&amp;amp;gt;
&amp;amp;lt;magic number &amp;amp;quot;ARROW1&amp;amp;quot;&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个文件格式并不要求 &lt;code&gt;RecordBatch&lt;/code&gt; 中使用的字典 id 要定义在前面的 &lt;code&gt;DictionaryBatch&lt;/code&gt; 中，主要这些 id 定义在文件的某处即可。此外，每个字典 ID 如果存在多个非增量字典也是无效的（比如：不支持字典覆盖替换）。增量字典按照他们在文件尾部中出现的顺序应用生效。以这种格式创建的文件推荐使用 “.arrow” 文件扩展名。请注意这种格式创建的文件有时也被称为“Feature V2”，使用 “.feature” 文件扩展名，这个名称和扩展名源自“Feature （V1）” - Arrow 项目早期为 Python（Pandas） 和 R 语言的语言无关快速数据框（data frame）存储做的一个概念验证。&lt;/p&gt;
&lt;p&gt;另附 - File.fbs 中 Footer 定义：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;include &amp;amp;quot;Schema.fbs&amp;amp;quot;;

namespace org.apache.arrow.flatbuf;

/// ----------------------------------------------------------------------
/// Arrow 文件元数据
///

table Footer {
  version: org.apache.arrow.flatbuf.MetadataVersion;
  schema: org.apache.arrow.flatbuf.Schema;
  dictionaries: [ Block ];
  recordBatches: [ Block ];
  /// 用户自定义元数据
  custom_metadata: [ KeyValue ];
}

struct Block {
  /// Index to the start of the RecordBlock (note this is past the Message header)
  offset: long;
  /// Length of the metadata
  metaDataLength: int;
  /// Length of the data (this is aligned so there can be a gap between this and
  /// the metadata).
  bodyLength: long;
}

root_type Footer;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;字典编码消息&lt;/h3&gt;
&lt;p&gt;字典是以成批记录序列的形式写入流或者文件格式的，其成批记录中仅包含单个字段列。因此，一个字典成批记录序列的完整语义 schema 包括所有字典带的 schema。所以必须先从字典成批记录的 schema 中读取字典类型信息，才能正确地对字典数据进行解析翻译：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;table DictionaryBatch {
  id: long;
  data: RecordBatch;
  isDelta: boolean = false;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;字典消息元数据中的字典 &lt;code&gt;id&lt;/code&gt; 可以在数据成批记录的 schema 中被多次引用，因此同一个字典可以被多个数据字段列使用。可以阅读&lt;a href=&apos;&quot;https://arrow.apache.org/docs/format/Columnar.html#dictionary-encoded-layout&quot;&apos;&gt;字典编码内存布局&lt;/a&gt;一节了解字典编码数据的语义。&lt;/p&gt;
&lt;p&gt;字典 &lt;code&gt;isDelta&lt;/code&gt; 标志位允许对前面存在的字典进行扩展，以便支持后续成批记录的解析。如果一个字典成批记录的 &lt;code&gt;isDelta&lt;/code&gt; 设置为真（true），则表示它的向量数据应该和前面同 id 的字典成批记录拼接在一起。假设对一列数据进行流式编码，该列数据为一个字符串列表 &lt;code&gt;[&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;A&amp;quot;]&lt;/code&gt;，其增量（delta）字典成批记录的形式可能如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;B&amp;amp;quot;
(2) &amp;amp;quot;C&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
0
1
2
1

&amp;amp;lt;DICTIONARY 0 DELTA&amp;amp;gt;
(3) &amp;amp;quot;D&amp;amp;quot;
(4) &amp;amp;quot;E&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 1&amp;amp;gt;
3
2
4
0
EOS&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或者，如果 &lt;code&gt;isDelta&lt;/code&gt; 被设置为假（false），那么同 ID 的字典，后面的会覆盖替换前面的。同样使用如上的例子，对应编码形式可能如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;lt;SCHEMA&amp;amp;gt;
&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;B&amp;amp;quot;
(2) &amp;amp;quot;C&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 0&amp;amp;gt;
0
1
2
1

&amp;amp;lt;DICTIONARY 0&amp;amp;gt;
(0) &amp;amp;quot;A&amp;amp;quot;
(1) &amp;amp;quot;C&amp;amp;quot;
(2) &amp;amp;quot;D&amp;amp;quot;
(3) &amp;amp;quot;E&amp;amp;quot;

&amp;amp;lt;RECORD BATCH 1&amp;amp;gt;
2
1
3
0
EOS&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2024-12-07</pubDate>
            <link>https://blog.xiayf.cn/posts/arrow-ipc.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/arrow-ipc.html</guid>
        </item>
        
        <item>
            <title>团队开发流程规范</title>
            <description>&lt;p&gt;&lt;em&gt;本文原是针对实际工作中团队的情况编写的一份流程规范说明，隐去敏感信息之后存放于此。&lt;/em&gt;&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2023/04/05/wQ9bOaXyNiCjh5H.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;开发流程规范 是一种团队文化，也是服务和业务稳定性的基本保障线。&lt;/p&gt;
&lt;h2&gt;一、文档&lt;/h2&gt;
&lt;blockquote&gt;&lt;p&gt;共识：“谋定而后动”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;团队的开发工作主要来自3个方面：工程优化（平响优化、性能优化、稳定性/可用性优化等）、算法业务需求、产品业务需求。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（强制）每一项开发工作实际编码之前，都需要梳理一份文档，放在 开发文档 目录下&lt;/li&gt;
&lt;li&gt;（建议）文档命名规则如示例 “w1-20220721-xxx需求”、“w1-20220721-xxx优化”，“w1” 是文档的按序编号。&lt;/li&gt;
&lt;li&gt;（建议）每一项工作，上线/推全后，部署相关信息、工程指标变化、业务指标变化、资源成本变化、遗留待优化的非关键问题等相关信息也应补充到文档中。&lt;/li&gt;
&lt;li&gt;（建议）如果走实验流程，也在在文档中加上“实验推进板块”，记录实验推进情况，遇到的问题等，特别是对于多场景实验推进的情况。&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.1 工程优化 文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;背景/现状描述/问题分析&lt;/li&gt;
&lt;li&gt;优化方案/设计方案&lt;/li&gt;
&lt;li&gt;预期收益&lt;/li&gt;
&lt;li&gt;分工排期&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.2 算法业务需求文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确算法负责人，链接上算法侧相关文档（要求算法同学提供） - 文档中包含 背景、预期收益、算法逻辑/模型等要点信息&lt;/li&gt;
&lt;li&gt;明确工程方案，对于复杂的算法业务需求，应该给出设计概要&lt;/li&gt;
&lt;li&gt;预估资源成本&lt;/li&gt;
&lt;li&gt;明确项目优先级 和 排期 / Deadline&lt;/li&gt;
&lt;li&gt;对于高优紧急需求，尽可能预先明确进度风险点&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.3 产品业务需求文档&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确产品负责人，链接上产品侧相关文档（要求产品同学提供） - 文档中包含 背景、预期收益、产品规则等要点信息&lt;/li&gt;
&lt;li&gt;明确工程方案，对于复杂的产品业务需求，应该给出设计概要&lt;/li&gt;
&lt;li&gt;预估资源成本&lt;/li&gt;
&lt;li&gt;明确项目优先级 和 排期 / Deadline&lt;/li&gt;
&lt;li&gt;对于高优紧急需求，尽可能预先明确进度风险点&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.4 所有文档&lt;/h3&gt;
&lt;p&gt;（强制）必须包含：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;测试用例设计和全面完整的测试报告/diff 报告&lt;/li&gt;
&lt;li&gt;包含对应各个代码库变更的 MR 链接、发布版本的 tag 链接&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;二、编码&lt;/h2&gt;
&lt;h3&gt;2.1 统一代码规范&lt;/h3&gt;
&lt;blockquote&gt;&lt;p&gt;共识：新代码统一新风格，老代码风格维持不变。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;2.1.1 C++&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/cppguide.html&apos;&gt;Google C++ Style Guide&lt;/a&gt;、&lt;a href=&apos;https://zh-google-styleguide.readthedocs.io/en/latest/google-cpp-styleguide/contents/&apos;&gt;Google C++ 风格指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码规范/风格检查工具：&lt;a href=&apos;https://github.com/cpplint/cpplint&apos;&gt;cpplint&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Google 官方提供的工具，用于检测 C++ 代码是否符合 Google C++ Style Guide&lt;/li&gt;
&lt;li&gt;VS Code 插件：&lt;a href=&apos;https://marketplace.visualstudio.com/items?itemName=mine.cpplint&apos;&gt;cpplint - Visual Studio Marketplace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vim 插件：&lt;a href=&apos;https://github.com/vim-syntastic/syntastic&apos;&gt;vim-syntastic/syntastic: Syntax checking hacks for vim (github.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clion 插件：&lt;a href=&apos;https://plugins.jetbrains.com/plugin/7871-clion-cpplint&apos;&gt;CLion-cpplint - CLion Plugin | Marketplace (jetbrains.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;代码格式化工具：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html&apos;&gt;clang-format&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;项目根目录下放置 .clang-format 文件，编辑器/IDE 配置成编码时自动格式化或者保存时自动格式化：&lt;/li&gt;
&lt;li&gt;VS Code 插件：&lt;a href=&apos;https://marketplace.visualstudio.com/items?itemName=xaver.clang-format&apos;&gt;Clang-Format - Visual Studio Marketplace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vim 集成：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html#vim-integration&apos;&gt;https://clang.llvm.org/docs/ClangFormat.html#vim-integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clion 集成：&lt;a href=&apos;https://clang.llvm.org/docs/ClangFormat.html#clion-integration&apos;&gt;https://clang.llvm.org/docs/ClangFormat.html#clion-integration &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;---
BasedOnStyle: Google
---
Language: Cpp
IndentWidth: 4
ColumnLimit: 120
DerivePointerAlignment: false
PointerAlignment: Left
SortIncludes: CaseSensitive
Standard: Auto
AccessModifierOffset: -4
SpacesBeforeTrailingComments: 2
AllowShortBlocksOnASingleLine: Never
AllowShortIfStatementsOnASingleLine: Never
AllowShortLoopsOnASingleLine: false
AllowShortFunctionsOnASingleLine: Empty
AlignTrailingComments: true
BinPackParameters: false
AllowAllParametersOfDeclarationOnNextLine: false&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;2.1.2 Java&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/javaguide.html&apos;&gt;Google Java Style Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.jetbrains.com/idea/&apos;&gt;IDE - Jetbrains IDEA&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;下载代码风格定义文件：&lt;a href=&apos;https://raw.githubusercontent.com/google/styleguide/gh-pages/intellij-java-google-style.xml&apos;&gt;intellij-java-google-style.xml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;导入 IDEA&lt;/li&gt;
&lt;li&gt;安装 Save Actions 插件&lt;/li&gt;
&lt;li&gt;配置 Save Actions 插件&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;2.1.3 Python&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Python 3 + &lt;a href=&apos;https://docs.python.org/3/library/venv.html&apos;&gt;venv 虚拟环境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://google.github.io/styleguide/pyguide.html&apos;&gt;Google Python Style Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码规范/风格检查工具：&lt;a href=&apos;https://pylint.pycqa.org/en/latest/&apos;&gt;pylint&lt;/a&gt;、&lt;a href=&apos;https://google.github.io/styleguide/pyguide.html#21-lint&apos;&gt;https://google.github.io/styleguide/pyguide.html#21-lint&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Vim 集成：&lt;a href=&apos;https://github.com/vim-syntastic/syntastic&apos;&gt;vim-syntastic/syntastic: Syntax checking hacks for vim (github.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VS Code 集成：&lt;a href=&apos;https://code.visualstudio.com/docs/python/linting#_pylint&apos;&gt;Linting Python in Visual Studio Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyCharm 插件：&lt;a href=&apos;https://plugins.jetbrains.com/plugin/11084-pylint&apos;&gt;Pylint - IntelliJ IDEA &amp; PyCharm Plugin | Marketplace (jetbrains.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;代码格式化工具：&lt;a href=&apos;https://github.com/google/yapf/&apos;&gt;yapf&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Vim 集成：&lt;a href=&apos;https://github.com/google/yapf/tree/main/plugins#vim&apos;&gt;https://github.com/google/yapf/tree/main/plugins#vim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VS Code 集成：&lt;a href=&apos;https://code.visualstudio.com/docs/python/editing#_formatting&apos;&gt;Editing Python Code in Visual Studio Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyCharm 集成：&lt;a href=&apos;https://github.com/google/yapf/issues/631&apos;&gt;How do I install yapf in pycharm · Issue #631 · google/yapf (github.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.2 代码分支管理&lt;/h3&gt;
&lt;blockquote&gt;&lt;p&gt;共识：一个代码库一个主分支；所有开发分支在测试/实验验证之后都需要合入主分支&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;（强制）基本的 git 工作流：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每项开发工作，都从主分支签出一个（公共）开发分支&lt;/li&gt;
&lt;li&gt;如果是多人协作的开发工作，则基于新签出的公共开发分支，每个人各自签出个人的开发分支，进行独立开发&lt;/li&gt;
&lt;li&gt;个人开发自测完成后，合入公共开发分支，进行集成测试联调&lt;/li&gt;
&lt;li&gt;如果走实验流程，则使用（公共）开发分支的 sandbox 镜像部署实验集群&lt;/li&gt;
&lt;li&gt;实验推全反转下线后，（公共）开发分支合入主分支，并基于主分支上的正式 tag 镜像发布基准集群&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;（建议）分支命名规范：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（公共）开发分支：
&lt;ul&gt;&lt;li&gt;常规需求开发分支：feature/[目标服务名]-[文档 ID]&lt;/li&gt;
&lt;li&gt;紧急需求开发分支：urgent/[目标服务名]-[文档 ID]&lt;/li&gt;
&lt;li&gt;紧急修复开发分支：hotfix/[目标服务名]-[文档 ID]&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;个人开发分支：在（公共）开发分支后带上个人 ID，示例：feature/[目标服务名]-[文档 ID]-[个人 ID]&lt;/li&gt;
&lt;li&gt;对紧急需求和紧急修复开发分支，可以先创建一个文档，拿到文档 ID，内容可能来不及写得非常完善，但之后应该进行补充完善&lt;/li&gt;
&lt;li&gt;不符合规范的开发分支，不能推送到远程代码库（不能对团队其他人可见），通过 git hook 来强行限制&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;（建议）所有（公共）开发分支、（需要代码评审的）个人开发分支，都应该创建对应的 MR，邀请其他人进行代码评审时，提供对应的 MR&lt;/p&gt;
&lt;h3&gt;2.3 Commit 规范&lt;/h3&gt;
&lt;p&gt;&lt;a href=&apos;https://www.conventionalcommits.org/zh-hans/v1.0.0/&apos;&gt;约定式提交 (conventionalcommits.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（建议）参考 Apache 顶级项目的实践（如 apache/arrow），commit log 的“描述”部分先带上文档链接。&lt;/p&gt;
&lt;h3&gt;2.4 MR 与代码评审&lt;/h3&gt;
&lt;blockquote&gt;&lt;p&gt;共识：质量把关、经验传承&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;从团队和长远来看，Code Review 的重要性再怎么强调都不为过。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（强制）每个开发分支的工作在开实验或者合入主分支之前，都需要邀请至少 3 名资深同学进行 Code Review&lt;/li&gt;
&lt;li&gt;（强制）评审员在确认没有意见或者所有优化意见都已得到合理解决后对 MR 进行点赞 👍&lt;/li&gt;
&lt;li&gt;（强制）开发分支/MR 需要攒 3 个以上的点赞才能开实验流量或者合入主分支&lt;/li&gt;
&lt;li&gt;（强制）对于基于分支开实验流量的分支代码，也必须经 code review 后，基于分支进行打实验 tag，并基于实验 tag 进行线上发布。&lt;/li&gt;
&lt;li&gt;（建议）适当约束分支合入权限，仅资深同学（具体名单？）才能将开发分支/MR 合入主分支&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-markdown&quot;&gt;&lt;code&gt;变更应该组织成1个或多个补丁/MR，视变更大小而定，组织方式遵循以下规范指南：
- MR 应该小一点
- MR 应该都可以独立编译并且是正确的（所有测试用例都通过）。不需要你验证这一点，但是需要在代码中放入一种标记来反映 MR 是否违反了这条规则。例如：在 fix 一个问题之前，先引入一个回归测试用例用例。
- MR 应该自包含（高内聚），并且只做一件事情。
- 每个 MR 都应该包含一份描述性的提交日志（commit log）。
- MR 的描述信息不应该假设代码评审人是一个专家。它应该包含足够的上下文信息，确保即使一个普通的小白也能理解。
- MR 的描述信息应该自包含，也不要引用无法保持关联的讨论信息（“如每日沟通达成的一致结论”）。
- MR 应该包含变更的动机（背景）。不能简单地说一句“让 X 完成 Y”，而应该仔细解释为什么要这么做。 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;另附：&lt;a href=&apos;https://google.github.io/eng-practices/&apos;&gt;Google Engineering Practices Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2.5 CI 约束&lt;/h3&gt;
&lt;p&gt;因当前一个代码库支持产出不同服务的二进制程序和 Docker 镜像，为加速 CI，使用了条件编译，根据不同条件触发不同 CI 流水线。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;根据分支名的目标服务名对应触发不同 CI 流水线（all 则触发所有的 CI 流水线）&lt;/li&gt;
&lt;li&gt;MR 合入 master 分支时，必须触发所有 CI 流水线。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;基于 .gitlab-ci.yml 配置强行约束。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;2.6 版本 Tag 规范&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;正式tag
&lt;ul&gt;&lt;li&gt;只能在 master 分支上打 tag，tag 命名规范为 v主版本号.次版本号.修订号，基于 语义化版本&lt;/li&gt;
&lt;li&gt;tag 内容必须包含必要的描述性信息，声明此次变更的内容，包含相关的 MR、文档链接&lt;/li&gt;
&lt;li&gt;hotfix 版本 tag，应该以 fix 之前的 tag 为前缀，加上“-hotfix” 后缀，示例：v10.0.1-hotfix；如果对同一个 tag 的代码发生了不只一次 hotfix，则继续补充上秒级的时间戳作为后缀&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;实验tag
&lt;ul&gt;&lt;li&gt;在分支上打tag进行线上实验开量，tag命名规范：exp.文档编号.迭代版本号，示例：exp.w88.0&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.7 监控打点和日志&lt;/h3&gt;
&lt;blockquote&gt;&lt;p&gt;共识：以尽可能小的性能开销最大化系统的可观测性&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;（建议）多使用 ROC 打点，借助多维数据分析，方便问题定位分析&lt;/li&gt;
&lt;li&gt;（强制）注意日志级别（DEBUG、INFO、ERROR、FATAL）的语义
&lt;ul&gt;&lt;li&gt;不要使用非 DEBUG 级别来输出 DEBUG 日志&lt;/li&gt;
&lt;li&gt;注意 FATAL 的实际影响&lt;/li&gt;
&lt;li&gt;不同环境使用不同的日志级别，生产环境不要输出 DEBUG 日志，https://github.com/google/glog#setting-flags&lt;/li&gt;
&lt;li&gt;（建议）使用 glog vlog 来进一步控制不同环境/场景下的日志量，https://github.com/google/glog#verbose-logging&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（强制）不要默默地失败
&lt;ul&gt;&lt;li&gt;ERROR/WARNING 日志&lt;/li&gt;
&lt;li&gt;Event 打点&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）使用 Event 打点充分表现输入量、输入类型、输出量、变化趋势
&lt;ul&gt;&lt;li&gt;请求 QPS、增量消息 TPS、不同类型增量消息的 TPS、。。。&lt;/li&gt;
&lt;li&gt;基准数据的统计计数&lt;/li&gt;
&lt;li&gt;请求来源：客户端类型粒度、客户端 ip 粒度、场景维度、媒体维度、。。。&lt;/li&gt;
&lt;li&gt;trigger 数、各类过滤器数目统计&lt;/li&gt;
&lt;li&gt;检索结果数量、截断后/实际返回给客户端的结果数量&lt;/li&gt;
&lt;li&gt;各类过滤器的过滤量&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）使用 Transaction 表现耗时分布 - 整体耗时多少、时间都花在哪些环节（包括 RPC 框架内的等待时延）：Tt = T1 + T2 + ...&lt;/li&gt;
&lt;li&gt;（建议）使用 Metric 表现跨节点/集群/场景的业务指标变化趋势&lt;/li&gt;
&lt;li&gt;（建议）性能考虑，打点接口调用次数应小于等于请求 QPS、消息 TPS&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;2.8 最佳实践&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）尽早严格检测请求、数据、配置等输入的合法性&lt;/li&gt;
&lt;li&gt;（建议）尽量不使用配置中心的配置监听&lt;/li&gt;
&lt;li&gt;（建议）多了解使用基础库 - boost、abseil-cpp 等&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;三、测试&lt;/h2&gt;
&lt;h3&gt;3.1 单元测试&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;明确单元测试与集成测试的区别，&lt;a href=&apos;https://zh.wikipedia.org/wiki/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95&apos;&gt;单元测试 - 维基百科，自由的百科全书 (wikipedia.org)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;单元测试的作用：
&lt;ul&gt;&lt;li&gt;验证某个逻辑的当前实验是否符合预期&lt;/li&gt;
&lt;li&gt;更重要的是对以后的代码变更可能造成的非预期影响/破坏进行一定的防御&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;GoogleTest，用好 Mocking&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;（强制）CI 强制要求新增/变更代码的测试覆盖率。（基于 .gitlab-ci.yml 配置强行约束？）&lt;/p&gt;
&lt;h3&gt;3.2 集成测试&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）任何代码变更，都必须经过自测/集成测试
&lt;ul&gt;&lt;li&gt;任务可以正常跑起来，变更的逻辑已生效，产出的结果确认符合预期&lt;/li&gt;
&lt;li&gt;服务可以正常运行起来，变更的逻辑已生效，可以正常加载数据/索引，请求响应的结果确认符合预期&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（建议）测试环境/工具
&lt;ul&gt;&lt;li&gt;独立的测试验证集群&lt;/li&gt;
&lt;li&gt;开发机环境下的 Docker 环境 + 代码库中的 Dockerfile
&lt;ul&gt;&lt;li&gt;docker build -t image-name .&lt;/li&gt;
&lt;li&gt;docker run -dp 8003:8003 image-name&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;易用的脚本 - 一键启动+索引数据加载、易用的客户端工具、易用的数据校验工具&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;3.3 批量 Diff 测试&lt;/h3&gt;
&lt;p&gt;（强制）如果代码变更影响了索引或者检索逻辑，则应该进行充分的 diff：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果走实验，则部署新实验集群后开实验之前，进行 基准集群 VS. 实验集群 的请求结果 diff&lt;/li&gt;
&lt;li&gt;如果不走实验，则基于独立的测试验证集群，进行 生产集群 VS. 测试集群 的请求结果 diff
&lt;ul&gt;&lt;li&gt;diff 完成后，即刻释放测试集群资源&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;对于 diff 结果，不管最后的 diff 率有多小，只要有 diff，就需要确认 diff 来源/原因是否符合预期&lt;/li&gt;
&lt;li&gt;diff 的不同请求数量必须达到 1000 以上&lt;/li&gt;
&lt;li&gt;统一使用易用且功能完善的 diff 工具&lt;/li&gt;
&lt;li&gt;生产集群发版或者实验集群开流量之前，在周知相关人员时，必须一并提供 diff 结果以及已确认 diff 来源符合预期&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;四、发布&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;（强制）流量高峰期不发版&lt;/li&gt;
&lt;li&gt;（建议）周五晚上及周末不发版&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;4.1 发布之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）评估确认好本次发布前后服务集群负载是否会有变化，如果变更会影响集群负载上涨，则应提前扩容&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内进行通告，通告模板如下：&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;变更通知：
- 变更内容：xxxx
- 涉及集群和场景：xxx
- 操作人：xxx
- 相关文档（含需求背景、工程方案、代码 MR、diff / 测试报告等信息） 或 实验链接：xxx&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4.2 发布期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）先灰度发布一行或者少量行，确认各项工程指标+业务指标无异常后，再全量发布&lt;/li&gt;
&lt;li&gt;（强制）发布期间需要保持关注告警以及关键工程指标和业务指标&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;4.3 发布之后&lt;/h3&gt;
&lt;p&gt;（强制）发版完成后，确认各项工程指标/业务指标正常后，在相关大群内周知发版完成，确认各项指标平稳/符合预期&lt;/p&gt;
&lt;h2&gt;五、实验&lt;/h2&gt;
&lt;h3&gt;5.1 实验开量之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）人工刷 demo，全链路验证&lt;/li&gt;
&lt;li&gt;（强制）实验集群资源预估准备，包括评估链路中间环节资源负载变化&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内通告，通告信息：实验名、实验链接&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.2 实验期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）实验刚开量时，关注实时报表 10~30 分钟变化趋势：&lt;/li&gt;
&lt;li&gt;（建议）每天及时查看实验平台上当前实验的天级实验报表，如果有较明显的负向指标，则应及时通告出来，与相关同学一起分析可能的原因&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.3 实验扩量或推全之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）实验集群资源预估准备，包括评估链路中间环节资源负载变化&lt;/li&gt;
&lt;li&gt;（强制）与相关算法同学确认好实验时长与实验效果是否达到扩量要求&lt;/li&gt;
&lt;li&gt;（强制）在相关大群内通告，通告信息：实验名、实验链接、流量从多少变化到多少&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;5.4 实验扩量或推全操作期间&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;（强制）对实验集群负载情况保持关注&lt;/li&gt;
&lt;li&gt;（建议）对于推全操作，尽可能灰度推全，中间步骤留一定时间确认集群负载和流量变化是否符合预期&lt;/li&gt;
&lt;li&gt;（建议）先开反转，再进行推全，避免不必要的资源腾挪扩缩，也能一定程度上控制风险&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;六、规范落地&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;（建议）规范流程支持工具和平台不断优化，尽可能减少规范流程造成的人力负担&lt;/li&gt;
&lt;li&gt;（建议）不断更新完善规范&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2023-04-05</pubDate>
            <link>https://blog.xiayf.cn/posts/team-dev-process-std.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/team-dev-process-std.html</guid>
        </item>
        
        <item>
            <title>与一个前 leader 的交流笔记</title>
            <description>&lt;p&gt;如下这份笔记，是 19 年和一个前 leader 交流后记录下来的。说是交流，其实是针对我当时工作中存在的问题，他给我提出的一些改进建议。如今再看看，仍然能引起自己的思考。&lt;/p&gt;
&lt;h2&gt;2019-10-27&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;如何讨论需求/技术方案&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;系统性理解需求
&lt;ul&gt;&lt;li&gt;全面梳理技术方案，论证方案的不合理之处&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;如何证明方案不合理？
&lt;ul&gt;&lt;li&gt;资源成本（机器、人力），重复工作也是对资源的一种浪费&lt;/li&gt;
&lt;li&gt;对效果（收入等）的影响&lt;/li&gt;
&lt;li&gt;要站在“公正”的角度来论证，从大家共有的认知(机器、带宽、内存)出发&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;最后才是什么系统复杂度（说到这个点，很容易扯淡，谁都会说自己复杂）&lt;/p&gt;
&lt;p&gt;讨论问题的时候，自己不做，但不要从“硬推给别人的角度”去讨论，而是要从“为啥自己不应该做”的角度出发。比如做了，导致系统耦合，复杂，做了导致多余的调用量更多等 。&lt;/p&gt;
&lt;h2&gt;2019-12-17&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;跨团队工作讨论时，围绕应该怎么做（怎么做最合理）来讨论，而不是围绕如果自己来做会有什么困难来讨论&lt;/li&gt;
&lt;li&gt;项目/系统要有 目标/长远架构图（最终做成什么样子，核心 KPI）&lt;/li&gt;
&lt;li&gt;做好向上汇报&lt;/li&gt;
&lt;li&gt;不要拿“做的过程中的困难”来搪塞不做，而是要从客观事实的角度来问应不应该做&lt;/li&gt;
&lt;li&gt;不要聚焦于解决现实世界的一个个问题，而是要靠具体的一个个问题，抽象出一张大图&lt;/li&gt;
&lt;li&gt;把自己的系统做成链路上最极致的那个，而不是等别人做好后来反推自己变革&lt;/li&gt;
&lt;li&gt;要区分重要和不重要的事情，核心的事情要仔细揣摩，没有人是傻子，那些资深的人说出的话更要揣摩，理解&lt;/li&gt;
&lt;li&gt;要有规划和愿景，leader 没有这些，团队走不远&lt;/li&gt;&lt;/ol&gt;</description>
            <pubDate>2022-11-16</pubDate>
            <link>https://blog.xiayf.cn/posts/talk-about-how-to-do.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/talk-about-how-to-do.html</guid>
        </item>
        
        <item>
            <title>读文笔记：关于 MMAP 与 SSD</title>
            <description>&lt;p&gt;设计一种存储，第一要明确应用场景和存储系统的工作负载，第二要了解底层硬件的特点。&lt;/p&gt;
&lt;h2&gt;1、&lt;a href=&apos;https://db.cs.cmu.edu/mmap-cidr2022/&apos;&gt;Are You Sure You Want to Use MMAP in Your Database Management System? &lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;MMAP（Memory-mapped file I/O）是操作系统提供的一种功能特性 - 将二级存储（磁盘、SSD）上一个文件的内容映射到程序/进程的地址空间，然后程序就可以以指针访问内存页的方式来访问文件内容。当程序访问到某个内存页时，操作系统就会自动将对应文件内容加载到该内存页中，当内存用满了，也会自动剔除某些内存页。&lt;/p&gt;
&lt;p&gt;MMAP 其实就一个现成的缓冲池（buffer pool），核心特点就是简单易用，不需要重复开发，缺点是在需要时无法精确控制其行为。&lt;/p&gt;
&lt;p&gt;使用 MMAP 的优势是由操作系统封装了如下功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从磁盘读数据&lt;/li&gt;
&lt;li&gt;不同线程读相同数据的并发处理&lt;/li&gt;
&lt;li&gt;缓存和缓冲管理（Caching and buffer management）&lt;/li&gt;
&lt;li&gt;从内存中剔除/驱逐内存页&lt;/li&gt;
&lt;li&gt;同一个机器上不同进程之间可以友好交互 🤔&lt;/li&gt;
&lt;li&gt;跟踪脏页以及将脏页写入磁盘 🤔&lt;/li&gt;
&lt;li&gt;相比 read/write 系统调用，mmap 不需要将内存页从内核空间拷贝到用户空间，而是直接从操作系统的内存页缓存中直接访问内存页，有一定的性能优势&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;MMAP 相关 POSIX API：mmap、madvise、mlock、msync。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/U7xMgzj36dZDGaO.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;① A program calls mmap and receives a pointer to the memory-mapped file contents.&lt;/p&gt;
&lt;p&gt;② The OS reserves part of the program’s virtual address space but does not load any part of the file.&lt;/p&gt;
&lt;p&gt;③ The program accesses the file’s contents using the pointer.&lt;/p&gt;
&lt;p&gt;④ The OS attempts to retrieve the page.&lt;/p&gt;
&lt;p&gt;⑤ Since no valid mapping exists for the specified virtual address, the OS triggers a page fault to load the referenced part of the file from secondary storage into a physical memory page.&lt;/p&gt;
&lt;p&gt;⑥ The OS adds an entry to the page table that maps the virtual address to the new physical address.&lt;/p&gt;
&lt;p&gt;⑦ The initiating CPU core also caches this entry in its local translation lookaside buffer (TLB) to accelerate future accesses.&lt;/p&gt;
&lt;p&gt;不过论文作者认为 mmap 存在一些数据安全性和系统性性能问题，为解决这些问题而引入的工程成本会抵消掉简单性：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、事务安全性（Transactional Safety）&lt;/strong&gt;：由于透明的页式调度机制，操作系统可能会任意时刻将一个脏页刷到二级存储中，不管写事务是否已提交。DBMS 无法组织这种内存数据刷出，并且发生时也不会接收到任何信号。所以基于 mmap 的数据库系统只能采用复杂的协议来确保（写/更新）事务安全，手段上大概分3种：操作系统写时复制、用户空间写时复制、影子页管理（shadow paging）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、I/O 停顿（I/O Stalls）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;mmap 不支持异步读；自己搞缓冲池的话，可以使用异步 I/O（比如 libaio、io_uring）来避免查询时阻塞线程&lt;/li&gt;
&lt;li&gt;对于 mmap，因为操作系统会自动/透明地剔除一些内存页，这样可能导致 - 如果某些只读查询命中了已被剔除的内存页，就会无法预知地触发阻塞性的页错误/缺页处理&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;解决方案：1、使用 mlock，不过操作系统对一个进程能锁住的内存页数量有限制；2、使用 madvise 的 MADV_SEQUENTIAL 标记，仅能问题的一部分；3、使用额外的线程来进行内存页预取，避免主线程被阻塞，不过会引入较大的复杂性&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、错误处理&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;DBMS 的核心职责之一是确保数据完整性 - 比如：校验磁盘数据是否有损坏&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用 mmap，DBMS 需要在每次内存页访问时检查校验和（checksum），因为内存页一次访问之后操作系统可能会将该页驱逐到磁盘&lt;/li&gt;
&lt;li&gt;如果 DBMS 是使用非内存安全的编程语言编写的，就有可能在指针操作时损坏内存页内容，所以需要在内存页刷到二级存储之前进行错误检测，mmap 会默默地将损坏的内存页持久化到二级存储&lt;/li&gt;
&lt;li&gt;使用 mmap 也更难优雅地进行 I/O 错误处理，和 mmap 内存交互的任何代码都可能抛出 SIGBUS 信号，DBMS 必须使用信号处理器（signal handlers）来处理 ❓&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4、性能问题（最重大）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;大家普遍认为 mmap 性能优于传统文件 I/O（read/write），因为它避免两个开销：(1) 显式调用 read/write 系统调用的开销 (2) mmap 会返回指向操作系统页缓存的页指针，因此避免了到用户内存空间的一次内存拷贝，也因此降低了内存占用；由此，大家也认为在 SSD 上 mmap 的性能优势会进一步扩大。&lt;/li&gt;
&lt;li&gt;不过实验测试发现：对于高带宽的二级存储设备（比如 SSD），DBMS 管理的数据量大于内存空间时，操作系统的页驱逐机制（page eviction mechanisms）多线程扩展性比较差（备注：因为 SSD I/O 带宽大、访问速度快，页驱逐机制就可能成了瓶颈）（we have found that the OS’s page eviction mechanisms cannot scale beyond a few threads for larger-thanmemory DBMS workloads on high-bandwidth secondary storage devices. We believe that one of the main reasons these performance issues have gone largely unnoticed is due to historically limited file I/O bandwidth）。瓶颈源于3个因素：
&lt;ul&gt;&lt;li&gt;页表争用（page table contention）/ 锁（备注：当前 linux 内核实现优化了这个问题，&lt;a href=&apos;https://github.com/torvalds/linux/blob/master/Documentation/mm/split_page_table_lock.rst&apos;&gt;linux/split_page_table_lock.rst at master · torvalds/linux (github.com)&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;单线程页驱逐（single-threaded page eviction），&lt;a href=&apos;https://biriukov.dev/docs/page-cache/4-page-cache-eviction-and-page-reclaim/&apos;&gt;Page Cache eviction and page reclaim | Viacheslav Biriukov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;旁路转换缓冲击落（TLB shootdowns）：TLB shootdowns occur during page eviction when a core needs to invalidate mappings in a remote TLB. Whereas flushing the local TLB is inexpensive, issuing interprocessor interrupts to synchronize remote TLBs can take thousands of cycles
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://juejin.cn/post/6844904084957315086&apos;&gt;深入理解 Linux 内核--jemalloc 引起的 TLB shootdown 及优化 - 掘金 (juejin.cn)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://www.kernel.org/doc/html/v4.18/core-api/cachetlb.html&apos;&gt;Cache and TLB Flushing Under Linux — The Linux Kernel documentation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;实验分析：&lt;/p&gt;
&lt;p&gt;As a baseline, we used the fio storage benchmarking tool (v3.25) with direct I/O (O_DIRECT) to bypass the OS page cache. Our analysis focused exclusively on read-only workloads, which represent the best-case scenario for mmap-based DBMSs.&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/FlAJqH8E4K1UWvp.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/qhz3OQHlgaZ2YMn.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/oczkfgLw9EMR1ue.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;p&gt;那么，到底要不要使用 mmap 呢？直接使用 ssd？还是自己搞一个 buffer pool？&lt;/p&gt;
&lt;p&gt;论文作者给出这样的结论：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;以下情况不要使用 mmap：
&lt;ul&gt;&lt;li&gt;需要以事务安全的方式进行更新操作&lt;/li&gt;
&lt;li&gt;希望处理缺页错误时不会阻塞在慢 I/O 上，或者希望明确控制哪些数据应该在内存中&lt;/li&gt;
&lt;li&gt;关心错误处理，也希望始终返回正确的数据结果&lt;/li&gt;
&lt;li&gt;要求在快速持久化存储设备（比如 SSD）上获得高吞吐&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;以下情况可能应该使用 mmap：
&lt;ul&gt;&lt;li&gt;内存可以容纳整个数据工作集（或者说整个数据库），并且是只读的工作负载&lt;/li&gt;
&lt;li&gt;希望将一个产品快速推向市场，也不关注数据一致性或者长期的工程技术债&lt;/li&gt;
&lt;li&gt;Otherwise, never 🤣🙃&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;彩蛋：论文的奇数页页眉  😂&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/AIqHKTC213FYaxX.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100&apos;/&gt;
&lt;h2&gt;2、&lt;a href=&apos;https://ayende.com/blog/196161-C/re-are-you-sure-you-want-to-use-mmap-in-your-database-management-system&apos;&gt;re: Are You Sure You Want to Use MMAP in Your Database Management System? &lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;本文作者认为自己实现一个内存分页管理器/缓冲池比较复杂，使用 mmap 来实现存储系统会很快。&lt;/p&gt;
&lt;p&gt;不过吐槽了原论文没有给出可供选择的替代方案，基准测试和结论之间也没太多相关性（compares apples to camels），也低估了自己实现一个替代 mmap 的缓冲池的复杂性。&lt;/p&gt;
&lt;p&gt;不用 mmap 的话，论文提及的那些问题，也是要解决的（If you aren’t using mmap, on the other hand, you still need to handle all those issues. That is a key point that I believe isn’t addressed in the paper. Solving those issues properly (and efficiently) is a seriously challenging task. Given that you are building a specialized solution, you can probably do better than the generic mmap, but it will absolutely have a cost. That cost is both in terms of runtime overhead as well as increased development time.）。&lt;/p&gt;
&lt;p&gt;原论文的实验说明了 mmap 的性能问题，但是换个 buffer pool 的实现能不能获得更好的性能呢？该文作者持悲观态度。&lt;/p&gt;
&lt;p&gt;存储系统实际面对的工作负载不会是完全的随机读（写）或顺序扫描，通常都具有一定的热点数据，这时 buffer pool 的优势就会体现出来？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;关于“问题 1 - 事务安全性” - 不用 mmap，解决这个问题的方案没什么不同（I don’t actually care if the data is written to memory behind my back. What I care about is MVCC (a totally separate concern than buffer management). The fact that I’m copying the modified data to the side means that I Can support concurrent transactions with far greater ease.）&lt;/li&gt;
&lt;li&gt;关于“问题 2 - I/O 停顿” - 该文作者认为确实个问题（not having control over the I/O means that you may incur a page fault at any time），并且是基于 mmap 的系统要面对的最大问题。不过实际情况是 linux 系统中 io_uring 之外的异步 I/O 方案在某些时候异步操作也会是阻塞的。是否使用 mmap，这个问题的解决方案也没有本质区别。&lt;/li&gt;
&lt;li&gt;关于“问题 3 - 错误处理” - 该文作者以自己开发的 Voron 为例说明即使使用 mmap，也可以较好地实现校验和检查（使用一个 bitmap 来记录哪些内存页被访问过，在第一次访问某个内存页的时候检查校验和），并认为程序一次运行过程中对于指定的一个内存页检查一次就可以，其他情况下的检查都是没有意义的。When you use read() to get data from the disk, you have no guarantees that the data wasn’t fetched from a cache along the way. So you may validate the data you read is “correct”, while the on disk representation is broken. For that reason, we only do the check once, instead of each time. 🤔 好像不是这个理？
&lt;ul&gt;&lt;li&gt;至于发现 I/O 错误，如何处理？该文作者认为答案只有一个 - 让它崩溃然后重新恢复并运行（Crash and then run recovery from scratch），因为如果 I/O 系统返回了一个错误，应用逻辑也不会有任何方式知道 I/O 系统的当前状态是什么，应该怎么解决，唯一的方式就是停下来，重新加载一切（应用 WAL 进行恢复），回到一个稳定状态。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;关于“问题 4 - 性能问题” -
&lt;ul&gt;&lt;li&gt;页表争用（page table contention）：linux 内核已优化解决&lt;/li&gt;
&lt;li&gt;单线程页驱逐（single-threaded page eviction）：如果写/更新频率不高，脏页不多的话，也不会成为性能瓶颈&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://stackoverflow.com/questions/3748384/what-is-tlb-shootdown&apos;&gt;旁路转换缓冲击落（TLB shootdowns）&lt;/a&gt;：在一定条件下才会成为性能瓶颈，当你真的遇到时应该也会多花钱买内存来解决 🤣🙃（In order to actually observe the cost of TLS Shootdown in a significant manner, you need to have: (1) really fast I/O (2)working set that significantly exceeds memory (3) no other work that needs to be done for processing a request; In practice, if you have really fast I/O, you spent money on that, you’ll more likely get more RAM as well. And you typically need to do something with the data you read, which means that you won’t notice the TLB shootdown as much）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;3、&lt;a href=&apos;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&apos;&gt;WiscKey: Separating Keys from Values in SSD-Conscious Storage&lt;/a&gt; /   &lt;a href=&apos;https://dgraph.io/blog/post/badger/&apos;&gt;Introducing Badger: A fast key-value store written purely in Go&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;WiscKey 是一个基于 LSM (Log Structured Merge)树的 KV 存储引擎，针对 SSD 的随机读和顺序读性能特点，将 Key 和 Value 分开存储，以尽可能缩小 I/O 放大问题，提升性能。&lt;/p&gt;
&lt;p&gt;Value 存放在 Log 文件中，LSM 树仅存储 Key 和 Value 在 Log 文件的位置以及长度/大小。&lt;/p&gt;
&lt;p&gt;对于 Value 比较大的应用场景，性能优势明显。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/y84VKqJZWMSjBu7.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;因为 LSM 树不存储 Value 本身，通常比较小，可以全部放在内存中，所以不考虑获取 Value 的值，点查和范围查找速度非常快。&lt;/p&gt;
&lt;p&gt;LSM 树比较小，所以 Compaction 次数少，速度快（特别是如果整个 LSM 都放在内存中的话）。Compaction 过程中不需要读写 Value 的值，所以 I/O 放大倍数要小很多。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/2tvp5LROXG4UYrw.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;点查过程，从 LSM 树中获取 Value 的位置和大小后，需要从 Value Log 中获取 Value 值。因为 LSM 树小，所以读放大倍数小，综合起来看，WiscKey 点查的性能优势依旧明显。&lt;/p&gt;
&lt;p&gt;范围查找/遍历过程，先从 LSM 树中获得目标范围内的所有 Value 的位置和大小，放入队列，使用多线程进行并发预取，利用 SSD 随机读的吞吐能力随并发树近线性增长的特点。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/APbQlhq3nWsf47j.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/j357k6XMfYO2udm.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;400&apos;/&gt;
&lt;p&gt;Value Log 也需要 GC，清理掉无用的 Value 值。LSM 树的 Compaction 主要是为了提升查找/检索的性能/效率，控制读放大，减少内存/磁盘空间占用是次要的。Value Log 的 GC 则主要是为了减少内存/磁盘空间占用。&lt;/p&gt;
&lt;p&gt;为了实现在线的轻量级 GC，Value Log 中也存储了 Key，&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/JMKxWiaCovyhgr8.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;tail 指向 Value Log 有效值范围内时序上最先写入的那个 value 的位置。&lt;/p&gt;
&lt;p&gt;head 指向 Value Log 中下一个新 value 写入的位置。&lt;/p&gt;
&lt;p&gt;tail 和 head 及其对应的位置信息均作为 kv 存入 LSM 树中（head 的指向什么时候会更新？：每次有新值写入的时候都更新？还是在 GC 的过程中才会更新？）&lt;/p&gt;
&lt;p&gt;GC 的流程为：&lt;/p&gt;
&lt;p&gt;① 从 tail 指向的位置开始顺序扫描一块数据，根据其中的 key 检索 LSM 树，确认当前 value 是否有效（没有被删除也没有被覆盖）&lt;/p&gt;
&lt;p&gt;② 如果有效则插入到 head 指向的位置，head 指向移动到下一个位置；如果无效，则直接丢弃&lt;/p&gt;
&lt;p&gt;③ 一块数据处理完成后，移动 tail 指向到下一个位置，释放/回收原来数据块的存储空间；然后继续循环处理&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;疑问&lt;/strong&gt;：1. GC 过程中每次向 head 插入有效值时，是否先要从 LSM 树中查询最新指向的位置？2. 在根据 key 从 LSM 树查询后将有效值写入 head 位置前，有新数据写入的话，怎么处理？GC 期间是否要停止正常的写操作？还是说对某个临界区加锁？&lt;/p&gt;
&lt;p&gt;LSM 树原理：&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/k6cHFOUluo1Ibfp.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/17WubUhqSpCjMr5.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/Tomk3VOEs7jduQl.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;&lt;a href=&apos;https://zhuanlan.zhihu.com/p/181498475&apos;&gt;LSM树详解 - 知乎 (zhihu.com)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;4、&lt;a href=&apos;http://www.vldb.org/pvldb/vol14/p364-didona.pdf&apos;&gt;Toward a Better Understanding and Evaluation of Tree Structures on Flash SSDs（VLDB）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;PTS - Persistent tree data structure&lt;/p&gt;
&lt;p&gt;使用 LSM 树（RocksDB）和 B+ 树（WiredTiger）来分析 SSD 基准测试（Benchmarking）中可能踩到的 7 个坑（pitfall）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）Running short tests / 测试过于短平快&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;p&gt;随着使用时间的增加，SSD 的性能会一定的动态变化。&lt;/p&gt;
&lt;p&gt;Because both the PTS and SSD performance vary over time, short-lived tests are unable to capture how the systems will behave under a continuous（non-bursty）workload.&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/HSuzIeC8itjndGw.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;WA-A（应用/存储系统的写放大） increases over time while the levels of the LSM-Tree fills up, and its curve flattens once the layout of the LSM tree has stabilized.&lt;/p&gt;
&lt;p&gt;WA-D（SSD 设备的写放大） increases over time because of the effect of garbage collection.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）Ignoring the device write amplification (WA-D) / 忽视了 SSD 设备本身的写放大&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;WA-D directly affects the throughput of the device, which strongly correlates with the application-level throughput.&lt;/li&gt;
&lt;li&gt;WA-D is an essential measure of the I/O efficiency of a PTS. 端到端的写放大倍数应该是 WA-A 乘以 WA-D&lt;/li&gt;
&lt;li&gt;WA-D measures the flash-friendliness of a PTS.
&lt;ul&gt;&lt;li&gt;A low WA-D indicates that a PTS generates a write access that does not incur much garbage collection overhead in the SSD.&lt;/li&gt;
&lt;li&gt;以前大家可能认为 LSM 树（顺序写）相比 B+ 树（随机写）对 SSD 更友好，但实测 WA-D 颠覆了这个认知&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;（3）Ignoring the internal state of the SSD / 忽视了 SSD 的初始内部状态&lt;/strong&gt; ⚡️&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/pFyqSCVZnrHB1g9.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Trim(Discard)的出现主要是为了提高GC的效率以及减少写入放大的发生，最大作用是清空待删除的无效数据&lt;/strong&gt;。在SSD执行读、擦、写步骤的时候，预先把擦除的步骤先做了，这样才能发挥出SSD的性能，通常SSD掉速很大一部分原因就是待删除的无效数据太多，每次写入的时候主控都要先做清空处理，所以性能受到了限制。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The steady-state performance of a PTS can greatly differ depending on the initial state of the drive, this is surprising.&lt;/p&gt;
&lt;p&gt;This phenomenon is caused by how the LBA (logic block address)  access patterns of RocksDB and WiredTiger intertwine with the SSD garbage collection mechanism as a function of the initial state the drive.&lt;/p&gt;
&lt;p&gt;WiredTiger only writes to a limited portion of the logical block address space.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（4）Ignore the dataset size / 忽视了数据集大小&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/SlVWJfP5rO7xpNQ.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;The amount of data stored by the SSD changes its behavior and affects overall performance.&lt;/p&gt;
&lt;p&gt;The performance degradation brought by the larger dataset is primarily due to the idiosyncrasies（特质/特点） of the SSD: larger datasets lead to more valid pages in each flash block, which increases the amount of data being relocated upon performing garbage collection, i.e., the WA-D&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（5）Ignoring the extra storage capacity a PTS needs to manage data and store additional meta-data / 未考虑空间放大（Space amplification）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;涉及存储成本&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（6）Ignoring SSD over-provisioning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;成本与性能之间的权衡折中 - 可以预留一部分 SSD 空间给 SSD 做 GC 使用，这部分空间对文件系统不可见。&lt;/p&gt;
&lt;img src=&apos;https://s2.loli.net/2022/11/16/YEFp5g69mnqBe3w.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;&lt;strong&gt;（7）Ignoring the effect of the underlying storage technology on performance&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;5、SSD 原理相关资料&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;https://zhuanlan.zhihu.com/p/102089411&apos;&gt;浅谈分布式存储之SSD基本原理 - 知乎 (zhihu.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;https://mp.weixin.qq.com/s/_uiCsFXWjepeHSdgiUABhg&apos;&gt;聊聊 SSD 的基本原理 (qq.com)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://xiongduo.cn/posts/coding-for-ssds-part-1-introduction-and-table-of-contents.html&apos;&gt;为SSD编程（1）：简介和目录 (xiongduo.cn)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://www.ssdfans.com/?p=8077&apos;&gt;SSD背后的秘密：SSD基本工作原理 (ssdfans.com)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2022-09-14</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-about-mmap-ssd.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-about-mmap-ssd.html</guid>
        </item>
        
        <item>
            <title>读文笔记：Kafka 官方设计文档</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://kafka.apache.org/documentation/#design&apos;&gt;http://kafka.apache.org/documentation/#design&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;数据持久化&lt;/h2&gt;
&lt;h4&gt;不用惧怕文件系统&lt;/h4&gt;
&lt;p&gt;磁盘的读写速度，取决于如何读写。对于线性读写方式，操作系统做了充分的优化：提前读 - 预取若干数据块，滞后写 - 将小的逻辑写操作合并成一个大的物理写操作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;http://queue.acm.org/detail.cfm?id=1563874&apos;&gt;研究&lt;/a&gt;表明：&lt;a href=&apos;http://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg&apos;&gt;顺序读写磁盘（sequential disk access）的速度有些时候比随机访问内存还要快&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;现代操作系统激进地尽可能将空闲内存用作磁盘缓存。所有磁盘读写都经过操作系统提供的统一缓存。这个特性没法轻易关闭，除非直接 I/O （direct I/O），因此，如果程序在用户进程中进行数据缓存，缓存的数据通常也是和操作系统页缓存重复的，缓存两遍，没啥意义，也浪费内存。&lt;/p&gt;
&lt;p&gt;而且，Kafka 是构建在 JVM 之上的，了解 Java 内存使用方式的人应该都知道：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;对象的内存开销非常高，通常是实际数据大小的2倍（甚至更多）&lt;/li&gt;
&lt;li&gt;随着堆上数据量增大，Java 的 GC 表现也会更糟糕&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;因此，使用文件系统并依赖于操作系统内存页缓存，优于在程序中维护一块内存缓存或其它结构。至少操作系统内存页缓存的可用内存翻倍了。另外，如果使用紧凑的字节结构来缓存数据，相比使用对象，可用内存可能还会翻倍。在 32GB 内存的机器上这么搞，缓存可用到 20-30GB，还不会对 GC 造成了什么坏影响。并且，即使服务重启，这块缓存空间也是热的（除非机器重启），用户进程内的内存缓存在服务重启后得重建（10GB的数据缓存可能需要10分钟左右）。&lt;/p&gt;
&lt;p&gt;这样也可以简化代码逻辑，因为缓存和文件系统之间的一致性由操作系统来保证了。&lt;/p&gt;
&lt;p&gt;这样一分析，设计就简单了：我们反其道而行之，所有数据都直接写到文件系统上持久化日志文件中，不需要在程序中使用内存缓存，也不必确保将数据刷到磁盘。这实际意味着数据转移到了内核的内存页缓存。&lt;/p&gt;
&lt;h4&gt;常量时间就能搞定&lt;/h4&gt;
&lt;p&gt;B 树的 O(log N) 时间复杂度，对于磁盘操作来说，并不能等同于常量时间复杂度。&lt;/p&gt;
&lt;p&gt;Kafka 采用日志文件方式，确保读写操作的时间复杂度是 O(1)。&lt;/p&gt;
&lt;p&gt;Kafka 不会在消息一被消费就立即删除，而是保留一段时间，这样对于消费者来说也更灵活一些。&lt;/p&gt;
&lt;h2&gt;效率&lt;/h2&gt;
&lt;p&gt;对于 Kafka 这类系统而言，即使像前述那样消除了糟糕的磁盘访问模式，也会遇到两个导致数据效率低的问题：&lt;strong&gt;过多的小 I/O 操作&lt;/strong&gt;，以及&lt;strong&gt;过多的字节拷贝&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;小 I/O 问题在客户端与服务端之间，以及服务端内部的数据持久化操作中都会发生。对此，Kafka 协议建立在 “消息集” （即一批消息）的抽象之上，这样网络请求读写的是一批一批的消息，减少了网络往返的时间开销（注：消息处理的实时性会相对差一点）。服务端也是一次将一批消息写到日志文件中，消费者也按序一次获取一批消息。这一简单的优化可以将吞吐能力提升几个数量级。&lt;/p&gt;
&lt;p&gt;对于过多的字节拷贝问题，在消息量大的时候，影响比较明显。Kafka 采用了一种标准化的二进制消息格式，producer、broker、consumer 都使用这种格式，这样数据块在传输期间不需要变动。&lt;/p&gt;
&lt;p&gt;broker 维护的消息日志只是一个目录下的一堆文件，文件内容是按序写入的消息集，消息集的数据格式同于 producer、consumer 使用的。共用一种数据格式方便了一个重要的操作优化：持久化日志块的网络传输。对于从内存页缓存（pagecache）到网络套接字（socket）的数据传输操作，现代 UNIX 操作系统提供了一种高度优化的代码执行路径。Linux 中使用 &lt;a href=&apos;http://man7.org/linux/man-pages/man2/sendfile.2.html&apos;&gt;sendfile 系统调用&lt;/a&gt; 可以利用这个优化。&lt;/p&gt;
&lt;p&gt;要理解 sendfile 的收益，需要先理解从文件到套接字传输数据的常规代码执行路径：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;操作系统从磁盘将数据读到内核空间的内存页缓存（pagecache）&lt;/li&gt;
&lt;li&gt;应用程序从内核空间减数据读到用户空间缓冲区&lt;/li&gt;
&lt;li&gt;应用程序将数据从用户空间缓冲区读到内核空间的套接字缓冲区&lt;/li&gt;
&lt;li&gt;操作系统将数据从套接字缓冲区读到 NIC 缓冲区，网卡从 NIC 缓冲区读取数据通过网络发出去&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;这一代码执行路径，涉及 4 次数据拷贝和 2 次系统调用，很显然是低效的。使用 sendfile，可以避免内核空间和用户空间之间一些不必要的数据拷贝，操作系统可以直接将数据从内存页缓存发送到网络。&lt;/p&gt;
&lt;p&gt;进一步了解 sendfile 以及 Java 平台如何支持零拷贝，可以阅读&lt;a href=&apos;https://developer.ibm.com/articles/j-zerocopy/&apos;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;生产者（The Producer）&lt;/h2&gt;
&lt;h4&gt;负载均衡&lt;/h4&gt;
&lt;p&gt;消息应该发到哪个分区（partition）由客户端根据哈希算法（或者随机）决定，并且消息是直接由 producer 发到目标分区的 leader broker，没有任何中间路由层。&lt;/p&gt;
&lt;p&gt;所有 Kafka 节点都可以响应元数据请求 - 告知客户端（producer 或 consumer）哪些服务节点还存活以及某个 topic 的各个分区 leader 分别是哪个节点（疑惑：如果某个分区 leader 节点挂掉之后，客户端如何获知？何时可以获知？）&lt;/p&gt;
&lt;h2&gt;消息交付语义&lt;/h2&gt;
&lt;p&gt;producer 和 consumer 之间的消息交付语义，分 3 种：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;最多消费一次 - 消息可能会丢失，但不会被重复消费&lt;/li&gt;
&lt;li&gt;最少消费一次 - 消息不会丢，但可能被重复消费&lt;/li&gt;
&lt;li&gt;仅消费一次 - 每个消息都会被消费且仅消费一次&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;这个问题可以分成两个阶段的问题：&lt;strong&gt;producer 向 broker 发布一个消息时的持久性保证&lt;/strong&gt; 以及 &lt;strong&gt;consumer 消费一个消息时的语义保证&lt;/strong&gt; （the durability guarantees for publishing a message and the guarantees when consuming a message）。&lt;/p&gt;
&lt;p&gt;producer 向 Kafka 集群发消息时，会提供一个请求参数 &lt;code&gt;acks&lt;/code&gt;：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;acks=0：表示 producer 不需要等分区 leader broker 返回任何响应，将消息存入套接字缓冲区（socket buffer）就当做消息已经发送成功。所以可靠性是没有保证的。&lt;/li&gt;
&lt;li&gt;acks=1：表示 分区 leader broker 将消息写入自己的本地日志文件，就向 producer 响应成功，不必等待分区副本 broker 同步好消息。&lt;/li&gt;
&lt;li&gt;acks=-1 或 acks=all：表示 分区 leader broker 需要等待所有同步副本 broker 同步好消息并响应成功，才向 producer 响应成功&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;第 2 种情况，如果分区 leader broker 挂掉/不存活，则副本未来得及同步的消息会丢失。&lt;/p&gt;
&lt;p&gt;第 3 种情况，只要有同步副本正常同步消息，那么即使 leader 挂了也不会丢数据。&lt;/p&gt;
&lt;p&gt;如果 leader 被系统判定为不存活，则会从（同步）副本中选举一个新的 leader，那么 Kafka 如何判定一个节点是否存活？存活判定依赖 2 个条件：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;节点必须维持与 Zookeeper 的 session 连接（通过 Zookeeper 的心跳机制）&lt;/li&gt;
&lt;li&gt;如果是一个从节点（follower），则必须不断从 leader 节点同步消息数据，且同步进度没有落后太多&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;如果 producer 在发送消息的过程中发生网络问题，它没法判定分区 leader 是否收到消息。0.11.0.0 版本之前，producer 只能重发消息，别无他法，因此只能提供“最少消费一次的”交付语义。0.11.0.0 版本之后，Kafka producer 支持一个幂等交付功能选项，可以确保消息重发不会导致 Kafka 的消息日志中出现重复的条目：broker 为每个 producer 分配一个 ID，然后基于消息序号来去重。&lt;/p&gt;
&lt;p&gt;也是从 0.11.0.0 版本开始，Producer 支持以类事务的语义向多个 topic 分区发送消息：要么所有消息都发送成功，要么都不成功。这个能力主要用于实现 Kafka topic 之间的仅处理一次语义。&lt;/p&gt;
&lt;p&gt;从 consumer 角度来看，同一个分区的所有副本，日志数据相同，消费进度也一样。consumer 可以控制自己对分区日志数据的消费位置。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果 consumer 读取消息后，先向 kafka 提交消费位置，再处理消息；如果该 consumer 挂掉或重启，会可能导致丢消息，从而只能满足“最多处理一次”交付语义。&lt;/li&gt;
&lt;li&gt;如果 consumer 读取消息后，是先处理，再提交消费位置；如果该 consumer 挂掉或重启，则可能导致重复消费消息，从而只能满足“最少处理一次”交付语义。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;如何实现“仅处理一次”语义？借助 Producer 的事务能力。&lt;/p&gt;
&lt;h2&gt;复制&lt;/h2&gt;
&lt;p&gt;复制的粒度/单元是 topic 分区。Kafka 集群中，每个分区都有一个 leader broker 节点，0个或多个从节点（follower）。分区读写都是由 leader broker 处理。&lt;/p&gt;
&lt;p&gt;如同一个普通的 consumer，从节点从 leader broker 拉取（pull）消息，然后写到自己的消息日志文件中。让从节点以 pull 的方式获取 leader 的消息数据，好处在于批量读写。&lt;/p&gt;
&lt;p&gt;对于 follower 节点而言，“是否存活”的实际含义是“是否顺利地从 leader 同步消息”，leader 节点会追踪“同步中”节点集（ISRs）。如果一个 follower 挂掉了/卡住了/同步落后太多了，则将其从这个 ISRs 中移除。follow 是否卡住或者同步落后太多，依据 &lt;code&gt;replica.lag.time.max.ms&lt;/code&gt; 配置参数判定。&lt;/p&gt;
&lt;p&gt;将某消息写到某个分区，如果该分区所有同步中副本都已经将该消息写到自己的消息日志文件中，则可以认为该消息的写操作已提交（committed），也就是真正的写成功。&lt;/p&gt;
&lt;p&gt;只有写提交的消息才会分发给 consumer。&lt;/p&gt;
&lt;p&gt;producer 可以选择是否等待消息写操作提交，在延迟（latency）和持久性（durability）之间权衡。&lt;/p&gt;
&lt;p&gt;Kafka 集群在某分区的 leader 节点挂掉之后，会快速进行失败转移（a short fail-over period），选举出新的分区 leader 节点，可用性不会受到影响。但如果发生网络分区（network partitions）问题，则无法保证可用性。CAP - C（Consistency）：一致性，A（Availability）：可用性，P（Partition Tolerance）：分区容错性 - 放弃了 分区容错性。&lt;/p&gt;
&lt;h4&gt;日志数据复制：仲裁成员集（Quorums）、同步中副本集（ISRs）和状态机&lt;/h4&gt;
&lt;p&gt;（备注：这一节我理解得还不太透彻。）&lt;/p&gt;
&lt;p&gt;一类常见的分布式系统是主从模式的，由主节点决定状态变化的顺序（the order of a series of values）。从节点通过日志复制（replicated log）方式同步状态数据。对于提交决策（commit decision）和选主（leader election），通常是基于多数人投票的机制。假设副本个数（注：个人理解包含主节点）为 2f+1，那么只有当 f+1 个副本写入成功，主节点才会将这个写操作标记为已提交（committed）。当主节点挂掉之后，基于 f 个状态最新的副本节点，可以选举出新的主节点，且状态不会有任何丢失。&lt;/p&gt;
&lt;p&gt;多数人投票方式，有一个优点：延迟取决于速度快的节点，而不是慢的。缺点是：对于实际的生产系统，抗风险能力还不够，而且不够灵活，不能让使用者做权衡。&lt;/p&gt;
&lt;p&gt;Kafka 选择仲裁成员集（quorum set）的方式与此不同，而不是基于多数人投票，而是动态维护一组同步中副本（ISR），这些副本与主节点保持同步。只有这组副本中的成员才有资格当选为主节点。ISR 集发生变化时会持久化到 Zookeeper 上。&lt;/p&gt;
&lt;p&gt;基于 ISR 模型，如果 topic 分区有 f+1 个副本，则可以容忍 f 个节点挂掉，也不会丢失任何已提交的消息。&lt;/p&gt;
&lt;p&gt;与 Kafka ISR 模型实际实现最相近的学术论文是微软的 &lt;a href=&apos;http://research.microsoft.com/apps/pubs/default.aspx?id=66814&apos;&gt;PacificA&lt;/a&gt;。&lt;/p&gt;
&lt;h4&gt;可用性和持久性保证&lt;/h4&gt;
&lt;p&gt;注意：producer 发送消息时设定 &lt;code&gt;acks=all&lt;/code&gt; 并不是要求所有的副本都确认写入成功，而是在当前同步中副本（ISR）都确认写入成功时，分区 leader 就向 producer 响应成功。例如：某个 topic 被设置为 2 个副本，然后其中一个副本节点挂掉，此时要求 &lt;code&gt;acks=all&lt;/code&gt; 的写操作也会成功。如果剩下的副本节点也挂了，那么就会丢消息啦。&lt;/p&gt;
&lt;p&gt;为了方便用户在 可用性 和 持久性 之间权衡，Kafka 提供两个 topic 级别的配置，用于 持久性 比 可用性 重要的情况：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&apos;http://kafka.apache.org/documentation/#design_uncleanleader&apos;&gt;禁用脏 leader 选举&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;指定一个最小 ISR 集大小（&lt;code&gt;min.insync.replicas&lt;/code&gt; 参数设置）：只有当 ISR 集大小大于设定的最小值，分区 [leader] 才会接受消息写入。这个设置只有当 producer 使用 &lt;code&gt;acks=all&lt;/code&gt; 时才会生效。（注：在我们生产环境中，分区副本数通常申请为 3（包含 leader），那么 &lt;code&gt;min.insync.replicas&lt;/code&gt; 应该设定为 2，但默认是 1。使用 1，那么当分区只有一个副本（即 leader），producer 也能写入成功，但如果这个副本又挂了，就会丢数据。）&lt;/li&gt;&lt;/ol&gt;
&lt;h4&gt;副本管理&lt;/h4&gt;
&lt;p&gt;一个 Kafka 集群上一般会有多个 topic，每个 topic 又有多个 partition，为了节点之间负载均衡，通常以&lt;strong&gt;循环（round-robin）方式&lt;/strong&gt;在所有节点上分布 partition 和 分区 leader 角色。&lt;/p&gt;
&lt;p&gt;另外，在分区 leader 节点之后重新选出 leader 之前，存在一段不可用的时间窗口，为了缩短这个时间窗口，Kafka 会从所有 broker 中选择一个作为“控制器（controller）”，这个控制器会检测 broker 级别的问题（failures），在发现某个 broker 挂掉之后，负责为受影响的分区指定新的 leader，而不是每个分区自己负责重新选主，这样的选主过程更轻量更快。如果控制器节点挂了，还存活的 broker 中的一个会成为新的控制器。&lt;/p&gt;
&lt;h2&gt;消费者消费进度跟踪&lt;/h2&gt;
&lt;p&gt;Kafka 为每个消费组（consumer group）指定一个 broker 来存储目标 topic 各个分区的消费进度（offsets），这个 broker 称为 &lt;strong&gt;组协调器（group coordinator）&lt;/strong&gt;。这个消费组中的任一消费者实例都应该将消费进度提交到这个组协调器，或者从这个组协调器获取启动之前上次的消费进度。Kafka 基于消费组的名称为消费组分配协调器。消费者可以向任一 broker 发送 FindCoordinatorRequest 请求来查找自己的协调器，并从 FindCoordinatorResponse 响应中获取协调器的详细信息。&lt;/p&gt;
&lt;p&gt;在组协调器接收到一个 OffsetCommitRequest 请求后，会将请求数据写到一个特殊的&lt;a href=&apos;http://kafka.apache.org/documentation/#compaction&apos;&gt;经压实的（compacted）&lt;/a&gt; Kafka topic - &lt;em&gt;__consumer_offsets&lt;/em&gt;。在目标分区的所有副本都确认收到了，协调器才会向消费者发送进度提交成功的响应。这个 topic 的消息日志数据会定期进行压实（compact），因为只需要为每个分区维护最新的消费进度。协调器也会在内存中缓存消费进度，方便快速响应消费进度查询请求。&lt;/p&gt;
&lt;p&gt;注：如果消费者/消费组特别多（例如：我们广告引擎服务，读取正排消息 topic，一个机器实例就是一个 consumer group，数量在几百到几千不等），那么组协调器的压力会比较大，那么确保组协调器的角色均匀分配到集群的所有 broker，比较关键。另外，&lt;em&gt;__consumer_offsets&lt;/em&gt; 这个 topic 的分区数量不能太少，最好和 broker 数量相同或者整数倍数量。&lt;/p&gt;</description>
            <pubDate>2019-10-13</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-kafka-design.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-kafka-design.html</guid>
        </item>
        
        <item>
            <title>读文笔记：Photon - Fault-tolerant and Scalable Joining of Continuous Data Streams</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/41318.pdf&apos;&gt;Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Photon 是谷歌广告系统中用于 join 广告曝光日志流和点击日志流的一套系统。&lt;/p&gt;
&lt;p&gt;数据流 join 为什么没用 flink 这类通用的流式处理框架？&lt;/p&gt;
&lt;p&gt;数据流 join，特别是广告数据流 join，技术上难在哪里？&lt;/p&gt;
&lt;p&gt;任一条流都可能乱序或延迟，广告点击涉及计费的问题，计费不能多算广告主的钱，也要尽可能避免漏计费，降低广告收入损失。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;该系统在谷歌生产环境中每分钟处理百万级的事件，端到端延迟小于 10 秒（注：对于广告实时竞价的广告主而言，这个延迟的长短很重要）。&lt;/p&gt;
&lt;p&gt;广告曝光、点击整体流程为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;用户搜索某个关键词时，谷歌的服务器会返回广告和搜索结果。广告服务器会将广告 query 和结果数据作为日志发送到多个日志数据中心（multiple logs-datacenters），最终持久化存储在 GFS 上。每次 query 都会被赋予一个唯一性 ID &lt;em&gt;query_id&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;对于搜索结果中的广告，用户可能会点击。广告点击会触发一次请求，谷歌的后端服务器将请求重定向到广告主的网站。在重定向之前，谷歌服务器会将点击事件记录到日志中，发送到多个日志数据中心。点击事件日志中包含广告曝光的 query_id，点击事件也会被赋予一个唯一性 ID &lt;em&gt;click_id&lt;/em&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;计费是在点击之后，但计费所需要的广告出价等信息是在曝光请求中记录的，出于数据敏感性、带宽、请求处理延迟等多方面的考量，计费相关的信息并不会返回到用户客户端，也就是说点击请求中不会包含计费直接相关的信息，需要将 点击日志 和 曝光日志 做一次 join，得到一条完整的上下文日志，才方便做后续计费等处理。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/EDOy6VKxeJUcgAW.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;论文中提了到该系统解决了几个技术挑战点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;仅处理一次语义（exactly-once semantics）：实际上达到的是 最多处理一次语义 （At most once），也就是绝对不能多算钱，然后尽可能避免少算钱&lt;/li&gt;
&lt;li&gt;自动化的跨数据中心容错：也就是多数据中心部署，如果有一个数据中心不可用（比如 网络问题），也不会影响系统正常处理数据&lt;/li&gt;
&lt;li&gt;横向扩展性高：也就是加机器就能应对消息量增长&lt;/li&gt;
&lt;li&gt;低时延&lt;/li&gt;
&lt;li&gt;流乱序&lt;/li&gt;
&lt;li&gt;主流延迟（delayed primary stream）：这里说的”主流“是曝光日志流&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;在我看来，该系统的亮点主要在前 3 点，后边细说。&lt;/p&gt;
&lt;p&gt;为解决 1、2 挑战点，系统引入一个服务模块：IdRegistry，这个服务的功能：提供点击事件 id（&lt;em&gt;click_id&lt;/em&gt;） 的存储和查询，如果某个 click_id 可以从 IdRegistry 中查到，则表示该点击事件已经处理过了，不要再次处理。&lt;/p&gt;
&lt;p&gt;并且，多数据中心都部署一套 Photon，但 IdRegistry 共享一个，多套 Photon 系统的输入相同，那么 IdRegistry 除了提供去重的功能，还提供了负载均衡的功能。正常情况下，假设 N 个数据中心，每个数据中心 Photon join 产出的日志数据量为总量的 1/N。&lt;/p&gt;
&lt;p&gt;当某个数据中心的 Photon 不可用时，相当于其负载动态地重新分配到其它数据中心，虽然总体能力上降低了，但只要处理能力有冗余，就不会影响正常处理。&lt;/p&gt;
&lt;p&gt;那么很明显，IdRegistry 很可能成为系统的短板；另外，曝光/点击的唯一性 ID 如何生成？如果由一个中心服务来提供唯一性 ID 的生成，那么这个服务也会成为系统的短板。&lt;/p&gt;
&lt;p&gt;所以，系统没有选择一个中心服务来生成唯一性 id，而是将 id 设计为包含3个部分：&lt;em&gt;ServerIP&lt;/em&gt;、&lt;em&gt;ProcessID&lt;/em&gt;、&lt;em&gt;Timestamp&lt;/em&gt;。由于日志文件中行之间大致是按照时间戳有序的，所以 id 中包含时间戳的一个额外好处是：根据 id 即可大致定位日志内容。另外，还有一个和横向扩展性相关的好处，后边细说。&lt;/p&gt;
&lt;p&gt;IdRegistry 的角色至关重要，所以将其实现为一个基于 Paxos 协议的分布式系统，根据 CAP 原则，可用性（此处是指&lt;strong&gt;吞吐能力&lt;/strong&gt;）受限。解决方案是：&lt;/p&gt;
&lt;p&gt;1、提高单机处理能力：服务端攒批处理，尽可能减少网络往返次数导致的等待（特别是：由于 IdRegistry 是跨地域分布式，部署上节点之间最大延迟是 100ms 左右）&lt;/p&gt;
&lt;p&gt;2、分片（Sharding）：根据 click_id 进行分片，但如果是固定分片，那么随着以后业务量增大，不好扩展。Photon 使用了一种基于时间段动态分片方案，这个方案基于 click_id 自带时间戳。大致逻辑是：使用一个配置，内容大致如下：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/VRlgr2CoD8zw7Mm.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;对于每个 click 日志，先根据 click_id 中的时间戳，判断分片数，并计算对应的分片 id。&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/JMWyQvrDZCaAEdH.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;hr&gt;
&lt;p&gt;系统的模块关系图如下所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/zghk6oVaqZ5uEs3.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;Photon 的 Dispatcher 模块并没有以 Kafka 这种消息队列作为输入，而是直接监听文件系统中的日志文件变更，这一点有点奇怪，不是特别理解。&lt;/p&gt;
&lt;p&gt;Joiner 负责实际的 join 工作，由于 3、4 都比较耗时，所以为了尽可能减少 Joiner 的工作量，Dispatcher 将点击事件日志发送给 Joiner，会先到 IdRegistry 中查一下该事件是否已被处理过，从而起到过滤作用。因多数据中心部署，实际过滤比为：$ \frac{N-1}{N} $。&lt;/p&gt;
&lt;p&gt;为了确保 Joiner 高可用，Joiner 是无状态的，向 Dispatcher 提供 RPC 接口，Joiner 内部有限流，以保证不会因为单个 Joiner 负载过大，导致处理时延增大。Dispatcher 调用 Joiner 失败后会重试，重试使用的是指数退避算法。但处理失败的点击事件，是另外存储在 GFS 上，应该是由另外的线程来负责重试，不会影响正常的事件处理。&lt;/p&gt;
&lt;p&gt;当 Joiner 收到一个点击事件的处理请求时，会根据点击日志数据中的 &lt;em&gt;query_id&lt;/em&gt; 从 EventStore 查询曝光日志详情，但因为曝光日志数据流可能会有延迟，所以可能会查不到，查不到且发现 click_id 中的时间戳早于某个阈值（比如是 N天前的一个事件），Joiner 会将该 click_id 标记为不可 join，然后向 Dispatcher 返回成功；如果 click_id 中的时间戳不早于阈值，则向 Dispatcher 返回失败，由 Dispatcher 来重试。&lt;/p&gt;
&lt;p&gt;为了确保不会多计费，Joiner 在将 join 结果写入 Joined Click Logs 之前，会向 IdRegistry 注册 click_id。&lt;/p&gt;
&lt;p&gt;假设注册实际上已成功，但因网络原因或 RPC 调用超时 Joiner 未收到成功响应，此时怎么办？Joiner 向 IdRegistry 注册 click_id 时，会附带一个额外的 唯一性 token，也包含3个部分：Joiner 服务器地址、进程 ID、时间戳，IdRegistry 会把这个唯一性 token 作为值存储下来，所以对于这种情况，Joiner 可以重复发注册请求，如果 IdRegistry 根据 token 发现已注册成功的 click_id 和当前收到的 click_id 来自同一个 Joiner，则也会返回注册成功。&lt;/p&gt;
&lt;p&gt;假设注册成功，合并结果写入异常，异常分为 2 种，需要解决：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;写入之前，Joiner 节点宕机或重启&lt;/li&gt;
&lt;li&gt;合并结果实际写入成功，但因为网络原因，Joiner 未收到响应&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;为尽可能减少因某个 Joiner 节点硬件异常导致的 join 结果丢失，IdRegistry 对于单个 Joiner 的请求有限流，这个限流会间接导致 Joiner 对 Dispatcher 限流。&lt;/p&gt;
&lt;p&gt;为了进一步减少因为上面2种异常情况以及其它异常导致的 Join 结果丢失，Photon 还提供一个校验系统：获取原始点击事件日志，如果该日志 click_id 在 IdRegistry 中存在，但合并结果中不存在，则根据 IdRegistry 存储的对应 click_id 的 token，判断对应的 Joiner 是否存活，如果存活，则交于该 Joiner 重新处理，如果对应的 Joiner 已不存在，则从 IdRegistry 中删除该 click_id 记录，然后交于任一 Joiner 来处理，都一样。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;EventStore 获取原始的曝光日志，向 Joiner 提供查询接口，返回原始的曝光日志内容。&lt;/p&gt;
&lt;p&gt;基于时间局部性，EventStore 内部分 2 层，第一层为 CacheEventStore - 一个类似 Memcached 的 KV 内存映射，K 是 query_id，V 是曝光日志内容，基于一致性哈希算法根据 query_id 进行分片，缓存几分钟最新的曝光日志数据，可以命中 90% 左右的查询请求。&lt;/p&gt;
&lt;p&gt;如果 CacheEventStore 查询 miss，则交于第二层 LogsEventStore 来处理。LogsEventStore 对 query_id 和 曝光日志所在的日志文件及目标起始行（因为日志文件数据大致按时间戳有序，根据 query_id 中的时间戳大致可以知道查询的起始行）建立索引（实际存储在 BigTable 中），查询时，先根据 query_id，查到目标日志文件和起始行，然后从日志文件中读取原始曝光日志内容。&lt;/p&gt;</description>
            <pubDate>2019-10-10</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-photon-paper.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-photon-paper.html</guid>
        </item>
        
        <item>
            <title>读文笔记：日志 - 每个软件工程师都应该了解的实时数据统一抽象</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&apos;&gt;The Log: What every software engineer should know about real-time data&apos;s unifying abstraction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概括，这篇文章细说了 Kafka 的本质原理、解决的问题、适用性等。&lt;/p&gt;
&lt;p&gt;Kafka 本质上是提供日志数据流。&lt;/p&gt;
&lt;p&gt;日志是客观世界的事件记录。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A log is perhaps the simplest possible storage abstraction. It is an append-only, totally-ordered sequence of records ordered by time.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;日志数据的特点是：只增不改，自带时间戳，数据存储的先后顺序即（大致）是实际发生的时间先后顺序。&lt;/p&gt;
&lt;p&gt;数据库可以基于日志来还原历史操作行为，并最终生成最新状态，主从同步就是这么干的。&lt;/p&gt;
&lt;p&gt;对于分布式系统而言，日志可以解决 2 个问题：按序改变状态和分发数据（ordering changes and distributing data）。&lt;/p&gt;
&lt;p&gt;状态机复制原则：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If two identical, deterministic processes begin in the same state and get the same inputs in the same order, they will produce the same output and end in the same state.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;分布式系统中各个节点可以依据日志来同步状态，达到（最终）一致性。并且，可以依据节点处理到哪行日志即可确定/表达该节点的状态。&lt;/p&gt;
&lt;p&gt;（日志）事件流（events）和数据表（tables）是一体两面（a facinating duality）：数据表的变更操作即是一个日志事件流，基于日志事件流可以生成数据表，并将其状态不断更新到最新，数据表的状态是日志事件流的在某个时间点的切面。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;events -&gt; table -&gt; events = events &lt;-&gt; table&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;The magic of the log is that if it is a complete log of changes, it holds not only the contents of the final version of the table, but also allows recreating all other versions that might have existed. It is, effectively, a sort of backup of every previous state of the table.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;源码版本控制系统（比如 git）也是基于日志实现的分布式系统，一次 commit 相当于一次日志记录。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;对于互联网/金融等行业的公司来说，数据是重要资产，如何尽可能发挥数据的潜在价值为公司增收，至关重要。因为管理、技术上的原因，公司通常分多个业务部门，各业务部门提供若干服务，各个服务都会产出数据，这些数据很可能需要跨部门跨服务流通，流通的速度越快，周期越短，收益越大。&lt;/p&gt;
&lt;p&gt;以前，数据的处理方式主要是批处理，并不是因为没有流处理的技术，而是数据流通的基础设施跟不上，没做到持续的数据流。&lt;strong&gt;（注：这个说法，我个人只部分认同，很多时候，批处理的时延和收益可以满足大部分需求，实时流处理的边际效益可能并不明显）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;流式处理是批处理的泛化形式（stream processing is a generalization of batch processing, and, given the prevalence of real-time data, a very important generalization）。&lt;/p&gt;
&lt;p&gt;为了避免因数据流通导致各个服务之间的直接耦合，新增一个统一的数据通道中间服务，各个服务只管对数据通道进行写入或读出，不用关心数据是哪个服务写入的，或者哪些服务在消费/使用自己产出的数据。&lt;strong&gt;（解耦）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外，消费者消费数据的速率可能不一样，也可能会经历异常重启等情况，让消费者来控制速率，并且多个消费者之间不会相互干扰，会更好。&lt;/p&gt;
&lt;p&gt;基于数据流通的需求和日志的理念，Linkedin 设计开发了 Kafka。&lt;/p&gt;
&lt;p&gt;因为日志数据量可能会很大，日志数据本质上是有序串行的，如果支持数据分片，分片之间并行消费，分片内日志数据全局有序，数据流通的吞吐能力就可以无限扩展。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;基于 Kafka 这类数据管道，服务之间可以实现多级串联。（注：我们现在做的服务就是这么干）&lt;/p&gt;
&lt;p&gt;这种分布式系统架构中，至少涉及 producer（生产者）、broker（中间人）、consumer（消费者）三个角色，角色之间在某些工作上如何分工也是值得思考的：&lt;/p&gt;
&lt;p&gt;生产者产生的数据应该是什么样的？ - 统一格式/编码、方便解析&lt;/p&gt;
&lt;p&gt;中间人（kafka）需要解决什么问题？- 对于单个生产者写入的数据，保证按写入顺序有序地分发给消费者；解决数据高可用，高吞吐能力；支持回溯/重复消费（因此数据需要保留指定时间长度），从而消费者出问题后可以从头消费数据恢复状态。因为支持很多消费者消费同一个数据流，所以平均下来，Kafka 服务的成本会比较低。&lt;/p&gt;
&lt;p&gt;消费者按各自的需求进行数据转换存储。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;对于实现高吞吐能力，除了分片，Kakfa 还充分利用了攒批处理：生产者可以批量发送，中间人将数据攒批写入磁盘日志文件 等等。&lt;/p&gt;
&lt;p&gt;此外，由于涉及大量的磁盘文件和网络之间数据读写，Kafka 还充分利用操作系统内核的零拷贝传输能力。&lt;/p&gt;</description>
            <pubDate>2019-10-10</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-the-log-article.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-the-log-article.html</guid>
        </item>
        
        <item>
            <title>Lucene 查询解析器语法（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://lucene.apache.org/core/8_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package.description&apos;&gt;Query Parser Syntax&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;概览&lt;/h2&gt;
&lt;p&gt;Lucene 除了提供 API 方便开发者创建查询请求，还通过一个查询解析器（一个词法分析器，使用 JavaCC 将一个字符串翻译成一个 Lucene 查询）提供一种功能丰富的查询语言。&lt;/p&gt;
&lt;p&gt;一般来说，查询解析器支持的语法在不同发布版本之间可能会有变化。当前这个文档页面描述的是当前这个发布版本的语法。如果你正在使用一个不同版本的 Lucene，请参考该版本自带的 docs/queryparsersyntax.html 文档。&lt;/p&gt;
&lt;p&gt;在选择使用这个查询解析器之前，请考虑以下 3 点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果你准备以编程的方式生成一个查询字符串，然后使用查询解析器来解析它。那么，你应该认真考虑一下是否应该直接使用查询 API 来构建查询。换句话说，查询解析器专门用于人类输入的文本，而不是程序生成的文本。&lt;/li&gt;
&lt;li&gt;不可分词（untokenized）的域（译者注：抱歉，此处没太理解）最好直接添加到查询中，而不是通过查询解析器来解析。如果一个域的值是通过应用自动生成的，那么应该为这个域自动生成查询子句。分析器（查询解析器所使用的）是专门用于将人类输入的文本转换成一些词（terms），那么程序自动生成的值，也应该由程序自动添加到查询中。&lt;/li&gt;
&lt;li&gt;从查询形式来看，如果域的值是普通文本，则应该使用查询解析器。所有其它值类型，比如：日期范围、关键词等等，最好通过查询 API 直接添加。如果一个域的值仅限于一个有限的集合（可以通过一个下拉菜单指定），则不应该添加到查询字符串（后续会被解析）中，而是应该作为一个 TermQuery 子句添加到查询中。&lt;/li&gt;&lt;/ol&gt;
&lt;h2&gt;词（Terms）&lt;/h2&gt;
&lt;p&gt;一个查询语句可以拆解成 词（terms） 和 操作符（operators）。词又分为两种：单个词（single Terms）和短语（Phrases）。&lt;/p&gt;
&lt;p&gt;单个词是指 ”test“ 或 ”Hello“ 这类单词。&lt;/p&gt;
&lt;p&gt;短语是指以双引号包围起来的一组单词，比如：”hello dolly“。&lt;/p&gt;
&lt;p&gt;多个词（Multiple terms）可以使用布尔操作符组合在一起，实现一个更加复杂的查询（如下文所示）。&lt;/p&gt;
&lt;p&gt;备注：用于创建索引的解析器也会用于解析查询字符串中的词和短语。因此，选择合适的解析器很重要，否则解析器可能会被查询字符串中的词干扰（译者注：这句应该是指英文解析器可能无法对中文进行正确分词的问题）。&lt;/p&gt;
&lt;h2&gt;域（Fields）&lt;/h2&gt;
&lt;p&gt;Lucene 支持分多个字段/域的数据。搜索时，可以指定一个域，也可以使用默认域。域的名称以及默认域与具体实现相关。&lt;/p&gt;
&lt;p&gt;输入域的名称，后跟一个冒号（:），以及目标搜索词，即可对任意一个域进行搜索。&lt;/p&gt;
&lt;p&gt;举例来说，假设一个 Lucene 索引包含 2 个域：title 和 text，text 是默认域。若想查找标题为 ”The Right Way“ 且文本内容包含 ”don&apos;t go this way“ 的文档，可以输入：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:&amp;amp;quot;The Right Way&amp;amp;quot; AND text:go&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或者：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:&amp;amp;quot;The Right Way&amp;amp;quot; AND go&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为 text 是默认域，所以域的标志可以省略。&lt;/p&gt;
&lt;p&gt;注意：指定的域仅对紧跟其后的词生效，因此，如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:The Right Way&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将对 title 域仅查找 ”The“，并对默认域（当前这个例子中是指 text 域）查找 ”Right“ 和 ”Way“。&lt;/p&gt;
&lt;h2&gt;词修饰语（Term Modifiers）&lt;/h2&gt;
&lt;p&gt;Lucene 支持修饰查询词（modifying query terms）来提供多种搜索方式。&lt;/p&gt;
&lt;h3&gt;通配符搜索&lt;/h3&gt;
&lt;p&gt;Lucene 支持对单个词(single terms)（不是短语查询 phrase queries）进行单个字符和多个字符的通配搜索。&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;?&lt;/code&gt; 符号进行单个字符的通配搜索。&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;*&lt;/code&gt; 符号进行多个字符的通配搜索。&lt;/p&gt;
&lt;p&gt;单字符通配搜索用于查找替换单个字符即可匹配的词。举例来说，若要搜索 ”text“ 或 ”test“，可以如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;te?t&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;多字符通配搜索用于查找替换0个或多个字符即可匹配的词。举例来说，若要搜索 ”test“、”tests“ 或 ”tester“，可以如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;test*&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以对词的中间部分进行通配搜索：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;te*t&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;备注：不可以将 &lt;code&gt;*&lt;/code&gt; 或 &lt;code&gt;?&lt;/code&gt; 符号用作一次搜索的首个字符。&lt;/p&gt;
&lt;h3&gt;正则表达式搜索&lt;/h3&gt;
&lt;p&gt;Lucene 支持正则表达式搜索，匹配斜杠（&lt;code&gt;/&lt;/code&gt;） 之间的模式。正则表达式的语法在不同的发布版本之间可能会有差异，目前支持的语法在 &lt;a href=&apos;http://lucene.apache.org/core/8_2_0/core/org/apache/lucene/util/automaton/RegExp.html?is-external=true&apos;&gt;RegExp&lt;/a&gt; 类文档中有说明。举例来说，查找包含 ”moat“ 或 ”boat“ 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;/[mb]oat/&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;模糊搜索&lt;/h3&gt;
&lt;p&gt;Lucene 支持基于 Damerau-Levenshtein 编辑距离的模糊搜索。在单个词的最后添加波浪符（~）即可进行模糊搜索。举例来说，使用模糊搜索查找拼写上近似 ”roam“ 的词：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;roam~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个查询语句会找到 foam 和 roams 这类词。&lt;/p&gt;
&lt;p&gt;模糊搜索可以通过一个额外（可选）的参数来指定允许的最大编辑次数。这个参数值界于 0 和 2 之间，例如：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;roam~1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果未指定该参数，则默认使用 2 个编辑距离。&lt;/p&gt;
&lt;p&gt;以前，这里还允许使用浮点数。现在这个语法已被考虑弃用，将于 Lucene 5.0 中移除。&lt;/p&gt;
&lt;h3&gt;邻近搜索&lt;/h3&gt;
&lt;p&gt;Lucene 支持查找指定距离的邻近词。在短语的最后添加拨浪符（~）即可进行邻近搜索。举例来说，在文档中搜索 ”apache“ 和 ”jakarta“ 相距 10 个词的模式：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot;~10&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;范围搜索&lt;/h3&gt;
&lt;p&gt;范围查询可以要求域的值在范围查询语句指定的上下界之间。范围查询对于上下界可以包含也可以不包含。排序按照字典序进行。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;mod_date:[20020101 TO 20030101]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个查询语句会查找 mod_date 域的值在 20020101 和 20030101 （包含上下界） 之间的文档。注意：范围查询并不是仅适用于日期域，也可以对非日期的域进行范围查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:{Aida TO Carmen}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个查询语句会查找到 title 域的值在 Aida 和 Carmen （不包含上下界）之间的所有文档。&lt;/p&gt;
&lt;p&gt;包含上下界的范围查询使用方括号来表示。不包含上下界的范围查询使用大括号来表示。&lt;/p&gt;
&lt;h3&gt;词加权（Boosting a term）&lt;/h3&gt;
&lt;p&gt;Lucene 会基于文档中找到的词对匹配到的文档提供相关性级别（译者疑问：基于向量余弦来计算相关性？）。可以在目标搜索词之后紧接一个脱字符 “^”，后跟一个加权系数（一个数字）来提升该搜索词的相关性权重。加权系统越高，查询命中的文档与该词的相关性越强。&lt;/p&gt;
&lt;p&gt;加权操作允许对词进行加权控制文档的相关性。例如，假设你正在搜索：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;jakarta apache&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后希望搜索结果和词 ”jakarta“ 更相关一些，则可以使用 ”^“ 符号后跟一个加权系数对这个词进行加权，即如下这样查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;jakarta^4 apache&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这会使得查找到的文档和词 ”jakarta“ 看起来更相关一些。也可以对短语进行加权，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot;^4 &amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;默认，加权系数是 1。加权系统可以小于 1（比如：0.2），但必须大于 0。&lt;/p&gt;
&lt;h2&gt;布尔操作符&lt;/h2&gt;
&lt;p&gt;布尔操作符允许使用逻辑操作符组合多个词。Lucene 支持的布尔操作符包含 &lt;code&gt;AND&lt;/code&gt;、&lt;code&gt;+&lt;/code&gt;、&lt;code&gt;OR&lt;/code&gt;、&lt;code&gt;NOT&lt;/code&gt; 及 &lt;code&gt;-&lt;/code&gt;（备注：布尔操作符必须全部是大写字母）。&lt;/p&gt;
&lt;h3&gt;OR&lt;/h3&gt;
&lt;p&gt;“OR” 操作符是默认的连接操作符。这意味着如果两个词之间没有布尔操作符，则使用 “OR” 操作符。OR 操作符链接两个词，并匹配包含其中任意一个词的文档。这相当于集合的并集操作。“||” 符合可用于替代单词 “OR”。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句来搜索包含 “jakarta apache” 或仅是 “jakarta” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; jakarta&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; OR jakarta&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;AND&lt;/h3&gt;
&lt;p&gt;&quot;AND&quot; 操作符会匹配文本内容中同时存在两个词（因为 AND 是二元操作符）的文档。这相当于集合的交集操作。“&amp;&amp;” 符号可用于替代单词 “AND”。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句来搜索包含 “jakarta apache” 和 “Apache Lucene” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; AND “Apache Lucene”&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;+&lt;/h3&gt;
&lt;p&gt;“+”（必需）操作符要求文档的某个域中包含 “+” 符号之后的词。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句来搜索（必须）包含 “jakarta” 以及可能包含 “lucene”（包不包含都可以）的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;+jakarta lucene&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;NOT&lt;/h3&gt;
&lt;p&gt;若文档包含“NOT”之后的词，“NOT” 操作会排查该文档。这相当于集合的差集操作。“!” 符号可用于替代单词 “NOT”。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句搜索包含 ”jakarta apache“ 但不包含 ”Apache Lucene“ 的文档”：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; NOT &amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;备注：“NOT” 操作符不可以用于单个词。例如，如下搜索不会返回任何结果：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;NOT &amp;amp;quot;jakarta apache&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;-&lt;/h3&gt;
&lt;p&gt;如果文档包含”-“符号之后的词，那么”-“（禁止）操作符会排除这些文档。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句来查询包含 ”jakarta apache“ 但不包含 ”Apache Lucene“ 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;quot;jakarta apache&amp;amp;quot; -&amp;amp;quot;Apache Lucene&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;分组&lt;/h2&gt;
&lt;p&gt;Lucene 支持使用圆括号对子句进行分组，构成子查询。如果你想控制一个查询语句的布尔逻辑，这对非常有用。&lt;/p&gt;
&lt;p&gt;比如，使用如下查询语句来搜索包含 “jakarta” 或 “apache”，以及 “website” 的文档：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;(jakarta OR apache) AND website&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如此就消除了任何困惑，确保你想表达是：必须存在 “website”，以及可能存在词 “jakarta” 或 “apache”。&lt;/p&gt;
&lt;h2&gt;域分组&lt;/h2&gt;
&lt;p&gt;Lucene 支持使用圆括号对单个域的多个子句进行分组。&lt;/p&gt;
&lt;p&gt;例如，若想搜索一个 title 中既包含单词“return”且包含短语“pink panther”，可以使用如下查询：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;title:(+return +&amp;amp;quot;pink panther&amp;amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;特殊字符转义&lt;/h2&gt;
&lt;p&gt;Lucene 支持对查询语法使用的特殊字符进行转移。目前这些特殊字符如下列表所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;+ - &amp;amp;amp;&amp;amp;amp; || ! ( ) { } [ ] ^ &amp;amp;quot; ~ * ? : \ /&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在特殊字符之前加 &lt;code&gt;\&lt;/code&gt; 来转义。例如，使用如下查询语句来搜索 &lt;code&gt;(1+1):2&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;\(1\+1\)\:2&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2019-09-04</pubDate>
            <link>https://blog.xiayf.cn/posts/lucene-query-parser-syntax.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/lucene-query-parser-syntax.html</guid>
        </item>
        
        <item>
            <title>一个 Python 小项目的小结</title>
            <description>&lt;p&gt;前段时间临时接手一个 Python 小项目，这个项目实现的类似一个管控平台，其中核心功能是为算法同学提供机器学习模型训练任务的全流程管理，平台后端基于 Flask 框架实现，前端基于 Ant Design Pro 实现。&lt;/p&gt;
&lt;p&gt;代码稍微有些乱，所以做了部分代码的重构，在此做点经验小结。&lt;/p&gt;
&lt;h3&gt;1、并行化或异步化&lt;/h3&gt;
&lt;p&gt;部分请求处理逻辑，由于比较耗时，故使用线程池来加速，或者使用独立线程异步处理，或者先存储一个中间状态，由后台定时任务来完成实际的处理工作。对于异步处理结果，前端通过轮询来获取。&lt;/p&gt;
&lt;p&gt;线程池的使用，主要使用 map 方法：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from multiprocessing.dummy import Pool

input_list = [...]
pool: Pool = Pool(len(input_list))
pool.map(func, input_list)
pool.close()
pool.join()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;独立线程异步处理：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;import multiprocessing

p = multiprocessing.Process(target=func, args=(...))
p.start()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;定时任务，基于 apscheduler 库实现：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from apscheduler.schedulers.background
import BackgroundScheduler

scheduler = BackgroundScheduler()
scheduler.add_join(func, &amp;amp;apos;interval&amp;amp;apos;, seconds=1)
scheduler.start()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为对于 Python 应用，通常会使用 gunicorn 这种 WSGI HTTP 服务器以多进程启动多个应用实例，提升请求吞吐能力。但是对于定时任务我们希望只有一个实例，对此，如果使用 gunicorn，可以基于它的 preload 机制来实现：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# wsgi.py
import app

if __name__ == &amp;amp;quot;__main__&amp;amp;quot;:
    app.run()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# 注意其中的 --preload 参数
gunicorn --workers=4 --preload --log-level=info --access-logfile=access.log -b 0.0.0.0:8080 wsgi:app&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;preload 机制简单来说，就是 import app 类所在的模块及其依赖的各个模块（import 过程中会执行其中的语句），然后 fork 出多个进程，每个进程都执行 app.run()。&lt;/p&gt;
&lt;h4&gt;2、实现一些通用方案对异常进行捕获或重试&lt;/h4&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def exception_try(times: int = 3, sleep_then_try_seconds=None):
    def decorator(f):
        def wrapper(*args, **kwargs):
            count = 0
            exception = None
            while count &amp;amp;lt; times:
                try:
                    return f(*args, **kwargs)
                except Exception as e:
                    exception = e
                    count += 1
                    logging.exception(&amp;amp;quot;Try {} times&amp;amp;quot;.format(count))
                    if (sleep_then_try_seconds is not None) and count &amp;amp;lt; times:
                        time.sleep(sleep_then_try_seconds)
            raise exception
        return wrapper
    return decorator&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@exception_try(times=3, sleep_then_try_seconds=0.5)
def connect(self):
    return pymysql.connect(host=self.host, user=self.user, password=self.password, db=self.db, charset=self.charset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个装饰器方法用于实现异常重试，并且可以指定重试的时间间隔，实际使用下来效果较好。而且也不会因为 &lt;code&gt;try...except&lt;/code&gt; 导致大块代码缩进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;确保数据库连接关闭（其它类似资源也可以这样实现）&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def with_db(db: Connection, exception_callback=None):
    def decorator(f):
        def db_context(*a, **kw):
            try:
                return f(db, *a, **kw)
            except Exception as e:
                logging.exception(str(e))
                if exception_callback is not None:
                    exception_callback(e)
            finally:
                try:
                    db.close()
                except:
                    pass
        return db_context

    return decorator&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 将 conf.db.connect() 对象作为 delete_task_from_job_queue 的第一个参数注入，task_id 这个参数以不定参数的方式传入 delete_task_from_job_queue
with_db(conf.db.connect())(delete_task_from_job_queue)(task_id)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个装饰器方法用于确保数据库连接在异常发生也能正常关闭，防止资源泄露。&lt;/p&gt;
&lt;h4&gt;3、循环等待或超时&lt;/h4&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class TimeoutCondition(object):

    def __init__(self, condition_func, timeout_seconds):
        self.condition = condition_func
        self.timeout = timeout_seconds
        self.begin = None
        self.timeout_false = True
        self.cond_true = True

    def __bool__(self):
        if self.begin is None:
            self.begin = timeit.default_timer()
        self.cond_true = self.condition()
        self.timeout_false = self.timeout &amp;amp;lt;= 0 or (timeit.default_timer() - self.begin) &amp;amp;lt; self.timeout
        return self.cond_true and self.timeout_false

    def is_timeout(self):
        return self.cond_true and not self.timeout_false&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;cond = TimeoutCondition(lambda : len(service_list) == 0, 5)
while cond:
    time.sleep(1)
    service_list = get_service_list()
if cond.is_timeout():
    return None, None&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;TimeoutCondition&lt;/code&gt; 用于实现循环等待某个条件满足，但为了避免死循环，所以加一个超时条件判断。实例化参数第一个是原始的条件判断 lambda 语句，第二个是一个超时设置。另外，借助魔术方法 &lt;code&gt;__bool__&lt;/code&gt;，让 TimeoutCondtion 的实例用起来像是一个布尔变量，调用 &lt;code&gt;is_timeout()&lt;/code&gt; 方法可以区分循环等待退出是因为原始条件满足，还是超时退出的。&lt;/p&gt;
&lt;h4&gt;4、按部署环境配置应用的行为&lt;/h4&gt;
&lt;p&gt;应用在不同的环境（开发、测试、生产）中应该允许加载不同的配置，配置不同的行为。&lt;/p&gt;
&lt;p&gt;当前应用处于什么环境，可以通过环境变量来配置，应用初始化时最先检测当前处于什么环境，之后的初始化流程就可以依据环境配置来加载配置，定制应用行为。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# conf/__init__.py
class AppConfig(object):
    app_env = os.getenv(&amp;amp;apos;APP_ENV&amp;amp;apos;, &amp;amp;apos;development&amp;amp;apos;)
    is_prod = app_env == &amp;amp;apos;production&amp;amp;apos;
    is_dev = app_env == &amp;amp;apos;development&amp;amp;apos;
    is_testing = app_env == &amp;amp;apos;testing&amp;amp;apos;
    
    # 其余应用配置项
    ...

conf = AppConfig()


def _load_config_by_env(env: str):
    &amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
    不同环境加载不同的配置文件
    配置目录结构：
    conf/
        __init__.py
        development.py
        production.py
        testing.py
    &amp;amp;apos;&amp;amp;apos;&amp;amp;apos;
    module = importlib.import_module(&amp;amp;apos;conf.{}&amp;amp;apos;.format(env))
    if not hasattr(module, &amp;amp;apos;Config&amp;amp;apos;):
        logging.warning(&amp;amp;apos;Not find {} config&amp;amp;apos;.format(env))
        return
    for name, value in getattr(module, &amp;amp;apos;Config&amp;amp;apos;).__dict__.items():
        if name.startswith(&amp;amp;apos;__&amp;amp;apos;):
            continue
        conf.__dict__[name] = value&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# 根据环境配置日志级别
log_level = logging.INFO if conf.is_prod else logging.DEBUG
logging.basicConfig(format=consts.LOG_FORMAT, level=log_level)&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;5、方便排查问题的日志输出&lt;/h4&gt;
&lt;p&gt;日志是问题排查的主要信息来源，所以日志记录得好不好，很关键。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# https://github.com/python/cpython/blob/3.7/Lib/logging/__init__.py#L457
# 日志时间 - 日志级别 - 代码文件路径 - 行号 - 进程 ID - 线程名称 - 日志内容
LOG_FORMAT = &amp;amp;apos;%(asctime)-15s - %(levelname)s - %(pathname)s - %(lineno)d - %(process)d - %(threadName)s - %(message)s&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;6、API 规范与异常提示&lt;/h4&gt;
&lt;p&gt;为了统一前端 API 响应处理，有必要对 API 响应体的结构指定标准。以我个人的习惯，所有从应用代码中返回的响应，HTTP 状态码都应该是 200，具体当前 API 请求成功还是失败，如果失败，失败的原因是什么都应该包含在响应体中，响应体大致的结构为：&lt;/p&gt;
&lt;pre class=&quot;language-json&quot;&gt;&lt;code&gt;{
    &amp;amp;quot;code&amp;amp;quot;: ...,
    &amp;amp;quot;msg&amp;amp;quot;: &amp;amp;quot;...&amp;amp;quot;,
    &amp;amp;quot;data&amp;amp;quot;: ...
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;code 表示请求处理失败时，data 字段可选，code 表示请求处理成功时，msg 字段可选。&lt;/p&gt;
&lt;p&gt;前端配合对响应体进行统一检测和提示：&lt;/p&gt;
&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code&gt;import { notification } from &amp;amp;apos;antd&amp;amp;apos;;

function defaultHTTPCodeHandler(response) {
  if (response.status &amp;amp;gt;= 400) {
    // 注意 clone
    response.clone().text().then(respBody =&amp;amp;gt; {
      notification.error({message: &amp;amp;apos;API 异常响应&amp;amp;apos;, description: `${response.status}, ${respBody}`, duration: null});
      console.log(`${response.status}, ${respBody}`);
    });
  }
}

function defaultMsgCodeHandler(response) {
  if (response.status === 200) {
    // 注意 clone
    response.clone().json().then(jsonBody =&amp;amp;gt; {
      // 0、200、10000 都属于成功响应
      if (jsonBody !== undefined &amp;amp;amp;&amp;amp;amp; jsonBody.code !== undefined &amp;amp;amp;&amp;amp;amp; jsonBody.code !== 0 &amp;amp;amp;&amp;amp;amp; jsonBody.code !== 200 &amp;amp;amp;&amp;amp;amp; jsonBody.code != 10000) {
        notification.error({message: &amp;amp;apos;请求失败&amp;amp;apos;, description: `${jsonBody.code}, ${jsonBody.msg}`, duration: null});
        console.log(`${jsonBody.code}, ${jsonBody.msg}`);
      }
    });
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;并且统一封装发起请求的逻辑：&lt;/p&gt;
&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code&gt;export function corsFetch(url, init, httpCodeCallback, msgCodeCallback) {
  const host = myHost();
  let urlPrefix = host;
  // 自带 host，则不额外补充 host 前缀
  if (url.startsWith(&amp;amp;quot;http://&amp;amp;quot;) || url.startsWith(&amp;amp;quot;https://&amp;amp;quot;)) {
    urlPrefix = &amp;amp;apos;&amp;amp;apos;;
  }
  const httpCodeHandler = httpCodeCallback === undefined ? defaultHTTPCodeHandler : httpCodeCallback;
  const msgCodeHandler = msgCodeCallback === undefined ? defaultMsgCodeHandler : msgCodeCallback;
  // 对于线上环境或者测试环境，不跨域
  if (host === PROD_ENV_HOST || host === TEST_ENV_HOST) {
    const promise = fetch(urlPrefix + url, init);
    promise.then((response) =&amp;amp;gt; httpCodeHandler(response));
    promise.then((response) =&amp;amp;gt; msgCodeHandler(response));
    return promise;
  }
  // 对于本地测试环境，跨域访问预发环境 API 数据，方便测试
  let corsInit = {
    credentials: &amp;amp;apos;include&amp;amp;apos;,
    mode: &amp;amp;apos;cors&amp;amp;apos;,
    redirect: &amp;amp;apos;follow&amp;amp;apos;,
  };
  if (init !== undefined) {
    corsInit = { ...corsInit, ...init };
  }
  if (urlPrefix !== &amp;amp;apos;&amp;amp;apos;) {
    urlPrefix = TEST_ENV_HOST;
  }
  const promise = fetch(urlPrefix + url, corsInit);
  promise.then((response) =&amp;amp;gt; httpCodeHandler(response));
  promise.then((response) =&amp;amp;gt; msgCodeHandler(response));
  return promise;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中为了方便本地开发测试，允许本地开发环境跨域访问测试环境（最好不要直接跨越访问生产环境），并且自动区分，corsFetch 调用方无感知。&lt;/p&gt;</description>
            <pubDate>2019-08-14</pubDate>
            <link>https://blog.xiayf.cn/posts/a-python-project-summary.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/a-python-project-summary.html</guid>
        </item>
        
        <item>
            <title>Reactor 官方文档翻译简化版</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/&apos;&gt;Reactor 3 Reference Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1. 起步&lt;/h2&gt;
&lt;h3&gt;1.1 Reactor 简介&lt;/h3&gt;
&lt;p&gt;Reactor 是为 JVM 准备的一个完全非阻塞的反应式编程基础组件，支持高效的需求管理（以管理“反压”的形式），直接与 Java 8 的函数式 API 集成，尤其是 &lt;code&gt;CompletableFuture&lt;/code&gt;、&lt;code&gt;Stream&lt;/code&gt; 以及 &lt;code&gt;Duration&lt;/code&gt;，提供可组合的异步序列 API - &lt;code&gt;Flux&lt;/code&gt;（适用于 N 个元素的序列）和 &lt;code&gt;Mono&lt;/code&gt;（适用于 0 或 1个元素的序列）--- 并且全面地（extensively）实现了 &lt;a href=&apos;https://www.reactive-streams.org/&apos;&gt;反应式流（Reative Streams）&lt;/a&gt; 规范。&lt;/p&gt;
&lt;p&gt;借助 &lt;code&gt;reactor-netty&lt;/code&gt; 项目，Reactor 也支持进程间的非阻塞通信，适用于微服务架构。&lt;code&gt;reactor-netty&lt;/code&gt; 为 HTTP（包括 Websockets）、TCP 以及 UDP 提供支持反压的网络引擎，完全支持反应式编码解码。&lt;/p&gt;
&lt;h3&gt;1.2 理解 BOM&lt;/h3&gt;
&lt;p&gt;Reactor 3 开始采用 BOM （Bill of Materials，物料清单）发布模型（自 &lt;code&gt;reactor-core 3.0.4&lt;/code&gt; 开始，使用 &lt;code&gt;Aluminium&lt;/code&gt;（铝）版本序列），一个版本包含一组相关组件的版本，这些版本组件之间兼容性非常好，允许这些组件采用不同的版本命名方式。&lt;/p&gt;
&lt;p&gt;BOM 发布模型本身也是版本化的，以一个代号后接一个修饰词来命名一个版本序列。如下是一个示例列表：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;Aluminium-RELEASE
Californium-BUILD-SNAPSHOT
Aluminium-SR1
Bismuth-RELEASE
Californium-SR32&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代号等价于常规的 &lt;code&gt;大版本号.小版本号&lt;/code&gt; 形式，通常以字母升序方式取自 &lt;a href=&apos;https://en.wikipedia.org/wiki/Periodic_table#Overview&apos;&gt;元素周期表&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;按照时间顺序，修饰词分别为如下几个：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;BUILD-SNAPSHOT：为开发测试构建的版本。&lt;/li&gt;
&lt;li&gt;M1 .. N：里程碑版本或者开发者预览版本。&lt;/li&gt;
&lt;li&gt;RELEASE：一个代号系列中的首个 GA（General Availability 通用）发行版。&lt;/li&gt;
&lt;li&gt;SR1 .. N：一个代号系列中的后续 GA 发行版 - 相当于一个补丁版本。（SR 代表 “Service Release”（服务版本））&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;1.3 如何获取 Reactor&lt;/h3&gt;
&lt;h4&gt;1.3.1 以 Maven 管理依赖包&lt;/h4&gt;
&lt;p&gt;Maven 原生支持 BOM 模型概念。首先，在你的 &lt;code&gt;pom.xml&lt;/code&gt; 文件添加如下代码片段来引入 BOM：&lt;/p&gt;
&lt;pre class=&quot;language-xml&quot;&gt;&lt;code&gt;&amp;amp;lt;dependencyManagement&amp;amp;gt; 
    &amp;amp;lt;dependencies&amp;amp;gt;
        &amp;amp;lt;dependency&amp;amp;gt;
            &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
            &amp;amp;lt;artifactId&amp;amp;gt;reactor-bom&amp;amp;lt;/artifactId&amp;amp;gt;
            &amp;amp;lt;version&amp;amp;gt;Bismuth-RELEASE&amp;amp;lt;/version&amp;amp;gt;
            &amp;amp;lt;type&amp;amp;gt;pom&amp;amp;lt;/type&amp;amp;gt;
            &amp;amp;lt;scope&amp;amp;gt;import&amp;amp;lt;/scope&amp;amp;gt;
        &amp;amp;lt;/dependency&amp;amp;gt;
    &amp;amp;lt;/dependencies&amp;amp;gt;
&amp;amp;lt;/dependencyManagement&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果顶部标签（&lt;code&gt;dependencyManagement&lt;/code&gt;）已经存在，则只添加上面该标签的内部内容。&lt;/p&gt;
&lt;p&gt;接下来，将依赖包添加到项目中，和一般依赖包一样，不过没有 &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt;，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-xml&quot;&gt;&lt;code&gt;&amp;amp;lt;dependencies&amp;amp;gt;
    &amp;amp;lt;dependency&amp;amp;gt;
        &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
        &amp;amp;lt;artifactId&amp;amp;gt;reactor-core&amp;amp;lt;/artifactId&amp;amp;gt; 
    &amp;amp;lt;/dependency&amp;amp;gt;
    &amp;amp;lt;dependency&amp;amp;gt;
        &amp;amp;lt;groupId&amp;amp;gt;io.projectreactor&amp;amp;lt;/groupId&amp;amp;gt;
        &amp;amp;lt;artifactId&amp;amp;gt;reactor-test&amp;amp;lt;/artifactId&amp;amp;gt; 
        &amp;amp;lt;scope&amp;amp;gt;test&amp;amp;lt;/scope&amp;amp;gt;
    &amp;amp;lt;/dependency&amp;amp;gt;
&amp;amp;lt;/dependencies&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;1.3.2 以 Gradle 管理依赖包&lt;/h4&gt;
&lt;p&gt;Gradle 核心并不支持 Maven BOM，不过可以借助 Spring 的 &lt;a href=&apos;https://github.com/spring-gradle-plugins/dependency-management-plugin&apos;&gt;gradle-dependency-management&lt;/a&gt; 插件。&lt;/p&gt;
&lt;p&gt;首先，应用插件，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;plugins {
    id &amp;amp;quot;io.spring.dependency-management&amp;amp;quot; version &amp;amp;quot;1.0.6.RELEASE&amp;amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后使用它来引入 BOM，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;dependencyManagement {
     imports {
          mavenBom &amp;amp;quot;io.projectreactor:reactor-bom:Bismuth-RELEASE&amp;amp;quot;
     }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后将依赖添加到项目中，无需指定版本号，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-gradle&quot;&gt;&lt;code&gt;dependencies {
     compile &amp;amp;apos;io.projectreactor:reactor-core&amp;amp;apos; 
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;2. 反应式编程简介&lt;/h2&gt;
&lt;p&gt;Reactor 是反应式编程范式的一个实现。反应式编程的定义归纳起来，如下所示：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;反应式编程是一个异步编程范式，关注数据流和变化的传播。这意味着通过被采用编程语言可以轻松地表达静态（比如 数组）或动态（比如 事件发射器）数据流。 --- https://en.wikipedia.org/wiki/Reactive_programming&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;反应式编程方向的首个重要工作是：微软在 .NET 生态体系中创建了反应式扩展（Rx）库，然后 RxJava 在 JVM 上实现了反应式编程。时光飞逝，经 Reative Streams 的大力推进，Java 社区终于出现了反应式编程标准，该规范定义了一组接口以及 JVM 上反应式编程库之间的交互规则。Java 9 标准库已将这组接口集成到 &lt;code&gt;Flow&lt;/code&gt; 类（译注：见&lt;a href=&apos;https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/Flow.html&apos;&gt;https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/Flow.html&lt;/a&gt;）中。&lt;/p&gt;
&lt;p&gt;反应式编程范式在面向对象语言中通常表现为一个观察者设计模式的扩展。你也可以将主流的反应式流模式（reactive streams pattern）和大家熟知的迭代器设计模式做对比，所有这些库中都存在对标于 &lt;code&gt;Iterable&lt;/code&gt; - &lt;code&gt;Iterator&lt;/code&gt; 的概念（译注：比如 发布者-消费者）。主要差别在于：迭代器是基于 pull 方式，反应式流则基于 push 方式。&lt;/p&gt;
&lt;p&gt;使用迭代器是一个命令式编程的模式，即使如何访问数据（accessing values）完全是 &lt;code&gt;Iterable&lt;/code&gt; 的职责，但实际上，何时访问序列中的下一个（&lt;code&gt;next()&lt;/code&gt;）值取决于开发者的选择。在反应式流中，上述 &lt;code&gt;Iterable&lt;/code&gt; - &lt;code&gt;Iterator&lt;/code&gt; 对的等价物为 &lt;code&gt;Publisher&lt;/code&gt; - &lt;code&gt;Subscriber&lt;/code&gt;。不过，在出现新的数据/事件时，由 &lt;code&gt;Publisher&lt;/code&gt; 通知 &lt;code&gt;Subscriber&lt;/code&gt;，这个“推”特性也是实现反应式的关键之处。并且，在被推送的值上应用哪些操作是声明式表达而不是命令式表达的：程序员表达的是计算逻辑而不是描述精确的控制流。&lt;/p&gt;
&lt;p&gt;除了“推”的特性，反应式流也良好地定义了如何处理错误和结束流。一个 &lt;code&gt;Publisher&lt;/code&gt; 可以向它的 &lt;code&gt;Subscriber&lt;/code&gt; 推送新的值（通过调用订阅者的 &lt;code&gt;onNext&lt;/code&gt; 方法），也可以推送错误（调用 &lt;code&gt;onError&lt;/code&gt; 方法）或结束（调用 &lt;code&gt;onComplete&lt;/code&gt;方法）信号。错误和结束信号都可以终结事件序列。简而言之，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;onNext x 0..N [onError | onComplete]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个方式非常灵活。这个模式支持“没有值”、“一个值”或“n个值”（包括值无限的序列，比如时钟的持续滴答事件）的各种使用场景。&lt;/p&gt;
&lt;p&gt;但是，起初，我们为什么需要这样一个异步的反应式的编程库？&lt;/p&gt;
&lt;h3&gt;2.1 阻塞即是资源浪费&lt;/h3&gt;
&lt;p&gt;现代的软件应用，并发用户量非常巨大，即使现代硬件的处理能力一直在提升，软件的性能仍旧是一个关键问题。&lt;/p&gt;
&lt;p&gt;宽泛来讲，提升一个程序的性能，有两种方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;并行化&lt;/strong&gt; 使用更多的线程和更多的硬件资源。&lt;/li&gt;
&lt;li&gt;对于当前的硬件资源，&lt;strong&gt;寻求更高效的使用方式&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;通常，Java 开发者会使用阻塞性的代码编写程序，这种代码编写方式容易触及性能瓶颈，然后引入更多的线程来运行相似的阻塞性代码。但是，这种资源利用的扩展方式很快就会引发竞态（contention）和并发的问题。&lt;/p&gt;
&lt;p&gt;更糟糕的是，阻塞就意味着浪费资源。如果你稍加分析，就会发现一旦程序牵涉一些等待延迟（尤其是 I/0 操作，比如等待一个数据库请求或者一个网络调用），资源就会被浪费，因为此时线程（可能是大量线程）是空闲的，等待着数据。&lt;/p&gt;
&lt;p&gt;因此，并行化方式并非银弹。为了压榨出硬件的全部能力，并行化是必要的，但并行化的代码理解（reason about）起来也非常复杂，实际威力也会因为资源浪费而大打折扣。&lt;/p&gt;
&lt;h3&gt;2.2 异步可以解决问题吗？&lt;/h3&gt;
&lt;p&gt;前面提到的第二种方式 - 寻求更高效的使用方式 - 是资源浪费问题的一个解决方案。通过编写异步非阻塞的代码，在发生阻塞等待时，切换执行另一个活跃任务，活跃任务使用的是相同的底层资源，然后在异步处理过程结束后再切回到当前进程来执行。&lt;/p&gt;
&lt;p&gt;但是我们如何编写在 JVM 上异步执行的代码？ Java 提供了两种异步编程模型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;回调&lt;/strong&gt;：异步方法没有返回值，但接受一个额外的 &lt;code&gt;callback（回调）&lt;/code&gt;参数（一个 lambda 表达式或匿名类），在得到异步处理结果时会调用这个回调。一个众所周知的例子是 Swing 的 &lt;code&gt;EventListener&lt;/code&gt; 派生类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Future&lt;/strong&gt;：这种异步方法在调用时会&lt;em&gt;即刻&lt;/em&gt;返回一个 &lt;code&gt;Future&amp;lt;T&amp;gt;&lt;/code&gt;。这个异步过程会计算出一个 &lt;code&gt;T&lt;/code&gt; 类型的值，不过需要通过 &lt;code&gt;Future&lt;/code&gt; 对象来访问。计算出来的值不能立即可用，可以对 &lt;code&gt;Future&lt;/code&gt; 对象进行探询直到值计算出来。例如：&lt;code&gt;ExecutorService&lt;/code&gt; 运行 &lt;code&gt;Callable&amp;lt;T&amp;gt;&lt;/code&gt; 任务就是提供 &lt;code&gt;Future&lt;/code&gt; 对象来获取异步结果。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;那么这两种技术方案就足够好了吗？在很多使用场景下并不理想，这两种方式都有局限。&lt;/p&gt;
&lt;p&gt;多个回调难以组合使用，容易导致代码难以阅读和维护（就是所谓的“回调地狱”）。&lt;/p&gt;
&lt;p&gt;来看一个例子：在界面上为用户显示他最喜爱的5个物件，如果用户还没有任何喜欢的物件，则给出建议物件。这个逻辑涉及3个服务（第一个服务提供物件 ID，第二个服务获取物件的详细信息，第三个服务提供建议物件的详细信息），如下所示：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;回调地域的示例&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorites(userId, new Callback&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt;() { // 1
    public void onSuccess(List&amp;amp;lt;String&amp;amp;gt; list) { // 2
        if (list.isEmpty()) { // 3
            suggestionService.getSuggestions(new Callback&amp;amp;lt;List&amp;amp;lt;Favorite&amp;amp;gt;&amp;amp;gt;() {
                public void onSuccess(List&amp;amp;lt;Favorite&amp;amp;gt; list) { // 4
                    UiUtils.submitOnUiThread(() -&amp;amp;gt; { // 5
                        list.stream()
                            .limit(5)
                            .forEach(uiList::show); // 6
                    })
                }
                
                public void onError(Throwable error) { // 7
                    UiUtils.errorPopup(error);
                }
            });
        } else {
            list.stream() // 8
                .limit(5)
                .forEach(favId -&amp;amp;gt; favoriteService.getDetails(favId, // 9
                    new Callback&amp;amp;lt;Favorite&amp;amp;gt;() {
                        public void onSuccess(Favorite details) {
                            UiUtils.submitOnUiThread(() -&amp;amp;gt; uiList.show(details));
                        }

                        public void onError(Throwable error) {
                            UiUtils.errorPopup(error);
                        }
                    }
                ));
        }
    }
    
    public void onError(Throwable error) {
        UiUtils.errorPopup(error);
    }
})&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;基于回调的服务：&lt;code&gt;Callback&lt;/code&gt; 接口定义了两个方法，异步处理成功时调用其中的 &lt;code&gt;onSuccess&lt;/code&gt;，异步处理发生错误时调用 &lt;code&gt;onError&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;第一个服务以其结果 - 喜爱物件的 ID 列表 - 调用回调方法。&lt;/li&gt;
&lt;li&gt;如果列表为空，则必须转到 &lt;code&gt;suggestionService&lt;/code&gt; 来处理。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;suggestionService&lt;/code&gt; 向第二个回调传递一个 &lt;code&gt;List&amp;lt;Favorite&amp;gt;&lt;/code&gt; 列表。&lt;/li&gt;
&lt;li&gt;对于 UI 渲染，必须让消费数据的代码运行在 UI 的线程中。&lt;/li&gt;
&lt;li&gt;这里我们使用了 Java 8 的 &lt;code&gt;Stream&lt;/code&gt; 将建议物件的数量限制为5个，然后在 UI 中渲染成一个图形化列表。&lt;/li&gt;
&lt;li&gt;在每个回调层级，我们都以相同的方式处理错误：在弹出框中显示错误信息。&lt;/li&gt;
&lt;li&gt;回到 喜爱物件 ID 列表的层级。如果 &lt;code&gt;userService&lt;/code&gt; 服务返回一个不为空的 ID 列表，则转到 &lt;code&gt;favoriteService&lt;/code&gt; 去获取带详细信息的 &lt;code&gt;Favorite&lt;/code&gt; 对象。因为只需要5个喜爱物件，所以先使用流式处理将 ID 数量限制为 5 个。&lt;/li&gt;
&lt;li&gt;再一次，使用一个回调。这一次我们获取到完整的 &lt;code&gt;Favorite&lt;/code&gt; 对象，并在 UI 线程中将其在 UI 上渲染出来。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;看看有多少代码，理解起来也有点困难，其中也有一些重复的代码片段。再来看看使用 Reactor 如何来实现这段逻辑：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;和回调实现方式等价的 Reactor 实现&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorite(userId) // 1
            .flatMap(favoriteService::getDetails) // 2
            .switchIfEmpty(suggestionService.getSuggestions()) // 3
            .take(5) // 4
            .publishOn(UiUtils.uiThreadScheduler()) // 5
            .subscribe(uiList::show, UiUtils::errorPopup); // 6&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;开启一个喜爱物件 ID 的流。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;异步地&lt;/em&gt;将 ID 转换成带详细信息的 &lt;code&gt;Favorite&lt;/code&gt; 对象（&lt;code&gt;flatMap&lt;/code&gt;）。至此我们得到一个 &lt;code&gt;Favorite&lt;/code&gt; 对象流。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;Favorite&lt;/code&gt; 流为空，则切换到备选处理方式 &lt;code&gt;suggestionService&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;我们只关注产出流中的前（最多）5个元素。&lt;/li&gt;
&lt;li&gt;最后，在 UI 线程中处理每份数据。&lt;/li&gt;
&lt;li&gt;真正触发流的处理：描述了如何处理最终的数据（显示为一个 UI 列表），以及在发生错误时如何处理（显示一个弹出框）。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;如果希望确保在 800ms 以内获取到喜爱物件 ID 列表，如果超时，则从缓存中获取数据，如何实现？基于回调的代码实现，这是一个复杂的任务。使用 Reactor，只需在操作链中添加一个 &lt;code&gt;timeout&lt;/code&gt; 算子就能轻松搞定，如下所示：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;超时回退处理的 Reactor 代码示例&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;userService.getFavorites(userId)
            .timeout(Duration.ofMillis(800)) // 1
            .onErrorResume(cacheService.cachedFavoritesFor(userId)) // 2
            .flatMap(favoriteService::getDetails)
            .switchIfEmpty(suggestionService.getSuggestions())
            .take(5)
            .publishOn(UiUtils.uiThreadScheduler())
            .subscribe(uiList::show, UiUtils::errorPopup);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;如果前置处理超过 800ms 还没输出任何事件，则下发一个错误。&lt;/li&gt;
&lt;li&gt;在收到错误事件时，回退到调用 &lt;code&gt;cacheService&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;操作链的余下部分和前一个例子类似。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;使用 &lt;code&gt;Future&lt;/code&gt; 对象相比回调更好一点，不过组合使用起来也不太方便，尽管 Java 8 引入 &lt;code&gt;CompletableFuture&lt;/code&gt; 改善了这一问题。将多个 &lt;code&gt;Future&lt;/code&gt; 对象组织在一起，可行但并不容易。另外，&lt;code&gt;Future&lt;/code&gt; 还有其它问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;容易碰到另一个阻塞的情况：调用 &lt;code&gt;Future&lt;/code&gt; 对象的 &lt;code&gt;get()&lt;/code&gt; 方法。&lt;/li&gt;
&lt;li&gt;不支持惰性计算。&lt;/li&gt;
&lt;li&gt;对多个值的处理和高级错误处理缺乏支持。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;来看看另一个例子：先获取一个 ID 列表，然后根据 ID 获取一个名字以及获取一个统计数值，再将名字和统计数值组合起来使用，这几个步骤都必须是异步的。如下示例以一组 &lt;code&gt;CompletableFuture&lt;/code&gt; 来实现这个逻辑：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;CompletableFuture&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; ids = ifhIds(); // 1

CompletableFuture&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; results = ids.thenComposeAsync(l -&amp;amp;gt; { // 2
    Stream&amp;amp;lt;CompletableFuture&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; zip = 
            l.stream().map(i -&amp;amp;gt; { // 3
                CompletableFuture&amp;amp;lt;String&amp;amp;gt; nameTask = ifhName(i); // 4
                CompletableFuture&amp;amp;lt;Integer&amp;amp;gt; statTask = ifhStat(i); // 5
                return nameTask.thenCombineAsync(statTask, (name, stat) -&amp;amp;gt; &amp;amp;quot;Name &amp;amp;quot; + name + &amp;amp;quot; has stats &amp;amp;quot; + stat); // 6
            });
    List&amp;amp;lt;CompletableFuture&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; combinationList = zip.collect(Collectors.toList()); // 7
    CompletableFuture&amp;amp;lt;String&amp;amp;gt;[] combinationArray = combinationList.toArray(new CompletableFuture[combinationList.size()]);
    
    CompletableFuture&amp;amp;lt;Void&amp;amp;gt; allDone = CompletableFuture.allOf(combinationArray); // 8
    return allDone.thenApply(v -&amp;amp;gt; combinationList.stream()
                    .map(CompletableFuture::join) // 9
                    .collect(Collectors.toList()));
});

List&amp;amp;lt;String&amp;amp;gt; results = result.join(); // 10
assertThat(results).contains(
		&amp;amp;quot;Name NameJoe has stats 103&amp;amp;quot;,
		&amp;amp;quot;Name NameBart has stats 104&amp;amp;quot;,
		&amp;amp;quot;Name NameHenry has stats 105&amp;amp;quot;,
		&amp;amp;quot;Name NameNicole has stats 106&amp;amp;quot;,
		&amp;amp;quot;Name NameABSLAJNFOAJNFOANFANSF has stats 121&amp;amp;quot;);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;一开始获得一个 &lt;code&gt;Future&lt;/code&gt; 结果 - 为后续处理提供一个 &lt;code&gt;id&lt;/code&gt; 列表。&lt;/li&gt;
&lt;li&gt;一旦获得 &lt;code&gt;id&lt;/code&gt; 列表就可以开始进一步的异步处理。&lt;/li&gt;
&lt;li&gt;逐个处理列表中的元素。&lt;/li&gt;
&lt;li&gt;异步获取关联的名字。&lt;/li&gt;
&lt;li&gt;异步获取关联的统计数值。&lt;/li&gt;
&lt;li&gt;组合两个异步结果。&lt;/li&gt;
&lt;li&gt;至此我们得到一个 &lt;code&gt;Future&lt;/code&gt; 对象列表，表示所有的组合任务。&lt;/li&gt;
&lt;li&gt;将 &lt;code&gt;Future&lt;/code&gt; 对象数组传给 &lt;code&gt;CompletableFuture.allOf&lt;/code&gt; 方法，这个方法会输出一个 &lt;code&gt;Future&lt;/code&gt; 对象，当 &lt;code&gt;Future&lt;/code&gt; 对象数组代表的异步任务都完成时，这个 &lt;code&gt;Future&lt;/code&gt; 对象代表的异步任务也就完成了。&lt;/li&gt;
&lt;li&gt;此处的特殊之处在于：在（&lt;code&gt;allOf&lt;/code&gt; 返回的）&lt;code&gt;CompletableFuture&amp;lt;Void&amp;gt;&lt;/code&gt; 对象表示的异步任务结束时，遍历 &lt;code&gt;Future&lt;/code&gt; 对象列表（combinationList），使用 &lt;code&gt;join()&lt;/code&gt; 方法（此次不会阻塞，因为 &lt;code&gt;allOf&lt;/code&gt; 会确保所有异步任务都已完成）获取收集异步任务结果。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;10. 触发执行整个异步处理流水线（调用 &lt;code&gt;join()&lt;/code&gt; 方法），然而等着异步处理完成并返回一个结果列表，就可以进行断言判断了。&lt;/p&gt;
&lt;p&gt;Reactor 自带了很多组合算子，可以简化这个处理过程的实现，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; ids = ifhrIds(); // 1

Flux&amp;amp;lt;String&amp;amp;gt; combinations = 
        ids.flatMap(id -&amp;amp;gt; { // 2
            Mono&amp;amp;lt;String&amp;amp;gt; nameTask = ifhrName(id); // 3
            Mono&amp;amp;lt;Integer&amp;amp;gt; statTask = ifhrStat(id); // 4
            
            return nameTask.zipWith(statTask, // 5
                    (name, stat) -&amp;amp;gt; &amp;amp;quot;Name &amp;amp;quot; + name + &amp;amp;quot; has stats &amp;amp;quot; + stat);
        });
        
Mono&amp;amp;lt;List&amp;amp;lt;String&amp;amp;gt;&amp;amp;gt; result = combinations.collectList(); // 6

List&amp;amp;lt;String&amp;amp;gt; results = result.block(); // 7
assertThat(results).containsExactly( // 8
    &amp;amp;quot;Name NameJoe has stats 103&amp;amp;quot;,
    &amp;amp;quot;Name NameBart has stats 104&amp;amp;quot;,
    &amp;amp;quot;Name NameHenry has stats 105&amp;amp;quot;,
    &amp;amp;quot;Name NameNicole has stats 106&amp;amp;quot;,
    &amp;amp;quot;Name NameABSLAJNFOAJNFOANFANSF has stats 121&amp;amp;quot;
);&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;这次，一开始我们得到一个异步提供的字符串序列（&lt;code&gt;ids&lt;/code&gt;）（一个 &lt;code&gt;Flux&amp;lt;String&amp;gt;&lt;/code&gt; 对象）。&lt;/li&gt;
&lt;li&gt;对于序列中的每个元素，异步处理两次（在 &lt;code&gt;flatMap&lt;/code&gt; 的 lambda 参数值中）。&lt;/li&gt;
&lt;li&gt;获取关联的名字。&lt;/li&gt;
&lt;li&gt;获取关联的统计值。&lt;/li&gt;
&lt;li&gt;异步组合两个值&lt;/li&gt;
&lt;li&gt;在异步处理的结果可用时，将它们聚合到一个 &lt;code&gt;List&lt;/code&gt; 对象中。&lt;/li&gt;
&lt;li&gt;在实际项目中，我们通常会继续异步处理 &lt;code&gt;Flux&lt;/code&gt;，比如：异步组合使用它或者直接订阅它。最可能的是，返回这个 &lt;code&gt;Mono&lt;/code&gt; 类型的 &lt;code&gt;result&lt;/code&gt;。因为这里只是个测试，所以使用了 block，等待处理结束，直接返回值的聚合列表。&lt;/li&gt;
&lt;li&gt;对结果进行断言判断。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;使用回调和 &lt;code&gt;Future&lt;/code&gt; 对象的问题是类似的，反应式编程以 &lt;code&gt;发布者（Publisher）- 订阅者（Subscriber）&lt;/code&gt; 解决了这些问题。&lt;/p&gt;
&lt;h3&gt;2.3 从命令式到反应式编程&lt;/h3&gt;
&lt;p&gt;反应式编程库，比如 Reactor，目标是解决 JVM 上“经典”异步处理方式的弊端，同时也专注于提供以下几个方面的特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;可组合性&lt;/strong&gt; 和 &lt;strong&gt;代码可读性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将数据视作一个&lt;strong&gt;流&lt;/strong&gt;，并提供丰富的&lt;strong&gt;算子&lt;/strong&gt;来操作流&lt;/li&gt;
&lt;li&gt;在&lt;strong&gt;订阅（subscriber）&lt;/strong&gt;之前不会实际做任何事情&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反压&lt;/strong&gt; 或者说 消费者通知生产者流速过高的能力&lt;/li&gt;
&lt;li&gt;与并发无关（concurrency-agnostic）的&lt;strong&gt;高阶（high level）&lt;/strong&gt;抽象，&lt;strong&gt;适用性强（high value）&lt;/strong&gt;（译注：并发无关是指这种抽象对于并发非并发的场景都适用）&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;3. Reactor 核心特性&lt;/h2&gt;
&lt;p&gt;Reactor 项目的主要成果是 &lt;code&gt;reactor-core&lt;/code&gt; - 一个遵循&lt;a href=&apos;https://www.reactive-streams.org/&apos;&gt;反应式流&lt;/a&gt;规范并支持 Java 8 的反应式编程库。&lt;/p&gt;
&lt;p&gt;Reactor 引入 2 个可组合的反应式类型（实现了 &lt;code&gt;Publisher&lt;/code&gt; 接口并且提供丰富的算子）： &lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt;。一个 &lt;code&gt;Flux&lt;/code&gt; 对象代表包含 0 到 N 个元素的反应式序列，&lt;code&gt;Mono&lt;/code&gt; 对象代表单值或空（0或1个元素）的结果。&lt;/p&gt;
&lt;h3&gt;3.1 Flux - 0-N 个值的异步序列&lt;/h3&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/oKMX4rTvUViZRHj.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;h3&gt;3.2 Mono - 包含 0 或 1 个值的异步结果&lt;/h3&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/8WxGgH9UkcQwuX4.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;h3&gt;3.3 创建一个 Flux 或 Mono 并进行订阅的一些简单方法&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 的类中包含大量的工厂方法，上手使用 Reactor 最简单的方式是从中选择一个用起来。&lt;/p&gt;
&lt;p&gt;例如，创建一个 &lt;code&gt;String&lt;/code&gt; 序列，可以逐个列举出这些字符串，或者将这些字符串放到一个集合中，然后基于这个集合创建一个 Flux，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; seq1 = Flux.just(&amp;amp;quot;foo&amp;amp;quot;, &amp;amp;quot;bar&amp;amp;quot;, &amp;amp;quot;foobar&amp;amp;quot;);

List&amp;amp;lt;String&amp;amp;gt; iterable = Arrays.asList(&amp;amp;quot;foo&amp;amp;quot;, &amp;amp;quot;bar&amp;amp;quot;, &amp;amp;quot;foobar&amp;amp;quot;);
Flux&amp;amp;lt;String&amp;amp;gt; seq2 = Flux.fromIterable(iterable);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其它一些工厂方法的使用示例如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Mono&amp;amp;lt;String&amp;amp;gt; noData = Mono.empty();
Mono&amp;amp;lt;String&amp;amp;gt; data = Mono.just(&amp;amp;quot;foo&amp;amp;quot;);
Flux&amp;amp;lt;Integer&amp;amp;gt; numbersFromFiveToSeven = Flux.range(5, 3);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于订阅操作，&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 借助了 Java 8 的 lambda 表达式。有大量 &lt;code&gt;.subscribe()&lt;/code&gt; 的重载方法/变种方法（variants）可选选择使用，使用 lambda 表达式来实现回调的不同组合，如下所示是这些方法的签名：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Flux 中基于 lambda 表达式的订阅方法变种&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;subscribe();

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer,
          Runnable completeConsumer);

subscribe(Consumer&amp;amp;lt;? super T&amp;amp;gt; consumer,
          Consumer&amp;amp;lt;? super Throwable&amp;amp;gt; errorConsumer,
          Runnable completeConsumer,
          Consumer&amp;amp;lt;? super Subscription&amp;amp;gt; subscriptionConsumer);&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p&gt;这些订阅方法都会返回一个订阅操作的引用，当不再需要更多的数据时，可以使用这个引用来取消订阅。一旦取消，数据源就应该停止产出数据，并清理使用的所有资源。这一 “取消并清理” 行为在 Reactor 中以通用的 &lt;code&gt;Disposable&lt;/code&gt; 接口来表现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;3.3.1 lambda 表达式的替代方案：BaseSubscriber&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 提供了一个相比上面那么订阅方法更通用的 &lt;code&gt;subscribe&lt;/code&gt; 方法，其参数是一个完整的 &lt;code&gt;Subscriber&lt;/code&gt; 实例，而不是根据几个 lambda 表达式组合出一个 &lt;code&gt;Subscriber&lt;/code&gt; 实例。为了方便实现这样的一个 &lt;code&gt;Subscriber&lt;/code&gt;，Reactor 提供了一个名为 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的可扩展的抽象类。&lt;/p&gt;
&lt;p&gt;下面来实现一个，我们将其命名为 &lt;code&gt;SampleSubscriber&lt;/code&gt;。如下示例演示了如何将其应用到一个 &lt;code&gt;Flux&lt;/code&gt; 序列上：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;SampleSubscriber&amp;amp;lt;Integer&amp;amp;gt; ss = new SampleSubscriber&amp;amp;lt;Integer&amp;amp;gt;();
Flux&amp;amp;lt;Integer&amp;amp;gt; ints = Flux.range(1, 4);
//
ints.subscribe(i -&amp;amp;gt; System.out.println(i),
    error -&amp;amp;gt; System.err.println(&amp;amp;quot;Error &amp;amp;quot; + error),
    () -&amp;amp;gt; {System.out.println(&amp;amp;quot;Done&amp;amp;quot;);},
    s -&amp;amp;gt; s.request(10));
//
ints.subscribe(ss);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如下示例演示了 &lt;code&gt;SampleSubscriber&lt;/code&gt; 继承自 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的一个最简化实现：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;package io.projectreactor.samples;

import org.reactivestreams.Subscription;
import reactor.core.publisher.BaseSubscriber;

public class SampleSubscriber&amp;amp;lt;T&amp;amp;gt; extends BaseSubscriber&amp;amp;lt;T&amp;amp;gt; {

	public void hookOnSubscribe(Subscription subscription) {
		System.out.println(&amp;amp;quot;Subscribed&amp;amp;quot;);
		request(1);
	}

	public void hookOnNext(T value) {
		System.out.println(value);
		request(1);
	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;BaseSubscriber&lt;/code&gt; 还提供了一个 &lt;code&gt;requestUnbounded()&lt;/code&gt; 方法来切换到无限消费模式（相当于 &lt;code&gt;request(Long.MAX_VALUES)&lt;/code&gt;），另外也提供了一个 &lt;code&gt;cancel()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;除了 &lt;code&gt;hookOnSubscribe&lt;/code&gt; 和 &lt;code&gt;hookOnNext&lt;/code&gt;，&lt;code&gt;BaseSubscriber&lt;/code&gt; 还提供了其他钩子方法（方法体为空，提供继承重写）：&lt;code&gt;hookOnComplete&lt;/code&gt;、&lt;code&gt;hookOnError&lt;/code&gt;、&lt;code&gt;hookOnCancel&lt;/code&gt; 以及 &lt;code&gt;hookFinally&lt;/code&gt;（当事件/消息序列（流）终止时，一定会调用该方法，调用时会传入一个 &lt;code&gt;SignalType&lt;/code&gt; 类型参数表示终止的类型）。&lt;/p&gt;
&lt;h4&gt;3.3.2 关于反压和调整请求量的方式&lt;/h4&gt;
&lt;p&gt;在 Reactor 中实现反压，是通过向上游算子发送一个 &lt;code&gt;请求（request）&lt;/code&gt;来逐级传播消费者的压力，直到数据源。当前请求的总量有时又称为当前的“需求量” 或者 “待满足（pending）的请求量”。需求量的上限是 &lt;code&gt;Long.MAX_VALUE&lt;/code&gt;，表示一个无限量的请求（意思是“尽快产出数据“ - 反压也就失效了）。&lt;/p&gt;
&lt;p&gt;最终的订阅者在订阅之前会发出首个请求，订阅所有消息/数据最直接的方式是即刻触发一个无限量（Long.MAX_VALUE）的请求：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;subscribe()&lt;/code&gt; 以及大部分基于 lambda 表达式的变种方法（除了那个接受 &lt;code&gt;Consumer&amp;lt;Subscription&amp;gt;&lt;/code&gt; 类型参数的方法）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;block()&lt;/code&gt;、&lt;code&gt;blockFirst()&lt;/code&gt; 和 &lt;code&gt;blockLast()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;toIterable()&lt;/code&gt; 或 &lt;code&gt;toStream()&lt;/code&gt; 进行遍历&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;对首个请求进行定制的最简单方式是以一个 &lt;code&gt;BaseSubscriber&lt;/code&gt; 派生类实例来 &lt;code&gt;subscribe&lt;/code&gt;，派生类重写 &lt;code&gt;BaseSubscriber&lt;/code&gt; 的 &lt;code&gt;hookOnSubscribe&lt;/code&gt; 方法，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .doOnRequest(r -&amp;amp;gt; System.out.println(&amp;amp;quot;request of &amp;amp;quot; + r))
    .subscribe(new BaseSubscriber&amp;amp;lt;Integer&amp;amp;gt;() {

      @Override
      public void hookOnSubscribe(Subscription subscription) {
        request(1);
      }

      @Override
      public void hookOnNext(Integer integer) {
        System.out.println(&amp;amp;quot;Cancelling after having received &amp;amp;quot; + integer);
        cancel();
      }
    });&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面这个代码片段输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;request of 1
Cancelling after having received 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;改变下游需求量的算子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;谨记：订阅时指定的需求量，上游操作链中的每个算子都可以对其作出调整。一个典型案例是 &lt;code&gt;buffer(N)&lt;/code&gt; 算子：如果它收到一个 &lt;code&gt;request(2)&lt;/code&gt; 请求，它会理解为2个缓冲区的请求量。因为缓冲区需要 N 个元素才认为是满的，所以 &lt;code&gt;buffer&lt;/code&gt; 算子将请求量调整成了 &lt;code&gt;2 x N&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;你也许也注意到某些算子存在这样的变种 - 接受一个名为 &lt;code&gt;prefetch&lt;/code&gt; 的 &lt;code&gt;int&lt;/code&gt; 类型参数。这是另外一类修改下游请求量的算子。这类算子（比如 &lt;code&gt;flatMap&lt;/code&gt;）通常是处理内部序列（inner sequences），从每个进入的元素派生出一个 &lt;code&gt;Publisher&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;预取（prefetch）&lt;/code&gt;是调整内部序列请求量的一个方式。如果未指定，多数这类算子会以 32 为初始需求量。&lt;/p&gt;
&lt;p&gt;这类算子通常也会实现一个&lt;strong&gt;填补优化方案&lt;/strong&gt;：算子一旦看到 25% 的预取请求量已完成，就会向上游再发起 25% 的请求量。这是一个启发式优化，如此这类算子就可以主动地为即将到来的请求量做好准备。&lt;/p&gt;
&lt;p&gt;最后，再介绍一对直接用于调整请求量的算子：&lt;code&gt;limitRate&lt;/code&gt; 和 &lt;code&gt;limitRequest&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;limitRate(N)&lt;/code&gt; 把下游的请求量拆分成多个更小量的请求向上游传播。例如，一个 &lt;code&gt;100&lt;/code&gt; 的请求传到算子 &lt;code&gt;limitRate(10)&lt;/code&gt;，则会变成 10 次请求，一次请求 10，传播到上游。注意：&lt;code&gt;limitRate&lt;/code&gt; 实际上以这种形式实现了前面提到的填补优化方案。&lt;/p&gt;
&lt;p&gt;这个算子有一个变种，允许开发者调整预取填补量（即算子变种的 &lt;code&gt;lowTide&lt;/code&gt; 参数）：&lt;code&gt;limitRate(highTide, lowTide)&lt;/code&gt;。&lt;code&gt;lowTide&lt;/code&gt; 参数设定为 &lt;code&gt;0&lt;/code&gt; 时，会导致严格限制一次请求 &lt;code&gt;highTide&lt;/code&gt; 个，而不是经填补策略进一步调整过的一次请求量。&lt;/p&gt;
&lt;p&gt;此外，&lt;code&gt;limitRequest(N)&lt;/code&gt; 则是限制了下游最大的需求总量。它会累加请求量直到 &lt;code&gt;N&lt;/code&gt;。如果一次请求没有让需求总量超过 &lt;code&gt;N&lt;/code&gt;，则这次请求会完整地传播到上游（译注：意思是如果一次请求让需求总量超过了 &lt;code&gt;N&lt;/code&gt;，这次请求的请求量会被裁剪）。如果数据源发出的数据总量达到了限制的总量，&lt;code&gt;limitRequest&lt;/code&gt; 则认为这个序列可以结束了，向下游发送一个 &lt;code&gt;onComplete&lt;/code&gt; 信号，并取消数据源。&lt;/p&gt;
&lt;h3&gt;3.4 动态地（programmatically）创建一个序列&lt;/h3&gt;
&lt;h4&gt;3.4.1 同步的 generate&lt;/h4&gt;
&lt;p&gt;动态创建一个 &lt;code&gt;Flux&lt;/code&gt; 最简单的方式是借助 &lt;code&gt;generate&lt;/code&gt; 方法，该方法接受一个生成器函数。&lt;/p&gt;
&lt;p&gt;这一方式可以实现&lt;strong&gt;同步的&lt;/strong&gt;且&lt;strong&gt;一个接一个&lt;/strong&gt;地下发数据，这意味着接收方（sink）是一个 &lt;code&gt;SynchronousSink&lt;/code&gt;，其 &lt;code&gt;next()&lt;/code&gt; 方法在一次回调方法调用中最多只能调用一次。可以在其后再调用 &lt;code&gt;error(Throwable)&lt;/code&gt; 或 &lt;code&gt;complete()&lt;/code&gt;，视你的需求而定。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;generate&lt;/code&gt; 方法变种的这个应该是最有用的：允许保持一个状态，在调用接收方的 &lt;code&gt;next&lt;/code&gt; 方法时可以基于这个状态来决定下发什么数据。那么这个生成器函数就成了一个 &lt;code&gt;BiFunction&amp;lt;S, SynchronousSink&amp;lt;T&amp;gt;, S&amp;gt;&lt;/code&gt; 实例，其中 &lt;code&gt;&amp;lt;S&amp;gt;&lt;/code&gt; 即是状态对象的类型。对于初始状态，可以提供一个 &lt;code&gt;Supplier&amp;lt;S&amp;gt;&lt;/code&gt; 来获取，这样生成器函数每轮调用都会返回一个新的状态。&lt;/p&gt;
&lt;p&gt;例如，可以使用一个 &lt;code&gt;int&lt;/code&gt; 实例作为状态：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 基于状态的 generate 方法使用示例
Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    () -&amp;amp;gt; 0, // 1
    (state, sink) -&amp;amp;gt; {
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + state + &amp;amp;quot; = &amp;amp;quot; + 3*state); // 2
        if (state == 10) sink.complete(); // 3
        return state + 1; // 4
    });&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;以 0 作为初始状态。&lt;/li&gt;
&lt;li&gt;基于状态（state）决定下发什么消息/数据。&lt;/li&gt;
&lt;li&gt;基于状态决定何时可以停止流/序列。&lt;/li&gt;
&lt;li&gt;返回一个新状态，下次调用时可以使用（除非在这次调用时已经终止序列）。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;也可以使用一个 &lt;code&gt;&amp;lt;S&amp;gt;&lt;/code&gt; 类型的可变对象。比如，上面的示例可以使用一个 &lt;code&gt;AtomicLong&lt;/code&gt; 实例作为状态来重写，每轮调用都会改变它的值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    AtomicLong::new,
    (state, sink) -&amp;amp;gt; {
        long i = state.getAndIncrement();
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + i + &amp;amp;quot; = &amp;amp;quot; + 3*i);
        if (i == 10) sink.complete();
        return state;
    });&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;&lt;p&gt;如果状态对象在序列终止时需要清理一些资源，则应该使用 &lt;code&gt;generate(Supplier&amp;lt;S&amp;gt;, BiFunction, Consumer&amp;lt;S&amp;gt;)&lt;/code&gt; 变种方法来清理最后的状态实例。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;如下示例使用的 &lt;code&gt;generate&lt;/code&gt; 方法接受一个 &lt;code&gt;Consumer&lt;/code&gt; 类型参数：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux.generate(
    AtomicLong::new,
    (state, sink) -&amp;amp;gt; {
        long i = state.getAndIncrement();
        sink.next(&amp;amp;quot;3 x &amp;amp;quot; + i + &amp;amp;quot; = &amp;amp;quot; + 3*i);
        if (i == 10) sink.complete();
        return state;
    }, (state) -&amp;amp;gt; System.out.println(&amp;amp;quot;state: &amp;amp;quot; + state));&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;3.4.2 异步多线程的 create&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;create&lt;/code&gt; 是动态创建一个 &lt;code&gt;Flux&lt;/code&gt; 的更高级的方式，适用于每轮下发多个数据，甚至是从多个线程中下发数据。&lt;/p&gt;
&lt;p&gt;这个方法会向回调方法传入一个 &lt;code&gt;FluxSink&lt;/code&gt; 实例参数，在回调方法体中可以调用这个参数的 &lt;code&gt;next&lt;/code&gt;、&lt;code&gt;error&lt;/code&gt; 和 &lt;code&gt;complete&lt;/code&gt; 方法。与 &lt;code&gt;generate&lt;/code&gt; 不同，它没有基于状态的变种方法。另外，回调方法中，可以多线程地触发事件（trigger multi-threaded events）。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;create&lt;/code&gt; 非常适用于将一个已有的 API （比如：一个基于监听器的异步 API）桥接到反应式上下文中。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;create&lt;/code&gt; 并不会自动并行化执行你的代码，也不会让处理过程自动变成异步的，即使它可以配合异步 API 使用。如果在 &lt;code&gt;create&lt;/code&gt; 的 lambda 表达式中发生阻塞，就会存在死锁或者其它副作用的风险。即使借助 &lt;code&gt;subscribeOn&lt;/code&gt;，也要当心 &lt;code&gt;create&lt;/code&gt; lambda 表达式中长时间的阻塞（比如无限循环调用 &lt;code&gt;sink.next(t)&lt;/code&gt;）锁住流水线处理： （译注：异步的）数据请求可能根本得不到执行，因为（译注：线程池只有一个线程）同一个线程一直被无限循环占用着。使用 &lt;code&gt;subscribeOn(Scheduler, false)&lt;/code&gt; 变种方法：&lt;code&gt;requestOnSeparateThread = false&lt;/code&gt; 将使用 &lt;code&gt;Scheduler&lt;/code&gt; 的线程来执行 &lt;code&gt;create&lt;/code&gt; 方法的回调，在原始的线程中执行 &lt;code&gt;request&lt;/code&gt;，从而让数据仍然可以流动起来。（译注：此处逻辑有点绕，也可能是因为 subscribeOn 方法本身语义就不太直观）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;假设我们要使用一个基于监听器的 API，它按块处理数据，提供两类事件：（1）来了一块数据，（2）处理可以结束了（终止事件），如下 &lt;code&gt;MyEventListener&lt;/code&gt; 接口定义所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;interface MyEventListener&amp;amp;lt;T&amp;amp;gt; {
    void onDataChunk(List&amp;amp;lt;T&amp;amp;gt; chunk);
    void processComplete();
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们使用 &lt;code&gt;create&lt;/code&gt; 将这个 API 桥接到一个 &lt;code&gt;Flux&amp;lt;T&amp;gt;&lt;/code&gt; 实例上：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.create(sink -&amp;amp;gt; {
    myEventProcessor.register(  // 4
        new MyEventListener&amp;amp;lt;String&amp;amp;gt;() { // 1
            public void onDataChunk(List&amp;amp;lt;String&amp;amp;gt; chunk) {
                for(String s : chunk) {
                    sink.next(s); // 2
                }
            }
            
            public void processComplete() {
                sink.complete(); // 3
            }
        }
    );
});&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;桥接到 &lt;code&gt;MyEventListener&lt;/code&gt; API&lt;/li&gt;
&lt;li&gt;数据块中每个元素都成了 &lt;code&gt;Flux&lt;/code&gt; 中的元素。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;processComplete&lt;/code&gt; 事件转换成了 &lt;code&gt;onComplete&lt;/code&gt; 事件。&lt;/li&gt;
&lt;li&gt;所有这些逻辑都是在 &lt;code&gt;myEventProcessor&lt;/code&gt; 执行时异步完成的。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;此外，因为 &lt;code&gt;create&lt;/code&gt; 可以桥接异步 API，并管理反压，通过指定一个 &lt;code&gt;OverflowStrategy&lt;/code&gt; 策略，可以调整如何智能地处理反压：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;IGNORE&lt;/code&gt; 完全忽略下游的反压请求。这一策略在下游的队列满时（when queues get full downstream）会导致 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常抛出。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ERROR&lt;/code&gt; 在下游处理不过来时会下发（onError）一个 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常消息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DROP&lt;/code&gt; 如果下游还没准备好接收当前事件，则直接丢弃。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BUFFER&lt;/code&gt; （默认策略）如果下游处理不过来，则将所有事件放入缓冲区。（缓冲区大小无限制，所以可能会导致内存溢出&lt;code&gt;OutOfMemoryError&lt;/code&gt;）&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;Mono&lt;/code&gt; 也有一个 &lt;code&gt;create&lt;/code&gt; 生成器方法。Mono 的 create 方法传入回调的 &lt;code&gt;MonoSink&lt;/code&gt; 参数不允许下发多个消息，在第一个消息之后它会丢弃所有的消息。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;3.4.3 异步单线程的 push&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;push&lt;/code&gt; 的功能介于 &lt;code&gt;generate&lt;/code&gt; 和 &lt;code&gt;create&lt;/code&gt; 之间，适用于处理来自单个生产者的事件。&lt;code&gt;push&lt;/code&gt; 也可以是异步的，也可以使用 &lt;code&gt;create&lt;/code&gt; 支持的超限策略来管理反压，然而，同时（at a time）只能有一个生产线程调用 &lt;code&gt;next&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.push(sink -&amp;amp;gt; {
    myEventProcessor.register(
        new SingleThreadEventListener&amp;amp;lt;String&amp;amp;gt;() { // 1
            
            public void onDataChunk(List&amp;amp;lt;String&amp;amp;gt; chunk) {
                for (String s: chunk) {
                    sink.next(s); // 2
                }
            }
            
            public void processComplete() {
                sink.complete(); // 3
            }
            
            public void processError(Throwable e) {
                sink.error(e); // 4
            }
        }
    );
});&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;桥接到 &lt;code&gt;SingleThreadEventListener&lt;/code&gt; 的 API。&lt;/li&gt;
&lt;li&gt;在单个监听器线程中使用 &lt;code&gt;next&lt;/code&gt; 向下游（sink - 接收方）推送事件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;complete&lt;/code&gt; 事件也是由同一个监听器线程发出的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;error&lt;/code&gt; 事件也是由同一个监听器线程发出的。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;推/拉 混合模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多数 Reactor 算子，比如 &lt;code&gt;create&lt;/code&gt;，都遵从 &lt;strong&gt;推/拉（push/pull）&lt;/strong&gt; 混合模型。这意味着尽管大部分的处理过程都是异步的（暗指“推”的方式），也存在小部分逻辑是 &lt;em&gt;拉（pull）&lt;/em&gt;方式：数据请求。&lt;/p&gt;
&lt;p&gt;消费者从数据源&lt;em&gt;拉取&lt;/em&gt;数据，意指：数据源在消费者首次请求后才会发出数据，然后只有要数据就会推送给消费者，不过数据量不会超过消费者请求的量。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;push()&lt;/code&gt; 和 &lt;code&gt;create()&lt;/code&gt; 都可以配置（set up）一个 &lt;code&gt;onRequest&lt;/code&gt; 事件消费者来管理请求量，并且确保仅当存在已发起的请求，数据才会推送给下游。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux&amp;amp;lt;String&amp;amp;gt; bridge = Flux.create(sink -&amp;amp;gt; {
    myMessageProcessor.register(
        new MyMessageListener&amp;amp;lt;String&amp;amp;gt;() {
            
            public void onMessage(List&amp;amp;lt;String&amp;amp;gt; messages) {
                for (String s: messages) {
                    sink.next(s); // 3
                }
            }
        }
    );
    sink.onRequest(n -&amp;amp;gt; {
        List&amp;amp;lt;String&amp;amp;gt; messages = myMessageProcessor.getHistory(n); // 1
        for (String s: messages) {
            sink.next(s); // 2
        }
    });    
});&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;译者注：上面这个示例有点问题，实际并不存在这样一个 create 方法，并且 sink.onRequest 实际代表一个无限量（n = Long.MAX_VALUE）的请求。&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在请求发起后，拉取消息。&lt;/li&gt;
&lt;li&gt;如果即刻有消息了，则推送给下游。&lt;/li&gt;
&lt;li&gt;后续异步到达的消息也会推送给下游。&lt;/li&gt;&lt;/ol&gt;
&lt;h3&gt;3.5 多线程 和 调度器 （Threading and Schedulers）&lt;/h3&gt;
&lt;p&gt;Reactor，与 RxJava 类似，可以认为是&lt;strong&gt;并发无关的&lt;/strong&gt;，也就是说，Reactor 并不强制使用并发（a concurrency&lt;/p&gt;
&lt;p&gt;model），而是，让开发者按需决定是否使用并发。然而，Reactor 也提供一些功能方便开启并发。&lt;/p&gt;
&lt;p&gt;获取到一个 &lt;code&gt;Flux&lt;/code&gt; 或 &lt;code&gt;Mono&lt;/code&gt; 处理流，并不意味着它在一个专用（dedicated）的线程（&lt;code&gt;Thread&lt;/code&gt;） 中运行。相反，多数算子也是运行在前一个算子运行的线程中。除非特意指定，首个（topmost）算子（数据源）就运行在执行 &lt;code&gt;subscribe()&lt;/code&gt; 方法调用的线程中。如下示例在一个新建线程中运行一个 &lt;code&gt;Mono&lt;/code&gt; 处理流。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;public static void main(String[] args) {
    final Mono&amp;amp;lt;String&amp;amp;gt; mono = Mono.just(&amp;amp;quot;Hello &amp;amp;quot;); // 1
    
    new Thread(() -&amp;amp;gt; mono
        .map(msg -&amp;amp;gt; msg + &amp;amp;quot;thread &amp;amp;quot;)
        .subscribe(v -&amp;amp;gt; // 2 
            System.out.println(v + Thread.currentThread().getName()) // 3
        )
    ).join();
}&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;Mono&amp;lt;String&amp;gt;&lt;/code&gt; 是在主（&lt;code&gt;main&lt;/code&gt;）线程中装配的（assembled）。&lt;/li&gt;
&lt;li&gt;然而， 订阅操作发生在 &lt;code&gt;Thread-0&lt;/code&gt; 线程中。&lt;/li&gt;
&lt;li&gt;因而，&lt;code&gt;map&lt;/code&gt; 和 &lt;code&gt;onNext&lt;/code&gt; 的回调（译注：&lt;code&gt;onNext&lt;/code&gt; 的回调即 subscribe 方法传入的 lambda 表达式）实际上也是在 &lt;code&gt;Thread-0&lt;/code&gt; 上执行。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;上述的代码会输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;hello thread Thread-0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reactor 中，运行模型以及实际的运行过程发生在什么地方由使用什么 &lt;code&gt;Scheduler&lt;/code&gt; 决定。&lt;a href=&apos;https://projectreactor.io/docs/core/release/api/reactor/core/scheduler/Scheduler.html&apos;&gt;Scheduler&lt;/a&gt; 类似于 &lt;code&gt;ExecutorService&lt;/code&gt;，负有调度职责，但具备一个专用的抽象，功能更强大，充当一个时钟的角色，可用的实现更多。&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;https://projectreactor.io/docs/core/release/api/reactor/core/scheduler/Schedulers.html&apos;&gt;Schedulers&lt;/a&gt; 类提供了一些静态方法来访问这些运行上下文：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当前线程（&lt;code&gt;Schedulers.immediate()&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;单个可复用的线程（&lt;code&gt;Schedulers.single()&lt;/code&gt;）。注意：这个方法会为所有调用方（译注：调用 Schedulers.single()）复用同一个线程，指导 &lt;code&gt;Scheduler&lt;/code&gt; 销毁（disposed）。如果期望每次调用返回一个专用线程，则应该使用 &lt;code&gt;Schedulers.newSingle()&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;一个弹性的线程池（&lt;code&gt;Schedulers.elastic()&lt;/code&gt;）。这个 Scheduler 会按需创建新的工作者线程池（worker pool），并复用空闲的工作者线程池。如果工作者线程池空闲时间太长（默认 60s）则会被销毁。对于 I/O 阻塞工作而言这是一个好选择。&lt;code&gt;Schedulers.elastic()&lt;/code&gt; 可以简便地为阻塞处理过程提供独立的线程（its own thread），这样阻塞操作就不会占用（tie up）其他资源。详情请参考 &lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/#faq.wrap-blocking&apos;&gt;如何包装一个同步阻塞的调用？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;固定数量工作者的（译注：我暂时的理解 - 工作者（worker）也是一个线程池）一个池，专门为并行处理工作做过调优（Schedulers.parallel()）。它会创建和 CPU 核心数量相同的工作者。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;此外，也可以使用 &lt;code&gt;Schedulers.fromExecutorService(ExecutorService)&lt;/code&gt; 基于已有的 ExecutorService 创建一个 Scheduler。（也可以基于一个 Executor 来创建，但不建议这么干（译注：因为 Executor 不能销毁释放））&lt;/p&gt;
&lt;p&gt;也可以使用 &lt;strong&gt;newXXX&lt;/strong&gt; 这类方法创建各种调度器（scheduler）类型的全新实例。例如，使用 &lt;code&gt;Schedulers.newElastic(yourScheduleName)&lt;/code&gt; 创建一个名为 &lt;code&gt;yourScheduleName&lt;/code&gt; 的全新的弹性调度器（elastic scheduler）。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;elastic&lt;/code&gt; 调度器用于兼容处理不可避免的历史遗留的阻塞性代码，但 &lt;code&gt;single&lt;/code&gt; 和 &lt;code&gt;parallel&lt;/code&gt; 调度器不行，因而，如果在 &lt;code&gt;single&lt;/code&gt; 或 &lt;code&gt;parallel&lt;/code&gt; 调度器上使用 Reactor 的阻塞性 API（&lt;code&gt;block()&lt;/code&gt;、&lt;code&gt;blockFirst()&lt;/code&gt;、&lt;code&gt;blockLast()&lt;/code&gt;，或者进行 &lt;code&gt;toIterable()&lt;/code&gt; 或 &lt;code&gt;toStream()&lt;/code&gt; 迭代），会导致抛出 &lt;code&gt;IllegalStateException&lt;/code&gt; 异常。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;如果自定义调度器所创建的线程实例实现了 &lt;code&gt;NonBlocking&lt;/code&gt; 标记性接口（marker interface），那么这个调度器也可以被标记为”仅适用于非阻塞性使用（non blocking only）“。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;某些算子默认会从 &lt;code&gt;Schedulers&lt;/code&gt; 选择一个特定的调度器来使用（通常也支持选择其他的）。例如，调用工厂方法 &lt;code&gt;Flux.interval(Duration.ofMills(300))&lt;/code&gt; 会生成一个 &lt;code&gt;Flux&amp;lt;Long&amp;gt;&lt;/code&gt; 实例 - 每 300 ms 输出一个滴答事件。这个方法底层实现默认使用 &lt;code&gt;Schedulers.parallel()&lt;/code&gt;。如下代码行演示了如何将调度器修改成类似于 &lt;code&gt;Schedulers.single()&lt;/code&gt; 的调度器新实例：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.interval(Duration.ofMillis(300), Schedulers.newSingle(&amp;amp;quot;test&amp;amp;quot;));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reactor 提供了两种方式来切换反应式链中的执行上下文（或者说 &lt;code&gt;调度器&lt;/code&gt;）：&lt;code&gt;publishOn&lt;/code&gt; 和 &lt;code&gt;subscribeOn&lt;/code&gt;。两者都是接受一个 &lt;code&gt;Scheduler&lt;/code&gt; 类型参数并将执行上下文切换到这个调度器。不过，链中 &lt;code&gt;publishOn&lt;/code&gt; 所处的位置很关键，而 &lt;code&gt;subscribeOn&lt;/code&gt; 处于哪个位置都无所谓。要理解这个差别的原因，得先理解 &lt;a href=&apos;https://projectreactor.io/docs/core/release/reference/#reactive.subscribe&apos;&gt;订阅之前实际什么都没有发生&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Reactor，串接算子，就是将很多 &lt;code&gt;Flux&lt;/code&gt; 和 &lt;code&gt;Mono&lt;/code&gt; 的实现一个套一个，逐层封装。一旦订阅，就创建了一个 &lt;code&gt;Subscriber&lt;/code&gt; 对象链，沿链回溯即可找到第一个发布者。这些实现细节是隐藏在接口背后，开发者可见的是最外层的那个 &lt;code&gt;Flux&lt;/code&gt;（或 &lt;code&gt;Mono&lt;/code&gt;）以及 &lt;code&gt;Subscription&lt;/code&gt;（译注：Reactor 中 Subscription 是一个接口类型，是 &lt;code&gt;Subscriber&lt;/code&gt; 接口中 &lt;code&gt;onSubscribe&lt;/code&gt; 方法参数的类型 - &lt;code&gt;public void onSubscribe(Subscription s)&lt;/code&gt;，用于向生产者请求数据 或者 取消订阅），但这些算子特定的链中消费者是幕后功臣。&lt;/p&gt;
&lt;p&gt;有了上面这些认知，现在我们可以进一步了解 &lt;code&gt;publishOn&lt;/code&gt; 和 &lt;code&gt;subscribeOn&lt;/code&gt; 这两个算子：&lt;/p&gt;
&lt;h4&gt;3.5.1 publishOn 方法&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;publishOn&lt;/code&gt; 和其他算子的用法一样，用在订阅链的中间环节，接收来自上游的信号，然后向下游重放这些信号，不过下发事件回调（&lt;code&gt;onEvent&lt;/code&gt;、&lt;code&gt;onError&lt;/code&gt;、&lt;code&gt;onComplete&lt;/code&gt;）是在关联 &lt;code&gt;Scheduler&lt;/code&gt; 的一个工作者上执行的。因此，这个算子会影响后续算子在哪执行（直到订阅链上又串接了另一个 &lt;code&gt;publishOn&lt;/code&gt;）：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将执行上下文切换到 &lt;code&gt;Scheduler&lt;/code&gt; 选择的一个线程上&lt;/li&gt;
&lt;li&gt;根据规范（as per the specification），&lt;code&gt;onNext&lt;/code&gt; 是按时序依次调用下发事件的，所以是占用一个线程（译注：这句不太理解，onNext happen in sequence, so this uses up a single thread）&lt;/li&gt;
&lt;li&gt;除非算子工作在一个特定的 &lt;code&gt;Scheduler&lt;/code&gt; 上（译注：某些算子的内部实现决定了这一点），&lt;code&gt;publishOn&lt;/code&gt; 之后的算子都是在同一个线程上执行&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Scheduler s = Schedulers.newParallel(&amp;amp;quot;parallel-scheduler&amp;amp;quot;, 4); // 1

final Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux
    .range(1, 2)
    .map(i -&amp;amp;gt; 10 + i) // 2
    .publishOn(s) // 3
    .map(i -&amp;amp;gt; &amp;amp;quot;value &amp;amp;quot; + i); // 4

new Thread(() -&amp;amp;gt; flux.subscribe(System.out::println));&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;创建一个新的 &lt;code&gt;Scheduler&lt;/code&gt;，内含 4 个线程&lt;/li&gt;
&lt;li&gt;第一个 &lt;code&gt;map&lt;/code&gt; 运行在 &lt;第5步&gt; 的匿名线程上&lt;/li&gt;
&lt;li&gt;&lt;code&gt;publishOn&lt;/code&gt; 将整个序列的后续处理切换到从 &lt;第1步&gt; 选出的线程上&lt;/li&gt;
&lt;li&gt;第二个 &lt;code&gt;map&lt;/code&gt; 运行在上面说的从 &lt;第1步&gt; 选出的线程上&lt;/li&gt;
&lt;li&gt;这个匿名线程是 &lt;em&gt;订阅&lt;/em&gt; 操作发生的地方。打印语句发生在 &lt;code&gt;publishOn&lt;/code&gt; 切换的最新执行上下文上&lt;/li&gt;&lt;/ol&gt;
&lt;h4&gt;3.5.2 subscribeOn 方法&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;subscribeOn&lt;/code&gt; 在构造反向链时应用于订阅处理过程（译注：所谓构造反向链时，是指调用 subscribe 方法时）。因此，无论你将 &lt;code&gt;subscribeOn&lt;/code&gt; 放在算子链的何处，&lt;strong&gt;它始终会影响源头下发数据的执行上下文&lt;/strong&gt;。然而，这并不会影响 &lt;code&gt;publishOn&lt;/code&gt; 之后算子调用的行为，它们仍然会切换到 &lt;code&gt;publishOn&lt;/code&gt; 指定的执行上下文。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从订阅操作发生时整个算子链所在的线程切换到新的线程&lt;/li&gt;
&lt;li&gt;从指定 &lt;code&gt;Scheduler&lt;/code&gt; 中选择一个线程&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;只有链中最早的 &lt;code&gt;subscribeOn&lt;/code&gt; 调用会发生实际作用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Scheduler s = Schedulers.newParallel(&amp;amp;quot;parallel-scheduler&amp;amp;quot;, 4); // 1

final Flux&amp;amp;lt;String&amp;amp;gt; flux = Flux
    .range(1, 2)
    .map(i -&amp;amp;gt; 10 + i) // 2
    .subscribeOn(s) // 3
    .map(i -&amp;amp;gt; &amp;amp;quot;value &amp;amp;quot; + i); // 4

new Thread(() -&amp;amp;gt; flux.subscribe(System.out::println)); // 5 &lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;创建一个新的 &lt;code&gt;Scheduler&lt;/code&gt;，内含 4 个线程&lt;/li&gt;
&lt;li&gt;第一个 &lt;code&gt;map&lt;/code&gt; 运行在这 4 个线程中的某个线程上&lt;/li&gt;
&lt;li&gt;...因为 &lt;code&gt;subscribeOn&lt;/code&gt; 将整个序列处理链从订阅操作发生时的执行上下文（第5步）切换到了新的上下文&lt;/li&gt;
&lt;li&gt;第二个 &lt;code&gt;map&lt;/code&gt; 和第一个 &lt;code&gt;map&lt;/code&gt; 运行在同一个线程上&lt;/li&gt;
&lt;li&gt;这个匿名线程是 &lt;em&gt;订阅操作&lt;/em&gt; 一开始发生的地方的，但是 &lt;code&gt;subscribeOn&lt;/code&gt; 即刻将上下文切换到调度器4个线程中的一个上&lt;/li&gt;&lt;/ol&gt;
&lt;h2&gt;4. 高级特性和概念&lt;/h2&gt;
&lt;h3&gt;4.1 使用 ConnectableFlux 将消息广播到多个订阅者&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;以后有空再翻译&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;4.2 3种分批处理方式&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;以后有空再翻译&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;4.3 使用 ParallelFlux 并行化处理&lt;/h3&gt;
&lt;p&gt;如今多核架构已是下里巴人，相应地，轻松实现并行化工作的工具手段很关键。Reactor 提供了一个特殊类型 - &lt;code&gt;ParallelFlux&lt;/code&gt; - 帮助实现并行化处理。&lt;code&gt;ParallelFlux&lt;/code&gt; 提供的算子是为并行化工作优化过的。&lt;/p&gt;
&lt;p&gt;对任意 &lt;code&gt;Flux&lt;/code&gt; 实例调用 &lt;code&gt;parallel()&lt;/code&gt;算子就能得到一个 &lt;code&gt;ParallelFlux&lt;/code&gt; 实例。这个方法本身并不能实现并行化工作，而是将工作负载拆分到多个“轨道”（默认“轨道”数量等于 CPU 核数）&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[^1]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;为了告知产出的 ParallelFlux 实例每个“轨道”在哪执行（以及如何并行执行“轨道”），则必须使用 &lt;code&gt;runOn(Scheduler)&lt;/code&gt;。注意：对于并行工作，推荐使用一个专用调度器 - &lt;code&gt;Schedulers.parallel()&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;对比如下两个示例，第一个示例的代码如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .parallel(2) // 1
    .subscribe(i -&amp;amp;gt; System.out.println(Thread.currentThread().getName() + &amp;amp;quot; -&amp;amp;gt; &amp;amp;quot; + i));&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;这里强制指定了“轨道”数量，而不依赖于 CPU 核数。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;第二个示例的代码如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;Flux.range(1, 10)
    .parallel(2)
    .runOn(Schedulers.parallel())
    .subscribe(i -&amp;amp;gt; System.out.println(Thread.currentThread().getName() + &amp;amp;quot; -&amp;amp;gt; &amp;amp;quot; + i));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第一个示例输出如下内容：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;main -&amp;amp;gt; 1
main -&amp;amp;gt; 2
main -&amp;amp;gt; 3
main -&amp;amp;gt; 4
main -&amp;amp;gt; 5
main -&amp;amp;gt; 6
main -&amp;amp;gt; 7
main -&amp;amp;gt; 8
main -&amp;amp;gt; 9
main -&amp;amp;gt; 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第二个示例正确地在两个线程上实现了并行化，输入如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;parallel-1 -&amp;amp;gt; 1
parallel-2 -&amp;amp;gt; 2
parallel-1 -&amp;amp;gt; 3
parallel-2 -&amp;amp;gt; 4
parallel-1 -&amp;amp;gt; 5
parallel-2 -&amp;amp;gt; 6
parallel-1 -&amp;amp;gt; 7
parallel-1 -&amp;amp;gt; 9
parallel-2 -&amp;amp;gt; 8
parallel-2 -&amp;amp;gt; 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果数据序列&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[^2]&lt;/a&gt;&lt;/sup&gt;已经在并行化处理，而你又想将其转回一个 “常规的” &lt;code&gt;Flux&lt;/code&gt; 实例，然后串行执行算子链余下的部分，则可以使用 &lt;code&gt;ParallelFlux&lt;/code&gt; 的 &lt;code&gt;sequential()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;注意：如果直接使用一个 &lt;code&gt;Subscriber&lt;/code&gt; 类型参数而不是 lambda 表达式来调用 &lt;code&gt;subscribe&lt;/code&gt; 方法，那么内部实现会隐式地调用 &lt;code&gt;sequential()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;由此也要注意：&lt;code&gt;subscribe(Subscriber&amp;lt;T&amp;gt;)&lt;/code&gt; 会合并所有数据“轨道”，而 &lt;code&gt;subscribe(Consumer&amp;lt;T&amp;gt;)&lt;/code&gt; 是运行所有的数据“轨道”。如果以 lambda 表达式调用 &lt;code&gt;subscribe&lt;/code&gt; 方法，那么每个 lambda 表达式都会被复制成多个实例（数量等于“轨道”数量）去执行&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot; role=&quot;doc-noteref&quot;&gt;[^3]&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;&lt;ol&gt;&lt;li id=&quot;fn:1&quot;&gt;&lt;p&gt;译注：这里的“轨道”其实不太直白。在实现上，&lt;code&gt;ParallelFlux&lt;/code&gt; 会将最后 &lt;code&gt;subscribe&lt;/code&gt; 的 onNext 回调按并行度（默认等于 CPU 核数 N）复制成 N 个，那么最终调用 ParallelFlux 的 N 个 Subscriber，从 ParallelFlux 实例到一个 Subscriber 的数据流路径可以理解为一个“轨道”，ParallelFlux 在接收到上游消息后按照 round-robin 方式选择一个 Subscriber 调用其 &lt;code&gt;onNext&lt;/code&gt; 下发消息，但 &lt;code&gt;onNext&lt;/code&gt; 是运行在什么线程上，是由 runOn 算子决定的，如果不使用 runOn 算子，那么所有 Subscriber 的 &lt;code&gt;onNext&lt;/code&gt; 方法调用都是同步运行在主线程上的。&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:2&quot;&gt;&lt;p&gt;译注：原文中用了多个词来表达相近的意思：sequence（序列）、stream（流）、flow（流），阅读时可以相互替代理解。此外，还有 event（事件）、data（数据）、message（消息），在当前上下文中，可以看成是等价的。&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn:3&quot;&gt;&lt;p&gt;译注：这话写得真蠢。详细解释见脚注 1。&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</description>
            <pubDate>2019-06-26</pubDate>
            <link>https://blog.xiayf.cn/posts/simplified-reactor-doc-zh.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/simplified-reactor-doc-zh.html</guid>
        </item>
        
        <item>
            <title>Java 单测伴侣 - mockito</title>
            <description>&lt;p&gt;其实工作以来，我很少写测试/单测代码，一方面是大部分互联网公司团队对测试的要求不高，另一方面是想写好测试代码还挺难的，挺花时间，其中最麻烦的是待测代码可能会访问外部资源（比如数据库、HTTP API），如果不能方便地进模拟访问这些外部资源，那么测试起来会非常麻烦。&lt;/p&gt;
&lt;p&gt;但，对于复杂逻辑，如果不经过严格测试，发布到生产环境，又有些不放心，没底气，或者在代码重构时，如果没有覆盖全面的测试，很难评估代码变动带来的影响。&lt;/p&gt;
&lt;p&gt;直到遇到 &lt;a href=&apos;https://site.mockito.org/&apos;&gt;mockito&lt;/a&gt;，我才觉得是时候认真写写测试代码了。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&apos;https://site.mockito.org/&apos;&gt;mockito&lt;/a&gt; 提供两种对象模拟方式：&lt;strong&gt;mock&lt;/strong&gt; 和 &lt;strong&gt;spy&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;简单来说，mock 模拟的对象是一个完全假的对象，只是具备指定类型的接口，以 &lt;code&gt;java.util.List&lt;/code&gt; 为例：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.mock;

List mockedList = mock(List.class);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;虽然 List 是一个 interface，也可以模拟出一个对象实例，这个 mockedList 对象具备 List 接口定义的所有方法，但所有方法都不具备实际的行为操作，对于有返回值的方法，则默认返回方法返回类型的默认值，没有返回值的方法，则纯粹是一个空方法。比如：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// mockedList 并不会真的把 1 存下来
mockedList.add(1);
// 所以，size() 返回默认值，输出 0
System.out.println(mockedList.size());
// 输出 null
System.out.println(mockedList.get(0));
// 输出 null
System.out.println(mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于模拟出来的对象，可以任意指定其方法的返回值，比如：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.when;

// 调用 size() 方法时，返回 10
when(mockedList.size()).willReturn(10);
when(mockedList.get(0)).willReturn(&amp;amp;quot;Hello World!&amp;amp;quot;);
when(mockedList.get(1)).thenReturn(&amp;amp;quot;您好！&amp;amp;quot;);

// 输出 10
System.out.println(mockedList.size());
// 输出 Hello World!
System.out.println(mockedList.get(0));
// 输出 您好！
System.out.println(mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然我们写测试代码时，并不会使用 System.out.println，然后看输出，而是使用&lt;strong&gt;断言&lt;/strong&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.junit.Assert.assertEquals;

assertEquals(10, mockedList.size());
assertEquals(&amp;amp;quot;Hello World!&amp;amp;quot;, mockedList.get(0));
assertEquals(&amp;amp;quot;您好！&amp;amp;quot;, mockedList.get(1));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;断言方法非常多，不仅仅只是 assertEquals。&lt;/p&gt;
&lt;p&gt;对于同一个方法，可以模拟多次调用返回不同的值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 会覆盖之前 mock 的行为：when(mockedList.size()).willReturn(10);
// 或者这么写：when(mockedList.size()).willReturn(0, -1, 10);
when(mockedList.size()).thenReturn(0).thenReturn(-1).thenReturn(10);
assertEquals(0, mockedList.size());
assertEquals(-1, mockedList.size());
assertEquals(10, mockedList.size());
// 第 3 次之后的 mockedList.size() 调用都返回 10
assertEquals(10, mockedList.size());

Iterator iterator = mock(Iterator.class);
// 或者这么写：when(iterator.next()).thenReturn(0, 1, 10, 1000);
when(iterator.next()).thenReturn(0).thenReturn(1).thenReturn(10).thenReturn(1000);
assertEquals(0, iterator.next());
assertEquals(1, iterator.next());
assertEquals(10, iterator.next());
assertEquals(1000, iterator.next());
// 第 4 次之后的 iterator.next() 调用都返回 1000
assertEquals(1000, iterator.next());&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;还可以模拟异常抛出：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List mockedList = mock(List.class);

when(mockedList.get(-1000)).thenThrow(new RuntimeException(&amp;amp;quot;参数异常！&amp;amp;quot;));
try {
    mockedList.get(-1000);
} catch (Exception e) {
    assertTrue(e instanceof RuntimeException);
    assertEquals(&amp;amp;quot;参数异常！&amp;amp;quot;, e.getMessage());
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以基于复杂的逻辑来构造返回值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.invocation.InvocationOnMock;
import org.mockito.stubbing.Answer;

List&amp;amp;lt;Integer&amp;amp;gt; mockedList = mock(List.class);
when(mockedList.get(anyInt())).thenAnswer(new EchoAnswer());

assertTrue(1 == mockedList.get(1));
assertTrue(10 == mockedList.get(10));

public class EchoAnswer implements Answer&amp;amp;lt;Integer&amp;amp;gt; {

    public Integer answer(InvocationOnMock var) {
        return var.getArgument(0);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了 &lt;code&gt;when(...).thenReturn(...)&lt;/code&gt; 风格的测试模拟方式，还有 BDD（Behavior Driven Development 行为驱动开发）风格的：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.BDDMockito.given;

// given
given(mockedList.get(0)).willReturn(100);
// when
int v = (int) mockedList.get(0);
// then
assertEquals(100, v);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果方法没有返回值，或者其它奇葩的需求，则没法使用 when.thenReturn / willReturn 这样的模拟方法，可以使用 &lt;code&gt;doReturn(...).when(...)...&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.doThrow;
import static org.mockito.Mockito.doReturn;

ArrayList mockedList = mock(ArrayList.class);
// clear 方法无返回值
doThrow(new RuntimeException(&amp;amp;quot;清除失败&amp;amp;quot;)).when(mockedList).clear();

try {
    mockedList.clear();
} catch (Exception e) {
    assertTrue(e instanceof RuntimeException);
    assertEquals(&amp;amp;quot;清除失败&amp;amp;quot;, e.getMessage());
}

// 没有意义，因为没法使用 断言 来验证，实际运行时会抛异常
doReturn(10).when(mockedList).clear();&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从示例代码可以看出，&lt;code&gt;doReturn(...).when(...)....&lt;/code&gt; 不会做类型校验，mockedList.clear() 返回值类型为 void，但我们模拟让其返回 10；所以，正常情况应该尽可能使用 &lt;code&gt;when(...).thenReturn(...)&lt;/code&gt; 或 &lt;code&gt;given(...).willReturn(...)&lt;/code&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;前述代码示例中，模拟方法的参数都做了硬编码，实际情况通常都不是这么测试，而是模拟方法的参数符合一定的要求即可，比如：在某个范围之内、符合类型的任何值：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.anyInt;

/*
以任何 int 类型的参数调用 mockedList.get 方法，都返回 100

如果写成 when(mockedList.get(0)).thenReturn(100)，则只有以 0 为参数调用 mockedList.get 方法，才会返回100，其他参数值，返回的都是默认值 0
*/
when(mockedList.get(anyInt())).thenReturn(100);

assertEquals(100, mockedList.get(0));
assertEquals(100, mockedList.get(1000));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可用的参数匹配器，见 org.mockito.ArgumentMatchers 类的静态方法列表，也可以自己实现 ArgumentMatcher 接口：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;package org.mockito;

public interface ArgumentMatcher&amp;amp;lt;T&amp;amp;gt; {
    boolean matches(T var1);
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.ArgumentMatcher;
import static org.mockito.Mockito.intThat;

when(mockedList.get(intThat(new LimitedInt()))).thenReturn(10);

assertEquals(null, mockedList.get(-1));
assertEquals(10, mockedList.get(1));
assertEquals(10, mockedList.get(99));
assertEquals(null, mockedList.get(100));

public class LimitedInt implements ArgumentMatcher&amp;amp;lt;Integer&amp;amp;gt; {

    public boolean matches(Integer var) {
        return var &amp;amp;gt; 0 &amp;amp;amp;&amp;amp;amp; var &amp;amp;lt; 100;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果被模拟的方法包含多个参数，那么这些参数要么全部使用匹配器，要么全部不使用。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;模拟某些类（A）的方法，通常会将 mock 出来的对象注入到依赖该类实例的其他类（B）中，来替代真实的依赖，这种方式的目的是为了测试类 B 的行为是否符合预期。&lt;/p&gt;
&lt;p&gt;另一个测试需求是，测试某个类 A&apos; 在某个上下文环境中的行为是否符合预期，比如： A&apos; 的某个方法是否被调用过、调用过几次、调用参数是否符合预期、几个方法之间的调用次序是否符合预期、方法调用耗时是否符合预期等等。&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.times;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.verifyZeroInteractions;

List mocked = mock(List.class);

Caller caller = new Caller();
caller.setList(mocked);

// 调用 0 次
caller.run(0);
// 验证是否从来没调用过 mocked.size()
verify(mocked, never()).size();
// 验证 没有和 mocked 产生过任何交互
// 因为 Caller.run 中调用了 list.isEmpty()，实际产生了交互，所以这行测试会失败
verifyZeroInteractions(mocked);

// 调用 10 次
caller.run(10);
// 验证是否调用 mocked.size() 10 次
verify(mocked, times(10)).size();

// 再调用一次
caller.run(1);
// 所以是 11 次了
verify(mocked, times(11)).size();

@Data
public class Caller {
    List list;

    public void run(int count) {
        for (int idx=0; idx &amp;amp;lt; count; idx++) {
            list.size();
        }
        //
        list.isEmpty();
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List mocked = mock(List.class);

mocked.add(1);
mocked.add(2);

verify(mocked).add(1);

// 是否有其他交互没有验证过？因为 mocked 还调用过 mocked.add(2)，所以这句测试会失败
verifyNoMoreInteractions(mocked);&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.InOrder;

// 也可以验证调用次序
List mocked1 = mock(List.class);
List mocked2 = mock(List.class);

mocked1.size();
mocked1.isEmpty();
mocked2.isEmpty();

// 会记录 mocked1、mocked2 中方法的调用/交互次序，要求：与 mocked1 的交互先于 mocked2
InOrder inOrder = inOrder(mocked1, mocked2);
// mocked1、mocked2 的交互顺序必须和 inOrder.verify 之间的顺序一致
inOrder.verify(mocked1).size();
inOrder.verify(mocked1).isEmpty();
inOrder.verify(mocked2).isEmpty();&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;也可以验证某个方法被调用时所使用的参数是否符合预期：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.mockito.ArgumentCaptor;

List mockedlist = mock(List.class);

Caller caller = new Caller();
caller.setList(mockedlist);
caller.run();

// 捕获 mockedList.add 的调用参数
ArgumentCaptor&amp;amp;lt;Integer&amp;amp;gt; argumentCaptor = ArgumentCaptor.forClass(Integer.class);
verify(mockedlist).add(argumentCaptor.capture());
assertTrue(100 == argumentCaptor.getValue());

@Data
public class Caller {
    List list;

    public void run() {
        list.add(100);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;前面的内容都是以 mock 为例，我们再来说说 spy，与 mock 的区别：&lt;/p&gt;
&lt;p&gt;mock 出来的对象是一个完全假的对象，但 spy 通常是基于一个具体的类或类实例，对其篡改某些方法，对于被篡改方法之外的方法，其行为都和调用真实对象的方法一样，不过并没有调用真实对象的方法，也不会对真实对象产生影响：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;// 基于一个实际的类实例
List&amp;amp;lt;Integer&amp;amp;gt; realList = new ArrayList&amp;amp;lt;&amp;amp;gt;(10);
List&amp;amp;lt;Integer&amp;amp;gt; spy = spy(realList);
        
spy.add(1);

// 被窃听的对象并没有发生变化
assertEquals(0, realList.size());
// 间谍对象确实将 1 存了下来
assertEquals(1, spy.size());
// 这句会抛出 java.lang.IndexOutOfBoundsException，因为 realList 还是为空
assertTrue(1 == realList.get(0));
assertTrue(1 == spy.get(0));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以基于一个具体的类来构造 spy，但这样无法使用带参数的构造方法，也无法指定类型参数：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;List&amp;amp;lt;Integer&amp;amp;gt; = spy(ArrayList.class);
assertEquals(0, spy.size());
spy.add(100);
assertEquals(1, spy.size());
assertTrue(100 == spy.get(0));

// 篡改方法
when(spy.size()).thenReturn(-1);
assertEquals(-1, spy.size());&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;实际上，mock 也可以基于具体的类来构造，这时可以指定某些方法实际调用具体类的方法。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;除了使用 mock、spy 方法来构造模拟对象，还可以通过注解来构造，但这样的话得指定 JUnit 的 Runner 为 &lt;code&gt;org.mockito.junit.MockitoJUnitRunner&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-java&quot;&gt;&lt;code&gt;import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.Mock;
import org.mockito.Spy;
import org.mockito.junit.MockitoJUnitRunner;

import java.util.ArrayList;
import java.util.List;

import static org.mockito.Mockito.when;
import static org.junit.Assert.assertTrue;

@RunWith(MockitoJUnitRunner.class)
public class testTester {

    @Mock
    private List&amp;amp;lt;Integer&amp;amp;gt; mocked;

    @Spy
    private ArrayList&amp;amp;lt;Integer&amp;amp;gt; spyed;

    @Test
    public void test() {
        when(mocked.isEmpty()).thenReturn(false);
        when(spyed.isEmpty()).thenReturn(false);

        assertTrue(!mocked.isEmpty());
        assertTrue(!spyed.isEmpty());

        mocked.add(0);
        spyed.add(0);

        assertTrue(0 == mocked.size());
        assertTrue(1 == spyed.size());
    }
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2019-06-17</pubDate>
            <link>https://blog.xiayf.cn/posts/mockito.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/mockito.html</guid>
        </item>
        
        <item>
            <title>《Python 编程之美》译者序</title>
            <description>&lt;p&gt;从毕业至今，在互联网行业从事软件研发工作，将近五年。这五年间，做过后端开发、前端开发、大数据处理等，使用过的编程语言包括：Python、PHP、Go、Java、JavaScript 等。&lt;/p&gt;
&lt;p&gt;虽说编程语言各异，但我使用它们来写各种项目的代码却一直坚持两点：代码可读性和自解释性/自文档性（self-documentation）。这很大程度上应该是受到 Python 语言设计哲学的影响 - 追求简单易读易懂的代码。&lt;/p&gt;
&lt;p&gt;很多人可能会认为这两点其实是一点 - 代码可读性，但我想做点区分：代码可读性突出对代码阅读者视觉上的影响，是否存在不必要的理解干扰，比如：必要的空行、变量定义与使用之间的距离、函数体/逻辑分支是否过长、逻辑表达是否直观等等。可读性高的代码通常都非常漂亮、赏心悦目。自解释性代码则更突出语义层面，比如：变量名称/函数名称/类名是否恰当、函数/方法/API 是否单一职责、工程目录结构/包/模块拆分是否符合“高内聚低耦合”原则等等。长期追求这两点，可以极大地提升个人，特别是团队的工作效率和工作质量。&lt;/p&gt;
&lt;p&gt;本书作者 Kenneth Reitz 于 2011 年发布 Requests 这个 HTTP 请求工具库，提出“for humans”的理念，强调软件/工具库应该对人类友好易用，这一理念本质上是对 Python 哲学（特别是上述两点）的一种引申和发扬。之后 Reitz 在一些 Python大会上做技术分享，宣扬“for humans”理念，对 Python 社区产生巨大影响。我在第一次用过 Requests 库之后，便很少使用 Python 标准库中的 urllib 和 urllib2，现在标准库文档中也特别建议开发者使用 Requests。&lt;/p&gt;
&lt;p&gt;因为对“for humans”理念的认同，也因为经常使用 Requests，所以当 Reitz 在 Github 上邀请我翻译 Requests 文档中文版时，我欣然接受，和另一个 Python 开发者共同翻译了 Requests 文档的首个官方中文翻译版。这“另一个 Python 开发者”也就是本书的另一个译者。&lt;/p&gt;
&lt;p&gt;在 Reitz 发起 “The Hitchhiker&apos;s Guide to Python!” 项目（也就是本书的社区开源版）后，我一直持续跟进阅读，收获巨大。后来得知这本开源书籍正式出版，欣喜若狂，辗转咨询多人，联系到刘皎老师 ，申请了本书的翻译工作。&lt;/p&gt;
&lt;p&gt;但是，后来发现翻译的工作量远远超出预估，除了个人的一些主观原因，主要因为本书内容的广度和深度：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;广度：本书由 Python 社区数百人共同创作而成，可以视作 Python 小百科全书。1-3章指导读者按照自己的需求选择安装配置 Python 版本/发行版、开发环境等。7-11章则针对不同的应用场景，从多个维度甄选对比了大量的 Python 库，读者可以“按图索骥”地做出自己的选择，从而节约大量的时间精力。因为译者的 Python 开发经验主要集中在 Web 开发和数据处理，对于很多应用场景下的 Python 库不太熟悉，所以翻译之前花费了大量时间来学习理解。&lt;/li&gt;
&lt;li&gt;深度：针对 Python 中手的核心需求，本书探讨了大量的最佳实践。其中4-5章通过大量示例具体地阐释了“Python 之禅”的句句箴言，如何编写高质量的 Python 代码，并精选若干高质量的知名 Python 开源项目，详细介绍如何通过阅读源码来提升编程技术水平。虽说 Python 社区几乎人人皆知“Python 之禅”，但如何落地到开发实践估计极少有人说得清楚。对照书中的实例阐释，译者几经调整推敲“Python 之禅”的译文，最终敲定的译文也不是特别令自己满意。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;相比原计划，本书最终延期近一年才得以翻译完成。除了歉意，我内心满是感谢：感谢邦杰中途友情加入，帮忙翻译了4-6章初稿，这三章的难度和长度都非常大；感谢编辑老师刘皎对我拖稿的次次容忍和耐心等待；感谢妻儿的理解，我对你们缺少了太多的陪伴。&lt;/p&gt;
&lt;p&gt;虽说我已尽自己所能地保证译文质量，但错误瑕疵难免，在此也请读者原谅。希望你们阅读愉快！&lt;/p&gt;
&lt;p&gt;至此，我如释重负。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;夏永锋&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;写于上海&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2018-04-01</pubDate>
            <link>https://blog.xiayf.cn/posts/the-python-guide.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-python-guide.html</guid>
        </item>
        
        <item>
            <title>《精通Python设计模式》译者序</title>
            <description>&lt;p&gt;在我读大学那几年，设计模式可谓火极一时，各大公司校招面试也几乎都会考设计模式，反观现在，则似乎很少有人聊设计模式的话题。是因为设计模式过时了吗？还是只是一个错误的概念？从个人这几年的开发经验来看，答案是否定的，设计模式并未过时，更不是一个错误的概念。从曾经的“红极一时”到如今的“门可罗雀”，只是说明软件开发行业以更加客观理性的态度来看待设计模式。软件开发领域的技术概念也似乎总是遵循这样的流行度变迁，最终一次又一次地证明不存在“银弹”。&lt;/p&gt;
&lt;p&gt;正确看待设计模式的前提是明白什么是设计模式。正如本书一开始就强调的：“设计模式的本质是在已有的方案之上发现更好的方案（而不是全新发明）”，这是一种务实的态度，设计模式并非是一种高大上或者神秘的东西，而是一些常见的软件工程设计问题的最佳实践方案。&lt;/p&gt;
&lt;p&gt;那么应该如何学习设计模式？个人认为软件开发技术的学习都应该以实践为前提，只有理解实践过程中遇到的种种问题，才能明白那些技术的本质和目的是什么，每种新技术都是因某个/某些问题而出现的，软件开发高手一般都反对新手一开始就一股脑地学习设计模式。有些新手学了点设计模式的理论后，甚至在软件开发过程中生搬硬套，结果是适得其反。因此，软件开发人员应该在积累了一定的开发经验，再系统地学习设计模式，效果往往也能事半功倍。&lt;/p&gt;
&lt;p&gt;现在有些积累一定开发经验的软件开发人员，在谈起设计模式时，一脸鄙夷。我想这也不是一种客观务实的态度。软件开发不是简单的累积代码，在实现业务功能的同时应该仔细考虑如何控制软件的复杂度。软件的复杂度分为两个层面：业务逻辑复杂度和代码实现复杂度。对同一个业务系统，不同的软件开发人员会有不同的实现，复杂度也不同，相应地实现的易理解性、可维护性、可扩展性也不同。软件开发人员应该不断学习如何控制软件的复杂度，学习并恰当地使用设计模式是应对软件复杂度的有效方法。&lt;/p&gt;
&lt;p&gt;然而，设计模式并非是固定不变的（如，《设计模式-可复用面向对象软件的基础》一书总结的23种模式），使用不同的编程语言来编写代码，需要学习的设计模式也不一样。一方面因为软件开发领域迅猛发展，一些新的软件工程问题也随之出现，另一方面则是新的语言新的平台会把一些常见设计模式吸收为内置特性。所以，软件开发人员因以实际问题为驱动，不断更新设计模式方面的知识。&lt;/p&gt;
&lt;p&gt;本书以Python编程语言为例，针对目前的软件开发领域，分三大类讲解了16种常用设计模式。使用Python语言编写示例代码，我认为作者主要是考虑到Python的抽象层次高、应用范围广，读者不会被一些实现细节的干扰，从而能快速直接地掌握模式的要领。&lt;/p&gt;
&lt;p&gt;全书始终保持务实的态度，列举了大量现实生活的例子和软件开发的例子，并为每个模式提供完整可运行的示例代码。虽然看起来在书中完整地给出所有示例代码，似乎没什么必要，但个人认为作者的用意是希望读者能动手照示例代码写一遍并运行起来看结果，实践为王，加强学习的效果。&lt;/p&gt;
&lt;p&gt;虽然是示例，作者还是坚持以地道的Python风格编写代码，以此说明不同语言不同平台要求软件开发人员学习的设计模式也有所不同。另外，开发人员也能从示例代码中学习到一些Python语言的高级特性，所以把本书当做Python开发进阶书籍也无不可。&lt;/p&gt;
&lt;p&gt;本书是个人正式翻译的第一本书。虽然以前翻译过很多文章，有些译文还有点影响，但毕竟与正式出版的有些不同，所以接手本书的翻译工作，我内心是有些忐忑的。我把翻译过程分为以下几个阶段进行：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;大致地预读一遍全书，整体上把握原书内容&lt;/li&gt;
&lt;li&gt;将原书翻译成初稿，此阶段基本保证译文的正确性&lt;/li&gt;
&lt;li&gt;通读审校初稿，此阶段确保译文的流畅性，以及用词和逻辑的一致性&lt;/li&gt;
&lt;li&gt;对着译稿，翻译相关图表中的单词；整理示例代码，并确保运行无误&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;希望通过这种方式基本保证译稿的质量。但因为个人精力有限能力不足，译稿中可能还是有些疏漏甚至错误之处，敬请原谅，也请将问题反馈给出版社，以便在下一版本中更正。&lt;/p&gt;
&lt;p&gt;另外，本书的示例代码已经存到Github的一个代码库（见&lt;a href=&apos;https://github.com/youngsterxyf/mpdp-code&apos;&gt;https://github.com/youngsterxyf/mpdp-code&lt;/a&gt;）中，如有需要，可下载。&lt;/p&gt;
&lt;p&gt;因个人私事，本书推延了一段时间才得以翻译完成，感谢图灵朱巍老师的体谅。译书是件费时费力的事情，感谢妻子郑荣的体谅和支持，也感谢公司领导贾磊和同事的支持，谢谢！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;夏永锋&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;于上海百度研发中心&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2016-07-01</pubDate>
            <link>https://blog.xiayf.cn/posts/mpdp.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/mpdp.html</guid>
        </item>
        
        <item>
            <title>Base64编码原理与应用</title>
            <description>&lt;p&gt;2015年，我们在青云平台上实现了“百度云观测”应用。青云应用本质上是一个iframe，在向iframe服务方发送的请求中会携带一些数据，青云平台会使用&lt;code&gt;Base64 URL&lt;/code&gt;对这些数据进行编码，其提供的编码解码算法示例如下：&lt;/p&gt;
&lt;pre class=&quot;language-php&quot;&gt;&lt;code&gt;// php版本
function base64_URL_encode($data) {
  return rtrim(strtr(base64_encode($data), &amp;amp;apos;+/&amp;amp;apos;, &amp;amp;apos;-_&amp;amp;apos;), &amp;amp;apos;=&amp;amp;apos;);
}
function base64_URL_decode($data) {
  return base64_decode(str_pad(strtr($data, &amp;amp;apos;-_&amp;amp;apos;, &amp;amp;apos;+/&amp;amp;apos;), 
                            strlen($data) % 4, &amp;amp;apos;=&amp;amp;apos;, STR_PAD_RIGHT));
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看出，&lt;code&gt;Base64 URL&lt;/code&gt; 是标准Base64编码的一个变种，分别用 &lt;code&gt;-&lt;/code&gt;、&lt;code&gt;_&lt;/code&gt; 替换标准Base64编码结果中的 &lt;code&gt;+&lt;/code&gt; 、 &lt;code&gt;/&lt;/code&gt; ，并删除结果最后的 &lt;code&gt;=&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;在实现 “百度云观测” 青云应用时，我在想：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为什么要使用Base64编码？&lt;/li&gt;
&lt;li&gt;Base64编码算法是什么样的？&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;本文是围绕这两个问题思考和实践的结果。&lt;/p&gt;
&lt;p&gt;我认为，理解Base64或其他类似编码的关键有两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;计算机最终存储和执行的是01二进制序列，这个二进制序列的含义则由解码程序/解释程序决定&lt;/li&gt;
&lt;li&gt;很多场景下的数据传输要求数据只能由简单通用的字符组成，比如HTTP协议要求请求的首行和请求头都必须是ASCII编码&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;以青云应用为例，简单解释这两点。青云平台通过POST一个表单来获取iframe，表单有 &lt;code&gt;payload&lt;/code&gt; 和 &lt;code&gt;signature&lt;/code&gt; 两项， &lt;code&gt;payload&lt;/code&gt; 原本是一个JSON对象，其中的键值可能包含一些特殊字符，比如 &lt;code&gt;&amp;amp;&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt; 等，由于青云设计的一种通用的请求交互方案，需要考虑iframe服务方服务器端的各种可能实现，有些服务器端实现没有考虑表单值有这些特殊字符，或者POST请求被中间服务器转换成GET请求再次发出，对于URL来说，&lt;code&gt;&amp;amp;&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt;都是具有特殊含义的字符，所以需要对请求数据进行特殊编码避免这些字符出现 - 数据发送方对数据按规则进行编码，接收方对应地按规则解码数据。&lt;/p&gt;
&lt;h2&gt;Base64编码原理&lt;/h2&gt;
&lt;p&gt;Base64编码之所以称为Base64，是因为其使用64个字符来对任意数据进行编码，同理有Base32、Base16编码。标准Base64编码使用的64个字符为：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/XHFMRvxfez4OVtr.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;这64个字符是各种字符编码（比如ASCII编码）所使用字符的子集，基本，并且可打印。唯一有点特殊的是最后两个字符，因对最后两个字符的选择不同，Base64编码又有很多变种，比如Base64 URL编码。&lt;/p&gt;
&lt;p&gt;Base64编码本质上是一种将二进制数据转成文本数据的方案。对于非二进制数据，是先将其转换成二进制形式，然后每连续6比特（2的6次方=64）计算其十进制值，根据该值在上面的索引表中找到对应的字符，最终得到一个文本字符串。&lt;/p&gt;
&lt;p&gt;假设我们要对 &lt;code&gt;Hello!&lt;/code&gt; 进行Base64编码，按照ASCII表，其转换过程如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/tJnClQsjc4WMGhB.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;可知 &lt;code&gt;Hello!&lt;/code&gt; 的Base64编码结果为 &lt;code&gt;SGVsbG8h&lt;/code&gt; ，原始字符串长度为6个字符，编码后长度为8个字符，每3个原始字符经Base64编码成4个字符，编码前后长度比4/3，这个长度比很重要 - 比原始字符串长度短，则需要使用更大的编码字符集，这并不我们想要的；长度比越大，则需要传输越多的字符，传输时间越长。Base64应用广泛的原因是在字符集大小与长度比之间取得一个较好的平衡，适用于各种场景。&lt;/p&gt;
&lt;p&gt;是不是觉得Base64编码原理很简单？&lt;/p&gt;
&lt;p&gt;但这里需要注意一个点：Base64编码是每3个原始字符编码成4个字符，如果原始字符串长度不能被3整除，那怎么办？使用0值来补充原始字符串。&lt;/p&gt;
&lt;p&gt;以 &lt;code&gt;Hello!!&lt;/code&gt; 为例，其转换过程为：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/5URB8nVis9ljwYe.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;&lt;em&gt;注：图表中蓝色背景的二进制0值是额外补充的。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Hello!!&lt;/code&gt; Base64编码的结果为 &lt;code&gt;SGVsbG8hIQAA&lt;/code&gt; 。最后2个零值只是为了Base64编码而补充的，在原始字符中并没有对应的字符，那么Base64编码结果中的最后两个字符 &lt;code&gt;AA&lt;/code&gt; 实际不带有效信息，所以需要特殊处理，以免解码错误。&lt;/p&gt;
&lt;p&gt;标准Base64编码通常用 &lt;code&gt;=&lt;/code&gt; 字符来替换最后的 &lt;code&gt;A&lt;/code&gt;，即编码结果为 &lt;code&gt;SGVsbG8hIQ==&lt;/code&gt;。因为 &lt;code&gt;=&lt;/code&gt; 字符并不在Base64编码索引表中，其意义在于结束符号，在Base64解码时遇到 &lt;code&gt;=&lt;/code&gt; 时即可知道一个Base64编码字符串结束。&lt;/p&gt;
&lt;p&gt;如果Base64编码字符串不会相互拼接再传输，那么最后的 &lt;code&gt;=&lt;/code&gt; 也可以省略，解码时如果发现Base64编码字符串长度不能被4整除，则先补充 &lt;code&gt;=&lt;/code&gt; 字符，再解码即可。&lt;/p&gt;
&lt;p&gt;为了理解Base64编码解码过程，个人实现了一个非常简陋的Base64编码解码程序，见：&lt;a href=&apos;https://github.com/youngsterxyf/xiaBase64&apos;&gt;youngsterxyf/xiaBase64&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;由于Base64应用广泛，所以很多编程语言的标准库都内置Base64编码解码包，如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;PHP：&lt;a href=&apos;http://php.net/manual/en/function.base64-encode.php&apos;&gt;base64_encode&lt;/a&gt;、&lt;a href=&apos;http://php.net/manual/en/function.base64-decode.php&apos;&gt;base64_decode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Python：&lt;a href=&apos;https://docs.python.org/2/library/base64.html&apos;&gt;base64包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go：&lt;a href=&apos;https://golang.org/pkg/encoding/base64/&apos;&gt;encoding/base64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;Base64编码应用&lt;/h2&gt;
&lt;p&gt;本文开始提到的青云应用例子只是Base64编码的应用场景之一。由于Base64编码在字符集大小与编码后数据长度之间做了较好的平衡，以及Base64编码变种形式的多样，使得Base64编码的应用场景非常广泛。下面举2个常用常见的例子。&lt;/p&gt;
&lt;h3&gt;HTML内嵌Base64编码图片&lt;/h3&gt;
&lt;p&gt;前端在实现页面时，对于一些简单图片，通常会选择将图片内容直接内嵌在页面中，避免不必要的外部资源加载，增大页面加载时间，但是图片数据是二进制数据，该怎么嵌入呢？&lt;a href=&apos;http://caniuse.com/#search=Data%20URI&apos;&gt;绝大多数现代浏览器&lt;/a&gt;都支持一种名为 &lt;code&gt;Data URLs&lt;/code&gt; 的特性，允许使用Base64对图片或其他文件的二进制数据进行编码，将其作为文本字符串嵌入网页中。以百度搜索首页为例，其中语音搜索的图标是个背景图片，其内容以 &lt;code&gt;Data URLs&lt;/code&gt; 形式直接写在css中，这个css内容又直接嵌在HTML页面中，如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/oa6rsPSwgMzv87l.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;&lt;code&gt;Data URLs&lt;/code&gt; 格式为：&lt;code&gt;url(data:文件类型;编码方式,编码后的文件内容)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;当然，也可以直接基于image标签嵌入图片，如下所示：&lt;/p&gt;
&lt;pre class=&quot;language-html&quot;&gt;&lt;code&gt;&amp;amp;lt;img alt=&amp;amp;quot;Embedded Image&amp;amp;quot; src=&amp;amp;quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIA...&amp;amp;quot; /&amp;amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但请注意：如果图片较大，图片的色彩层次比较丰富，则不适合使用这种方式，因为其Base64编码后的字符串非常大，会明显增大HTML页面，影响加载速度。&lt;/p&gt;
&lt;h3&gt;MIME（多用途互联网邮件扩展）&lt;/h3&gt;
&lt;p&gt;我们的电子邮件系统，一般是使用SMTP（简单邮件传输协议）将邮件从客户端发往服务器端，邮件客户端使用POP3（邮局协议，第3版本）或IMAP（交互邮件访问协议）从服务器端获取邮件。&lt;/p&gt;
&lt;p&gt;SMTP协议一开始是基于纯ASCII文本的，对于二进制文件（比如邮件附件中的图像、声音等）的处理并不好，所以后来新增MIME标准来编码二进制文件，使其能够通过SMTP协议传输。&lt;/p&gt;
&lt;p&gt;举例来说，我给自己发封邮件，正文为空，带一个名为hello.txt的附件，内容为 &lt;code&gt;您好！世界！&lt;/code&gt;。导出邮件源码，其关键部分如下图所示：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/c8wIeoij9HWt4Ph.jpg&apos; title=&apos;&apos; alt=&apos;&apos; width=&apos;600&apos;/&gt;
&lt;p&gt;&lt;code&gt;MIME-Version: 1.0&lt;/code&gt;：表示当前使用MIME标准1.0版本。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Content-Type: text/plain; name=&amp;quot;hello.txt&amp;quot;&lt;/code&gt;：表示附件文件名为 &lt;code&gt;hello.txt&lt;/code&gt; ，格式为纯文本。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Content-Transfer-Encoding: base64&lt;/code&gt;：表示附件文件内容使用base64编码后传输。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;5oKo5aW977yM5LiW55WM77yB&lt;/code&gt;：则是文件内容 &lt;code&gt;您好，世界！&lt;/code&gt; Base64编码后的结果。&lt;/p&gt;
&lt;p&gt;不过，MIME使用的不是标准Base64编码。&lt;/p&gt;
&lt;h2&gt;切忌误用&lt;/h2&gt;
&lt;p&gt;可能会有人在不理解Base64编码的情况下，将其误用于数据加密或数据校验。&lt;/p&gt;
&lt;p&gt;Base64是一种数据编码方式，目的是让数据符合传输协议的要求。标准Base64编码解码无需额外信息即完全可逆，即使你自己自定义字符集设计一种类Base64的编码方式用于数据加密，在多数场景下也较容易破解。&lt;/p&gt;
&lt;p&gt;对于数据加密应该使用专门的&lt;strong&gt;目前还没有有效方式快速破解的&lt;/strong&gt;加密算法。比如：对称加密算法&lt;code&gt;AES-128-CBC&lt;/code&gt;，对称加密需要密钥，只要密钥没有泄露，通常难以破解；也可以使用非对称加密算法，如 &lt;code&gt;RSA&lt;/code&gt;，利用极大整数因数分解的计算量极大这一特点，使得使用公钥加密的数据，只有使用私钥才能快速解密。&lt;/p&gt;
&lt;p&gt;对于数据校验，也应该使用专门的消息认证码生成算法，如 &lt;code&gt;HMAC&lt;/code&gt; - 一种使用单向散列函数构造消息认证码的方法，其过程是不可逆的、唯一确定的，并且使用密钥来生成认证码，其目的是防止数据在传输过程中被篡改或伪造。将原始数据与认证码一起传输，数据接收端将原始数据使用相同密钥和相同算法再次生成认证码，与原有认证码进行比对，校验数据的合法性。&lt;/p&gt;
&lt;p&gt;那么针对各大网站被脱库的问题，请问应该怎么存储用户的登录密码？&lt;/p&gt;
&lt;p&gt;答案是：在注册时，根据用户设置的登录密码，生成其消息认证码，然后存储用户名和消息认证码，不存储原始密码。每次用户登录时，根据登录密码，生成消息认证码，与数据库中存储的消息认证码进行比对，以确认是否为有效用户，这样即使网站被脱库，用户的原始密码也不会泄露，不会为用户使用的其他网站带来账号风险。&lt;/p&gt;
&lt;p&gt;当然，使用的消息认证码算法其哈希碰撞的概率应该极低才行，目前一般在HMAC算法中使用SHA256。对于这种方式需要注意一点：防止用户使用弱密码，否则也可能会被暴力破解。现在的网站一般要求用户密码6个字符以上，并且同时有数字和大小写字母，甚至要求有特殊字符。&lt;/p&gt;
&lt;p&gt;另外，也可以使用加入随机salt的哈希算法来存储校验用户密码。这里暂不细述。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;Base64兼顾字符集大小和编码后数据长度，并且可以灵活替换字符集的最后两个字符，以应对多样的需求，使其适用场景非常广泛。&lt;/p&gt;
&lt;p&gt;当然，很多场景下有多种编码方式可选择，并非Base64编码不可，视需求，权衡利弊而定。&lt;/p&gt;</description>
            <pubDate>2016-01-24</pubDate>
            <link>https://blog.xiayf.cn/posts/base64-encoding.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/base64-encoding.html</guid>
        </item>
        
        <item>
            <title>基于 Github 的 pull request 流程做开源贡献</title>
            <description>&lt;p&gt;最近给 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;beego&lt;/a&gt; 提了几个 pull request （简称PR），都已被接受。在使用pull request的过程中，遇到了一点小问题，才知以前并非真的理解这个流程，故在此做点记录整理。&lt;/p&gt;
&lt;p&gt;我以 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;beego&lt;/a&gt; 为例，将pull request的整体使用流程绘图如下：&lt;/p&gt;
&lt;img src=&apos;https://i.loli.net/2020/06/14/yFkLXVAHKxmwjq9.jpg&apos; title=&apos;fork-pull-request&apos; alt=&apos;fork-pull-request&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;beego代码库有两个长期分支 &lt;code&gt;master&lt;/code&gt; 和 &lt;code&gt;develop&lt;/code&gt;，&lt;code&gt;master&lt;/code&gt;为稳定分支，&lt;code&gt;develop&lt;/code&gt;为开发分支，所有PR都要求提交到 &lt;code&gt;develop&lt;/code&gt; 分支。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;先将 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 代码库 fork 一份到自己的名下（如我的 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; clone 到本地机器上做开发。因为PR要提到 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 develop 分支，所以最好对应地在你fork的代码库的 develop 分支做开发。在本地开发测试完成后，将commit push到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;在 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 页面点击 “New pull request”，会跳转到 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 创建一个新的PR，在页面中需要选择&lt;code&gt;base fork&lt;/code&gt;的目标分支（这里为 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 develop 分支）和&lt;code&gt;head fork&lt;/code&gt;的目标分支（这里为 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 develop 分支）。PR提交后，等待 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 代码库的协作者来review我的PR。&lt;/li&gt;
&lt;li&gt;如果其他人也给 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 提了PR（或者直接在 develop 上做了变更），我会把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 develop 分支同步到最新状态，便于我进行新的开发，同步的流程为：
&lt;ol&gt;&lt;li&gt;在本地代码库添加一个新的remote，名为 &lt;code&gt;beego&lt;/code&gt; ： &lt;code&gt;git remote add beego https://github.com/astaxie/beego.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在 &lt;code&gt;develop&lt;/code&gt; 分支上执行 &lt;code&gt;git pull beego develop&lt;/code&gt;，这会获取 &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; develop 分支最新的状态，并 merge 到本地代码库的 develop 分支&lt;/li&gt;
&lt;li&gt;将本地代码库的 develop 分支 push 到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; ：&lt;code&gt;git push origin develop&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;在发布新的版本时, &lt;a href=&apos;https://github.com/astaxie/beego&apos;&gt;astaxie/beego&lt;/a&gt; 的 &lt;code&gt;develop&lt;/code&gt; 分支会先 merge 到其 master 分支，然后打上新的 tag 。这时我也会把 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; 的 master 分支同步到最新状态，流程与 develop 分支相同。&lt;/li&gt;&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;在第3步中，如果发现&lt;code&gt;base fork&lt;/code&gt;的目标分支和&lt;code&gt;head fork&lt;/code&gt;的目标分支之间有代码冲突，则需要先在本地代码库对应的分支上解决这个冲突，然后 push 到 &lt;a href=&apos;https://github.com/youngsterxyf/beego&apos;&gt;youngsterxyf/beego&lt;/a&gt; ，再提PR。&lt;/p&gt;</description>
            <pubDate>2016-01-18</pubDate>
            <link>https://blog.xiayf.cn/posts/github-fork-pull-request.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/github-fork-pull-request.html</guid>
        </item>
        
        <item>
            <title>编程名言集锦（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://quotes.cat-v.org/programming/&apos;&gt;Programming Quotes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;译者：&lt;a href=&apos;https://github.com/youngsterxyf&apos;&gt;youngsterxyf&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;C.A.R. Hoare, The 1980 ACM Turing Award Lecture&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;There are two ways of constructing a software design: One way is to make it so simple that there are obviously no deficiencies and the other way is to make it so complicated that there are no obvious deficiencies.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;有两种软件设计的方式：一种是使它足够简单以致于明显没有缺陷，另一种则是使它足够复杂以致于没有明显的缺陷。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;E.W.Dijkstra&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The computing scientist&apos;s main challenge is not to get confused by the complexities of his own making.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;计算科学家的主要挑战是不要被他自己造成的复杂性搞糊涂了。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Gordon Bell&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The cheapest, fastest, and most reliable components are those that aren&apos;t there.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最廉价，最快速，并且最可靠的部件是那些还没被使用的。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://genius.cat-v.org/ken-thompson/&apos;&gt;Ken Thompson&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;One of my most productive days was throwing away 1000 lines of code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我最多产的一天抛弃了1000行代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://genius.cat-v.org/ken-thompson/&apos;&gt;Ken Thompson&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;When in doubt, use brute force.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;若无把握，暴力破解。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Jeff Sickel&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Deleted code is debugged code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;需要调试的代码都应该删除。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan, P. J. Plauger&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;调试的难度两倍于一开始的写代码。因此，如果你尽可能巧妙地编写代码，根据定义，说明你还不具备足够的智商来调试它。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The most effective debugging tool is still careful thought, coupled with judiciously placed print statements.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最有效的调试工具是静下心来仔细思考，辅之审慎地放置打印语句。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Brian W. Kernighan&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Controlling complexity is the essence of computer programming.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;计算机编程的本质是控制复杂度。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;David Gelernter&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Beauty is more important in computing than anywhere else in technology because software is so complicated. Beauty is the ultimate defence against complexity.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;相比其他技术领域，美对于计算来说更为重要，因为软件超乎寻常的复杂，而美是对复杂性的一种终极防御。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Doug Gwyn&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;UNIX was not designed to stop its users from doing stupid things, as that would also stop them from doing clever things.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;UNIX并不会阻止用户干蠢事，因为那样也会阻碍用户做些聪明的事情。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Carmack&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;If you&apos;re willing to restrict the flexibility of your approach, you can almost always do something better.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;限制方法的灵活性几乎总会让你把事情做得更好。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Osterhout&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;A program that produces incorrect result twice as fast is infinitely slower.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;结果不对，程序再快都顶个屁用。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Geer et al.&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The central enemy of reliability is complexity.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;可靠的最大敌人是复杂。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Edsger W. Dijkstra&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Simplicity is prerequisite for reliability.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;简单是可靠的先决条件。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Peter Deutsch&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The Eight Fallacies of Distributed Computing&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Essentially everyone, when they first build a distributed application, makes the following eight assumptions. All prove to be false in the long run and all cause big trouble and painful learning experiences.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;1. The network is reliable&lt;/p&gt;
&lt;p&gt;2. Latency is zero&lt;/p&gt;
&lt;p&gt;3. Bandwidth is infinite&lt;/p&gt;
&lt;p&gt;4. The network is secure&lt;/p&gt;
&lt;p&gt;5. Topology doesn&apos;t change&lt;/p&gt;
&lt;p&gt;6. There is one administrator&lt;/p&gt;
&lt;p&gt;7. Transport cost is zero&lt;/p&gt;
&lt;p&gt;8. The network is homogeneous&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;分布式计算的八大谬误&lt;/p&gt;
&lt;p&gt;实际上，每个人，当他第一次构建分布式应用时，都会作出如下八个假设。长远来看，这些假设都被证明是错误的，并且都造成了巨大的麻烦和沉痛的经验教训。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;网络可靠&lt;/li&gt;
&lt;li&gt;零延迟&lt;/li&gt;
&lt;li&gt;带宽无限&lt;/li&gt;
&lt;li&gt;安全网络&lt;/li&gt;
&lt;li&gt;拓扑不变&lt;/li&gt;
&lt;li&gt;有个管理者&lt;/li&gt;
&lt;li&gt;传输代价为零&lt;/li&gt;
&lt;li&gt;网络同构&lt;/li&gt;&lt;/ol&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Jon Bentley, Doug Mcllroy&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The key to performance is elegance, not battalions of special cases.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;性能的关键是优雅，而不是大堆的特殊情况。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Bill Gates&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Measuring programming progress by lines of code is like measuring aircraft building progress by weight.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;以代码行数来衡量程序设计的进度，就好比以重量来衡量飞机的制造进度。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;John Johnson&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;First, solve the problem. Then, write the code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;首先，解决问题。而后，编写代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Ken Thompson&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;You can&apos;t trust code that you did not totally create yourself.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;你不能信任非你完全自己写的代码。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Sean Parent&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Good code is short, simple, and symmetrical - the challenge is figuring out how to get there.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;好的代码，短小、简洁，并且匀称 - 而真正的挑战在于弄清如何达到这些目标。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Voltaire&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The best is the enemy of the good.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;追求完美是优秀软件的敌人。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Dr. Pamela Zave&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;The purpose of software engineering is to control complexity, not to create it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;软件工程的目标是控制复杂度，而不是增加复杂性。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Olin Shivers&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;I object to doing things that computers can do.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我反对去做那些计算机可以做的事情。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;merb motto&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;No code is faster than no code.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;没有什么代码会比没有代码速度更快。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Dave Parnas&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;As a rule, software systems do not work well until they have been used, and have failed repeatedly, in real applications.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;一般说来，软件系统只有得到实际应用，并且经历多次失败，才能工作得很好。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;RnRS&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;程序语言的设计不应该是特性的堆叠，而应该去除那些使得额外的特性显得必要的弱点和局限。&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Ryan Singer&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;So much complexity in software comes from trying to make one thing do two things.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;软件中如此多的复杂性皆来自于想在做一件事的同时多做几件事。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;未完待续&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2015-06-02</pubDate>
            <link>https://blog.xiayf.cn/posts/programming-quotes.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/programming-quotes.html</guid>
        </item>
        
        <item>
            <title>Go并发编程基础（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://www.nada.kth.se/~snilsson/concurrency/&apos;&gt;Fundamentals of concurrent programming&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;译注：原文章链接已失效，作者重新写了一篇内容相近的文章 &lt;a href=&apos;https://yourbasic.org/golang/concurrent-programming/&apos;&gt;Concurrent programming&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本文是一篇并发编程方面的入门文章，以&lt;a href=&apos;http://golang.org/&apos;&gt;Go语言&lt;/a&gt;编写示例代码，内容涵盖：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;运行期并发线程（goroutines）&lt;/li&gt;
&lt;li&gt;基本的同步技术（管道和锁）&lt;/li&gt;
&lt;li&gt;Go语言中基本的并发模式&lt;/li&gt;
&lt;li&gt;死锁和数据竞争&lt;/li&gt;
&lt;li&gt;并行计算&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;在开始阅读本文之前，你应该知道如何编写简单的Go程序。如果你熟悉的是C/C++、Java或Python之类的语言，那么 &lt;a href=&apos;http://tour.golang.org/welcome/1&apos;&gt;Go语言之旅&lt;/a&gt; 能提供所有必要的背景知识。也许你还有兴趣读一读 &lt;a href=&apos;http://code.google.com/p/go-wiki/wiki/GoForCPPProgrammers&apos;&gt;为C++程序员准备的Go语言教程&lt;/a&gt; 或 &lt;a href=&apos;http://www.nada.kth.se/~snilsson/go_for_java_programmers/&apos;&gt;为Java程序员准备的Go语言教程&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;1. 运行期线程&lt;/h3&gt;
&lt;p&gt;Go允许使用&lt;code&gt;go&lt;/code&gt;语句开启一个新的运行期线程，即 &lt;a href=&apos;http://golang.org/ref/spec#Go_statements&apos;&gt;goroutine&lt;/a&gt;，以一个不同的、新创建的goroutine来执行一个函数。同一个程序中的所有goroutine共享同一个地址空间。&lt;/p&gt;
&lt;p&gt;Goroutine非常轻量，除了为之分配的栈空间，其所占用的内存空间微乎其微。并且其栈空间在开始时非常小，之后随着堆存储空间的按需分配或释放而变化。内部实现上，goroutine会在多个操作系统线程上多路复用。如果一个goroutine阻塞了一个操作系统线程，例如：等待输入，这个线程上的其他goroutine就会迁移到其他线程，这样能继续运行。开发者并不需要关心/担心这些细节。&lt;/p&gt;
&lt;p&gt;下面所示程序会输出“Hello from main goroutine”。也可能会输出“Hello from another goroutine”，具体依赖于两个goroutine哪个先结束。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    go fmt.Println(&amp;amp;quot;Hello from another goroutine&amp;amp;quot;)
    fmt.Println(&amp;amp;quot;Hello from main goroutine&amp;amp;quot;)

    // 至此，程序运行结束，
    // 所有活跃的goroutine被杀死
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来的这个程序，多数情况下，会输出“Hello from main goroutine”和“Hello from another goroutine”，输出的顺序不确定。但还有另一个可能性是：第二个goroutine运行得极其慢，在程序结束之前都没来得及输出相应的消息。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    go fmt.Println(&amp;amp;quot;Hello from another goroutine&amp;amp;quot;)
    fmt.Println(&amp;amp;quot;Hello from main goroutine&amp;amp;quot;)

    time.Sleep(time.Second)        // 等待1秒，等另一个goroutine结束
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面则是一个相对更加实际的示例，其中定义了一个函数使用并发来推迟触发一个事件。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// 函数Publish在给定时间过期后打印text字符串到标准输出
// 该函数并不会阻塞而是立即返回
func Publish(text string, delay time.Duration) {
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
    }()    // 注意这里的括号。必须调用匿名函数
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你可能会这样使用&lt;code&gt;Publish&lt;/code&gt;函数：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    Publish(&amp;amp;quot;A goroutine starts a new thread of execution.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Let’s hope the news will published before I leave.&amp;amp;quot;)

    // 等待发布新闻
    time.Sleep(10 * time.Second)

    fmt.Println(&amp;amp;quot;Ten seconds later: I’m leaving now.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个程序，绝大多数情况下，会输出以下三行，顺序固定，每行输出之间相隔5秒。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run publish1.go
Let’s hope the news will published before I leave.
BREAKING NEWS: A goroutine starts a new thread of execution.
Ten seconds later: I’m leaving now.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一般来说，通过睡眠的方式来编排线程之间相互等待是不太可能的。下一章节会介绍Go语言中的一种同步机制 - 管道，并演示如何使用管道让一个goroutine等待另一个goroutine。&lt;/p&gt;
&lt;h3&gt;2. 管道（channel）&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/sushi-conveyor-belt.jpg&apos; title=&apos;Sushi conveyor belt&apos; alt=&apos;Sushi conveyor belt&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;&lt;a href=&apos;http://golang.org/ref/spec#Channel_types&apos;&gt;管道&lt;/a&gt;是Go语言的一个构件，提供一种机制用于两个goroutine之间通过传递一个指定类型的值来同步运行和通讯。操作符&lt;code&gt;&amp;lt;-&lt;/code&gt;用于指定管道的方向，发送或接收。如果未指定方向，则为双向管道。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;chan Sushi        // 可用来发送和接收Sushi类型的值
chan&amp;amp;lt;- float64    // 仅可用来发送float64类型的值
&amp;amp;lt;-chan int        // 仅可用来接收int类型的值&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;管道是引用类型，基于make函数来分配。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ic := make(chan int)    // 不带缓冲的int类型管道
wc := make(chan *Work, 10)    // 带缓冲的Work类型指针管道&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果通过管道发送一个值，则将&lt;code&gt;&amp;lt;-&lt;/code&gt;作为二元操作符使用。通过管道接收一个值，则将其作为一元操作符使用：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ic &amp;amp;lt;- 3        // 往管道发送3
work := &amp;amp;lt;-wc    // 从管道接收一个指向Work类型值的指针&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果管道不带缓冲，发送方会阻塞直到接收方从管道中接收了值。如果管道带缓冲，发送方则会阻塞直到发送的值被拷贝到缓冲区内；如果缓冲区已满，则意味着需要等待直到某个接收方获取到一个值。接收方在有值可以接收之前会一直阻塞。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关闭管道（Close）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;http://golang.org/ref/spec#Close&apos;&gt;close&lt;/a&gt; 函数标志着不会再往某个管道发送值。在调用&lt;code&gt;close&lt;/code&gt;之后，并且在之前发送的值都被接收后，接收操作会返回一个零值，不会阻塞。一个多返回值的接收操作会额外返回一个布尔值用来指示返回的值是否发送操作传递的。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;ch := make(chan string)
go func() {
    ch &amp;amp;lt;- &amp;amp;quot;Hello!&amp;amp;quot;
    close(ch)
}()
fmt.Println(&amp;amp;lt;-ch)    // 输出字符串&amp;amp;quot;Hello!&amp;amp;quot;
fmt.Println(&amp;amp;lt;-ch)    // 输出零值 - 空字符串&amp;amp;quot;&amp;amp;quot;，不会阻塞
fmt.Println(&amp;amp;lt;-ch)    // 再次打印输出空字符串&amp;amp;quot;&amp;amp;quot;
v, ok := &amp;amp;lt;-ch        // 变量v的值为空字符串&amp;amp;quot;&amp;amp;quot;，变量ok的值为false&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个带有&lt;code&gt;range&lt;/code&gt;子句的&lt;code&gt;for&lt;/code&gt;语句会依次读取发往管道的值，直到该管道关闭：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    // 译注：要想运行该示例，需要先定义类型Sushi，如type Sushi string
    var ch &amp;amp;lt;-chan Sushi = Producer()
    for s := range ch {
        fmt.Println(&amp;amp;quot;Consumed&amp;amp;quot;, s)
    }
}

func Producer() &amp;amp;lt;-chan Sushi {
    ch := make(chan Sushi)
    go func(){
        ch &amp;amp;lt;- Sushi(&amp;amp;quot;海老握り&amp;amp;quot;)    // Ebi nigiri
        ch &amp;amp;lt;- Sushi(&amp;amp;quot;鮪とろ握り&amp;amp;quot;) // Toro nigiri
        close(ch)
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;3. 同步&lt;/h3&gt;
&lt;p&gt;下一个示例中，我们让&lt;code&gt;Publish&lt;/code&gt;函数返回一个管道 - 用于在发布text变量值时广播一条消息：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// 在给定时间过期时，Publish函数会打印text变量值到标准输出
// 在text变量值发布后，该函数会关闭管道wait
func Publish(text string, delay time.Duration) (wait &amp;amp;lt;-chan struct{}) {
    ch := make(chan struct{})
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
        close(ch)    // 广播 - 一个关闭的管道都会发送一个零值
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：我们使用了一个空结构体的管道：&lt;code&gt;struct{}&lt;/code&gt;。这明确地指明该管道仅用于发信号，而不是传递数据。&lt;/p&gt;
&lt;p&gt;我们可能会这样使用这个函数：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    wait := Publish(&amp;amp;quot;Channels let goroutines communicate.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Waiting for the news...&amp;amp;quot;)
    &amp;amp;lt;-wait
    fmt.Println(&amp;amp;quot;The news is out, time to leave.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个程序会按指定的顺序输出以下三行内容。最后一行在新闻（news）一出就会立即输出。&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run publish2.go
Waiting for the news...
BREAKING NEWS: Channels let goroutines communicate.
The news is out, time to leave.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4. 死锁&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/traffic-jam.jpg&apos; title=&apos;traffic jam&apos; alt=&apos;traffic jam&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;现在我们在&lt;code&gt;Publish&lt;/code&gt;函数中引入一个bug：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func Publish(text string, delay time.Duration) (wait &amp;amp;lt;-chan struct{}) {
    ch := make(chan struct{})
    go func() {
        time.Sleep(delay)
        fmt.Println(&amp;amp;quot;BREAKING NEWS:&amp;amp;quot;, text)
        // 译注：注意这里将close函数调用注释掉了
        //close(ch)
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;主程序还是像之前一样开始运行：输出第一行，然后等待5秒，这时&lt;code&gt;Publish&lt;/code&gt;函数开启的goroutine会输出突发新闻（breaking news），然后退出，留下主goroutine独自等待。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    wait := Publish(&amp;amp;quot;Channels let goroutines communicate.&amp;amp;quot;, 5*time.Second)
    fmt.Println(&amp;amp;quot;Waiting for the news...&amp;amp;quot;)
    // 译注：注意下面这一句
    &amp;amp;lt;-wait
    fmt.Println(&amp;amp;quot;The news is out, time to leave.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此刻之后，程序无法再继续往下执行。众所周知，这种情形即为死锁。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;死锁是线程之间相互等待，其中任何一个都无法向前运行的情形。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Go语言对于运行时的死锁检测具备良好的支持。当没有任何goroutine能够往前执行的情形发生时，Go程序通常会提供详细的错误信息。以下就是我们的问题程序的输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;Waiting for the news...
BREAKING NEWS: Channels let goroutines communicate.
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan receive]:
main.main()
    .../goroutineStop.go:11 +0xf6

goroutine 2 [syscall]:
created by runtime.main
    .../go/src/pkg/runtime/proc.c:225

goroutine 4 [timer goroutine (idle)]:
created by addtimer
    .../go/src/pkg/runtime/ztime_linux_amd64.c:73&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大多数情况下找出Go程序中造成死锁的原因都比较容易，那么剩下的就是如何解决这个bug了。&lt;/p&gt;
&lt;h3&gt;5. 数据竞争（data race）&lt;/h3&gt;
&lt;p&gt;死锁也许听起来令人挺忧伤的，但伴随并发编程真正灾难性的错误其实是数据竞争，相当常见，也可能非常难于调试。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;当两个线程并发地访问同一个变量，并且其中至少一个访问是写操作时，数据竞争就发生了。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;下面的这个函数就有数据竞争问题，其行为是未定义的。例如，可能输出数值1。代码之后是一个可能性解释，试图搞清楚这一切是如何发生得。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func race() {
    wait := make(chan struct{})
    n := 0
    go func() {
        // 译注：注意下面这一行
        n++ // 一次访问: 读, 递增, 写
        close(wait)
    }()
    // 译注：注意下面这一行
    n++ // 另一次冲突的访问
    &amp;amp;lt;-wait
    fmt.Println(n) // 输出：未指定
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码中的两个goroutine（假设命名为&lt;code&gt;g1&lt;/code&gt;和&lt;code&gt;g2&lt;/code&gt;）参与了一次竞争，我们无法获知操作会以何种顺序发生。以下是诸多可能中的一种：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 从 &lt;code&gt;n&lt;/code&gt; 中获取值0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 从 &lt;code&gt;n&lt;/code&gt; 中获取值0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 将值从0增大到1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g1&lt;/code&gt; 将1写到 &lt;code&gt;n&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 将值从0增大到1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;g2&lt;/code&gt; 将1写到 &lt;code&gt;n&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;程序输出 n 的值，当前为1&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;“数据竞争（data race）”这名字有点误导的嫌疑。不仅操作的顺序是未定义的，其实根本没有任何保证（no guarantees whatsoever）。编译器和硬件为了得到更好的性能，经常都会对代码进行上下内外的顺序变换。如果你看到一个线程处于中间行为状态时，那么当时的场景可能就像下图所示的一样：&lt;/p&gt;
&lt;img src=&apos;https://yourbasic.org/golang/mid-action.jpg&apos; title=&apos;mid action&apos; alt=&apos;mid action&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;避免数据竞争的唯一方式是线程间同步访问所有的共享可变数据。有几种方式能够实现这一目标。Go语言中，通常是使用管道或者锁。（&lt;a href=&apos;http://golang.org/pkg/sync/&apos;&gt;sync&lt;/a&gt;和&lt;a href=&apos;http://golang.org/pkg/sync/atomic/&apos;&gt;sync/atomic&lt;/a&gt;包中还有更低层次的机制可供使用，但本文中不做讨论）。&lt;/p&gt;
&lt;p&gt;Go语言中，处理并发数据访问的推荐方式是使用管道从一个goroutine中往下一个goroutine传递实际的数据。有格言说得好：“不要通过共享内存来通讯，而是通过通讯来共享内存”。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func sharingIsCaring() {
    ch := make(chan int)
    go func() {
        n := 0 // 仅为一个goroutine可见的局部变量.
        n++
        ch &amp;amp;lt;- n // 数据从一个goroutine离开...
    }()
    n := &amp;amp;lt;-ch   // ...然后安全到达另一个goroutine.
    n++
    fmt.Println(n) // 输出: 2
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上代码中的管道肩负双重责任 - 从一个goroutine将数据传递到另一个goroutine，并且起到同步的作用：发送方goroutine会等待另一个goroutine接收数据，接收方goroutine也会等待另一个goroutine发送数据。&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;http://golang.org/ref/mem&apos;&gt;Go语言内存模型&lt;/a&gt; - 要保证一个goroutine中对一个变量的读操作得到的值正好是另一个goroutine中对同一个变量写操作产生的值，条件相当复杂，但goroutine之间只要通过管道来共享所有可变数据，那么就能远离数据竞争了。&lt;/p&gt;
&lt;h3&gt;6. 互斥锁&lt;/h3&gt;
&lt;img src=&apos;https://yourbasic.org/golang/lock.jpg&apos; title=&apos;lock&apos; alt=&apos;lock&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;有时，通过显式加锁，而不是使用管道，来同步数据访问，可能更加便捷。Go语言标准库为这一目的提供了一个互斥锁 - &lt;a href=&apos;http://golang.org/pkg/sync/#Mutex&apos;&gt;sync.Mutex&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;要想这类加锁起效的话，关键之处在于：所有对共享数据的访问，不管读写，仅当goroutine持有锁才能操作。一个goroutine出错就足以破坏掉一个程序，引入数据竞争。&lt;/p&gt;
&lt;p&gt;因此，应该设计一个自定义数据结构，具备明确的API，确保所有的同步都在数据结构内部完成。下例中，我们构建了一个安全、易于使用的并发数据结构，&lt;code&gt;AtomicInt&lt;/code&gt;，用于存储一个整型值。任意数量的goroutine都能通过&lt;code&gt;Add&lt;/code&gt;和&lt;code&gt;Value&lt;/code&gt;方法安全地访问这个数值。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// AtomicInt是一个并发数据结构，持有一个整数值
// 该数据结构的零值为0
type AtomicInt struct {
    mu sync.Mutex // 锁，一次仅能被一个goroutine持有。
    n  int
}

// Add方法作为一个原子操作将n加到AtomicInt
func (a *AtomicInt) Add(n int) {
    a.mu.Lock() // 等待锁释放，然后持有它
    a.n += n
    a.mu.Unlock() // 释放锁
}

// Value方法返回a的值
func (a *AtomicInt) Value() int {
    a.mu.Lock()
    n := a.n
    a.mu.Unlock()
    return n
}

func lockItUp() {
    wait := make(chan struct{})
    var n AtomicInt
    go func() {
        n.Add(1) // 一个访问
        close(wait)
    }()
    n.Add(1) // 另一个并发访问
    &amp;amp;lt;-wait
    fmt.Println(n.Value()) // 输出: 2
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;7. 检测数据竞争&lt;/h3&gt;
&lt;p&gt;竞争有时非常难于检测。下例中的这个函数有一个数据竞争问题，执行这个程序时会输出&lt;code&gt;55555&lt;/code&gt;。尝试一下，也许你会得到一个不同的结果。（&lt;a href=&apos;http://golang.org/pkg/sync/#WaitGroup&apos;&gt;sync.WaitGroup&lt;/a&gt;是Go语言标准库的一部分；用于等待一组goroutine结束运行。）&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func race() {
    var wg sync.WaitGroup
    wg.Add(5)
    // 译注：注意下面这行代码中的i++
    for i := 0; i &amp;amp;lt; 5; i++ {
        go func() {
            // 注意下一行代码会输出什么？为什么？
            fmt.Print(i) // 6个goroutine共享变量i
            wg.Done()
        }()
    }
    wg.Wait() // 等待所有（5个）goroutine运行结束
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于输出&lt;code&gt;55555&lt;/code&gt;，一个貌似合理的解释是：执行&lt;code&gt;i++&lt;/code&gt;的goroutine在其他goroutine执行打印语句之前就完成了5次&lt;code&gt;i++&lt;/code&gt;操作。实际上变量&lt;code&gt;i&lt;/code&gt;更新后的值为其他goroutine所见纯属巧合。&lt;/p&gt;
&lt;p&gt;一个简单的解决方案是：使用一个局部变量，然后当开启新的goroutine时，将数值作为参数传递：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func correct() {
    var wg sync.WaitGroup
    wg.Add(5)
    for i := 0; i &amp;amp;lt; 5; i++ {
        go func(n int) { // 使用局部变量
            fmt.Print(n)
            wg.Done()
        }(i)
    }
    wg.Wait()
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这次代码就对了，程序会输出期望的结果，如：&lt;code&gt;24031&lt;/code&gt;。注意：goroutine之间的运行顺序是不确定的。&lt;/p&gt;
&lt;p&gt;仍旧使用闭包，但能够避免数据竞争也是可能的，必须小心翼翼地让每个goroutine使用一个独有的变量。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func alsoCorrect() {
    var wg sync.WaitGroup
    wg.Add(5)
    for i := 0; i &amp;amp;lt; 5; i++ {
        n := i // 为每个闭包创建一个独有的变量
        go func() {
            fmt.Print(n)
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Println()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;数据竞争自动检测&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般来说，不太可能能够自动检测发现所有可能的数据竞争情况，但Go（从版本1.1开始）有一个强大的&lt;a href=&apos;http://tip.golang.org/doc/articles/race_detector.html&apos;&gt;数据竞争检测器&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;这个工具用起来也很简单：只要在使用&lt;code&gt;go&lt;/code&gt;命令时加上&lt;code&gt;-race&lt;/code&gt;标记即可。开启检测器运行上面的程序会给出清晰且信息量大的输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run -race raceClosure.go
Race:
==================
WARNING: DATA RACE
Read by goroutine 2:
    main.func·001()
      ../raceClosure.go:22 +0x65

Previous write by goroutine 0:
    main.race()
        ../raceClosure.go:20 +0x19b
    main.main()
        ../raceClosure.go:10 +0x29
    runtime.main()
        ../go/src/pkg/runtime/proc.c:248 +0x91

Goroutine 2 (running) created at:
    main.race()
      ../raceClosure.go:24 +0x18b
    main.main()
      ../raceClosure.go:10 +0x29
     runtime.main()
      ../go/src/pkg/runtime/proc.c:248 +0x91

==================
55555
Correct:
01234
Also correct:
01324
Found 1 data race(s)
exit status 66&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该工具发现一处数据竞争，包含：一个goroutine在第20行对一个变量进行写操作，跟着另一个goroutine在第22行对同一个变量进行了未同步的读操作。&lt;/p&gt;
&lt;p&gt;注意：竞争检测器只能发现在运行期确实发生的数据竞争（译注：我也不太理解这话，请指导）&lt;/p&gt;
&lt;h3&gt;8. Select语句&lt;/h3&gt;
&lt;p&gt;&lt;a href=&apos;http://golang.org/ref/spec#Select_statements&apos;&gt;select语句&lt;/a&gt;是Go语言并发工具集中的终极工具。select用于从一组可能的通讯中选择一个进一步处理。如果任意一个通讯都可以进一步处理，则从中随机选择一个，执行对应的语句。否则，如果又没有默认分支（default case），select语句则会阻塞，直到其中一个通讯完成。&lt;/p&gt;
&lt;p&gt;以下是一个玩具示例，演示&lt;code&gt;select&lt;/code&gt;语句如何用于实现一个随机数生成器：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;// RandomBits函数 返回一个管道，用于产生一个比特随机序列
func RandomBits() &amp;amp;lt;-chan int {
    ch := make(chan int)
    go func() {
        for {
            select {
            case ch &amp;amp;lt;- 0: // 注意：分支没有对应的处理语句
            case ch &amp;amp;lt;- 1:
            }
        }
    }()
    return ch
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面是相对更加实际一点的例子：如何使用select语句为一个操作设置一个时间限制。代码会输出变量news的值或者超时消息，具体依赖于两个接收语句哪个先执行：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;select {
case news := &amp;amp;lt;-NewsAgency:
    fmt.Println(news)
case &amp;amp;lt;-time.After(time.Minute):
    fmt.Println(&amp;amp;quot;Time out: no news in one minute.&amp;amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;函数 &lt;a href=&apos;http://golang.org/pkg/time/#After&apos;&gt;time.After&lt;/a&gt; 是Go语言标准库的一部分；它会在等待指定时间后将当前的时间发送到返回的管道中。&lt;/p&gt;
&lt;h3&gt;9. 综合所有示例&lt;/h3&gt;
&lt;p&gt;花点时间认真研究一下这个示例。如果你完全理解，也就对Go语言中并发的应用方式有了全面的掌握。&lt;/p&gt;
&lt;p&gt;这个程序演示了如何将管道用于被任意数量的goroutine发送和接收数据，也演示了如何将select语句用于从多个通讯中选择一个。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func main() {
    people := []string{&amp;amp;quot;Anna&amp;amp;quot;, &amp;amp;quot;Bob&amp;amp;quot;, &amp;amp;quot;Cody&amp;amp;quot;, &amp;amp;quot;Dave&amp;amp;quot;, &amp;amp;quot;Eva&amp;amp;quot;}
    match := make(chan string, 1) // 为一个未匹配的发送操作提供空间
    wg := new(sync.WaitGroup)
    wg.Add(len(people))
    for _, name := range people {
        go Seek(name, match, wg)
    }
    wg.Wait()
    select {
    case name := &amp;amp;lt;-match:
        fmt.Printf(&amp;amp;quot;No one received %s’s message.\n&amp;amp;quot;, name)
    default:
        // 没有待处理的发送操作
    }
}

// 函数Seek 发送一个name到match管道或从match管道接收一个peer，结束时通知wait group
func Seek(name string, match chan string, wg *sync.WaitGroup) {
    select {
    case peer := &amp;amp;lt;-match:
        fmt.Printf(&amp;amp;quot;%s sent a message to %s.\n&amp;amp;quot;, peer, name)
    case match &amp;amp;lt;- name:
        // 等待某个goroutine接收我的消息
    }
    wg.Done()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;示例输出：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ go run matching.go
Cody sent a message to Bob.
Anna sent a message to Eva.
No one received Dave’s message.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;10. 并行计算&lt;/h3&gt;
&lt;p&gt;并发的一个应用是将一个大的计算切分成一些工作单元，调度到不同的CPU上同时地计算。&lt;/p&gt;
&lt;p&gt;将计算分布到多个CPU上更多是一门艺术，而不是一门科学。以下是一些经验法则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个工作单元应该花费大约100微秒到1毫秒的时间用于计算。如果单元粒度太小，切分问题以及调度子问题的管理开销可能就会太大。如果单元粒度太大，整个计算也许不得不等待一个慢的工作项结束。这种缓慢可能因为多种原因而产生，比如：调度、其他进程的中断或者糟糕的内存布局。（注意：工作单元的数目是不依赖于CPU的数目的）&lt;/li&gt;
&lt;li&gt;尽可能减小共享的数据量。并发写操作的代价非常大，特别是如果goroutine运行在不同的CPU上。读操作之间的数据共享则通常不会是个问题。&lt;/li&gt;
&lt;li&gt;数据访问尽量利用良好的局部性。如果数据能保持在缓存中，数据加载和存储将会快得多得多，这对于写操作也格外地重要。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;下面的这个示例展示如何切分一个开销很大的计算并将其分布在所有可用的CPU上进行计算。先看一下有待优化的代码：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;type Vector []float64

// 函数Convolve 计算 w = u * v，其中 w[k] = Σ u[i]*v[j], i + j = k
// 先决条件：len(u) &amp;amp;gt; 0, len(v) &amp;amp;gt; 0
func Convolve(u, v Vector) (w Vector) {
    n := len(u) + len(v) - 1
    w = make(Vector, n)

    for k := 0; k &amp;amp;lt; n; k++ {
        w[k] = mul(u, v, k)
    }
    return
}

// 函数mul 返回 Σ u[i]*v[j], i + j = k.
func mul(u, v Vector, k int) (res float64) {
    n := min(k+1, len(u))
    j := min(k, len(v)-1)
    for i := k - j; i &amp;amp;lt; n; i, j = i+1, j-1 {
        res += u[i] * v[j]
    }
    return
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;思路很简单：确定合适大小的工作单元，然后在不同的goroutine中执行每个工作单元。以下是并发版本的 &lt;code&gt;Convolve&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func Convolve(u, v Vector) (w Vector) {
    n := len(u) + len(v) - 1
    w = make(Vector, n)

    // 将 w 切分成花费 ~100μs-1ms 用于计算的工作单元
    size := max(1, 1&amp;amp;lt;&amp;amp;lt;20/n)

    wg := new(sync.WaitGroup)
    wg.Add(1 + (n-1)/size)
    for i := 0; i &amp;amp;lt; n &amp;amp;amp;&amp;amp;amp; i &amp;amp;gt;= 0; i += size { // 整型溢出后 i &amp;amp;lt; 0
        j := i + size
        if j &amp;amp;gt; n || j &amp;amp;lt; 0 { // 整型溢出后 j &amp;amp;lt; 0
            j = n
        }

        // 这些goroutine共享内存，但是只读
        go func(i, j int) {
            for k := i; k &amp;amp;lt; j; k++ {
                w[k] = mul(u, v, k)
            }
            wg.Done()
        }(i, j)
    }
    wg.Wait()
    return
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;工作单元定义之后，通常情况下最好将调度工作交给运行时和操作系统。然而，对于 &lt;code&gt;Go 1.*&lt;/code&gt; 你也许需要告诉运行时希望多少个goroutine来同时地运行代码。&lt;/p&gt;
&lt;pre class=&quot;language-golang&quot;&gt;&lt;code&gt;func init() {
    numcpu := runtime.NumCPU()
    runtime.GOMAXPROCS(numcpu) // 尝试使用所有可用的CPU
}&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2015-05-20</pubDate>
            <link>https://blog.xiayf.cn/posts/fundamentals-of-concurrent-programming.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/fundamentals-of-concurrent-programming.html</guid>
        </item>
        
        <item>
            <title>又是一年</title>
            <description>&lt;p&gt;又是一年，依照惯例，得写一篇总结和计划。当然计划更多的只是一种自我鼓励，现实总是一次又一次地证明“计划赶不上变化”。&lt;/p&gt;
&lt;p&gt;我的2014，可能用三个关键词就能概括：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;结婚&lt;/li&gt;
&lt;li&gt;换工作&lt;/li&gt;
&lt;li&gt;众成技术聚乐部&lt;/li&gt;&lt;/ul&gt;
&lt;h3&gt;结婚&lt;/h3&gt;
&lt;p&gt;继13年领证，14年把婚礼也办了。由于两家离得远，婚礼也就分两次办。之间还补拍了婚纱照。虽然于我这些流程显得有点折腾，但重要的是大家都是很开心，也不希望老婆以后会有丁点遗憾。&lt;/p&gt;
&lt;p&gt;希望以后的日子总能努力让老婆开心幸福。&lt;/p&gt;
&lt;h3&gt;换工作&lt;/h3&gt;
&lt;p&gt;工作的时间并不长，本没想这么快换工作，何况我还是一个挺念旧的人。但还是那句话“计划赶不上变化”，不得已主动离职跳槽。&lt;/p&gt;
&lt;p&gt;对于目前的工作还比较满意，能做些自己喜欢做的事情，工作氛围也还不错。&lt;/p&gt;
&lt;p&gt;对于自己的要求就是踏踏实实做工作搞技术，不急不躁。&lt;/p&gt;
&lt;h3&gt;&lt;a href=&apos;http://happytechgroup.github.io/&apos;&gt;众成技术聚乐部&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;参加过各种大大小小的会议，总觉得水太多，但如果始终自己一个人蒙头研究技术，也有可能落得个“闭门造车”、“目光短浅”的下场，技术的“理”也是越辩越明，所以找了三五同学朋友搞起自己的技术沙龙，&lt;/p&gt;
&lt;p&gt;名为“众成技术聚乐部”，之所以为“众成”，是希望&lt;strong&gt;众人成就众人&lt;/strong&gt;，大家相互成就，之所以为“聚乐部”而不是“俱乐部”，是认为大家一起讨论分享技术应该是一件乐呵的事情，不要搞得那么严肃苦逼。&lt;/p&gt;
&lt;p&gt;聚乐部至今已搞了5次聚会，一个月一次，从我个人的角度来看，效果不错，虽然很多地方还有待改进。感谢所有成员的付出！&lt;/p&gt;
&lt;h3&gt;其他&lt;/h3&gt;
&lt;p&gt;技术上，相比上一年，有了些许进步 - 借着“众成”的技术分享，简单阅读了leveldb（Go语言版）的源码、Memcached源码等；为了把工作做得更好，又仔细地阅读了Yii框架源码，并写了&lt;a href=&apos;http://youngsterxyf.github.io/tag/yii.html&apos;&gt;系列文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在写博客一事上，2014年我也不算太偷懒，共写了26篇，虽然文章质量不咋地，远远未达到自己的要求，但一切贵在坚持，不是么？&lt;/p&gt;
&lt;p&gt;阅读方面，书目如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;淘宝技术这十年 （3星，成为大牛也是要看机遇的）&lt;/li&gt;
&lt;li&gt;Web容量规划的艺术 （4星）&lt;/li&gt;
&lt;li&gt;世界是数字的 （5星，计算机科普）&lt;/li&gt;
&lt;li&gt;三体（三册）（1、2册5星，第3册4星）&lt;/li&gt;
&lt;li&gt;20个月赚130亿 - YouTube创始人陈士骏自传 （4星，好吧，这翻译的书名真俗气，但其实是本挺不错的书）&lt;/li&gt;
&lt;li&gt;PHP精粹-编写高效PHP代码 （3星，仔细阅读了前半部分，快速浏览了后半部分）&lt;/li&gt;
&lt;li&gt;MacTalk - 人生元编程 (3星，电子书，大致过了一遍）&lt;/li&gt;
&lt;li&gt;编写高质量代码：改进Python程序的91个建议 （4星，需再读一遍）&lt;/li&gt;
&lt;li&gt;文明之光（两册，5星，有态度的浓缩的世界文明史）&lt;/li&gt;
&lt;li&gt;了不起的Node.js（2星，浏览了一遍）&lt;/li&gt;
&lt;li&gt;Pro Git （4星，Git资料中的No.1）&lt;/li&gt;
&lt;li&gt;演讲之禅：一位技术演讲家的自白 （4星，每个技术人都应该多演讲，所以推荐每个技术人都读一下这本书）&lt;/li&gt;
&lt;li&gt;高性能PHP应用开发 （3星）&lt;/li&gt;
&lt;li&gt;翻译漫谈：怎样翻译更地道 （4星，未读完）&lt;/li&gt;
&lt;li&gt;最璀璨的银河：刘慈欣经典作品集 （4星，读完三体，意犹未尽，故找来大刘的中短篇集读读）&lt;/li&gt;
&lt;li&gt;数据之巅 （5星，数据思维，有点震撼到我，推荐，需再读一遍）&lt;/li&gt;
&lt;li&gt;大型网站技术架构:核心原理与案例分析 (4星，虽然没什么新东西，但系统地科普了Web架构方面的东西，还是值得一读的)&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;从书目可以看出，技术相关的还是缺乏深度和专注。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;2015 ...&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;做好工作，多思考，多做实在的事情&lt;/li&gt;
&lt;li&gt;继续搞好众成技术聚乐部&lt;/li&gt;
&lt;li&gt;坚持写博客，向深度发展&lt;/li&gt;
&lt;li&gt;选择一两个优秀开源项目，读源码、写博客、做分享，旨在提高系统设计能力和编码能力&lt;/li&gt;
&lt;li&gt;读有想法、有深度的书&lt;/li&gt;
&lt;li&gt;考驾照 （别笑，哈哈）&lt;/li&gt;
&lt;li&gt;以讲师的身份参加一次技术会议&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;（额，“计划”本不该多说，但貌似还是说多了点...）&lt;/em&gt;&lt;/p&gt;</description>
            <pubDate>2015-01-03</pubDate>
            <link>https://blog.xiayf.cn/posts/the-2014-is-gone.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-2014-is-gone.html</guid>
        </item>
        
        <item>
            <title>面向分布式系统工程师的分布式系统理论（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer/&apos;&gt;Distributed systems theory for the distributed systems engineer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gwen Shapira，大腕级的解决方案架构师（SA），如今 Cloudera 的全职工程师，在&lt;a href=&apos;https://twitter.com/gwenshap/status/497203248332165121&apos;&gt; Twitter 上提的一个问题&lt;/a&gt;引起了我的思考。&lt;/p&gt;
&lt;p&gt;如果是以前，我可能会回答“嗯，这里有篇 FLP 论文，这里有篇 Paxos 论文，这里还有篇拜占庭将军问题的论文...”，我会罗列一箩筐重要的材料，如果你一头扎进去，至少花费 6 个月的时间才能过一遍这些材料。然而我已逐渐明白推荐大量的理论性的论文通常恰恰是着手学习分布式系统理论的错误方式（除非你在做一个 PhD 项目）。论文通常比较深入难懂，需要认真地研习，通常还需要&lt;em&gt;大量的时间投入（significant experience）&lt;/em&gt;来理清这些论文的重要贡献，以及在整个理论体系中的位置。要求工程师具备这样的专业水平又有多大的意义呢？&lt;/p&gt;
&lt;p&gt;但是，很遗憾，对分布式系统理论方面的重大研究成果和思想进行概括、归纳、背景分析的‘导引’性质的优秀材料非常缺乏；特别是没有居高临下态度的材料。对这块空白区域的思考让我想到了另一个有趣的问题：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;一个分布式系统工程师应该知道些什么分布式系统理论？&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在这种情况下，一知半解（a little theory）并不会是一件多危险的事情。因此我尝试整理一个列表，罗列出作为一个分布式系统工程师的我认为能够直接应用于我日常工作的一些基本概念；或者让分布式系统工程师完全有能力设计一个新系统的“筹码”。如果你认为我漏掉了一些东西，请联系我。&lt;/p&gt;
&lt;h4&gt;入门第一步&lt;/h4&gt;
&lt;p&gt;以下 4 篇材料出色地解释了构建分布式系统会遇到的一些挑战，共同概述了一系列分布式系统工程师必须要解决的技术上的难题，为之后章节中更深入的研究做好准备。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://book.mixu.net/distsys/&apos;&gt;好玩又实在的分布式系统理论&lt;/a&gt;是一本简短的书籍，其内容覆盖了分布式系统领域的一些基本议题，包括时间的作用及不同的复制策略。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/&apos;&gt;为分布式系统领域新人整理的笔记&lt;/a&gt; - 不是理论对理论地讲述，而是做一个非常好非常实用的平衡，让你对其余材料的阅读能够落地。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628&apos;&gt;分布式系统研究综述报告&lt;/a&gt; - 一篇经典的论文，解释了为什么不能将所有远程交互都模拟成和本地对象一样。&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing&apos;&gt;关于分布式计算的若干谬论&lt;/a&gt; - 分布式计算方面的8点谬论，提醒系统设计者可能会忘记的几类事情。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;失败和时间&lt;/h4&gt;
&lt;p&gt;分布式系统工程师需要面对的许多困难最终都可以归咎于两个潜在的原因：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;进程可能会失败&lt;/li&gt;
&lt;li&gt;不存在一种好的方式来周知目前为止进程已经做了些什么&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;进程之间对于&lt;em&gt;时间&lt;/em&gt;的认知能共享些什么？哪些失败的场景是能够检测到？什么算法和原语可能被正确地实现？这三个问题有着非常深层的联系。多数时候，我们会假设两个不同节点之间对于时间概念或时间以什么样的速度逝去没有任何可共享的认知。&lt;/p&gt;
&lt;p&gt;你应该知道：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;失败模式的（部分）分层：&lt;a href=&apos;http://www.cse.psu.edu/~gcao/teach/513-00/c7.pdf&apos;&gt;崩溃停止-&gt;排除（omission）&lt;/a&gt;-&gt;&lt;a href=&apos;http://en.wikipedia.org/wiki/Byzantine_fault_tolerance&apos;&gt;拜占庭容错&lt;/a&gt;。你应该理解：在高层次上可能发生的问题在低层次上肯定可能发生，在低层次上不可能发生的问题在高层次上也肯定不可能发生。&lt;/li&gt;
&lt;li&gt;在没有任何共享时钟的情况下如何判断在另一个事件之前是否产生了某事件。这意味着你需要理解 &lt;a href=&apos;http://web.stanford.edu/class/cs240/readings/lamport.pdf&apos;&gt;Lamport 时钟&lt;/a&gt;及其一般化的&lt;a href=&apos;http://en.wikipedia.org/wiki/Vector_clock&apos;&gt;向量时钟&lt;/a&gt;，也需要阅读一下&lt;a href=&apos;http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&apos;&gt;这篇 Dynamo 论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;单个失败发生的可能性对于我们实现正确的分布式系统到底会有多大的影响（请阅读下面关于 FLP 结果的笔记）？&lt;/li&gt;
&lt;li&gt;不同的时间模型：同步、部分同步和异步（若我找到好的参考文献会添加链接）&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;容错的基本矛盾&lt;/h4&gt;
&lt;p&gt;一个系统，若要不降级而容忍某些错误的发生，就必须能够好像那些错误没有发生一样地运作。这通常意味着系统的这些部分必须能够冗余地工作，但是非绝对必要地做更多的工作通常会在性能和资源耗用方面产生一些消耗。这是为系统添加容错带来的基本矛盾。&lt;/p&gt;
&lt;p&gt;你应该知道：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;确保单拷贝可串行化（single-copy serialisability）的仲裁（quorum）技术。可阅读 &lt;a href=&apos;https://ecommons.library.cornell.edu/bitstream/1813/6323/1/82-483.pdf&apos;&gt;Skeen 的原始论文&lt;/a&gt;，但可能更建议阅读&lt;a href=&apos;http://en.wikipedia.org/wiki/Quorum_(distributed_computing&apos;&gt;这个 Wikipedia 词条&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;关于&lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit/&apos;&gt;两阶段提交&lt;/a&gt;、&lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-three-phase-commit/&apos;&gt;三阶段提交&lt;/a&gt;和 &lt;a href=&apos;http://the-paper-trail.org/blog/consensus-protocols-paxos/&apos;&gt;Paxos&lt;/a&gt; 算法，以及为什么它们有不同的容错性质。&lt;/li&gt;
&lt;li&gt;最终一致性，及其他技术是如何以弱化对系统行为的保证为代价来尝试避免这种矛盾的。这篇 &lt;a href=&apos;http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&apos;&gt;Dynamo 论文&lt;/a&gt;是一个很好的起点，同时 Pat Helland 的经典之作 &lt;a href=&apos;http://www.ics.uci.edu/~cs223/papers/cidr07p15.pdf&apos;&gt;Life Beyond Transactions&lt;/a&gt; 也是必读的。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;基本的原语&lt;/h4&gt;
&lt;p&gt;分布式系统中很少有大家一致认同的基本构建块，但越来越多地在出现。你应该以下的问题是什么，以及在哪可以找到它们的解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;群首选举（leader election）（例如 &lt;a href=&apos;http://en.wikipedia.org/wiki/Bully_algorithm&apos;&gt;Bully 算法&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;一致的快照（例如 Chandy 和 Lamport 所写的&lt;a href=&apos;http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf&apos;&gt;经典论文&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;共识（阅读上文提到的关于 2PC 和 Paxos 的博文）&lt;/li&gt;
&lt;li&gt;分布式状态机复制（看看 &lt;a href=&apos;http://en.wikipedia.org/wiki/State_machine_replication&apos;&gt;Wikipedia&lt;/a&gt; 就可以，但 &lt;a href=&apos;http://research.microsoft.com/en-us/um/people/blampson/58-Consensus/Acrobat.pdf&apos;&gt;Lampson 的论文&lt;/a&gt;更权威，只是枯燥了点）。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;基础结论&lt;/h4&gt;
&lt;p&gt;某些客观事实是需要内化于心的，以下是几个关键点（a flavour）（当然还有更多）：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果进程之间可能丢失某些消息，那么不可能在实现一致性存储的同时能响应所有的请求。这就是 &lt;a href=&apos;http://lpd.epfl.ch/sgilbert/pubs/BrewersConjecture-SigAct.pdf&apos;&gt;CAP 定理&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;以这样一种方式（a.始终是正确的、b.始终能终止-若在一个可能因失败崩溃停止（crash-&lt;code&gt;*&lt;/code&gt; stop failures）的异步系统中有（甚至仅）一台机器失效时（FLP 的结果））。我希望在&lt;a href=&apos;http://www.slideshare.net/HenryRobinson/pwl-nonotes&apos;&gt;洛杉矶题为 Papers We Love 报告&lt;/a&gt;的第一部分幻灯片-进行证明之前-已经合理地解释了这个结论。&lt;em&gt;建议：没有实际的必要理解这个证明。&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;一般而言，消息交互少于两轮是不可能达成共识（Consensus）。&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;真实系统&lt;/h4&gt;
&lt;p&gt;最重要的练习是重复地阅读新兴的、真实系统的描述，并尝试评价它们的设计决策。一遍又一遍地这样去做。一些建议：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/gfs-sosp2003.pdf&apos;&gt;GFS&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/spanner-osdi2012.pdf&apos;&gt;Spanner&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41344.pdf&apos;&gt;F1&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/chubby-osdi06.pdf&apos;&gt;Chubby&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/archive/bigtable-osdi06.pdf&apos;&gt;BigTable&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41378.pdf&apos;&gt;MillWheel&lt;/a&gt;、&lt;a href=&apos;http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Schwarzkopf.pdf&apos;&gt;Omega&lt;/a&gt;、&lt;a href=&apos;http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/36356.pdf&apos;&gt;Dapper&lt;/a&gt;、&lt;a href=&apos;http://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf&apos;&gt;Paxos Made Live&lt;/a&gt;、&lt;a href=&apos;http://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/abstract&apos;&gt;The Tail At Scale&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Not Google:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&apos;http://research.microsoft.com/en-us/projects/dryad/eurosys07.pdf&apos;&gt;Dryad&lt;/a&gt;、&lt;a href=&apos;https://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf&apos;&gt;Cassandra&lt;/a&gt;、&lt;a href=&apos;http://ceph.com/papers/weil-ceph-osdi06.pdf&apos;&gt;Ceph&lt;/a&gt;、&lt;a href=&apos;https://ramcloud.stanford.edu/wiki/display/ramcloud/RAMCloud+Papers&apos;&gt;RAMCloud&lt;/a&gt;、&lt;a href=&apos;http://hyperdex.org/papers/&apos;&gt;HyperDex&lt;/a&gt;、&lt;a href=&apos;http://www.mpi-sws.org/~druschel/courses/ds/papers/cooper-pnuts.pdf&apos;&gt;PNUTS&lt;/a&gt;&lt;/p&gt;</description>
            <pubDate>2014-08-10</pubDate>
            <link>https://blog.xiayf.cn/posts/ds-4-dse.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/ds-4-dse.html</guid>
        </item>
        
        <item>
            <title>仓库作业机器监控系统设计与实现</title>
            <description>&lt;p&gt;近期在参与一个仓库作业机器监控项目。该项目的需求背景是：公司的电商业务在全国各地有多处或大或小的仓库，仓库的作业人员（没有IT技术背景）经常反馈/投诉作业机器断网、断电、连不了服务等问题。实际情况经常与反馈的不一致，但运维侧并没有数据可以证明，所以才有了这个项目的需求。&lt;/p&gt;
&lt;p&gt;该项目第一期的目标仅是&lt;em&gt;收集、展示作业机器某些监控指标数据，以便在快速定位解决问题，或至少有数据可查&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;为了避免大量监控数据上报影响到生产系统的网络服务，系统采用如下结构：&lt;/p&gt;
&lt;img src=&apos;../assets/inner_warehouse_monitor.png&apos; title=&apos;inner_warehouse_monitor&apos; alt=&apos;inner_warehouse_monitor&apos; width=&apos;600&apos;/&gt;
&lt;ol&gt;&lt;li&gt;实现一个 agent 用于在仓库作业 PC 或作业 PDA 上获取机器的监控数据；&lt;/li&gt;
&lt;li&gt;在仓库本地服务器上实现一个数据收集处理服务，提供 API 给 agent 上传监控数据；数据收集处理服务会将接收到的数据持久化到数据库，提供给仓库本地服务器上的 webApp 进行数据展示等；&lt;/li&gt;
&lt;li&gt;中心服务器可以调用各个仓库本地服务器上的 webApp 提供的数据查询接口（数据用于定位、发现问题）；定期按需对各个仓库本地服务器上的数据进行归档。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;这样，主要的工作都集中在&lt;strong&gt;作业机器上的 agent&lt;/strong&gt; 和&lt;strong&gt;数据收集处理服务、webApp&lt;/strong&gt;。这其中最关键的又是&lt;strong&gt;数据收集处理服务&lt;/strong&gt;。考虑到需要多地部署运维仓库本地服务器，而且某些大仓库作业机器的数目目前已多达800-1000，我们做了如下技术选型：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Golang 实现 agent、数据收集处理服务、webApp；&lt;/li&gt;
&lt;li&gt;以 SQLite 作为数据库来存储agent上报的所有数据；&lt;/li&gt;
&lt;li&gt;以 &lt;a href=&apos;http://bitly.github.io/nsq/&apos;&gt;NSQ&lt;/a&gt; 作为异步消息队列中间件；&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;选用 Golang 的理由是：可以静态编译，部署简单，只需将编译好的可执行二进制程序丢到服务器上跑起来就可以了。&lt;/p&gt;
&lt;p&gt;选用 SQLite 的理由是：不必像 MySQL 那样安装 server 程序，无需额外部署维护。当然 SQLite 的文件锁会大大影响数据库读写性能，我们通过尽可能拆分数据库，将不同的指标数据存储在不同的 SQLite DB 文件中，甚至将每台作业机器每个指标的每天的数据分别存储在不同的 DB 文件中，来尽可能减小文件锁的性能影响，目前看来效果还不错。&lt;/p&gt;
&lt;p&gt;选择 NSQ 的理由是：Golang 实现、分布式、伸缩性好、性能高、支持 HTTP/TCP 协议、自带web管理界面等。&lt;/p&gt;
&lt;p&gt;详细的系统结构图如下所示：&lt;/p&gt;
&lt;img src=&apos;../assets/inner_warehouse_monitor-arch.png&apos; title=&apos;inner_warehouse_monitor-arch&apos; alt=&apos;inner_warehouse_monitor-arch&apos; width=&apos;600&apos;/&gt;
&lt;p&gt;NSQ 支持多 topic（不同 topic 的数据不同），topic 又可以有多个 channel（同一个 topic 的所有channel中的数据相同，以多播的方式实现，每个 channel 在 client 中有一个对应的处理流程来处理 channel 中的数据）。我们将作业机器不同的监控指标数据作为不同 topic 传入 NSQ，多数指标数据只需持久化到数据库以备后用，所以这些 topic 仅需一个 channel。&lt;/p&gt;
&lt;p&gt;webApp 基于 Beego 框架实现，避免重复造轮子、工作量小。webApp中的数据展示采用 HighCharts、Raphael 实现，兼容性好。&lt;/p&gt;
&lt;p&gt;对于机器指标数据，其实不应该使用关系型数据库来存储，因为这种数据的特点是：写入之后只读不改、时间序列的、几乎没有关系型的读取操作、连续批量数据读取，所以开源监控系统如 Cacti、Ganglia 等均使用 RRDtool 来读写指标数据。所以如上所述，我们将指标数据的存储尽可能地拆分成多个文件以提高读写性能而不会造成其他问题。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;系统的工作流程如下所述：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;作业机器上的 agent 启动后会先向 NSQ 的 register topic 发送一个注册消息，NSQ Client 根据该注册消息在 register 数据表中将该作业机器的状态改为“正常运行中”；&lt;/li&gt;
&lt;li&gt;然后，agent 定期上报监控数据到 NSQ，NSQ Client 中各种数据的处理流程将数据持久化到 SQLite 数据库文件；&lt;/li&gt;
&lt;li&gt;用户访问/中心服务器调用API时，webApp 读取 SQLite 数据库；&lt;/li&gt;
&lt;li&gt;有一个 Goroutine 针对注册过的作业机器定期检测3分钟以内是否收到过其上报的心跳数据，若未收到，则将机器状态从“正常运行中”改成“运行异常”，若收到，则将“运行异常”改为“正常运行中”；&lt;/li&gt;
&lt;li&gt;作业机器在正常关机时会向 NSQ 的 register topic 发送一个正常关机的消息，Client 读取到该消息后，会将该机器在 register 数据表中的状态改为“已正常关机”。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;目前，系统工作良好。之后会对系统做压测，如果出现瓶颈，估计可能还是数据存储，这样的话我们可能会尝试 RRDtool 或 &lt;a href=&apos;http://influxdb.org/&apos;&gt;InfluxDB&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-11-29</pubDate>
            <link>https://blog.xiayf.cn/posts/inner-warehouse-monitor-system.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/inner-warehouse-monitor-system.html</guid>
        </item>
        
        <item>
            <title>读书笔记：Just For Fun - The Story of an Accidental Revolutionary</title>
            <description>&lt;p&gt;前些天偶然在图灵社区上看到&lt;a href=&apos;http://www.ituring.com.cn/book/1115?q=%E8%B6%8A%E7%8E%A9%E8%B6%8A%E5%A4%A7&apos;&gt;这本书的出版计划&lt;/a&gt;，才猛然想起之前看过一两个章节，遂再次找到该书的&lt;a href=&apos;http://ishare.iask.sina.com.cn/f/14439267.html&apos;&gt;中文电子版&lt;/a&gt;（&lt;em&gt;原谅我&lt;/em&gt;）（关于该电子版，我不清楚其来源。中国青年出版社出过该书的中文版，译名为《乐者为王》，不知该电子版即为该中文版，还是开源爱好者自己翻译。不过翻译质量不高，应该不是正式出版的），花了一天左右时间看完。&lt;/p&gt;
&lt;p&gt;本书由 Linus Torvalds 和 David Diamond 合著，书写方式是 Linus 自述，穿插 David Diamond 的一些采访旁白，主要讲述 Linus 如何偶然地成为信息时代的一个革命者（The Story of an Accidental Revolutionary）。Linus 在书中表达了对 Linux 这一伟大的开源项目的看法、对于人生意义、事物发展规律等问题的个人理解。以下是书中让我印象比较深刻的几处内容：&lt;/p&gt;
&lt;h2&gt;生活的意义&lt;/h2&gt;
&lt;p&gt;对于这一哲学性的问题，估计现在很多人见到都会发笑。本书以这个问题的讨论开始，并以这个问题结尾。Linus并没有直接地回答，而是举例说明人类社会的事物发展都必然经过三个阶段---生存、社会秩序、娱乐，那么生活的意义就是促成这一发展过程：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;李纳斯：这个答案基本上简单而漂亮。 它不会给你的生活以任何意义，但可以告诉你将发生什么。&lt;/p&gt;
&lt;p&gt;有三件事具有生命的意义。它们是你生活当中所有事情的动机，包括你所做的任何事情和一个生命体该做的所有事情。&lt;/p&gt;
&lt;p&gt;第一是生存，第二是社会秩序，第三是娱乐。生活中所有的事情都是按这个顺序发展的。娱乐之后便一无所的。&lt;/p&gt;
&lt;p&gt;因此从某种意义上说，这意味着生活的意义就是要达到第三个阶段。你一旦达到了第三个阶段，就算成功了。但首先要越过前两个阶段。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我认为这一理解是非常漂亮的。对于该问题（我为什么而活？），以前我也思考了很多，但最后的答案竟然是---活着本来就是没有意义的，一切意义都是人为地赋予。答案很悲观，Linus 的答案本质上也是如此，只不过避免了直接面对该问题，以顺从事物发展规律作为生活的意义，对我有所启发，也让我多了些生活的“正能量”。&lt;/p&gt;
&lt;p&gt;对于未来的预言，特别是计算机行业的发展，Linus 同样并没有直接回答问题，同样地以此作为回答：人们并不是真的需要计算机（包含网络等等），而是需要基于计算机实现生存、社会秩序、娱乐三个目标，那么未来的一切、计算机行业的发展必然是更好地帮助人们实现这三个目标。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;关于娱乐，有本书《娱乐至死》表达了对人类社会发展泛娱乐化、特别是教育趋向娱乐化的担忧。从另一角度佐证了 Linus 的看法，只不过一消极悲观，一积极乐观。&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;与Andrew S. Tanenbaum的争论&lt;/h2&gt;
&lt;p&gt;这一事件在 Wikipedia 上还有专门的词条-&lt;a href=&apos;http://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate&apos;&gt;Tanenbaum-Torvalds debate&lt;/a&gt;。以前也关注过该事件，但把问题的重心放在了“微内核（Micro kernel）”和“宏内核（Monolithic kernel）”的优缺点上，看了该书之后才真正理解 Linus 的选择，并赞同他的看法。&lt;/p&gt;
&lt;p&gt;这一争论的原文见&lt;a href=&apos;https://groups.google.com/forum/#!topic/comp.os.minix/wlhw16QWltI%5B1-25-false%5D&apos;&gt;邮件列表&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;对于 Tanenbaum 提出的问题，Linus 做了如下回答：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;安德鲁塔南鲍姆写道：&lt;/p&gt;
&lt;p&gt;&gt;我在美国待了几个星期，所以没来得及对Linux做多少评论(不是说如果我在，我就会说什么)。但是，Linux 确实值得一评。我现在就有话要说。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&gt;正如你们所知，MINIX 只是我的爱好，每当晚上我写烦了书，如果当时没有什么战争、 革命、 直播的参议院听政会，我就会摆弄 MINIX。我的真正职业是大学教授和操作系统领域中的研究人员。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;你用这个作为 MINIX 局限性的借口？对不起，但是你输了。我的借口比你的还多，而 Linux 在很多领域还是胜 MINIX 一筹。更别说 MINIX 的大部分似乎是由布鲁斯?伊文斯编写的了。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;反驳一：你说你把 MINIX 当作爱好来玩――那么，请问是谁在拿 MINIX 挣钱呢？又是谁在免费发送 Linux 呢？再来谈谈爱好。让 MINIX 能免费获得，我对 MINIX 的最大抱怨就会消失。Linux 在很大程度上对我是一个爱好(但是一个很严肃的爱好，最棒的一种爱好)。我没有从我的爱好中赚一分钱，它也不是我在大学要修的课程之一。我是纯粹用我自己的时间，在自己的机器上做出来的。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;反驳二：你是教授和研究人员。这真是一个 MINIX 出现核心缺陷的好借口。我只能希望 Amoeba 不会像 MINIX 那样垮掉。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&gt;1.微内核对 Monolithic system&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;没错，Linux 是 Monolithic 的，我同意微内核是好一点儿。 如果不是你的话题有争议性，我可能会同意你的大部分意见。从理论角度(及审美角度)而言，Linux 输了。如果 GNU 的 kernel 在去年春天就已完善的话，我可能就不会开始这个工程。而事实是，GNU 还没有完善，也远非如此。如果现在就已实现的这一点而论，Linux才大获全胜。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&gt;MINIX 是一个基于微内核的系统。Linux 是 Monolithic 的系统。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;如果这是判断一个 kernel 好坏的唯一标准，你的观点就对了。但你没提到的是，MINIX 在微内核方面的表现并不出色，而且对核内真正的多任务操作仍存在着问题。 如果我做的是一个在多线程文件系统上有问题的 OS 的话，我就不会这么快来责备别人。而事实上，我竭尽所能来使人们忘记软件设计者在此问题上的惨败。(是的，我知道 MINIX 拥有众多黑客支持者，但他们只是黑客。而布鲁斯?伊文斯告诉我有很多可以竞争的机会。)&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&gt;2.可移植性&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;“可移植性是给那些写不出新程序的人们准备的。”&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;――我，现在刚说的，口出狂言&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;事实上，Linux 比 MINIX 更具有可移植性。 “你说什么？”我听见你说。 是真的――但却不是在你所说的意义上。我使 Linux 尽量符合标准(我当时手边并没有 POSIX 标准)。 把程序移植到 Linux 上比到 MINIX 上要容易得多。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;我同意，可移植性是个好东西，但是只有在它确实有意义的地方才是个令人向往的特性。没有必要专门使一个操作系统太具有可移植性：能粘到可移植的 API 上就行了。操作系统的实质就是利用硬件的特点，并将其隐藏在一层高级的系统调用后面。而 Linux 就是如此，它比任何 kernel 都更多地利用了386的特性。当然这使得kernel确实不可移植，但是这也使设计大为简化，是一个可以接受的权宜之计，因为这首先保证了 Linux 的诞生。我也同意，Linux 又太不具有可移植性了。去年一月我拥有了自己的386，而 Linux 系统的创建在一定程度上成为了一个让我认识386的项目。如果要成为一个真正的项目，必须能够在可移植性方面做一些事情。 但是，我最初的设计思想就是没有考虑到可移植性，如果我这样说并不是太过分地为自己辩护。去年四月我开始这个项目时，认为不会有什么人会真的使用它。我很高兴我的这个想法错了。 随着我对源代码的发布，每个人都可以免费来装截 Linux，哪怕还不是很方便。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;李纳斯&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;附：很抱歉我有时言辞过激。如果你没有其他的操作系统可供选择的话，MINIX 已经挺好的了。如果你有五到十个386机器闲着没用，那么 Amoeba 也会不错，只是我确定无疑是没有的。我一般不会勃然大怒，但是在涉及到 Linux 的问题时，我是有点容易感情用事。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这一反驳非常精彩，并且有说服力！特别是对于“可移植性”问题的说明，值得每个程序员阅读。&lt;/p&gt;
&lt;h2&gt;知识产权&lt;/h2&gt;
&lt;p&gt;关于知识产权，通常有两种截然不同的观点：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;有些人认为，专利和劳动保险形式的知识产权法规是自由世界的祸害，信息提供者(IP)法规并不仅仅是训导，实际上简直就是罪恶，应该尽快地加以铲除。 另一些人认为整个世界经济实际上是由知识产权所驱动的。这些人想通过他们的努力来加强IP法规的法律地位。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;而 Linus 是这么认为：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;对于许多人，包括对我自己而言，知识产权是有关人类的创造活动的规则，是关于那些使我们成为人类――而不是动物(当然，这本身是一件好事)的活动的规则。正是在这个意义上，“知识产权”这一名称本身就是一种侮辱。 它并不是如有形财产那样可以出售，它是创造性活动本身，这是人类所能够做到的最伟大的事情。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;那种创造――不管它是以绘画、 音乐、 雕塑、 菱或是程序的方式出现，都应当受到尊重：创造者和他所创造的事物之间有着你所无法切断的密切联系。这就像母亲与孩子之间的联系，或者如同中国菜与味精之间的联系。 但是与此同时，它却又是世界上每一个人都应当分享的事物，因为它是属于人类共同的。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;你拥有你所创造的东西就意味着你可以控制它的使用。 例如，你有权将这一艺术成果出售给其他人，而且在这个问题上，除了美国国税局以外，任何人都不会说什么。 但是，它其实并不仅仅是钱的问题，而是其他人在同样的问题上陷于困惑时帮他们解决了问题，省却了时间与精力。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;许多要求加强知识产权立法的讨论是基于这样一种观点，即：给创造者和艺术家以更多的“保护”。而人们似乎不曾、或者说是从未意识到，这样一种强有力的权利导致一些人剥夺了另一些人的权利。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;我热爱版权。我只是认为没必要将版权所有者的权利无限扩大。不要扩大到将消费者的权利都被剥夺殆尽。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;很显然，只有极少的个人获得了专利。 另一方面，公司却获得了大量的专利。这些专利是他们用来对付其他公司的有力武器，可以威胁别人因专利侵权而要面临起诉。现今的专利系统基本上可以说是信息提供者这间的冷战，而不是他们之前的核战争。目前这种情况也不见得比过去的冷战好。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;如果你想避免专利申请过程中的麻烦，你可以采用更为厉害的手段：商业秘密。商业秘密的优点在于，你不必担心什么商业秘密办公室或者类似的机构：你只需要将其封存起来，然后就不必顾虑那么多了。&lt;/p&gt;
&lt;p&gt;过去人们一直是这样做的，实际上这也就是法规之所以被引入的原因所在。为了鼓励个人和公司公开其秘密，专利法允许在一定期限内保护市场――如果你公开你所拥有的秘密的话。一个针锋相对的基本形式是：你告诉大家你是如何做成某事的，那么我们就允许你拥有一定年限的特殊权利。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;在专利产生之前，人们会充满猜忌地保守他们自己的技术优势，一直到将它们带入坟墓。很显然，那是不利于技术进步的，因为有前途的技术从来没有向其他人公开过。对于专利特权的承诺使得专利成为将秘密告诉大家的一种强有力的刺激，因为你再也不用担心你的竞争对手会发现你在做什么了。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;然而，那是过去，现在情形不同了。 如今，即使是商业秘密也有了法律保护，尽管它们的理由世人无法理解。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;很大程度上，在这场知识产权战争中寻求和平的解决之道正是公开源代码所努力的目标。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;同一事物的另一面在于，的确，知识产权可能是不公平的，的确，知识产权法规在很大程度上将其目标定位于大公司而不是消费者权利，甚至也不是个人著作者或创新者。 然而其主体是积极有利的。知识产权集中于强有力的权利之上，与之相对应的事实是这一强有力的武器在市场上是如此的有效。 核武器是冷战时代的终极力量，同样的原因使得知识产权在技术战争时代里大受欢迎。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;虽然大量的新措施使非法使用他人的知识产权变得更加困难，但同时也使得合法使用他人的知识产权变得更加困难。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;原谅我喋喋不休地摘录了这么多内容，但其实书中这部分的内容还有很多精彩之处。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;知识产权本来的目的是保护创造者的基本权利，以促进创新和分享，但知识产权如果走过了头（例如如今的专利战争）就会导致创新难以普及，他人无法合法合理地使用这些创新。开源运动则鼓励充分地开放分享创新，同时通过各种形式许可证来保护创造者的基本权利，这也就意味着开源运动的理念不仅只是影响计算机行业，也会对所有行业产生巨大的正面影响。&lt;/p&gt;
&lt;p&gt;人类社会的发展是一个积累的过程，创新知识的分享越充分，积累也就越快，人类社会的发展也就越快。这也是我欣赏支持黑客精神和开源运动的缘由。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;关于书名的翻译&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这本书的书名，中国青年出版社的版本是译为《乐者为王》，而将要出版的人民邮电出版社的版本貌似要译为《越玩越大-我和 Linux 的故事》（正式出版前的暂译名？）。对于这两个译名我都不满意。原书取名《Just For Fun --- The Story of an Accidental Revolutionary》，我想应该是考虑了两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Linus 非常看重尊重自己的兴趣。其实 Linux 就是始于它的个人兴趣，也因此 Linux 到如今的发展及其造成的广泛影响也是当初Linus没有料想也不可能料想到的，人生往往如此，很多事情都是 Accidental 的；&lt;/li&gt;
&lt;li&gt;Linus 认为任何人类社会事物发展的终极阶段就是---娱乐，那么生活的意义就是不断努力为达到这一终极阶段而贡献自己的一份力量。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;对于第二点，该书的最后一节中作者做了明确的说明：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;对了，就是这三件事：生存、你在社会中的位置、还有快乐。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;这三件事就是我们正在做着的事情。 任何其他的事物，都是社会学家可能会称之为“突发行为”的东西，它们源于那些规则更为简单的行为模式。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;然而事情不仅仅是“这就是激励人生活的事物”。如果情形是这样的话，那它们也就不会成为关于生命的理论了。令人感兴趣的，这三种激励因素有着内在的次序，而这一次序表明了生命的所在。事情并不仅仅是，我们人类被这三种事物所驱使――对于人类以外的其他生命行为也是如此。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;这一次序是：生存；社会交往；寻找乐趣。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;它也是进化的次序。这就是我们选择了“Just for Fun”作为本书名称的原因。&lt;/p&gt;
&lt;p&gt;因为我们曾经所做的一切事情，似乎最终都是为了我们自己的乐趣。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;译名《乐者为王》虽然简练，却不能明确地表达这两层意思。《越玩越大-我和Linux的故事》则跟闹着玩似的。&lt;/p&gt;
&lt;p&gt;为什么不直译为《只为乐趣》呢？&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关于本书，阮一峰也写过一篇阅读笔记，见&lt;a href=&apos;http://www.ruanyifeng.com/blog/2012/09/linus_torvalds.html&apos;&gt;《Linus Torvalds 自传》摘录&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-11-07</pubDate>
            <link>https://blog.xiayf.cn/posts/reading-just-for-fun.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/reading-just-for-fun.html</guid>
        </item>
        
        <item>
            <title>搭建高可用负载均衡组件及缓存DNS</title>
            <description>&lt;p&gt;该项工作，如题所示，主要分为两部分：高可用负载均衡组件、缓存 DNS。&lt;/p&gt;
&lt;h2&gt;高可用负载均衡组件&lt;/h2&gt;
&lt;p&gt;需求：优化业务系统架构中某些关键环节，针对 TCP 层数据流量进行负载均衡，并保证服务的高可用。&lt;/p&gt;
&lt;p&gt;技术选型：HAProxy + Keepalived，这对组合比较常见成熟。&lt;/p&gt;
&lt;p&gt;另外，由于 HAProxy 的负载均衡任务可能比较多，靠人工修改配置来增删改任务不方便可靠，所以实现了一个简单的 HAProxy 管理系统，&lt;/p&gt;
&lt;p&gt;以后经实际使用验证和完善会开放源码。&lt;/p&gt;
&lt;img src=&apos;../assets/high-availability-load-balancer.png&apos; title=&apos;high availability load balancer&apos; alt=&apos;high availability load balancer&apos; width=&apos;100%&apos;/&gt;
&lt;h2&gt;缓存 DNS&lt;/h2&gt;
&lt;p&gt;先以 www.qq.com 为例，解释一下域名解析过程：&lt;/p&gt;
&lt;img src=&apos;../assets/resolve-qq-com.jpg&apos; title=&apos;resolve qq.com&apos; alt=&apos;resolve qq.com&apos; width=&apos;600&apos;/&gt;
&lt;ol&gt;&lt;li&gt;用户向 Local DNS 发起 &lt;code&gt;www.qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;Local DNS 向根服务器发起 &lt;code&gt;com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;根服务器向 Local DNS 返回 &lt;code&gt;com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS 向 &lt;code&gt;com.&lt;/code&gt; 权威服务器发起 &lt;code&gt;qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.&lt;/code&gt; 权威服务器向 Local DNS 返回 &lt;code&gt;qq.com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS向 &lt;code&gt;qq.com.&lt;/code&gt; 权威服务器发起 &lt;code&gt;www.qq.com.&lt;/code&gt; 查询请求；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;qq.com.&lt;/code&gt; 权威服务器向 Local DNS 返回 &lt;code&gt;www.qq.com.&lt;/code&gt; 解析记录；&lt;/li&gt;
&lt;li&gt;Local DNS 向用户返回 &lt;code&gt;www.qq.com&lt;/code&gt; 解析记录。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;Local DNS 一般由网络运营商（如电信、网通等）提供。&lt;/p&gt;
&lt;p&gt;缓存 DNS 处于用户端（这是一个相对的概念）与 local DNS 之间，利用 DNS 服务器软件的缓存功能以及缓存 DNS 与用户端的近距离特点来加速域名解析。&lt;/p&gt;
&lt;p&gt;也可以在缓存 DNS 上按需求进行域名劫持。运营商为了牟利，也会在 local DNS 上进行域名劫持，这对于各大互联网公司对外提供的服务来说是个很大的问题。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;在完成该工作后，我编写了一份安装配置文档，方便其他同事参考。文档见： &lt;a href=&apos;../assets/high-availability-load-balancer-and-dns.pdf&apos;&gt;HAProxy+HAProxyConsole+Keepalived+BIND安装配置文档.pdf&lt;/a&gt;。&lt;/p&gt;</description>
            <pubDate>2013-10-16</pubDate>
            <link>https://blog.xiayf.cn/posts/ha-lb-and-dns.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/ha-lb-and-dns.html</guid>
        </item>
        
        <item>
            <title>通过示例学习Git内部构造（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://teohm.github.io/blog/2011/05/30/learning-git-internals-by-example/&apos;&gt;Learning Git Internals by Example&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;状态：草稿&lt;/p&gt;
&lt;p&gt;计划修订本文，未来可能会简化一些...&lt;/p&gt;
&lt;h2&gt;动机&lt;/h2&gt;
&lt;p&gt;从Subversion和Mercurial切换到Git之后的几个月，我始终觉得Git在本质上是不同于Subversion和Mercurial的，但没法确切地说出区别。&lt;/p&gt;
&lt;p&gt;我经常在Github上看到tree、parent等术语，也搞不清楚它们确切的含义。&lt;/p&gt;
&lt;p&gt;因此我决定花些时间学学Git。&lt;/p&gt;
&lt;p&gt;我会尝试概述，并阐述一路走来学到的关于Git的关键信息...但这仅是有助于我回答Git与其他源码控制工具区别的Git内部构造基本知识。&lt;/p&gt;
&lt;h2&gt;实体、引用、索引（Objects，References，The Index）&lt;/h2&gt;
&lt;p&gt;要理解Git内部构造的核心，我们应理解三个东西： &lt;strong&gt;实体&lt;/strong&gt;、&lt;strong&gt;引用&lt;/strong&gt;、 &lt;strong&gt;索引&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我发现这个模型非常优雅。用一个小小的图表就能完全展现，也易于理解记忆。&lt;/p&gt;
&lt;img src=&apos;../assets/git-internals/big-picture.png&apos; title=&apos;Big Picture&apos; alt=&apos;Big Picture&apos; width=&apos;500&apos;/&gt;
&lt;h3&gt;实体&lt;/h3&gt;
&lt;p&gt;你提交到一个Git代码仓库中的所有文件，包括每个提交的说明信息（the commit info）都在目录 &lt;code&gt;.git/objects/&lt;/code&gt;中存储为&lt;strong&gt;实体&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一个实体以一个40字符长度的字符串（该实体内容的SHA1哈希值）来标识。&lt;/p&gt;
&lt;p&gt;实体有&lt;strong&gt;4类&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;em&gt;blob&lt;/em&gt; - 存储文件内容。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tree&lt;/em&gt; - 存储目录结构和文件名。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;commit&lt;/em&gt; - 存储提交的说明，组成Git的提交图谱。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tag&lt;/em&gt; - 存储带注释的标签（tag）。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;下文的示例会阐明这些实体是如何相互关联的。&lt;/p&gt;
&lt;h3&gt;引用&lt;/h3&gt;
&lt;p&gt;Git中，一个&lt;em&gt;分支（branch）&lt;/em&gt;、&lt;em&gt;远程分支（remote branch）&lt;/em&gt;或一个&lt;em&gt;标签（tag）&lt;/em&gt;（也称为轻量标签）仅是&lt;strong&gt;指向一个实体的一个指针&lt;/strong&gt;，这里的实体通常是一个commit实体。&lt;/p&gt;
&lt;p&gt;这些引用以文本文件的形式存储在目录&lt;code&gt;.git/refs/&lt;/code&gt;中。&lt;/p&gt;
&lt;h4&gt;符号引用（Symbolic References）&lt;/h4&gt;
&lt;p&gt;Git有一种特殊的引用，称为&lt;em&gt;符号引用&lt;/em&gt;。它并不直接指向一个实体，而是&lt;strong&gt;指向另一个引用&lt;/strong&gt;。举例来说，&lt;code&gt;.git/HEAD&lt;/code&gt;就是一个符号引用。它指向你正在工作的当前分支。&lt;/p&gt;
&lt;h3&gt;索引&lt;/h3&gt;
&lt;p&gt;索引是一个暂存区，以二进制文件的形式存储为文件&lt;code&gt;.git/index&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;当&lt;code&gt;git add&lt;/code&gt;一个文件，Git将该文件的信息添加到索引中。当&lt;code&gt;git commit&lt;/code&gt;，Git仅提交索引文件中列出的文件。&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p&gt;我们来演练一个简单的示例，创建一个Git代码仓库，提交一些文件，看看幕后&lt;code&gt;.git&lt;/code&gt;目录中都发生了些什么。&lt;/p&gt;
&lt;h3&gt;初始化新的代码仓库&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git init canai&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/init.png&apos; title=&apos;初始化代码仓库后&apos; alt=&apos;初始化代码仓库后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了空目录&lt;code&gt;.git/objects/&lt;/code&gt;和&lt;code&gt;.git/refs/&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;还没有索引（Index）文件。&lt;/li&gt;
&lt;li&gt;创建了符号索引文件&lt;code&gt;HEAD&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/HEAD
ref: refs/heads/master&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加新文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ echo &amp;amp;quot;A roti canai project.&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; README
$ git add README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/new-file.png&apos; title=&apos;添加新文件后&apos; alt=&apos;添加新文件后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了索引（Index）文件。它有一个SHA1哈希值指向一个blob实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 5f89c6f016cad2d419e865df380595e39b1256db 0 README&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个blob实体。README文件的内容存储在该blob中。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/5f/89c6f016cad2d419e865df380595e39b1256db
$ git cat-file blob 5f89c6
A roti canai project.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;首次提交&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git commit -m&amp;amp;apos;first commit&amp;amp;apos;
[master (root-commit) d9976cf] first commit
1 files changed, 1 insertions(+), 0 deletions(-)
create mode 100644 README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/first-commit.png&apos; title=&apos;首次提交后&apos; alt=&apos;首次提交后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了分支‘master’引用，指向‘master’分支中最新的commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/heads/master 
d9976cfe0430557885d162927dd70186d0f521e8&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了第一个commit实体，指向代码仓库根目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/d9/976cfe0430557885d162927dd70186d0f521e8
$ git cat-file commit d9976cf
tree 0ff699bbafc5d17d0637bf058c924ab405b5dcfe
author Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306739524 +0800
committer Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306739524 +0800

first commit&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了tree实体。该tree代表目录“canai”。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/0f/f699bbafc5d17d0637bf058c924ab405b5dcfe
$ git ls-tree 0ff699
100644 blob 5f89c6f016cad2d419e865df380595e39b1256db  README&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个修改过的文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ echo &amp;amp;quot;Welcome everyone.&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; README
$ git add README&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/modified-file.png&apos; title=&apos;添加一个修改过的文件后&apos; alt=&apos;添加一个修改过的文件后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了索引（Index）文件。注意到了吗？它记录了一个新blob。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 1192db4c15e019da7fc053225d09dea14bc3ac07 0 README&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的blob实体。README的整个内容被存入一个新的blob。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/11/92db4c15e019da7fc053225d09dea14bc3ac07
$ git cat-file blob 1192db
A roti canai project.
Welcome everyone.&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;向子目录中添加文件&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ mkdir doc
$ echo &amp;amp;quot;[[TBD]] manual toc&amp;amp;quot; &amp;amp;gt;&amp;amp;gt; doc/manual.txt
$ git add doc&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/subdir.png&apos; title=&apos;向子目录添加文件后&apos; alt=&apos;向子目录添加文件后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了索引（Index）文件。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-files --stage
100644 1192db4c15e019da7fc053225d09dea14bc3ac07 0 README
100644 ea283e4fb22719fad512405d41dffa050cd16f9a 0 doc/manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的blob实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;# .git/objects/ea/283e4fb22719fad512405d41dffa050cd16f9a
$ git cat-file blob ea283
[[TBD]] manual toc&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;第二次提交&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git commit -m&amp;amp;apos;second commit&amp;amp;apos;
[master 556eaf3] second commit
 2 files changed, 2 insertions(+), 0 deletions(-)
 create mode 100644 doc/manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/second-commit.png&apos; title=&apos;第二次提交后&apos; alt=&apos;第二次提交后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更新了分支“master”引用，指向该分支中最新的commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/heads/master 
556eaf374886d4c07a1906b9fdcaba195292b96&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了第二个commit实体。注意它的“parent”是指向首个commit实体。这样形成了一个提交图谱。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git cat-file commit 556e
tree 7729a8b15b747bce541a9752a8f10d57daf221b6
parent d9976cfe0430557885d162927dd70186d0f521e8
author Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306743598 +0800
committer Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306743598 +0800

second commit&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的代码仓库根目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-tree 7729
100644 blob 1192db4c15e019da7fc053225d09dea14bc3ac07  README
040000 tree 6ff17d485bf857514f299f0bde0e2a5c932bd055  doc&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个新的子目录tree实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git ls-tree 6ff1
100644 blob ea283e4fb22719fad512405d41dffa050cd16f9a  manual.txt&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个注释标签（annotated tag）&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git tag -a -m&amp;amp;apos;this is annotated tag&amp;amp;apos; v0.1 d9976&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/annotated-tag.png&apos; title=&apos;添加一个注释标签后&apos; alt=&apos;添加一个注释标签后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了一个标签引用，指向一个tag实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/tags/v0.1 
c758f4820f02acf20bb3f6d7f6098f25ee6ed730&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;创建了一个tag实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git cat-file tag c758
object d9976cfe0430557885d162927dd70186d0f521e8
type commit
tag v0.1
tagger Huiming Teo &amp;amp;lt;huiming@favoritemedium.com&amp;amp;gt; 1306744918 +0800

this is annotated tag&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;添加一个新的（轻量的）标签&lt;/h3&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ git tag root-commit d9976&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&apos;../assets/git-internals/new-tag.png&apos; title=&apos;添加一个新的轻量标签后&apos; alt=&apos;添加一个新的轻量标签后&apos; width=&apos;500&apos;/&gt;
&lt;p&gt;发生了什么呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建了一个标签引用，指向一个commit实体。&lt;/li&gt;&lt;/ul&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;$ cat .git/refs/tags/root-commit 
d9976cfe0430557885d162927dd70186d0f521e8&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;补充阅读&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://book.git-scm.com/index.html&apos;&gt;Git社区书&lt;/a&gt;“第7章：内部构造探究”&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://progit.org/book/ch9-0.html&apos;&gt;Pro Git&lt;/a&gt;“第9章：Git内部构造”。&lt;/li&gt;&lt;/ul&gt;
&lt;h2&gt;接下来做什么呢？&lt;/h2&gt;
&lt;p&gt;寻找适合分布式团队、长期项目的一个最小化git工作流。&lt;/p&gt;</description>
            <pubDate>2013-09-28</pubDate>
            <link>https://blog.xiayf.cn/posts/learning-git-internals-by-example.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/learning-git-internals-by-example.html</guid>
        </item>
        
        <item>
            <title>工作中的技术人</title>
            <description>&lt;p&gt;工作入职半个月，有些事情不太顺利，还没有正式上手工作，也许大公司的节奏便是如此，但我内心是比较急的，希望能尽快地上手做实际的工作，而不是学习和等待。&lt;/p&gt;
&lt;p&gt;这半个月里，主要是熟悉工作环境，学习了解工作相关的技术。虽说学习，但其实大部分相关技术以前都了解或使用过，只是经验还不够。&lt;/p&gt;
&lt;p&gt;第一周，除了常规的入职事宜，搭建了开发测试环境，并阅读理解工作中使用的web框架。对于这个框架，有太多的吐槽点，严格地说算不上是个框架，可能是因为写得比较早。对于框架，我认为最重要的是为多人协作完成一件事情提供实现上的规范，其次是代码复用，减少工作量。但这个框架除了一些供复用的代码，就啥都没有了。&lt;/p&gt;
&lt;p&gt;第二周，学习巩固PHP基础，一直没认真地学习过PHP，只是在实习的时候做了一些开发，稍微了解了下Yii框架和Zend框架，觉得太复杂了点。除此之外，初步了解组内的运维工作，特别是整个系统的架构。&lt;/p&gt;
&lt;p&gt;经过一番思考，基于自己的理解，昨天编写了一个玩具性质的MVC web框架原型&lt;a href=&apos;https://github.com/youngsterxyf/minibean&apos;&gt;minibean&lt;/a&gt;，该框架以路由转发和控制器为核心，所有非静态文件请求的处理都以Application类对象为入口，按照一定规则对请求URI经路由转发找到对应的控制器类，控制器对象中调用模型与视图的类对象等。以后随着开发经验的增加以及对其他开源成熟框架的学习，会不断地完善该框架。在编写该框架的过程中，深感自己经验的不足，特别是对于Model层，以后可能会刻意阅读某些开源框架的Model层实现。&lt;/p&gt;
&lt;p&gt;目前组内开发工作还很初步，还没有一个正规的开发流程，也没有明确的开发规范。这样虽然没法从已有的工作中学习很多，但也许有机会参与到这些事情创造过程中，收获会更大。&lt;/p&gt;
&lt;p&gt;经过和老同事讨论，以后开发工作涉及的语言和工具包括：Nginx、MySQL、PHP、Redis/Memcached、SVN等，对于这些东西，我都是需要深入学习加强的（当然首先是要解决业务需求）。另外，鉴于原有的那个框架实在不怎么样，以后新的工作可能会选择Zend Framework作为开发框架。&lt;/p&gt;
&lt;p&gt;对于工作环境，我觉得不太满意的地方主要是技术氛围不太浓厚，以后有机会和大家一起建立起好的技术氛围，搞搞技术分享讨论什么的。另外，有点憋屈的是，觉着自己被小看了，老同事老觉得应届毕业生啥的不懂，所以也不急着分配具体的工作给我，老让我学习学习再学习。个人认为最好的学习方式是给个具体的需求，具体的问题让我去解决，有经验的同事只需对结果把把关就可以。当我在这过程中遇到搞不定的问题再向他们请教，以这种方式来上手熟悉工作也许更好。我个人也比较喜欢直接丢个实际的问题让我去解决。&lt;/p&gt;
&lt;p&gt;对于今后的自己，我有两点忠告：&lt;/p&gt;
&lt;p&gt;1、时刻警惕迷失&lt;/p&gt;
&lt;p&gt;虽然工作很重要，要解决业务需求，工作所涉及的技术也应该扎实掌握，深入理解，但不能把自己局限在此，也不能让自己迷失在过于细节的地方。公司提供了一个完善的平台，但这个平台在我看来自足得有些封闭，所以需警惕，要不断地和同事，和公司外面的人交流学习。要经常自我反思，回顾自己走过的路，要让自己的大脑空闲下来花些时间整体规划即将要做的事情。&lt;/p&gt;
&lt;p&gt;2、保持锐气&lt;/p&gt;
&lt;p&gt;初步觉着有些同事没什么工作生活技术的激情，可能是长时间工作的缘故，也可能是因为我还太年轻。但目前我还不愿意自己进入那种状态。自己以后应该更加主动积极地对待工作。我喜欢称呼自己为“技术人”，因为“技术人”不仅是搞技术的，更重要的是对技术有热情，有使命感。&lt;/p&gt;</description>
            <pubDate>2013-04-23</pubDate>
            <link>https://blog.xiayf.cn/posts/technical-person.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/technical-person.html</guid>
        </item>
        
        <item>
            <title>弄清问题，再求解决</title>
            <description>&lt;p&gt;今天同事问我：是否有什么python库或工具能够将网页内容转换成图片格式的。他在做这方面的事情，还没有好的方法，因为觉得我对python比较熟悉，所以问一下。&lt;/p&gt;
&lt;p&gt;但是我从一开始我就犯错误了。其实我至少应该问一下：为什么要解决这个问题？也就是业务需求是什么？并且稍微一想这个问题其实比较含糊。现在的web页面可以很简单，也可能很复杂。那么这个问题里的“网页”是什么样的网页呢？是任何可能的网页么？目的是需要通过图片来展示网页的哪个部分的信息还是整个网页？这些问题我都没问，也没仔细考虑。&lt;/p&gt;
&lt;p&gt;在没有明确需求的情况下，我就认为是将任何形式的网页完整地转换成图片，但又没弄清如果是这种情况问题的难度有多大。&lt;/p&gt;
&lt;p&gt;在听完问题后，我就想到可能有两种方法：1. 先将网页转换成pdf，然后转换成图片，因为我对于将网页转换成pdf格式的方法有点印象；2.可能存在python实现的工具直接将网页转换成图片格式。你是否发现我的思路有个误区：问题的解决方案需要python代码实现，我假设了需要将这个功能嵌入到一个大的程序中。&lt;/p&gt;
&lt;p&gt;然后我就开始蒙头google找方案。经过一番“艰苦卓绝”的查找，发现：1.确实有如xhtml2pdf等工具能将网页转换成pdf格式，但貌似对于中文的支持不是很好；2.没有好的python库或工具能够直接将网页转换成图片格式，有的方案要收费，有的方案需要调用第三方API，而公司的数据明显是不能让第三方获得的。&lt;/p&gt;
&lt;p&gt;在查找解决方案的过程中，我也逐步意识到上述的那些问题，特别是若假设需要将任何形式的网页转换成图片格式，这个难度非常大，为什么呢？因为现在很多网页的部分内容都是由JS生成的，若你的程序只是简单地从服务器获取网页，该网页含有的JS代码并不会执行，将该网页转换成图片格式，图片所包含的信息与浏览器中展示的并不相同。所以你的程序起码需要包含一个JS解释器。OK，难度一下子就上去了。在我逐步了解其中的难度后，我开始尝试换个角度来考虑问题，反思同事所要解决的业务需求是什么。&lt;/p&gt;
&lt;p&gt;在与他的进一步沟通之后，我才知道：一些总结汇报邮件中需要添加数据统计图，而原有的数据统计图在Web监控页面中，由Raphaeljs库绘制成SVG矢量图。由于无法期望邮件的接收者是从网页版邮箱阅读邮件（他们很可能使用各种邮件客户端如Outlook查看邮件），所以发送带有JS的HTML格式的邮件是没用的。&lt;/p&gt;
&lt;p&gt;在了解业务需求后，我们就明白了其实问题本质上不是要将网页转换成图片，而是要获得&lt;strong&gt;图片格式的数据可视化结果&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那么问题就简单多了，可能从以下三个角度寻找解决方案：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;将网页完整地转换成图片格式&lt;/li&gt;
&lt;li&gt;将网页中的SVG内容转换成图片格式&lt;/li&gt;
&lt;li&gt;使用本地的数据可视化工具将统计数据源，即Raphaeljs绘制SVG矢量图的JSON数据源绘制成图片&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;这三种方案中第二种最佳，为什么呢？因为第一种需要做一些额外的转换工作，自己实现的难度较大，第三种方案与Web监控页面所使用的是不同的数据可视化工具，所以产生的结果一般是不相同的，除非Raphaeljs支持图片格式的输出，那么应该就可以使用nodejs来实现。&lt;/p&gt;
&lt;p&gt;经过网络查找，发现第一种方案与第二种方案都有现成的工具。&lt;/p&gt;
&lt;p&gt;第一种方案：&lt;a href=&apos;https://github.com/ariya/phantomjs&apos;&gt;phantomjs&lt;/a&gt;可以完成，phantomjs包含了webkit，所以解释JS什么的就不再是个问题了，它有个&lt;a href=&apos;https://github.com/ariya/phantomjs/wiki/Screen-Capture&apos;&gt;Screen Capture&lt;/a&gt;的功能模块支持将网页完整地转换成图片格式，但由于要做很多额外的工作，所以效率比较低。&lt;/p&gt;
&lt;p&gt;第二种方案是从Highcharts的&lt;a href=&apos;http://www.highcharts.com/demo/&apos;&gt;Demo&lt;/a&gt;中挖掘出来的，如图所示：&lt;/p&gt;
&lt;img src=&apos;../assets/highchartjsdemo.png&apos; title=&apos;highchartjs_demo&apos; alt=&apos;highchartjs_demo&apos; width=&apos;100%&apos;/&gt;
&lt;p&gt;Demo中可以输出多种图片格式，通过chrome浏览器的开发者工具可以发现其实现是向服务器export.highcharts.com发送一个请求，请求中包含网页中生成的SVG矢量图数据、目标图片格式等信息，服务器对该请求进行处理后返回目标格式图片。那么服务器端是如何将SVG转换成图片格式的呢？在Highcharts的&lt;a href=&apos;http://docs.highcharts.com/&apos;&gt;文档&lt;/a&gt;中有个名为&lt;code&gt;Export module&lt;/code&gt;的部分，其中说明了实现原理以及如何搭建这样的一个格式转换服务器。从文档可以看出这个实现方法的核心是借助了&lt;a href=&apos;http://xmlgraphics.apache.org/batik/tools/rasterizer.html&apos;&gt;batik-rasterizer.jar&lt;/a&gt;这个Java工具包，它能将SVG转换成图片或PDF格式。&lt;/p&gt;
&lt;p&gt;从上述该问题解决方案的寻找过程可以看出，&lt;strong&gt;很多时候并不是问题有多复杂或有多难，而是我们根本没有明确业务需求，没有搞清楚真正需要解决的问题，而对模糊的问题描述自以为是地作出一些假设，然后蒙头去解决错误的问题，从而浪费了很多时间&lt;/strong&gt;。&lt;/p&gt;</description>
            <pubDate>2013-04-09</pubDate>
            <link>https://blog.xiayf.cn/posts/understand-before-solve.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/understand-before-solve.html</guid>
        </item>
        
        <item>
            <title>回顾2012，展望2013</title>
            <description>&lt;p&gt;过去的一年里发生了很多事情，很大一部分原来就已在&lt;a href=&apos;http://youngsterxyf.github.io/2012/01/01/2011-summary/&apos;&gt;2011年终-回顾与展望&lt;/a&gt;一文中提及---实习、找工作、毕业，除此之外还有：我和女朋友定亲了，总算朝着婚姻近了一步，哈哈。&lt;/p&gt;
&lt;h2&gt;实习&lt;/h2&gt;
&lt;p&gt;关于实习有太多的话想说。7个月的时间里浓缩了太多的欢乐，太欢乐了。原本以为我的读书生涯就要这么平淡无奇地结束了，没想到在这个结尾处竟然给了我个大惊喜，所谓惊喜并不是这份实习有多牛逼，而是遇到了一群欢乐的人，一群“重口味”的人，一群彪悍的人，而其中绝大部分是女人，噢，女生更恰当些。&lt;/p&gt;
&lt;p&gt;在G1C1，我快乐地写代码，上班是种享受，我想以后很可能不会再有这样的享受了。在G1C1，我逐步地发展成为一个吃货，所以毫无疑问地胖了，原本我以为自己会一直瘦下去。另外，我也黑了，因为经过了无数次地“被黑”，但她们说我应该高兴才对，她们“黑”我是因为“爱”我。关于“黑”这件事情，刚入职的时候，我是很同情wenbin的，因为见他被“黑”得体无完肤的，可我也没逃脱作为一个G1C1码农的宿命，wenbin走后，替代了他的角色，而我走后，comen则替代了我的角色，可惜之后就不会再有了。&lt;/p&gt;
&lt;p&gt;吃，是Google的特色，故在G1C1也不例外。因为G1C1不与其他部门在一起，所以没法吃食堂。但我们也不亏，老大带着我们吃遍了办公室方圆几里地叫得出名的饭店，吃饱吃好，并且一天一换。并且吃饭的场景实在不得不让码农感到幸福，男女比例经常是6：1，与“交大男女七比一，一对情侣三对基”的情形那是恰好相反，而且我们实验室甚至比七比一的情况还严重。所以我一直来回感受两种极端。又由于女生的食量多半偏小，作为男生，最后“扫盘”的工作那自然是义不容辞的，胖也就必然的结果了。&lt;/p&gt;
&lt;p&gt;因为工作内容比较多元化，所以G1C1实习生的专业背景与就读学校覆盖面很大，可以说是“一锅大杂烩”。专业不同，并没有妨碍交流，反而使工作氛围更加活跃，具备专业特色的阐述方式与内容相互碰撞交融。&lt;/p&gt;
&lt;p&gt;很想逐个介绍我所知道的G1C1er们，可苦于胸无半点墨水，只好作罢。但你们应知道，应相信，现在，以后，我都会一直念着你们，想着你们。感谢和你们一起度过的美好青春时光。&lt;/p&gt;
&lt;h2&gt;找工作&lt;/h2&gt;
&lt;p&gt;我的求职经历并不顺利，主要原因是对于求职的“求”字在认识上有所偏差。我不喜欢“求”，我认为找工作就和找对象一样，我想找你，你认可我，才行。我就这样，你不要我，拉倒。这种想法导致我并没有认真准备笔试面试。其实找工作和学校里的应试是一样一样的，所以你得做题，各种应试的题目，除了一流的公司，一般公司考的都是老题目或者类似的题目。另外，要注意找工作的目标不是向公司证明你的能力，而是拿到offer，“不择手段”地拿到offer。&lt;/p&gt;
&lt;p&gt;对自己未来几年做了基本的定位之后，我没有参加银行、国企一类公司的招聘，集中应聘技术型的私企外企大小公司，由于裸考裸面，结果多半不太理想。这里对于应聘的公司不做评价，求职的具体过程也不详述，只是真心感谢那些认可我赏识我的人，还有虽然拒了我但真心帮助我的人，谢谢你们。&lt;/p&gt;
&lt;p&gt;最后，腾讯收了我，虽然待遇和职位的工作内容不是很理想，但我想应该是个不错的机会，值得以后好好努力工作，感谢当时的几个面试官，也就是我以后的同事，当然还要特别感谢yuye同学，你也算是一个“奇葩”吧，哈哈，没有任何贬义哦。&lt;/p&gt;
&lt;p&gt;我之所以选择技术作为我的职业目标，一方面当然是因为我本来学的就是技术，但更重要的是因为做技术比较纯粹，我希望自己以后心里能一直很踏实安心。&lt;/p&gt;
&lt;h2&gt;毕业&lt;/h2&gt;
&lt;p&gt;说到毕业论文，一个字足以概括---“水”。哈哈，但幸好顺利毕业了，虽然过程很痛苦，很煎熬。现在的我无所事事，坐等毕业，哈哈。&lt;/p&gt;
&lt;p&gt;这次毕业与本科毕业有什么本质区别呢？那就是这次我是真的要结束读书的生活了，正式进入社会，需要承担的责任也是完全不相同的，并且以后我应该不会继续深造求学了。&lt;/p&gt;
&lt;p&gt;回顾十几年的读书生涯，实在难舍。&lt;/p&gt;
&lt;h2&gt;定亲&lt;/h2&gt;
&lt;p&gt;和女朋友相关的文字，我写得很少，自己也觉得有点对不住女朋友。其原因一方面是从我们认识到现在4年多的时间里，我正逐步地趋向沉默，文字表达越来越少；另一方面是我觉得幸福其实是一件挺私密的事情，不能多晒。所以，我不说并不是因为我不幸福，其实我一直幸福得偷着乐呢，哈哈。&lt;/p&gt;
&lt;p&gt;定亲的过程并没有想的那么顺利，要考虑很多问题，要和双方父母亲人沟通，特别是要和女朋友沟通，从恋爱逐步走向婚姻，会遇到很多很多现实的细节。面对现实，会产生矛盾，但没有什么大不了的，相爱的人请记住，矛盾没有什么大不了的，不要夸张了问题而放弃了情感。&lt;/p&gt;
&lt;h2&gt;谈谈自己&lt;/h2&gt;
&lt;p&gt;回顾从大一到现在的几年时间，我的变化应该算是蛮大的，我逐步地不再关注那些大层面上的事情，不去想那些形而上的问题。那些事情，那些问题，想不透，看不穿，也不会真的有解。这辈子，我们能做的其实很少很少，做些力所能及的事情也算是不浪费生命吧。也许有人认为这是“认命”了，认为我在逐渐成为一个“单向度”的人，但其实我还是想趁活着多扑腾几下的，按照自己的想法去活，只不过想法换了个方面。&lt;/p&gt;
&lt;h2&gt;未来一年&lt;/h2&gt;
&lt;p&gt;也得为这新的一年做点规划，定点目标啥的。可以从工作、健康、情感、技术等几个方面来谈吧。&lt;/p&gt;
&lt;p&gt;对于工作，我希望自己能够踏实些，逐步精通工作相关的技术，多认识一些人，对所处的技术行业有个更清晰的认识。&lt;/p&gt;
&lt;p&gt;身心健康应该始终放在第一位，要多运动锻炼，坚持跑步什么的，多出去走走，断然拒绝“宅”的习惯，特别是要多和女朋友出去玩，这个可以做个详细的计划。时间是靠自己安排的，理由也会有千万，但都不应接受其成为不注意身心健康的原因。&lt;/p&gt;
&lt;p&gt;情感方面，希望自己能够一如既往，并且更加耐心，细心，注意交流沟通。另外，要尽快完成婚姻的流程。&lt;/p&gt;
&lt;p&gt;说到技术，还是老毛病，有太多东西想学，不过现在学习方式在逐步进入良性循环，心态上也不会那么盲目了。接下来的一年里，自己必须不避重就轻，要攻关把核心技术练扎实，多写代码，多整理总结。&lt;/p&gt;
&lt;p&gt;过去的一年里，书籍阅读不多，也不见得是件坏事。不过新的一年里，应该要精读一些书，包括文史与技术类的，多思考。&lt;/p&gt;
&lt;p&gt;上述也说不上是规划，只是对自己提点要求和期望，希望自己在各方面都有所进步。&lt;/p&gt;</description>
            <pubDate>2013-01-18</pubDate>
            <link>https://blog.xiayf.cn/posts/review12-lookinto13.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/review12-lookinto13.html</guid>
        </item>
        
        <item>
            <title>装饰器与函数式 Python（译）</title>
            <description>&lt;p&gt;原文：&lt;a href=&apos;http://www.brianholdefehr.com/decorators-and-functional-python&apos;&gt;Decorators and Functional Python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;装饰器是Python的一大特色。除了在语言中的原本用处，还帮助我们以一种有趣的方式（函数式）进行思考。&lt;/p&gt;
&lt;p&gt;我打算自底向上解释装饰器如何工作。首先解释几个话题以帮助理解装饰器。然后，深入一点探索几个简单的装饰器以及它们如何工作。最后，讨论一些更高级的使用装饰器的方式，比如：传递可选参数给装饰器或者串接几个装饰器。&lt;/p&gt;
&lt;p&gt;首先以我能想到的最简单的方式来定义Python函数是什么。基于该定义，我们可以类似的简单方式来定义装饰器。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;函数是一个完成特定任务的可复用代码块。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;好的，那么装饰器又是什么呢？&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;装饰器是一个修改其他函数的函数。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;现在在装饰器的定义上进行详述，先解释一些先决条件。&lt;/p&gt;
&lt;h2&gt;函数是一等对象&lt;/h2&gt;
&lt;p&gt;Python中，所有东西都是对象。这意味着可以通过名字引用函数，以及像其他对象那样传递。例如：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def traveling_function():
    print &amp;amp;quot;Here I am!&amp;amp;quot;

function_dict = {
    &amp;amp;quot;func&amp;amp;quot;: traveling_function
}

trav_func = function_dict[&amp;amp;apos;func&amp;amp;apos;]
trav_func()
# &amp;amp;gt;&amp;amp;gt; Here I am!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;traveling_function&lt;/code&gt; 被赋值给 &lt;code&gt;function_dict&lt;/code&gt; 字典中键 &lt;code&gt;func&lt;/code&gt; 的值，仍旧可以正常调用。&lt;/p&gt;
&lt;h2&gt;一等函数允许高阶函数&lt;/h2&gt;
&lt;p&gt;我们可以像其他对象那样传递函数。可以将函数作为值传递给字典，放在列表中，或者作为对象的属性进行赋值。那为什么不能作为参数传给另一个函数呢？当然可以！如果一个函数接受另一个函数作为其参数或者返回另一个函数，则称之为高阶函数。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def self_absorbed_function():
    return &amp;amp;quot;I&amp;amp;apos;m an amazing function!&amp;amp;quot;

def printer(func):
    print &amp;amp;quot;The function passed to me says: &amp;amp;quot; + func()

# Call `printer` and give it `self_absorbed_function` as an argument
printer(self_absorbed_function)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function passed to me says: I&amp;amp;apos;m an amazing function!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在你也看到函数可以作为参数传给另一个函数，而且传给函数的函数还可以调用。这允许我们创建一些有意思的函数，例如装饰器。&lt;/p&gt;
&lt;h2&gt;装饰器基础&lt;/h2&gt;
&lt;p&gt;本质上，装饰器就是一个以另一个函数为参数的函数。大多数情况下，它们会返回所包装函数的一个修改版本。来看个我们能想到的最简单的装饰器---同一性（identity）装饰器，或许对我们理解装饰器的工作原理有所帮助。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def identity_decorator(func):
    def wrapper():
        func()
    return wrapper

def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

# `decorated_function` 是 `identity_function` 返回的函数，也就是嵌套函数 `wrapper`
decorated_function = identity_function(a_function)

# 如下调用 `identity_function` 返回的函数
decorated_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里， &lt;code&gt;identity_decorator&lt;/code&gt; 根本没有修改它包装的函数，只是简单地返回一个函数（wrapper），这个函数在被调用之时，会去调用原来作为 &lt;code&gt;identity_decorator&lt;/code&gt; 参数的函数。这是个没有用处的装饰器！&lt;/p&gt;
&lt;p&gt;关于 &lt;code&gt;identity_decorator&lt;/code&gt; 的有趣之处是 &lt;code&gt;wrapper&lt;/code&gt; 能够访问变量 &lt;code&gt;func&lt;/code&gt; ，即使 &lt;code&gt;func&lt;/code&gt; 并非是它的参数。这归因于闭包。&lt;/p&gt;
&lt;h2&gt;闭包&lt;/h2&gt;
&lt;blockquote&gt;&lt;p&gt;闭包是一个花哨的术语，意为声明一个函数时，该函数会维持一个指向声明所处词法环境的引用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;上例中定义的函数 &lt;code&gt;wrapper&lt;/code&gt; 能够在其局部作用域（local scope）中访问 &lt;code&gt;func&lt;/code&gt;。这意味着在 &lt;code&gt;wrapper&lt;/code&gt; （返回并赋值给变量 &lt;code&gt;decorated_function&lt;/code&gt; ）的整个生命周期内，它都可以访问 &lt;code&gt;func&lt;/code&gt; 变量。一旦 &lt;code&gt;identity_decorator&lt;/code&gt;返回，那么访问 &lt;code&gt;func&lt;/code&gt; 的唯一方式就是通过 &lt;code&gt;decorated_function&lt;/code&gt; 。 &lt;code&gt;func&lt;/code&gt; 只作为一个变量存在于 &lt;code&gt;decorated_function&lt;/code&gt; 作用域环境的内部。&lt;/p&gt;
&lt;h2&gt;一个简单的装饰器&lt;/h2&gt;
&lt;p&gt;现在我们来创建一个确实有点用的装饰器。这个装饰器所做的就是记录它所修改的函数被调用了多少次。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def logging_decorator(func):
    def wrapper():
        wrapper.count += 1
        print &amp;amp;quot;The function I modify has been called {0} time(s)&amp;amp;quot;.format(wrapper.count)
        func()
    wrapper.count = 0
    return wrapper

def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

modified_function = logging_decorator(a_function)

modified_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function I modify has been called 1 time(s).
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.

modified_function()
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; The function I modify has been called 2 time(s).
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们说装饰器会修改函数，这样来想对理解也是有帮助的。但如例子所见， &lt;code&gt;logging_decorator&lt;/code&gt; 返回的是一个类似于 &lt;code&gt;a_function&lt;/code&gt; 的新函数，只是多了一个日志特性。&lt;/p&gt;
&lt;p&gt;上例中， &lt;code&gt;logging_decorator&lt;/code&gt; 不仅接受一个函数作为参数，并且返回一个函数， &lt;code&gt;wrapper&lt;/code&gt; 。每次 &lt;code&gt;logging_decorator&lt;/code&gt; 返回的函数得到调用，它就对 &lt;code&gt;wrapper.count&lt;/code&gt; 的值加1，打印出来，然后调用 &lt;code&gt;logging_decorator&lt;/code&gt; 包装的函数。&lt;/p&gt;
&lt;p&gt;你也许正疑惑为什么我们的计数器是 &lt;code&gt;wrapper&lt;/code&gt; 的一个属性而不是一个普通的变量。难道 &lt;code&gt;wrapper&lt;/code&gt; 的闭包环境不是让我们访问在其局部作用域中声明的任意变量么？是的，但有个问题。Python中，闭包允许对其函数作用域链中任一变量的进行任意读操作，但只允许对可变对象（列表、字典、等等）进行写操作。整数在Python中是非可变对象，因此我们不能修改 &lt;code&gt;wrapper&lt;/code&gt; 内部整型变量的值。相反，我们将计数器作为 &lt;code&gt;wrapper&lt;/code&gt; 的一个属性---一个可变对象，因此可以随我们自己增大它的值。&lt;/p&gt;
&lt;h2&gt;装饰器语法&lt;/h2&gt;
&lt;p&gt;在前一个例子中，我们看到可以将一个函数作为参数传给装饰器，从而使用装饰器函数对该函数进行包装。然而，Python还有一个语法模式使得这一切更加直观，更容易阅读，一旦你熟悉了装饰器。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# In the previous example, we used our decorator function by passing the
# function we wanted to modify to it, and assigning the result to a variable
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m happiest when decorated.&amp;amp;quot;

# Here we will make the assigned variable the same name as the wrapped function
some_function = logging_decorator(some_function)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# We can achieve the exact same thing with this syntax:
@logging_decorator
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m happiest when decorated&amp;amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用装饰器语法，鸟瞰其中发生的事情：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;解释器到达被装饰的函数，编译 &lt;code&gt;some_function&lt;/code&gt;，并将其命名为 &apos;some_function&apos;。&lt;/li&gt;
&lt;li&gt;然后将该函数传递给装饰行中指定的装饰器函数（ &lt;code&gt;logging_function&lt;/code&gt; ）。&lt;/li&gt;
&lt;li&gt;装饰器函数（通常是用来包装原函数的另一个函数）的返回值取代原来的函数（&lt;code&gt;some_function&lt;/code&gt; ），绑定到变量名 &lt;code&gt;some_function&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;将这些步骤记住，让我们来更清晰地解释 &lt;code&gt;identity_decorator&lt;/code&gt; 。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def identity_decorator(func):
    # Everything here happens when the decorator LOADS and is passed
    # the function as decribed in step 2 above
    def wrapper():
        # Things here happen each time the final wrapped function gets CALLED
        func()
    return wrapper&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;希望那些注释有助于理解。每次调用被包装的函数，仅执行装饰器返回的函数中的指令。返回函数之外的指令仅执行一次---上述步骤2中描述的：装饰器首次接收到传递给它的待包装函数之时。&lt;/p&gt;
&lt;p&gt;在观察更多的有意思的装饰器之前，我想再解释一样东西。&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;*args&lt;/code&gt; 与 &lt;code&gt;**kwargs&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;以前你也许有时会把这两者相混淆了。让我们一次性地讨论它们。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;通过在形参列表中使用 &lt;code&gt;*args&lt;/code&gt; 语法，python函数能够接收可变数量的位置参数(positional arguments)。 &lt;code&gt;*args&lt;/code&gt; 会将所有没有关键字的参数放入一个参数元组中，在函数里可以访问元组中的参数。相反，将 &lt;code&gt;*args&lt;/code&gt; 用于函数调用时的实参列表之时，它会将参数元组展开成一系列的位置参数。&lt;/li&gt;&lt;/ul&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def function_with_many_arguments(*args):
    print args

# `args` within the function will be a tuple of any arguments we pass
# which can be used within the function like any other tuple
function_with_many_arguments(&amp;amp;apos;hello&amp;amp;apos;, 123, True)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; (&amp;amp;apos;hello&amp;amp;apos;, 123, True)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def function_with_3_parameters(num, boolean, string):
    print &amp;amp;quot;num is &amp;amp;quot; + str(num)
    print &amp;amp;quot;boolean is &amp;amp;quot; + str(boolean)
    print &amp;amp;quot;string is &amp;amp;quot; + string

arg_list = [1, False, &amp;amp;apos;decorators&amp;amp;apos;]

# arg_list will be expanded into 3 positional arguments by the `*` symbol
function_with_3_parameters(*arg_list)
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; num is 1
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; boolean is False
# &amp;amp;gt;&amp;amp;gt;&amp;amp;gt; string is decorators&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重述一遍：在形参列表中， &lt;code&gt;*args&lt;/code&gt;会将一系列的参数压缩进一个名为&apos;args&apos;的元组，而在实参列表中， &lt;code&gt;*args&lt;/code&gt; 会将一个可迭代的参数数据结构展开为一系列的位置实参应用于函数。&lt;/p&gt;
&lt;p&gt;如你所见在实参展开的例子中， &lt;code&gt;*&lt;/code&gt; 符号可与&apos;args&apos;之外的名字一起使用。当压缩/展开一般的参数列表，使用 &lt;code&gt;*args&lt;/code&gt; 的形式仅仅是一种惯例。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;**kwargs&lt;/code&gt; 与 &lt;code&gt;*args&lt;/code&gt; 的行为类似，但用于关键字参数而非位置参数。如果在函数的形参列表中使用 &lt;code&gt;**kwargs&lt;/code&gt; ，它会收集函数收到的所有额外关键字参数，放入一个字典中。如果用于函数的实参列表，它会将一个字典展开为一系列的关键字参数。&lt;/li&gt;&lt;/ul&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def funtion_with_many_keyword_args(**kwargs):
    print kwargs

function_with_many_keyword_args(a=&amp;amp;apos;apples&amp;amp;apos;, b=&amp;amp;apos;bananas&amp;amp;apos;, c=&amp;amp;apos;cantalopes&amp;amp;apos;)
# &amp;amp;gt;&amp;amp;gt; {&amp;amp;apos;a&amp;amp;apos;:&amp;amp;apos;apples&amp;amp;apos;, &amp;amp;apos;b&amp;amp;apos;:&amp;amp;apos;bananas&amp;amp;apos;, &amp;amp;apos;c&amp;amp;apos;:&amp;amp;apos;cantalopes&amp;amp;apos;}&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def multiply_name(count=0, name=&amp;amp;apos;&amp;amp;apos;):
    print name * count

arg_dict = {&amp;amp;apos;count&amp;amp;apos;: 3, &amp;amp;apos;name&amp;amp;apos;: &amp;amp;apos;Brian&amp;amp;apos;}

multiply_name(**arg_dict)
# &amp;amp;gt;&amp;amp;gt; BrianBrianBrian&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;既然你理解了 &lt;code&gt;*args&lt;/code&gt; 与 &lt;code&gt;**kwargs&lt;/code&gt; 的工作原理，那么我们就继续研究一个你会发现很有用的装饰器。&lt;/p&gt;
&lt;h2&gt;缓存制表（Memoization）&lt;/h2&gt;
&lt;p&gt;缓存制表是避免潜在的昂贵的重复计算的一种方法，通过缓存函数每次执行的结果来实现。这样，下一次函数以相同的参数执行，就可以从缓存中获取返回结果，不需要再次计算结果。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

def memoize(func):
    cache = {}

    @wraps(func)
    def wrapper(*args):
        if args not in cache:
            cache[args] = func(*args)
        return cache[args]
    return wrapper

@memoize
def an_expensive_function(arg1, arg2, arg3):
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你可能注意到了示例代码中一个奇怪的 &lt;code&gt;@wraps&lt;/code&gt; 装饰器。在完整地讨论 &lt;code&gt;memoize&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;之前我将简要地解释这个装饰器。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用装饰器的一个副作用是被包装的函数失去了本来有的 &lt;code&gt;__name__&lt;/code&gt; ， &lt;code&gt;__doc__&lt;/code&gt; ， 以及 &lt;code&gt;__module__&lt;/code&gt; 属性。 &lt;code&gt;wraps&lt;/code&gt; 函数是一个包装另一个装饰器返回的函数的装饰器，将那三个属性的值恢复为函数未装饰之时的值。例如： 如果不使用 &lt;code&gt;wraps&lt;/code&gt; 装饰器， &lt;code&gt;an_expensive_function&lt;/code&gt; 的名字（通过 &lt;code&gt;an_expensive_function.__name__&lt;/code&gt; 可以看到）将是 &apos;wrapper&apos; 。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;我认为 &lt;code&gt;memoize&lt;/code&gt; 是一个很好的装饰器用例。它服务于一个很多函数都需要的目的，通过将它创建为一个通用装饰器，我们可以将它的功能应用于任一能够从其中获益的函数。这就避免了在多种不同的场合重复实现这个功能。因为不需要重复自己，所以我们的代码更容易维护，并且更容易阅读和理解。只要读一个单词你就能立刻理解函数使用了缓存制表。&lt;/p&gt;
&lt;p&gt;需要提醒的是：缓存制表仅适用于纯函数。也就是说给定一个特定的参数设置，函数确定总会产生相同的结果。如果函数依赖于不作为参数传递的全局变量、I/O、或者其它任意可能影响返回值的东西，缓存制表会产生令人迷惑的结果！并且，一个纯函数不会有任何副作用。因此，如果你的函数会增大一个计数器，或者调用另一个对象的方法，或者其它任意不在函数的返回结果中表示的东西，当结果是从缓存中返回时，副作用操作并不会得到执行。&lt;/p&gt;
&lt;h2&gt;类的装饰器&lt;/h2&gt;
&lt;p&gt;最初，我们说装饰器是一个修改另一个函数的函数，但其实它们可以用于修改类或者方法。对类进行装饰并不常见，但某些情况下作为元类(metaclass)的一个替代，类的装饰器是一个有用的工具。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;foo = [&amp;amp;apos;important&amp;amp;apos;, &amp;amp;apos;foo&amp;amp;apos;, &amp;amp;apos;stuff&amp;amp;apos;]

def add_foo(klass):
    klass.foo = foo
    return klass


@add_foo
class Person(object):
    pass

brian = Person()

print brian.foo
# &amp;amp;gt;&amp;amp;gt; [&amp;amp;apos;important&amp;amp;apos;, &amp;amp;apos;foo&amp;amp;apos;, &amp;amp;apos;stuff&amp;amp;apos;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在，类 &lt;code&gt;Person&lt;/code&gt; 的任一对象都有一个超级重要的 &lt;code&gt;foo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;属性！注意，因为我们装饰的是一个类，所以装饰器返回的不是一个函数，而是一个类。更新一下装饰器的定义：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;装饰器是一个修改函数、或方法、或类的函数。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;装饰器类&lt;/h2&gt;
&lt;p&gt;事实证明我早先对你隐瞒了一些其它事情。不仅装饰器可以装饰一个类，并且装饰器也可以是一个类！对于装饰器的唯一要求就是它的返回值必须可调用(callable)。这意味着装饰器必须实现 &lt;code&gt;__call__&lt;/code&gt; 魔术方法，当你调用一个对象时，会隐式调用这个方法。函数当然是隐式设置这个方法的。我们重新将 &lt;code&gt;identity_decorator&lt;/code&gt; 创建为一个类来看看它是如何工作的。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class IdentityDecorator(object):
    def __init__(self, func):
        self.func = func

    def __call__(self):
        self.func()


@IdentityDecorator
def a_function():
    print &amp;amp;quot;I&amp;amp;apos;m a normal function.&amp;amp;quot;

a_function()
# &amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m a normal function.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如下是上例中发生的事情：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当 &lt;code&gt;IdentityDecorator&lt;/code&gt; 装饰 &lt;code&gt;a_function&lt;/code&gt; 时，它的行为就和装饰器函数一样。这个代码片段等价于上例中的装饰器语法： &lt;code&gt;a_function = IdentityDecorator(a_function)&lt;/code&gt; 。调用（实例化）该装饰器类时，需将其装饰的函数作为一个实参传递给它。&lt;/li&gt;
&lt;li&gt;实例化 &lt;code&gt;IdentityDecorator&lt;/code&gt; 之时，会以被装饰的函数作为实参调用初始化函数 &lt;code&gt;__init__&lt;/code&gt; 。本例中，初始化函数所做的事情就是将被装饰函数赋值给一个属性，这样之后就可以通过其它方法进行调用。&lt;/li&gt;
&lt;li&gt;最后，调用 &lt;code&gt;a_function&lt;/code&gt; （实际上是返回的包装了 &lt;code&gt;a_function&lt;/code&gt; 的 &lt;code&gt;IdentityDecorator&lt;/code&gt; 对象）之时，会调用对象的 &lt;code&gt;__call__&lt;/code&gt; 方法。这仅是一个同一性装饰器，所以方法只是简单地调用了该类所装饰的函数。&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;再次更新一下我们对装饰器的定义！&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;装饰器是一个修改函数、方法或者类的可调用对象。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;带参数的装饰器&lt;/h2&gt;
&lt;p&gt;有时，需要根据不同的情况改变装饰器的行为。你可以通过传参来做到这一点。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

def argumentative_decorator(gift):
    def func_wrapper(func):
        @wraps(func)
        def returned_wrapper(*args, **kwargs):
             print &amp;amp;quot;I don&amp;amp;apos;t like this &amp;amp;quot; + gift + &amp;amp;quot;you gave me!&amp;amp;quot;
             return func(gift, *args, **kwargs)
        return returned_wrapper
    return func_wrapper

@argumentative_decorator(&amp;amp;quot;sweater&amp;amp;quot;)
def grateful_function(gift):
    print &amp;amp;quot;I love the &amp;amp;quot; + gift + &amp;amp;quot;!Thank you!&amp;amp;quot;

grateful_function()
# &amp;amp;gt;&amp;amp;gt; I don&amp;amp;apos;t like this sweater you gave me!
# &amp;amp;gt;&amp;amp;gt; I love the sweater! Thank you!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们来看看如果不使用装饰器语法这个装饰器函数是如何工作的：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;# If we tried to invoke without an argument:
grateful_function = argumentative_function(grateful_function)

# But when given an argument, the pattern changes to:
grateful_function = argumentative_decorator(&amp;amp;quot;sweater&amp;amp;quot;)(grateful_function)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;需要注意的地方是：当给定参数，首先仅以那些参数调用装饰器---被包装的函数并不在参数中。装饰器调用返回后，装饰器要包装的函数被传递给装饰器初始调用返回的函数（本例中，为 &lt;code&gt;argumentative_decorator(&amp;quot;sweater&amp;quot;)&lt;/code&gt; 的返回值）。&lt;/p&gt;
&lt;p&gt;逐步地：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;解释器到达被装饰函数之处，编译 &lt;code&gt;grateful_function&lt;/code&gt; ，并将其绑定到名字&apos;grateful_function&apos;。&lt;/li&gt;
&lt;li&gt;传递参数&quot;sweater&quot;调用 &lt;code&gt;argumentative_decorator&lt;/code&gt; ，返回 &lt;code&gt;func_wrapper&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;以 &lt;code&gt;grateful_function&lt;/code&gt; 为参调用 &lt;code&gt;func_wrapper&lt;/code&gt; ，返回 &lt;code&gt;returned_wrapper&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;最后， &lt;code&gt;returned_wrapper&lt;/code&gt; 取代原来的函数 &lt;code&gt;grateful_function&lt;/code&gt; ，并绑定到名字&apos;grateful_function&apos; 。&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;我想这一过程相比没有装饰器参数理解起来更难一点，但是如果你花些时间将其理解通透，我希望是有意义的。&lt;/p&gt;
&lt;h2&gt;带可选参数的装饰器&lt;/h2&gt;
&lt;p&gt;有多种方式让装饰器接受可选参数。根据你是想使用位置参数、关键字参数还是两者皆是，需要使用稍微不同的模式。如下我将展示一种接受一个可选关键字参数的方式：&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;from functools import wraps

GLOBAL_NAME = &amp;amp;quot;Brian&amp;amp;quot;

def print_name(function=None, name=GLOBAL_NAME):
    def actual_decorator(function):
        @wraps(function)
        def returned_func(*args, **kwargs):
            print &amp;amp;quot;My name is &amp;amp;quot; + name
            return function(*args, **kwargs)
        return returned_func

    if not function:    # User passed in a name argument
        def waiting_for_func(function):
            return actual_decorator(function)
        return waiting_for_func

    else:
        return actual_decorator(function)

@print_name
def a_function():
    print &amp;amp;quot;I like the name!&amp;amp;quot;

@print_name(name=&amp;amp;apos;Matt&amp;amp;apos;)
def another_function():
    print &amp;amp;quot;Hey, that&amp;amp;apos;s new!&amp;amp;quot;

a_function()
# &amp;amp;gt;&amp;amp;gt; My name is Brian
# &amp;amp;gt;&amp;amp;gt; I like that name!

another_function()
# &amp;amp;gt;&amp;amp;gt; My name is Matt
# &amp;amp;gt;&amp;amp;gt; Hey, that&amp;amp;apos;s new!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们传递关键字参数 &lt;code&gt;name&lt;/code&gt; 给 &lt;code&gt;print_name&lt;/code&gt;，那么它的行为就与前一个例子中的 &lt;code&gt;argumentative_decorator&lt;/code&gt; 相似。即，首先以 &lt;code&gt;name&lt;/code&gt; 为参调用 &lt;code&gt;print_name&lt;/code&gt; 。然后，将待包装的函数传递给首次调用返回的函数。&lt;/p&gt;
&lt;p&gt;如果我们没有提供 &lt;code&gt;name&lt;/code&gt; 实参， &lt;code&gt;print_name&lt;/code&gt; 的行为就与前面我们看到的不带参数的装饰器一样。装饰器仅以待包装的函数作为唯一的参数进行调用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;print_name&lt;/code&gt; 支持两种可能性。它会检查是否收到作为参数的被包装函数。如果没有，则返回函数&lt;/p&gt;
&lt;p&gt;&lt;code&gt;waiting_for_func&lt;/code&gt;，该函数可以被包装函数作为参数进行调用。如果收到被包装函数作为参数，则跳过中间步骤，直接调用 &lt;code&gt;actual_decorator&lt;/code&gt; 。&lt;/p&gt;
&lt;h2&gt;串接装饰器&lt;/h2&gt;
&lt;p&gt;现在来探索一下今天要讲的最后一个装饰器的特性：串接。你可以在任意给定的函数之上堆叠使用多个装饰器， 这种构建函数的方式与使用多重继承构建类相类似。不过最好不要疯狂使用这种特性。&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@print_name(&amp;amp;apos;Sam&amp;amp;apos;)
@logging_decorator
def some_function():
    print &amp;amp;quot;I&amp;amp;apos;m the wrapped function!&amp;amp;quot;

some_function()
# &amp;amp;gt;&amp;amp;gt; My name is Sam
# &amp;amp;gt;&amp;amp;gt; The function I modify has been called 1 time(s).
# &amp;amp;gt;&amp;amp;gt; I&amp;amp;apos;m the wrapped function!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当你串接使用装饰器时，它们堆叠的顺序是自底向上的。将被包装的函数 &lt;code&gt;some_function&lt;/code&gt; 经编译后传递给它之上的第一个装饰器（ &lt;code&gt;logging_decorator&lt;/code&gt; ）。然后第一个装饰器的返回值被传递给第二个装饰器。依此逐个应用链上每个装饰器。&lt;/p&gt;
&lt;p&gt;因为我们使用的两个装饰器都是 &lt;code&gt;print&lt;/code&gt; 一个值，然后执行传递给它们的函数，这意味着当调用被包装函数时，链中的最后一个装饰器 &lt;code&gt;print_name&lt;/code&gt; 打印输出中的第一行。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;我认为装饰器最大的好处之一在于让你能够从更高的抽象层次进行思考。假如你开始阅读一个函数定义，看到有一个 &lt;code&gt;memoize&lt;/code&gt; 装饰器，你立刻就能明白你正在看的是一个使用缓存制表的函数。如果缓存制表的代码包含在函数体内，就会需要额外的脑力进行解析，并且会有引入误解的可能。使用装饰器也允许代码复用，从而节省时间、简化调试，并且使得重构更加容易。&lt;/p&gt;
&lt;p&gt;玩玩装饰器也是一种很好的学习函数式概念（如高阶函数与闭包）的方式。&lt;/p&gt;
&lt;p&gt;我希望本文阅读起来很愉快，并且内容翔实。&lt;/p&gt;</description>
            <pubDate>2013-01-04</pubDate>
            <link>https://blog.xiayf.cn/posts/decorators-and-functional-python.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/decorators-and-functional-python.html</guid>
        </item>
        
        <item>
            <title>Python装饰器入门（译）</title>
            <description>&lt;p&gt;原文: &lt;a href=&apos;http://www.thumbtack.com/engineering/a-primer-on-python-decorators/&apos;&gt;A primer on Python decorators&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python允许你，作为程序员，使用函数完成一些很酷的事情。在Python中，函数是&lt;a href=&apos;http://en.wikipedia.org/wiki/First-class_function&apos;&gt;一等对象(first-class object)&lt;/a&gt;，这就意味着你可以像使用字符串，整数，或者任何其他对象一样使用函数。例如，你可以将函数赋值给变量:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def square(n):
...     return n * n;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; square(4)
16
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; alias = square
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; alias(4)
16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然而，一等函数的真正威力在于你可以把函数传给其他函数，或者从其他函数中返回函数。Python的内置函数map利用了这种能力：给map传个函数以及一个列表，它会依次以列表中每个元素为参数调用你传给它的那个函数，从而生成一个新的列表。如下所示的例子中应用了上面的那个square函数:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; number = [1, 2, 3, 4, 5]
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; map(square, numbers)
[1, 4, 9, 16, 25]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果一个函数接受其他函数作为参数，以及/或者返回一个函数，那么它就被称为&lt;a href=&apos;http://en.wikipedia.org/wiki/Higher-order_function&apos;&gt;高阶函数&lt;/a&gt; 。虽然map函数只是简单地使用了我们传给它的函数，而没有改变这个函数，但我们也可以使用高阶函数去改变其他函数的行为。&lt;/p&gt;
&lt;p&gt;例如，假设有这样一个函数，会被调用很多次，以致运行代价非常昂贵:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def fib(n):
...      &amp;amp;quot;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;quot;
...      return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们一般会保存计算过程中每次递归调用的结果，这样，对于函数调用树中经常出现某个n，当需要计算n对应的结果时，就不需要重复计算了。有多种方式可以做到这点。例如，我们可以将这些结果存在一个字典中，当以某个值为参数调用fib函数时，就先到这个字典去查一下其结果是否已经计算出来了。&lt;/p&gt;
&lt;p&gt;但这样的话，每次我们想要调用fib函数，都需要重复那段相同的字典检查样板式代码。相反，如果让fib函数自己在内部负责存储其结果，那么在其他代码中调用fib，就非常方便，只要简单地调用它就行了。这样一种技术被称为&lt;a href=&apos;http://en.wikipedia.org/wiki/Memoization&apos;&gt;memoization&lt;/a&gt;(注意没有字母r的哦)。&lt;/p&gt;
&lt;p&gt;我们可以把这种memoization代码直接放入fib函数，但是Python为我们提供了另外一种更加优雅的选择。因为可以编写修改其他函数的函数，那么我们可以编写一个通用的memoization函数，以一个函数作为参数，并返回这个函数的memoization版本:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def memoize(fn):
    stored_results = {}

    def memoized(*args):
        try:
            # try to get the cached result
            return stored_results[args]
        except KeyError:
            # nothing was cached for those args. let&amp;amp;apos;s fix that.
            result = stored_results[args] = fn(*args)
            return result
    return memoized&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如上， &lt;code&gt;memoize&lt;/code&gt; 函数以另一个函数作为参数，函数体中创建了一个字典对象用来存储函数调用的结果：键为被memoized包装后的函数的参数，值为以键为参数调用函数的返回值。 &lt;code&gt;memoize&lt;/code&gt; 函数返回一个新的函数，这个函数会首先检查在 &lt;code&gt;stored_results&lt;/code&gt; 字典中是否存在与当前参数对应的条目；如果有，对应的存储值会被返回；否则，就调用经过包装的函数，存储其返回值，并且返回给调用者。memoize返回的这种新函数常被称为&quot;包装器&quot;函数，因为它只是另外一个真正起作用的函数外面的一个薄层。&lt;/p&gt;
&lt;p&gt;很好，现在有了一个memoization函数，我们可以把fib函数传给它，从而得到一个经过包装的fib，这个版本的fib函数不需要重复以前那样的繁重工作:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
fib = memoize(fib)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过高阶函数memoize，我们获得了memoization带来的好处，并且不需要对fib函数自己做出任何改变，以免夹杂着memoization的代码而模糊了函数的实质工作。但是，你也许注意到上面的代码还算有点别扭，因为我们必须写3遍fib。由于这种模式-传递一个函数给另一个函数，然后将结果返回给与原来那个函数同名的函数变量-在使用包装器函数的代码中极为常见，Python为其提供了一种特殊的语法：装饰器:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memoize
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n -1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们说memoize函数装饰了fib函数。需要注意的是这仅是一种语法上的简便写法(译注：就是我们常说的&quot;语法糖&quot;)。这段代码与前面的代码片段做的是同样的事情：定义一个名为fib的函数，把它传给memoize函数，将返回结果存为名为fib的函数变量。特殊的(看起来有点奇怪的)@语法只是减少了冗余。&lt;/p&gt;
&lt;p&gt;你可以将多个装饰器堆叠起来使用，它们会自底向上地逐个起作用。例如，假设我们还有另一个用来帮助调试的高阶函数:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def make_verbose(fn):
    def verbose(*args):
        # will print (e.g.) fib(5)
        print &amp;amp;apos;%s(%s)&amp;amp;apos; % (fb.__name__, &amp;amp;apos;, &amp;amp;apos;.join(repr(arg) for arg in args))
        return fn(*args)   # actually call the decorated function

    return verbose&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的两个代码片段做的是同样的事情:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memoize
@make_verbose
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
fib = memoize(make_verbose(fib))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有趣的是，Python并没有限制你在@符号后只能写一个函数名：你也可以调用一个函数，从而能够高效地传递参数给装饰器。假设我们并不满足于简单的memoization，还想将函数的结果存储到&lt;a href=&apos;http://memcached.org/&apos;&gt;memcached&lt;/a&gt;中。如果你已经写了一个 &lt;code&gt;memcached&lt;/code&gt; 装饰器函数，那么可以(例如)传递一个服务器地址给它:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;@memcached(&amp;amp;apos;127.0.0.1:11211&amp;amp;apos;)
def fib(n):
    return n if n in [0, 1] else fib(n - 2) + fib(n - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非装饰器语法的写法会如下展开:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;fib = memcached(&amp;amp;apos;127.0.0.1:11211&amp;amp;apos;)(fib)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Python配备有一些作为装饰器使用的非常有用的函数。例如，Python有一个 &lt;code&gt;classmethod&lt;/code&gt; 函数，可以创建大致类似于java的静态方法:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;class Foo(object):
    SOME_CLASS_CONSTANT = 42

    @classmethod
    def add_to_my_constant(cls, value):
        # Here, `cls` will just be Foo, buf if you called this method on a
        # subclass of Foo, `cls` would be that subclass instead.
        return cls.SOME_CLASS_CONSTANT + value

Foo.add_to_my_constant(10)  # =&amp;amp;gt; 52

# unlike in Java, you can also call a classmethod on an instance
f = Foo()
f.add_to_my_constant(10)    # =&amp;amp;gt; 52&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;旁注：文档字符串&lt;/h2&gt;
&lt;p&gt;Python函数可以包含更多的信息，而不仅仅是代码：它们也包含有用的帮助信息，比如函数名称，文档字符串:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; def fib(n):
...     &amp;amp;quot;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;quot;
...     return n if n in [0, 1] else fib(n - 2) + fib(n - 1)
...
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;fib&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__
&amp;amp;apos;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Python内置函数&lt;a href=&apos;http://docs.python.org/library/functions.html#help&apos;&gt;help&lt;/a&gt;输出的就是这些信息。但是，当函数被包装之后，我们看到就是包装器函数的名称和文档字符串了:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib = memoized(fib)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;memoized&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那样的信息并没有什么用处。幸运的是，Python包含一个名为 &lt;code&gt;functools.wraps&lt;/code&gt; 的助手函数，能够把函数的帮助信息拷贝到其包装器函数:&lt;/p&gt;
&lt;pre class=&quot;language-python&quot;&gt;&lt;code&gt;import functools
def memoize(fn):
    stored_results = {}
        
    @functools.wraps(fn)
    def memoized(*args):
        # (as before)

    return memoized&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用装饰器帮助你编写装饰器会使很多事情令人非常满意。现在，如果使用更新过的memoize函数重试前面的代码，我们将会看到得到保留的文档:&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib = memoized(fib)
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__name__
&amp;amp;apos;fib&amp;amp;apos;
&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; fib.__doc__
&amp;amp;apos;Recursively (i.e., dreadfully) calculate the nth Fibonacci number.&amp;amp;apos;&lt;/code&gt;&lt;/pre&gt;</description>
            <pubDate>2012-07-30</pubDate>
            <link>https://blog.xiayf.cn/posts/a-primer-on-python-decorators.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/a-primer-on-python-decorators.html</guid>
        </item>
        
        <item>
            <title>关于技术的学习方法</title>
            <description>&lt;p&gt;关于学习，时间短与效果好始终是一对矛盾的统一体。&lt;/p&gt;
&lt;p&gt;很多时候，要想在最短的时间内完成一件事情，最好的方法就是依葫芦画瓢，但这样的话，即使完成了事情，也只是知其然而不知其所以然，长久来看，对于学习者的能力不会有多大的提高。&lt;/p&gt;
&lt;p&gt;从长远来看，要想自己基础扎实，能力强，那就得一步一步的来，从基础知识开始，一点一点的搞懂，但这种方式需要花费很多时间，短时间内效果不明显。而且，可能效果没有预期的那么好。&lt;/p&gt;
&lt;p&gt;那么，如果做个权衡呢？&lt;/p&gt;
&lt;p&gt;我想，也许最好的学习方式是：先依葫芦画瓢地实践，获得一些直观感受，最好还有一些疑问。在实践完成之后，在整理自己的疑问，以及实践中涉及的知识要点，通过查阅图书或者网络资料，逐个知识点巩固，逐个解决疑问，并整理成文。这个整理总结的过程可能需要较长的时间。&lt;/p&gt;
&lt;p&gt;这种方式的优势在于：1.能让你快速地完成事情；2.实践中用到的知识多半会在以后的实践中经常用到，掌握的就是一些最重要的东西，而不会学习一些很少使用的深奥偏门知识。&lt;/p&gt;</description>
            <pubDate>2012-05-11</pubDate>
            <link>https://blog.xiayf.cn/posts/about-method-of-learning-technology.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/about-method-of-learning-technology.html</guid>
        </item>
        
        <item>
            <title>学习的"道"与"术"</title>
            <description>&lt;p&gt;读研以来，一直觉得自己的学习方法不够高效。试图将要学习的东西进行分类，然后以不同的方法学习之。那么该如何分类呢？我觉得以&quot;道&quot;与&quot;术&quot;区分之比较合适。&lt;/p&gt;
&lt;p&gt;何为&quot;道 &quot;？汉语辞典中有两条解释：&lt;strong&gt;1.指法则、规律；2.学术或宗教的思想体系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;何为&quot;术&quot;？：&lt;strong&gt;技艺&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;字面理解，“术”更为具体，是完成一件事情的具体过程。而“道”者则是指导实践的思想，是能够举一反三的事物规律。&lt;/p&gt;
&lt;p&gt;那么是否“道”比“术”更重要呢？我想未必。任何理论，任何“道”都最终来源于“术”的实践过程，也最终需要在“术”上得到实施，才能体现其价值。“道”与“术”两者相辅相成。那么在我们学习一门学问的过程中，就存在一个“道”与“术”何者为先的问题，即从“道”还是“术”入手学习？&lt;/p&gt;
&lt;p&gt;孟岩说过这么一段话：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;我主张,在具备基础之后,学习任何新东西,都要抓住主线,突出重点。对于关键理论的学习,要集中精力,速战速决。而旁枝末节和非本质性的知识内容,完全可以留给实践去零敲碎打。&lt;/p&gt;
&lt;p&gt;原因是这样的,任何一个高级的知识内容,其中都只有一小部分是有思想创新、有重大影响的,而其它很多东西都是琐碎的、非本质的。因此,集中学习时必须把握住真正重要那部分,把其它东西留给实践。对于重点知识,只有集中学习其理论,才能确保体系性、连贯性、正确性,而对于那些旁枝末节,只有边干边学能够让你了解它们的真实价值是大是小,才能让你留下更生动的印象。如果你把精力用错了地方,比如用集中大块的时间来学习那些本来只需要查查手册就可以明白的小技巧,而对于真正重要的、思想性东西放在平时零敲碎打,那么肯定是事倍功半,甚至适得其反。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;虽然这段话并没有明确区分学习的“道”与“术”，以及何者为先的问题。但却大致说明了何为正确的学习方法。&lt;/p&gt;
&lt;p&gt;从“道”与“术”的角度来理解，那关键的，核心的，创新的部分即为“道”，“大道”。而那细节的则是“术”的部分，是需要长时间的实践的，也许只有在实践中遇到的细节才是有意义的。&lt;/p&gt;
&lt;p&gt;但那“具备基础之后”的“基础”是什么呢？我想应该是：1.明确问题是什么。这一点是再怎么强调都不为过的。要解决一个问题却没有真正明确问题到底是什么，那你努力多半是白费的。2.这东西是用来干什么用的，是用来解决什么问题的？对于工科学生来说，学习新东西的时候，这一点是需要首先明确的，只有明确了“干什么用的”，才能抓住学习的重点，提高学习的效率。3. 与以前的类似的东西相比，其区别是什么？一样东西，一种理论其价值往往在于对前人的突破，这突破的地方才是我们真正要掌握的。在学习一样东西之前，不妨多问问自己为什么要学这个，这东西对自己有多大的提升？不断地重复学习类似的东西，多半是没有意义的。&lt;/p&gt;
&lt;p&gt;具备了基础之后，对于关键理论的学习，是不是只要抱着书本，理论对理论的学习就行呢？我想这是万万不可的。特别是对于着重于实践性的学问，比如编程，理论对理论地学习，只会让你吃力不讨好。绝大多数的创新理论，核心理论，都不是一下子就能理解的，特别是当你对这一领域的学问并不熟悉的情况下，它需要在反复的实践中逐步地加深理解。&lt;/p&gt;
&lt;p&gt;那么对于关键内容的学习，我觉得这样学习会比较合适：先快速地，在尽可能短的时间内把关键内容浑沦吞枣地过一遍，能理解多少是多少，目的是为了获得一个理论的一个Big Picture，明确理论的各个部分之间的大致关系。然后对于每个部分，以及部分之间的关系，逐个地通过实践来验证你的理解，但这个实践过程并不属于“术”，因为它不是为了技艺，而只是为了验证自己对理论的理解。这一验证过程结束之后，你应该就能够对关键理论有个整体的正确的理解了。&lt;/p&gt;
&lt;p&gt;然后，你就放开手去干吧，去解决那些现实中的问题！&lt;/p&gt;
&lt;p&gt;也许，你会说，不用这么复杂吧？是的，如果你只是为了解决一个实际的问题，而这个问题也存在相近的解决方案，你不想也不需要弄懂这个问题，好吧，那你就直接去找解决方案吧。但你解决这个问题之后，你学到了什么呢？当你再次遇到一个本质上一样的问题的时候，你还是能快速地解决么？没有真正弄懂问题，没有弄懂问题背后的知识，那你就准备着为类似的问题重复地去寻找解决方案吧。恩，看起来有点傻哦。&lt;/p&gt;</description>
            <pubDate>2012-03-31</pubDate>
            <link>https://blog.xiayf.cn/posts/dao-and-shu-about-learning.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/dao-and-shu-about-learning.html</guid>
        </item>
        
        <item>
            <title>Python学习路线(针对具备一定编程经验者)</title>
            <description>&lt;p&gt;相比C,C++,JAVA等编程语言，Python是易学的。但要想深入地理解Python，并熟练地编写Python风格的Python代码。我想还是有一长段路程要走的。下面即是我的一点经验总结，主要是为了整理自己学习的思路。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;花1-2天的时间阅读一本好的Python入门书籍，并在亲手实践书中的代码。推荐入门书籍：《A byte of Python》(中文翻译《简明Python教程》)或《Practical Programming:An Introduction to Computer Science Using Python》(中文翻译《Python实践教程》)或者其他的比较薄的入门书籍。&lt;/li&gt;
&lt;li&gt;抛开书籍，用Python去写一切你想写的程序。这时最好的参考文档即为：(1).Python命令解释器中的help(),dir()辅助方法；(2).Python官网文档：&lt;a href=&apos;http://docs.python.org/&apos;&gt;http://docs.python.org/&lt;/a&gt; 。遇到不清楚的地方就用这两个方法查，再不行就去google一下。&lt;/li&gt;
&lt;li&gt;两三个月之后，积累一点的代码量，再重新找本讲解比较详细的书，重新梳理一下自己对Python的理解，纠正自己实践中一些不好的方式。推荐书籍：《Beginning Python: From Novice to Professional》(中文翻译《Python基础教程》)，《Learning Python》(中文翻译《Python学习手册》)，《Dive into Python》，《Core Python Programming》等。另外，也应该在编码的过程中重复地去查阅Python标准函数库，标准库里已有模块实现的功能就不要自己实现。&lt;/li&gt;
&lt;li&gt;之后，根据实际需要，去了解使用一下Python的各个方面的函数库(比如http://docs.python.org/modindex.html中罗列出来的，以及matplotlib, numpy等用于科学计算，图形图像处理的)，特别是诸多的Web框架(django, web2py, cherrypy, tornado等)，可以先从简单的开始。如果是对Python的底层实现感兴趣，那么就该去看看Python源码，阅读一下《Python源码剖析》; 如果对文本处理感兴趣，可以阅读一下《Text processing in Python》等； 如果对网络感兴趣，可以阅读《Foundations of Python Network Programming》，尝试实现一个简单的web server ...&lt;/li&gt;
&lt;li&gt;Python相关的开源函数库非常非常的多，各个方面的都有，所以学习者应该尝试着去用它们，了解它们，而不是啥都要自己来实现。因为Python擅长的就是快速开发，而且站在前人的肩膀上，我们才能站得更高，看得更远。当然如果你想加深自己对某个方面的理解，也可以尝试去实现一些简单的模块。&lt;/li&gt;
&lt;li&gt;总之一句话：学习Python的关键就是用！而且是要多用别人的。动手实践才是王道！那么多优秀的开源函数库不要浪费了！&lt;/li&gt;&lt;/ol&gt;</description>
            <pubDate>2012-02-21</pubDate>
            <link>https://blog.xiayf.cn/posts/the-path-of-learning-python.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/the-path-of-learning-python.html</guid>
        </item>
        
        <item>
            <title>2011年终-回顾与展望</title>
            <description>&lt;p&gt;昨晚实验室聚餐，和师兄们喝醉了，明年的这个时候，我也就和他们一样将要毕业。时间，总是往前看觉得很漫长，可回过头去看看，一年也就是瞬间的事情。&lt;/p&gt;
&lt;p&gt;2011，我从研一走向研二，2012，我将从研二走向研三，继而毕业，工作。&lt;/p&gt;
&lt;p&gt;回顾过去一年，于我自己而言，过得很平淡，也许是大学以来最平淡的一年，只能说也许，因为对于2011，我记不得太多的事情。&lt;/p&gt;
&lt;p&gt;这一年里，我，一个技术男，比以前更宅，话也相对少了很多，直接表现为QQ空间或者校内上的文字写得很少。很少和别人谈论自己，因为我觉得纠结于那个“小我”是件很“小青年”的事情。人与人之间不可避免的隔膜导致了个人的事情不管多大在别人眼里都是微不足道的，在别人的心里掀不起半点波澜，说过了也就忘了。所以那些关于自己的，还是放在心里比较好，毋须说些没意义的。&lt;/p&gt;
&lt;p&gt;这一年里，我想得挺多，但真正做了或者说做好的却很少。这是件严重的事情。特别在技术上，东看西看，东学西学，眼界确实开阔很多，也养成了较为良好的技术趣味。但从技术能力上来说，真不好说，我都不知道自己有几斤几两。&lt;/p&gt;
&lt;p&gt;这一年里，最大的收获，也许是对“学习”的重新认识，以及试图从“学知识”向“做事情”转变(这里的“做事情”特指“解决实际问题”)，以前的自己太喜欢太沉迷于学东西，而忽略了自主地做事情。“生有涯，而知无涯”的无奈是必须面对的，对于有限的人生来说，知识必须对自己有用才值得学，特别是技术相关的知识，那怎么知道哪些知识对自己有用呢？得“边用边学”，需要用的时候再学。所以应多做事情，应找实际的问题，尝试去解决，在解决问题的过程中学习。解决实际问题才是根本，才是目的，而不是学习。学生时代习惯了学，习惯了边学边用，但对于研究生，对于以后的工作来说，光顾着学是没用的，而且一味的学也是非常难以深入的，要对某个方面有个深入的理解，必须通过做事情，发现问题，解决问题。&lt;/p&gt;
&lt;p&gt;这一转变过程让我非常纠结，而且到目前为止还算不上成功。可能对于很多人来说，这个过程可能很简单，但对于我来说，好奇心强，喜欢学东西的来说，确实极其艰难的。每做一件事情，都很可能陷入学习的状态，而不会及时地适可而止。&lt;/p&gt;
&lt;p&gt;这一过程希望在2012年有个很好的进展。&lt;/p&gt;
&lt;p&gt;这一年里，我逐步意识到自己存在的另一个大问题---不够自信，其外在表现为和别人一起时，极其容易将自己的观点让位于别人的观点，即使我并不认为自己的观点存在什么问题，或者别人的观点比我的更正确。我只是不想凌驾于别人之上，不想让自己影响到别人。这听起来似乎不关乎自信，但我想本质上是的。“不够自信”这看起来也似乎不是什么大问题，但我想对于一个成年人，特别是一个男人，自信是非常重要的，对于事业也是件非常重要的事情。以前自己活得太谨慎，不喜欢在公共场合表现自己，觉得提高自己的内在修为才是重要的。但其实活在社会中，适时适当地表现自己，表达自己的观点，坚持自己的看法是非常重要的。有个词叫“内圣外王”，以后我得更加注重“外王”，内外兼修。&lt;/p&gt;
&lt;p&gt;这一年里，我活得又很随性(和“活得谨慎”矛盾而共存)，不太注意自己的言行，脏话口头禅也比较多，虽然在我看来，我的脏话全是在表达一种情绪，仅此而已。但我想在别人来看，其感受也许并不是这样的。我们年轻人还是要注意自己的形象的，呵呵。另外，尽量少评论别人，特别是别人的缺点。&lt;/p&gt;
&lt;p&gt;这一年里，我很懒散，自己都有些看不过去了，“这样的日子，再好的，没有了”，我想不是件好事情。能够自我安慰点是还读了点书，整理一下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;社科文艺类&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;佛祖在一号线&lt;/li&gt;
&lt;li&gt;书虫小札&lt;/li&gt;
&lt;li&gt;复杂性思想导论&lt;/li&gt;
&lt;li&gt;人生&lt;/li&gt;
&lt;li&gt;给研究生的学术建议&lt;/li&gt;
&lt;li&gt;边城&lt;/li&gt;
&lt;li&gt;朱镕基答记者问&lt;/li&gt;
&lt;li&gt;窗里窗外&lt;/li&gt;
&lt;li&gt;联大八年&lt;/li&gt;
&lt;li&gt;笑谈大先生&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;技术类&lt;/strong&gt; (部分是按需选取章节阅读)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Shell脚本学习指南&lt;/li&gt;
&lt;li&gt;Linux内核设计与实现&lt;/li&gt;
&lt;li&gt;鸟哥的Linux私房菜&lt;/li&gt;
&lt;li&gt;PHP和MySQL Web开发（原书第3版）&lt;/li&gt;
&lt;li&gt;分布式处理实践&lt;/li&gt;
&lt;li&gt;Java Collections&lt;/li&gt;
&lt;li&gt;可爱的Python&lt;/li&gt;
&lt;li&gt;浪潮之巅&lt;/li&gt;
&lt;li&gt;CSS Web设计快速上手&lt;/li&gt;
&lt;li&gt;编程人生&lt;/li&gt;
&lt;li&gt;C陷阱与缺陷&lt;/li&gt;
&lt;li&gt;调试九法&lt;/li&gt;
&lt;li&gt;黑客与画家&lt;/li&gt;
&lt;li&gt;Python UNIX 和Linux 系统管理指南&lt;/li&gt;
&lt;li&gt;版本控制之道&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;比较而言，数量上不算少，也不算多，但主要问题还是质量上，觉得自己有些浑沦吞枣，读得太匆忙。这是以后的阅读需要注意的，克制焦躁的心理，慢慢阅读消化。&lt;/p&gt;
&lt;p&gt;新的一年，具体来说，我需要面对的几件大事情，大致包括:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;小论文&lt;/li&gt;
&lt;li&gt;实习&lt;/li&gt;
&lt;li&gt;毕业论文，包括答辩&lt;/li&gt;
&lt;li&gt;找工作&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;2012年底，我将要毕业了(虽然，形式上是2013年毕业)，我就要工作了，这也许是和高考相当的一件大事，希望自己能够举重若轻，踏实准备，顺利应对。(再具体点是不是应该说多多coding，多做事情！哈哈)&lt;/p&gt;</description>
            <pubDate>2012-01-01</pubDate>
            <link>https://blog.xiayf.cn/posts/2011-summary.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/2011-summary.html</guid>
        </item>
        
        <item>
            <title>Linux添加定时任务</title>
            <description>&lt;p&gt;在Linux下如果希望某个任务定时地执行，一般是使用cron服务器，将任务添加到cron任务列表中。&lt;/p&gt;
&lt;h4&gt;启动，关闭，重启cron(需超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;/etc/init.d/cron start
/etc/init.d/cron stop
/etc/init.d/cron restart&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注:archlinux下为/etc/rc.d/crond start|stop|restart&lt;/p&gt;
&lt;h4&gt;查看用户设置的定时任务列表&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab [-u xxx] -l       #  xxx为用户名&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;编辑用户的定时任务列表(超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab -u xxx -e&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;删除用户的定时任务列表(超级用户权限)&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;crontab -u xxx -r&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;定时任务的编辑规则&lt;/h4&gt;
&lt;p&gt;cron的定时任务由两部分组成：（1）设置的时间（2）该时间下要执行的任务命令。&lt;/p&gt;
&lt;p&gt;时间分5个部分，依次为：&lt;/p&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;minute              0-59
hour                0-23 
day of month        1-31
month               1-12
day of week         0-7 (0 or 7 is Sun, or use names)&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;示例（每天临晨2点备份数据库）&lt;/h4&gt;
&lt;pre class=&quot;language-text&quot;&gt;&lt;code&gt;0 2 * * * mysqldump -hhostname -uusername -ppassword databasename &amp;amp;gt; backupfile.sql&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;使设置生效&lt;/h4&gt;
&lt;p&gt;设置完成后，重启cron即可使设置的计划任务定时执行了&lt;/p&gt;
&lt;h3&gt;详细内容参考&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&apos;http://fanqiang.chinaunix.net/system/linux/2005-06-13/3306.shtml&apos;&gt;http://fanqiang.chinaunix.net/system/linux/2005-06-13/3306.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://fanqiang.chinaunix.net/adm/storage/2005-03-23/2985.shtml&apos;&gt;http://fanqiang.chinaunix.net/adm/storage/2005-03-23/2985.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&apos;http://now-code.com/archives/196&apos;&gt;http://now-code.com/archives/196&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
            <pubDate>2011-12-07</pubDate>
            <link>https://blog.xiayf.cn/posts/cron-usage.html</link>
            <guid isPermaLink="true">https://blog.xiayf.cn/posts/cron-usage.html</guid>
        </item>
        
    </channel>
</rss>